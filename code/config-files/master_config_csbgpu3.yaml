dataset_settings:

    # Base directory where datasets will be placed
    datasets_dir: "datasets"
    # list of mapping files, one per species. Will be placed in datasets/mapping/species/

    cell_lines: 'datasets/drug-comb-db/cell_line.csv'
    mappings:
      #### Mapping options:
      # *mapping_file*: path to file. Can be gzipped
      # *species*: the name of the species 
      # *url*: the url of the file to download
      # *file_type*: type of mapping file. Current can be: 
      #     'list': a list of mappings (i.e., many-to-many) where the first column is a uniprot ID, second is the namespace, and third is the ID of the other namespace
      #     'table': a table of 1-to-1 mappings.
      # *namespaces*: namespaces to keep from the file. If 'all' is given, then keep all of the mappings. If *file_type* is table, should be the column names. 
          - mapping_file: "HUMAN_9606_idmapping.dat.gz"
            species: "human"
            url: "ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/idmapping/by_organism/HUMAN_9606_idmapping.dat.gz"
            type: "list"
            #namespaces: ["all"]
            #namespaces: ["ensembl", "gene_name", "string", "biogrid", "pharmgkb", "geneid"]
            namespaces: ["geneid", "gene_name", "ensembl", "string", "pharmgkb"]

          - mapping_file: "uniprot-reviewed-status.tab.gz"
            species: "human"
            url: "https://www.uniprot.org/uniprot/?query=*&format=tab&force=true&columns=id,reviewed,genes,protein%20names,organism-id&fil=organism:9606&compress=yes"
            type: "table"
            namespaces: ["Status"]

    # Download and parse *gene_sets*, *networks*, *drug targets*, etc.
    datasets_to_download:
     

      #### Network options:
      # *name*: name of this network. Will be used as the directory
      # *file_name*: the name of the file to download
      # *network_collection*: T/F. Specifies if the downloaded file is an archive containing many networks
      # *collection_settings*: settings to apply to each of the individual networks.
      # *weighted*: T/F. If False, a column of all 1s (i.e., unweighted) will be added after the first two columns. 
      #     If True, the first column in *columns_to_keep* should be the weights
      # *unpack_command*: The command to run to unpackage the file/archive. (e.g., unzip, gzip, tar -xvf)
      # *namespace*: the namespace of the nodes in the networks
      # *url*: the url of the file to download
      # *taxon*: the NCBI taxonomy ID of the species to which this network belongs. Currently not used.
      # *species*: the name of the species (i.e., human, mouse). TODO should be used to line up with the mapping
      # *prefer_reviewed*: when mapping, if any of the alternate IDs map to a reviewed UniProt ID, keeping only that one. Otherwise keep all UniProt IDs
      # *gzip_files*: gzip the individual files
      # *remove_filename_spaces*: if there are spaces in the file names, remove them
      # *columns_to_keep*: a list of indexes of columns to keep in the new file. Should be >= 2 (first two columns should be the tail and head of the edge) 
      #     If not specified, all columns will be kept
      # *sep*: the delimiter of columns in the files
        networks:
          - name: "stringv11"
            file_name: "9606-uniprot-links-full-v11.txt.gz"
            # This flag indicates the downloaded file has all string channels (i.e., "full")
            string_networks: True
            network_collection: False
            weighted: True
            #unpack_command: "gunzip"
            namespace: "string"
            url: "https://stringdb-static.org/download/protein.links.full.v11.0/9606.protein.links.full.v11.0.txt.gz"
            taxon: 9606
            species: "human"
            mapping_settings:
              # if there are multiple mappings to UniProt IDs, use only the 'reviewed' one(s) 
              prefer_reviewed: True
            # keep all of the columns
            #columns_to_keep: []
            sep: " "
            
string_network_preparation_settings:
    string_cutoff: 700
    string_nets: "combined_score"
    weight_method: add
    string_net_files: "9606-uniprot-links-full-v11.txt.gz"
    string_dir: "datasets/networks/stringv11/"


ml_models_settings:
    algs:
      synverse:
        should_run: True
        encoder: [ 'local_v2' ]
        conv: [ 'GCN' ]
        hsize: [ [ 128, 64 ] ]
        decoder: [ 'nn' ]
        nn_hsize: [ [ 256,64 ] ]
        batch: [ 8000 ]
        lr: [ 0.001 ]
        e: [ 1000 ]
        dr: [ 0.4 ] # add dropout=0 later
        bias: [ True ]
        drugfeat: [ True ]
        patience: [ 30 ]


      synverse_nogenex:
        should_run: True
        encoder: [ 'local_v2' ]
        conv: [ 'GCN' ]
        hsize: [ [ 128, 64 ] ]
        decoder: [ 'nn_nogenex' ]
        nn_hsize: [ [ 256,64 ] ]
        batch: [ 8000 ]
        lr: [ 0.001 ]
        e: [ 1000 ]
        dr: [ 0.2 ] # add dropout=0 later
        bias: [ True ]
        drugfeat: [ True ]
        patience: [ 30 ]


      decagon:
        should_run: True
        encoder: [ 'local_v2' ]
        conv: [ 'GCN' ]
        hsize: [ [ 128, 64 ] ]
        decoder: [ 'dedicom' ]
        batch: [ 8000 ]
        lr: [ 0.001 ]
        e: [ 1000 ]
        dr: [ 0.4 ]
        bias: [ True ]
        drugfeat: [ True ]
        patience: [ 30 ]

      synverse_v4:
        should_run: True
        encoder: [ 'local_v2' ]
        conv: [ 'GAT' ]
        hsize: [ [ 128, 64 ] ]
        decoder: [ 'nn' ]
        nn_hsize: [ [ 256,64 ] ]
        batch: [ 8000 ]
        lr: [ 0.001 ]
        e: [ 1000 ]
        dr: [ 0.2 ] # add dropout=0 later
        bias: [ True ]
        drugfeat: [ True ]
        patience: [ 30 ]



      synverse_tissuenet:
        should_run: False
        encoder: [ 'local' ]
        conv: [ 'GCN' ]
        decoder: [ 'dedicom' ]
        gg_decoder: [ 'dedicom' ]
        hsize: [ [ 128, 64 ] ]
        batch: [ 16000 ]
        lr: [ 0.001 ]
        e: [ 1000 ]
        dr: [ 0.4 ] # add dropout=0 later
        bias: [ True ]
        drugfeat: [ True ]
        patience: [ 30 ]
#
#        synverse_v2:
#          should_run: False
#          conv: ['GCN']
#          encoder: ['local']
#          decoder: ['nn']
#          hsize: [ [ 128, 64 ] ]
#          nn_hsize: [ [ 256,64 ] ]
#          batch: [8000]
#          lr: [ 0.0001 ]
#          e: [1000]
#          dr: [ 0.4 ] # add dropout=0 later
#          bias: [True]
#          drugfeat: [ True ]
#          patience: [20]
#
#        synverse_v3:
#          should_run: False
#          conv:  ['GCN']
#          encoder: ['local']
#          decoder: ['dedicom']
#          hsize: [ [ 128, 64 ] ]
#          nn_hsize: [ [ 256,64 ] ]
#          batch: [8000]
#          lr: [ 0.001 ]
#          e: [1000]
#          dr: [ 0.2 ] # add dropout=0 later
#          bias: [True]
#          drugfeat: [ True ]
#          patience: [20]




      deepsynergy: #best model
        should_run: False
        layers: [ [ 2048, 2048,1 ] ]
        lr: [ 0.001 ]
        dr: [ [ 0.2, 0.4 ] ]
        norm: [ 'tanh_norm' ]
        batch: [2048]
        e: [10]
        act: ['relu']
        patience: [2]
        use_genex: [False, True]
        use_target: [False, True]
        use_maccs: [False, True]



      svm:
        should_run: False
        gamma: ['auto']
        c: [1, 5, 10, 100]
        kernel: ['linear', 'poly', 'rbf', 'sigmoid']
        use_genex: [True]
        use_target: [True]



      gbr:
        should_run: False
        learning_rate: [0.001, 0.0001, 0.1]
        max_depth : [2, 4, 10]
        n_estimators: [100, 1000, 50]
        use_genex: True
        use_target: True


      dtf:
        should_run: False
        nn_struct: [[1024, 1024, 512], [2048, 2048, 1024], [2048, 1024, 512], [2048, 2048, 2048],
        [ 1024, 1024, 1024 ], [ 2048, 2048 ], [ 1024, 1024 ], [ 512, 512 ], [ 2048, 2014 ], [ 1024, 512 ] ]
        learning_rate: [0.0001]
        norm: ['norm','tanh', 'tanh_norm']
        dr: [[0, 0], [0.2, 0.5]]

split:
    sampling: 'semi_random'
    neg_frac: 1
    val_frac: 0.1
    folds: 5

    #1. Leave drug combination out in all cell line (leave_comb) 2. Random Cross Validation (random)
    #                  3. Leave one-drug out (lod) 4.Leave one-cell line out(loc)
#        types: ['leave_comb', 'leave_drug', 'leave_cell_line', leave_comb_cell_line','test_rare_cell_lines', 'random']
    type: 'leave_comb'
runs: 3

synergy_data_settings:
    apply_range: False
    min: 50
    max: 50000 #maximum number of pairs present across all cell lines is less than 50,000. So, want to put no limit on maix pairs then put max_pairs= 50,000

    apply_threshold: False #should apply threshold to determine synergy?
    threshold: 0

    take_top: True #or should take some top k percent pairs as synergistic
    n_top_cell_lines: 20
    percent: 10

    n_rare_cell_lines: 10


genex_data_settings:
  reduce_dim: True


autoencoder_settings:
    epochs: 1000
    h_sizes_and_out: [[256],[512],[256,64],[2048, 512],[1024, 256],[4096, 1024, 256],[2048, 512, 128],[1024,256,64]]

machine_name: 'csbgpu_3'
project_dir: '/home/tasnina/Projects/SynVerse/'
inputs:
    ppi:
        # mat: /c"+str(string_cutoff)+"_combined_score_sparse_net.mat"
        # nodes: "inputs/networks/c"+str(string_cutoff)+"_combined_score_node_ids.txt"
        string: 'inputs/networks/stringv11/'
        tissuenet: 'inputs/networks/tissuenet/HPA-Protein/'
    mapping: "/inputs/mappings/human/cell_line_to_tissue_mapping.tsv"

    drug:
        target: "inputs/drugs/drug_target_map.tsv"
        maccs_keys : "inputs/drugs/single_drugs_maccskeys_features.tsv"
        maccs_keys_targets: "inputs/drugs/single_drugs_maccskeys_target_features.tsv"
    cell_lines:
        Z_SCORE: "inputs/cell_lines/cell_lines_expression_Z_SCORE.tsv"
        REGULATION:  "inputs/cell_lines/cell_lines_expression_REGULATION.tsv"
        compressed_gene_expression: "inputs/cell_lines/models_07_13_can_use/compressed_gene_expression_manual.tsv"
        uncompressed_gene_expression: "inputs/cell_lines/models_07_13_can_use/uncompressed_gene_expression.tsv"
    synergy_dir: "inputs/synergy/"

    synergy: "inputs/synergy/synergy_labels.tsv"

output_dir:
  split: "outputs/split/"
  result: "outputs/result/"
  viz :  "outputs/viz/"

