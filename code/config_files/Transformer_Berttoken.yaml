# Input Settings: initialize base input folder names,
# dataset collections, and models to run
input_settings:
  score_name: 'S_mean_mean'
  # Base input directory
  input_dir: "inputs/"
  input_files:
    synergy_file: 'synergy/synergy_scores_S_mean_mean.tsv' #file containing triplets with S_mean_mean score for triplets in DrugComb.
    maccs_file: 'drug/MACCS.tsv'
    mfp_file: 'drug/Morgan_fingerprint.tsv'
    ecfp_file: 'drug/ECFP_4.tsv'
    smiles_file: 'drug/smiles.tsv'
    mol_graph_file: 'drug/molecular_graph.pickle'
    target_file: 'drug/target.tsv'
    genex_file: 'cell-line/gene_expression.tsv'
    lincs: 'cell-line/LINCS_1000.txt'
    vocab_file: 'drug/vocab_bpe_300_new.txt'
    net_file: 'network/STRING/9606.protein.links.v12.0.txt.gz'
    prot_info_file: 'network/STRING/9606.protein.info.v12.0.txt.gz'

  drug_features:
    - name: 'MACCS'
      use: [  false ]

    - name: 'ECFP_4'
      use: [   false  ]

    - name: 'MFP' #morgan fingerprint
      use: [  false  ]

    - name: 'mol_graph'
      encoder: 'GCN'
      use: [   false  ]

    - name: 'smiles'
      encoder: 'Transformer_Berttokenizer'
      use: [  true  ]

    - name: 'd1hot'
      use: [  false  ]


  cell_line_features:
    - name: 'c1hot'
      use: [true]

  model_info:
     decoder:
       name: 'MLP'
       hp_range: { 'lr': [ 1e-5, 1e-3 ], 'optimizer': [ 'Adam', 'SGD' ],
                   'sgd_momentum': [ 0.5, 0.99 ] ,
                   'num_hid_layers': [ 1,3 ] ,
                   'hid_0': [ 128, 256, 512, 1024, 2048, 4096 ],
                   'hid_1': [ 128, 256, 512, 1024, 2048, 4096 ],
                   'hid_2': [ 128, 256, 512, 1024, 2048, 4096 ],
                   'in_dropout_rate': [ 0.0, 0.5 ],
                   'hid_dropout_rate': [ 0.0, 0.5 ] }

       hp: {'hid_0': 2048, 'hid_1': 1024,'hid_2': 512, 'hid_dropout_rate': 0.3, 'in_dropout_rate': 0.1,
            'lr': 0.0001, 'num_hid_layers': 3, 'optimizer': 'Adam'}

     drug_encoder:
       - name: 'GCN'
         hp_range: { 'batch_norm': [ True, False ], 'gnn_num_layers': [ 1, 3 ], 'gnn_0': [ 256, 512, 1024, 2048, 4096 ] ,'gnn_1': [ 256, 512, 1024, 2048, 4096 ],
                     'gnn_2': [  256, 512, 1024, 2048, 4096 ],
                     'ff_num_layers': [ 1,3 ], 'ff_0': [ 256, 512, 1024, 2048, 4096 ] , 'ff_1': [ 256, 512, 1024, 2048, 4096 ] , 'ff_2': [ 256, 512, 1024, 2048, 4096 ],
                     'gnn_dropout': [ 0.0,0.5 ] }
         hp: { 'batch_norm': True, 'gnn_num_layers': 2 ,'gnn_0': 512 ,'gnn_1': 128, 'ff_num_layers': 1, 'ff_0': 128, 'gnn_dropout': 0.1 }

       - name: 'Transformer'
         hp_range: { 'transformer_batch_norm': [ True, False ], 'transformer_num_layers': [ 2, 3, 4 ] ,'transformer_embedding_dim': [ 64, 128, 256, 512, 1024, 2048 ] ,
                     'transformer_n_head': [ 4, 8 ], 'transformer_ff_num_layers': [ 64, 128, 256, 512, 1024, 2048 ], 'max_seq_length': [ 120 ],
                     'positional_encoding_type': [ 'learnable', 'fixed' ] }
         hp: {'positional_encoding_type': 'learnable', 'transformer_batch_norm': True, 'transformer_embedding_dim': 512,
                  'transformer_ff_num_layers': 1024, 'transformer_n_head': 8, 'transformer_num_layers': 3,'max_seq_length': 120}

       - name: 'Transformer_Berttokenizer'
         hp_range: { 'transformer_batch_norm': [ True, False ], 'transformer_num_layers': [ 2, 3, 4 ] ,'transformer_embedding_dim': [ 64, 128, 256, 512, 1024, 2048 ] ,
                     'transformer_n_head': [ 4, 8 ], 'transformer_ff_num_layers': [ 64, 128, 256, 512, 1024, 2048 ], 'max_seq_length': [ 120 ],
                     'positional_encoding_type': [ 'learnable', 'fixed' ] }
         hp: { 'hid_0': 1024, 'hid_dropout_rate': 0.05282017248732984, 'in_dropout_rate': 0.45595097943491075, 'lr': 0.0002569150545438125, 'max_seq_length': 120, 'num_hid_layers': 2, 'optimizer': 'Adam', 'positional_encoding_type': 'learnable', 'transformer_batch_norm': True, 'transformer_embedding_dim': 64,
               'transformer_ff_num_layers': 64, 'transformer_n_head': 4, 'transformer_num_layers': 4, 'hid_1': 128 }

  autoencoder_dims:  [[1024, 512], [512, 256], [256, 128], [256, 64]]
  batch_size: 4096
  epochs: 1500


  splits:
    - type: 'random'
      test_frac: 0.2
      val_frac: 0.25

    - type: 'leave_comb'
      test_frac: 0.2
      val_frac: 0.25

    - type: 'leave_drug'
      test_frac: 0.2
      val_frac: 0.25

    - type: 'leave_cell_line'
      test_frac: 0.2
      val_frac: 0.25

  wandb:
    enabled: False
    entity_name: 'ntasnina'
    token: 'd9462b91edea6523563900fab17134d7e9177e16'
    project_name: 'Synverse'
    timezone: 'US/Eastern'
    timezone_format: '%Y-%m-%d_%H-%M-%S'

  abundance: 0.05

  max_drug_feat: 1
  min_drug_feat: 1
  max_cell_feat: 1
  min_cell_feat: 1

  hp_tune: True
  bohb:
    min_budget: 27
    max_budget: 729
    n_iterations: 3
    run_id : 'synverse'
    server_type: 'local' #or cluster

  rewire_method: [  "SA", "SM" ]
output_settings:
  output_dir: 'outputs/'