/home/tasnina/Projects/SynVerse/code/main.py:1: DeprecationWarning: 
Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),
(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)
but was not found to be installed on your system.
If this would cause problems for you,
please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466
        
  import pandas as pd
SYNVERSE STARTING
Before filtering: 
#of triplets : 556893,
#drugs 3966, 
#cell lines 263
keeping top 6 cell lines, retrieved frac:0.15432946724056507
After filtering: 
#of triplets : 85945,
#drugs 439, 
#cell lines 6
TEST #triplets: 4524 
 #drugs: 87 
 #cell lines: 6
fold 0 # TRAIN triplets:  32261
fold 0 # VAL triplets:  2330
fold 1 # TRAIN triplets:  34273
fold 1 # VAL triplets:  1766
fold 2 # TRAIN triplets:  33218
fold 2 # VAL triplets:  2000
fold 3 # TRAIN triplets:  32141
fold 3 # VAL triplets:  2401
fold 4 # TRAIN triplets:  34190
fold 4 # VAL triplets:  1868
ran till model part
SPLIT:  leave_drug
DEBUG:hpbandster:wait_for_workers trying to get the condition
INFO:hpbandster:DISPATCHER: started the 'discover_worker' thread
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x1554727b0580; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:9090>
INFO:hpbandster:DISPATCHER: started the 'job_runner' thread
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: No dispatcher found. Waiting for one to initiate contact.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start listening for jobs
INFO:hpbandster:DISPATCHER: Pyro daemon running on localhost:35041
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 0 currently in the pool.
INFO:hpbandster:DISPATCHER: discovered new worker, hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:HBMASTER: number of workers changed to 1
DEBUG:hpbandster:Enough workers to start this run!
INFO:hpbandster:HBMASTER: starting run at 1717028294.7443745
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:adjust_queue_size: lock accquired
INFO:hpbandster:HBMASTER: adjusted queue size to (0, 1)
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 0) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 0) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 0)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 0) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 0) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 0)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 74, 'ff_num_layers': 2, 'gnn_0': 277, 'gnn_dropout': 0.28306983815768805, 'gnn_num_layers': 1, 'hid_0': 211, 'hid_dropout_rate': 0.4737949515335218, 'in_dropout_rate': 0.03350232936963732, 'lr': 0.0005233495884624044, 'num_hid_layers': 2, 'optimizer': 'SGD', 'ff_1': 70, 'hid_1': 1486, 'sgd_momentum': 0.46384949415816806}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
/home/tasnina/.conda/envs/synergy/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found
  warnings.warn(message)
e:  0   train_loss:  701.3154261218164   time:  1.675722360610962
e:  0   train_loss:  701.3154261218164   val_loss:  1651.8091464781917   time:  1.751100778579712
e:  1   train_loss:  675.1245291501432   time:  0.9850552082061768
e:  2   train_loss:  608.7075241988133   time:  1.0734508037567139
e:  3   train_loss:  580.0308709815614   time:  1.202202320098877
e:  4   train_loss:  557.7092624666744   time:  1.2352657318115234
e:  5   train_loss:  538.5826900961135   time:  1.220299243927002
e:  5   train_loss:  538.5826900961135   val_loss:  1329.4004163895572   time:  1.32728910446167
e:  6   train_loss:  511.7452361091826   time:  1.368858814239502
e:  7   train_loss:  493.89407829652106   time:  1.2571744918823242
e:  8   train_loss:  491.6929229164092   time:  1.328155517578125
e:  9   train_loss:  474.40784471182644   time:  1.2258951663970947
e:  10   train_loss:  478.13962375552694   time:  1.2292425632476807
e:  10   train_loss:  478.13962375552694   val_loss:  1426.7218987960382   time:  1.34775972366333
e:  11   train_loss:  477.3140566164396   time:  1.2356603145599365
e:  12   train_loss:  469.0492145490729   time:  1.2364554405212402
e:  13   train_loss:  481.8748407298634   time:  1.2335026264190674
e:  14   train_loss:  462.75571793027814   time:  1.2515127658843994
e:  15   train_loss:  462.5308639017205   time:  1.2712252140045166
e:  15   train_loss:  462.5308639017205   val_loss:  1340.9600916340871   time:  1.378781795501709
e:  16   train_loss:  459.28819614768076   time:  1.2441632747650146
e:  17   train_loss:  445.8655025878208   time:  1.3550586700439453
e:  18   train_loss:  458.8722569806394   time:  1.2214412689208984
e:  19   train_loss:  445.31423396813767   time:  1.2249162197113037
e:  20   train_loss:  450.06543823607535   time:  1.2235863208770752
e:  20   train_loss:  450.06543823607535   val_loss:  1548.881095261201   time:  1.330176591873169
e:  21   train_loss:  447.67749233266215   time:  1.2380938529968262
e:  22   train_loss:  446.76301964297875   time:  1.2467968463897705
e:  23   train_loss:  446.80814037247393   time:  1.2460355758666992
e:  24   train_loss:  445.79283689302156   time:  1.2375941276550293
e:  25   train_loss:  443.7481319858718   time:  1.24324631690979
e:  25   train_loss:  443.7481319858718   val_loss:  1540.520697420331   time:  1.3498313426971436
e:  26   train_loss:  448.42244597338   time:  1.237424612045288
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1064.4175155133462   time:  1.3633673191070557
e:  0   train_loss:  1064.4175155133462   val_loss:  607.2004036524376   time:  1.6170849800109863
e:  1   train_loss:  986.7924819804963   time:  1.353407621383667
e:  2   train_loss:  827.112351515717   time:  1.352694034576416
e:  3   train_loss:  726.7513691894343   time:  1.3456673622131348
e:  4   train_loss:  676.3148310328359   time:  1.347475528717041
e:  5   train_loss:  662.6185211317193   time:  1.3384275436401367
e:  5   train_loss:  662.6185211317193   val_loss:  548.2428739470848   time:  1.4392032623291016
e:  6   train_loss:  631.3421454790571   time:  1.4882733821868896
e:  7   train_loss:  644.7571772278864   time:  1.3518662452697754
e:  8   train_loss:  628.387773270865   time:  1.3522613048553467
e:  9   train_loss:  627.5810844732482   time:  1.3508837223052979
e:  10   train_loss:  617.7557370449242   time:  1.3444130420684814
e:  10   train_loss:  617.7557370449242   val_loss:  1117.9800230301018   time:  1.4461004734039307
e:  11   train_loss:  609.9623296180195   time:  1.3681533336639404
e:  12   train_loss:  608.747145836638   time:  1.4045307636260986
e:  13   train_loss:  618.6050266768212   time:  1.4483840465545654
e:  14   train_loss:  627.2922096618482   time:  1.3469290733337402
e:  15   train_loss:  632.2085326329473   time:  1.3721215724945068
e:  15   train_loss:  632.2085326329473   val_loss:  855.7678593245222   time:  1.4725914001464844
e:  16   train_loss:  613.578509657278   time:  1.3546955585479736
e:  17   train_loss:  608.9867084121181   time:  1.3554267883300781
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  18   train_loss:  600.9562179215102   time:  1.3595550060272217
e:  19   train_loss:  595.106445356137   time:  1.347975730895996
e:  20   train_loss:  603.057230860794   time:  1.5186374187469482
e:  20   train_loss:  603.057230860794   val_loss:  1069.0000573214766   time:  1.6198654174804688
e:  21   train_loss:  597.8828815184712   time:  1.357168197631836
e:  22   train_loss:  596.8418489928666   time:  1.3584370613098145
e:  23   train_loss:  612.3632776646718   time:  1.3862051963806152
e:  24   train_loss:  591.3528316944985   time:  1.3735148906707764
e:  25   train_loss:  591.5867800781314   time:  1.3610589504241943
e:  25   train_loss:  591.5867800781314   val_loss:  1499.46361135354   time:  1.4628570079803467
e:  26   train_loss:  595.3878812941825   time:  1.500342845916748
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1063.6555456486922   time:  1.3434038162231445
e:  0   train_loss:  1063.6555456486922   val_loss:  521.8689951247775   time:  1.4468510150909424
e:  1   train_loss:  953.2680186635051   time:  1.342496395111084
e:  2   train_loss:  795.7938648370421   time:  1.3450324535369873
e:  3   train_loss:  708.351221504638   time:  1.3425657749176025
e:  4   train_loss:  732.3443435919594   time:  1.3420231342315674
e:  5   train_loss:  655.3312462011886   time:  1.3409018516540527
e:  5   train_loss:  655.3312462011886   val_loss:  6089.219279249979   time:  1.444232702255249
e:  6   train_loss:  678.9612126572138   time:  1.4668970108032227
e:  7   train_loss:  649.8377226991859   time:  1.3498311042785645
e:  8   train_loss:  655.413690985612   time:  1.3301079273223877
e:  9   train_loss:  641.8633072252966   time:  1.3474986553192139
e:  10   train_loss:  642.4805597651103   time:  1.3426845073699951
e:  10   train_loss:  642.4805597651103   val_loss:  468.6804435914751   time:  1.4460704326629639
e:  11   train_loss:  658.4350340186406   time:  1.3411505222320557
e:  12   train_loss:  639.724758388833   time:  1.3395109176635742
e:  13   train_loss:  623.6378933460924   time:  1.3294093608856201
e:  14   train_loss:  700.85426524042   time:  1.4619812965393066
e:  15   train_loss:  672.8630560835999   time:  1.3410561084747314
e:  15   train_loss:  672.8630560835999   val_loss:  551.7241218791117   time:  1.4448528289794922
e:  16   train_loss:  608.1800211039402   time:  1.3425087928771973
e:  17   train_loss:  633.4564041562985   time:  1.3420073986053467
e:  18   train_loss:  625.1534163759815   time:  1.340700626373291
e:  19   train_loss:  628.9611089403968   time:  1.3373637199401855
e:  20   train_loss:  611.6094440356885   time:  1.4519991874694824
e:  20   train_loss:  611.6094440356885   val_loss:  917.3280436603497   time:  1.5552978515625
e:  21   train_loss:  618.9446489390289   time:  1.340890645980835
e:  22   train_loss:  626.3439091304804   time:  1.3387947082519531
e:  23   train_loss:  624.1036603300112   time:  1.3448972702026367
e:  24   train_loss:  636.4984737921737   time:  1.340092420578003
e:  25   train_loss:  605.2661491127   time:  1.3413889408111572
e:  25   train_loss:  605.2661491127   val_loss:  506.21567744435026   time:  1.444105625152588
e:  26   train_loss:  638.4686627749564   time:  1.3409686088562012
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  995.9427973677875   time:  1.2432031631469727
e:  0   train_loss:  995.9427973677875   val_loss:  893.6878121572972   time:  1.3518686294555664
e:  1   train_loss:  933.5590943924506   time:  1.3638348579406738
e:  2   train_loss:  792.4745884168815   time:  1.2189741134643555
e:  3   train_loss:  673.7166777228919   time:  1.2291769981384277
e:  4   train_loss:  660.521137486578   time:  1.2356367111206055
e:  5   train_loss:  651.859353547746   time:  1.2391555309295654
e:  5   train_loss:  651.859353547746   val_loss:  807.5602767122997   time:  1.347795009613037
e:  6   train_loss:  621.3159459596756   time:  1.2407302856445312
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  7   train_loss:  612.7485490683534   time:  1.2463390827178955
e:  8   train_loss:  608.806437360609   time:  1.2419164180755615
e:  9   train_loss:  582.3080709474797   time:  1.2428858280181885
e:  10   train_loss:  587.6319652760428   time:  1.2631499767303467
e:  10   train_loss:  587.6319652760428   val_loss:  933.425485309588   time:  1.5157930850982666
e:  11   train_loss:  617.5820390527109   time:  1.4031012058258057
e:  12   train_loss:  577.3406485669733   time:  1.4515092372894287
e:  13   train_loss:  579.8927893445622   time:  1.3324854373931885
e:  14   train_loss:  570.7957999406706   time:  1.3564808368682861
e:  15   train_loss:  582.8943082361792   time:  1.350147008895874
e:  15   train_loss:  582.8943082361792   val_loss:  797.5690531812464   time:  1.457637071609497
e:  16   train_loss:  572.9780606811643   time:  1.353980302810669
e:  17   train_loss:  572.9762949284949   time:  1.3539059162139893
e:  18   train_loss:  570.9484754302422   time:  1.3200609683990479
e:  19   train_loss:  561.0554155807203   time:  1.3324322700500488
e:  20   train_loss:  570.1437322522252   time:  1.3335402011871338
e:  20   train_loss:  570.1437322522252   val_loss:  970.5902884395084   time:  1.4412345886230469
e:  21   train_loss:  586.4416543098426   time:  1.2678523063659668
e:  22   train_loss:  570.1708281504539   time:  1.2491514682769775
e:  23   train_loss:  565.6956640083152   time:  1.361628532409668
e:  24   train_loss:  562.8732114632609   time:  1.2314128875732422
e:  25   train_loss:  562.4486124940918   time:  1.2234182357788086
e:  25   train_loss:  562.4486124940918   val_loss:  761.4507283435022   time:  1.3312041759490967
e:  26   train_loss:  563.0025472262564   time:  1.2376224994659424
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1073.1373685408935   time:  1.3545303344726562
e:  0   train_loss:  1073.1373685408935   val_loss:  666.4273828138389   time:  1.4574294090270996
e:  1   train_loss:  973.0311394848383   time:  1.3524658679962158
e:  2   train_loss:  799.7835886837141   time:  1.3558149337768555
e:  3   train_loss:  728.3024174665833   time:  1.4897973537445068
e:  4   train_loss:  682.6860141274307   time:  1.3875937461853027
e:  5   train_loss:  671.1163260605589   time:  1.3434052467346191
e:  5   train_loss:  671.1163260605589   val_loss:  865.0575308264507   time:  1.4456536769866943
e:  6   train_loss:  655.6180559830509   time:  1.353550910949707
e:  7   train_loss:  637.3072360931351   time:  1.3538427352905273
e:  8   train_loss:  626.3019499806894   time:  1.3547091484069824
e:  9   train_loss:  625.1192831195368   time:  1.3557701110839844
e:  10   train_loss:  633.5752420842766   time:  1.488999366760254
e:  10   train_loss:  633.5752420842766   val_loss:  573.304421031221   time:  1.5909514427185059
e:  11   train_loss:  634.0637801808112   time:  1.3459529876708984
e:  12   train_loss:  626.7180640773122   time:  1.354452133178711
e:  13   train_loss:  613.8366511467499   time:  1.342132329940796
e:  14   train_loss:  622.8615081458943   time:  1.3603835105895996
e:  15   train_loss:  608.0067231214651   time:  1.388037919998169
e:  15   train_loss:  608.0067231214651   val_loss:  652.4586234492748   time:  1.4897446632385254
e:  16   train_loss:  615.9281827655751   time:  1.3607404232025146
e:  17   train_loss:  608.0868163695959   time:  1.521894931793213
e:  18   train_loss:  606.9254127230741   time:  1.3491427898406982
e:  19   train_loss:  613.7793824213005   time:  1.33888840675354
e:  20   train_loss:  602.9426011990707   time:  1.3385238647460938
e:  20   train_loss:  602.9426011990707   val_loss:  750.3368881914126   time:  1.4406452178955078
e:  21   train_loss:  606.6563843326571   time:  1.3504977226257324
e:  22   train_loss:  617.6667221843676   time:  1.3437821865081787
e:  23   train_loss:  620.3154146687937   time:  1.479349136352539
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  24   train_loss:  612.1511043276535   time:  1.3441829681396484
e:  25   train_loss:  616.697073105101   time:  1.3499515056610107
e:  25   train_loss:  616.697073105101   val_loss:  1111.2032805095707   time:  1.4535672664642334
e:  26   train_loss:  600.0404156474563   time:  1.3850548267364502
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 0), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 0) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 0) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 0) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 0)
kwargs: {'config': {'batch_norm': True, 'ff_0': 74, 'ff_num_layers': 2, 'gnn_0': 277, 'gnn_dropout': 0.28306983815768805, 'gnn_num_layers': 1, 'hid_0': 211, 'hid_dropout_rate': 0.4737949515335218, 'in_dropout_rate': 0.03350232936963732, 'lr': 0.0005233495884624044, 'num_hid_layers': 2, 'optimizer': 'SGD', 'ff_1': 70, 'hid_1': 1486, 'sgd_momentum': 0.46384949415816806}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 736.215776660568, 'n_epochs': 27.0, 'info': {'validation loss': 736.215776660568}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 0) started
DEBUG:hpbandster:job_callback for (0, 0, 0) got condition
DEBUG:hpbandster:Only 1 run(s) for budget 27.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 0) finished
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 1) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 1) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 1)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 1) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 1) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 1)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 100, 'ff_num_layers': 1, 'gnn_0': 328, 'gnn_dropout': 0.18922446459404368, 'gnn_num_layers': 2, 'hid_0': 785, 'hid_dropout_rate': 0.2708897224252819, 'in_dropout_rate': 0.3710342355439332, 'lr': 0.00011939153447737812, 'num_hid_layers': 1, 'optimizer': 'SGD', 'gnn_1': 228, 'sgd_momentum': 0.7051705200345821}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  703.5146373362835   time:  1.4728498458862305
e:  0   train_loss:  703.5146373362835   val_loss:  1663.2099106152357   time:  1.586120843887329
e:  1   train_loss:  692.6397815992941   time:  1.4841766357421875
e:  2   train_loss:  676.4540448627916   time:  1.7220666408538818
e:  3   train_loss:  650.7391261464509   time:  1.5265681743621826
e:  4   train_loss:  620.8721940101424   time:  1.5009198188781738
e:  5   train_loss:  597.8299306254078   time:  1.4817728996276855
e:  5   train_loss:  597.8299306254078   val_loss:  1429.3076055498807   time:  1.5958304405212402
e:  6   train_loss:  586.3950466179366   time:  1.479173183441162
e:  7   train_loss:  577.9917354944785   time:  1.4513089656829834
e:  8   train_loss:  567.8936390748291   time:  1.4518945217132568
e:  9   train_loss:  554.3146615586976   time:  1.6466915607452393
e:  10   train_loss:  539.6662913918706   time:  1.4108998775482178
e:  10   train_loss:  539.6662913918706   val_loss:  1386.828365828939   time:  1.522705316543579
e:  11   train_loss:  523.5908616138802   time:  1.3671231269836426
e:  12   train_loss:  509.23403078133293   time:  1.3834755420684814
e:  13   train_loss:  495.25571012854755   time:  1.471040964126587
e:  14   train_loss:  486.6125178911742   time:  1.4742863178253174
e:  15   train_loss:  477.5336498647523   time:  1.3667187690734863
e:  15   train_loss:  477.5336498647523   val_loss:  1327.1552842612234   time:  1.478320837020874
e:  16   train_loss:  477.59829370280323   time:  1.372896432876587
e:  17   train_loss:  473.72077697856287   time:  1.3709404468536377
e:  18   train_loss:  459.83231873300525   time:  1.368196964263916
e:  19   train_loss:  457.83549124434165   time:  1.3634724617004395
e:  20   train_loss:  461.1416971340748   time:  1.3689591884613037
e:  20   train_loss:  461.1416971340748   val_loss:  1508.8350770796565   time:  1.479403018951416
e:  21   train_loss:  450.0342308930952   time:  1.36956787109375
e:  22   train_loss:  452.79933271921186   time:  1.3693087100982666
e:  23   train_loss:  444.06385594031923   time:  1.367955207824707
e:  24   train_loss:  448.4056631799194   time:  1.370067834854126
e:  25   train_loss:  444.03641182822315   time:  1.4888172149658203
e:  25   train_loss:  444.03641182822315   val_loss:  1376.2470507972896   time:  1.5920491218566895
e:  26   train_loss:  446.83459896417946   time:  1.3627512454986572
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1078.2218500518409   time:  1.4955196380615234
e:  0   train_loss:  1078.2218500518409   val_loss:  619.6075079682146   time:  1.601231575012207
e:  1   train_loss:  1041.4863585864932   time:  1.4953017234802246
e:  2   train_loss:  1008.8627691063741   time:  1.4942123889923096
e:  3   train_loss:  926.029675559796   time:  1.4937784671783447
e:  4   train_loss:  868.0701490351252   time:  1.4932007789611816
e:  5   train_loss:  796.4851408013934   time:  1.6084206104278564
e:  5   train_loss:  796.4851408013934   val_loss:  548.8805375767491   time:  1.713024377822876
e:  6   train_loss:  727.8463791746615   time:  1.4677743911743164
e:  7   train_loss:  679.735029472066   time:  1.4633257389068604
e:  8   train_loss:  659.3893876340757   time:  1.4959230422973633
e:  9   train_loss:  642.1343378319564   time:  1.4881110191345215
e:  10   train_loss:  630.4782938991553   time:  1.4965107440948486
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  10   train_loss:  630.4782938991553   val_loss:  740.2048572533599   time:  1.6082160472869873
e:  11   train_loss:  619.1180360995821   time:  1.900893211364746
e:  12   train_loss:  613.4342565330325   time:  1.5270581245422363
e:  13   train_loss:  613.5223807098605   time:  1.4943745136260986
e:  14   train_loss:  607.0043052800587   time:  1.495762586593628
e:  15   train_loss:  596.8446521151883   time:  1.5826780796051025
e:  15   train_loss:  596.8446521151883   val_loss:  599.6993373308603   time:  1.6882452964782715
e:  16   train_loss:  603.2452580483425   time:  1.4937834739685059
e:  17   train_loss:  598.3039374688424   time:  1.490483045578003
e:  18   train_loss:  588.6872917264028   time:  1.6033987998962402
e:  19   train_loss:  580.2200904527587   time:  1.4944441318511963
e:  20   train_loss:  587.7822047003666   time:  1.4943556785583496
e:  20   train_loss:  587.7822047003666   val_loss:  1172.062124326448   time:  1.5989394187927246
e:  21   train_loss:  596.5509241228264   time:  1.4935338497161865
e:  22   train_loss:  605.4218630851462   time:  1.493746280670166
e:  23   train_loss:  591.4335192165878   time:  1.4908649921417236
e:  24   train_loss:  586.743477680791   time:  1.485517978668213
e:  25   train_loss:  583.5061017421906   time:  1.6242294311523438
e:  25   train_loss:  583.5061017421906   val_loss:  612.8094892873695   time:  1.7279939651489258
e:  26   train_loss:  588.483471374623   time:  1.4563493728637695
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1098.2437726749658   time:  1.4970366954803467
e:  0   train_loss:  1098.2437726749658   val_loss:  532.3715711167199   time:  1.6051416397094727
e:  1   train_loss:  1085.7091471688168   time:  1.4868974685668945
e:  2   train_loss:  986.9422512025182   time:  1.4777798652648926
e:  3   train_loss:  939.865194104174   time:  1.476830005645752
e:  4   train_loss:  885.5722874017766   time:  1.4746363162994385
e:  5   train_loss:  778.8193112082986   time:  1.494250774383545
e:  5   train_loss:  778.8193112082986   val_loss:  498.9903342158549   time:  1.7313852310180664
e:  6   train_loss:  729.2126028685408   time:  1.4736428260803223
e:  7   train_loss:  702.6994005192823   time:  1.4765889644622803
e:  8   train_loss:  694.9746123435484   time:  1.4701659679412842
e:  9   train_loss:  645.5190786104819   time:  1.4750993251800537
e:  10   train_loss:  658.2323149991001   time:  1.4763867855072021
e:  10   train_loss:  658.2323149991001   val_loss:  527.0621210456335   time:  1.5839040279388428
e:  11   train_loss:  652.8804336746779   time:  1.4783918857574463
e:  12   train_loss:  643.4368780831284   time:  1.474151611328125
e:  13   train_loss:  621.6836128426102   time:  1.609635353088379
e:  14   train_loss:  639.0972975905648   time:  1.4697816371917725
e:  15   train_loss:  623.6842703584177   time:  1.473449945449829
e:  15   train_loss:  623.6842703584177   val_loss:  746.355010686991   time:  1.5802898406982422
e:  16   train_loss:  629.5393880980826   time:  1.4710252285003662
e:  17   train_loss:  637.1173368353574   time:  1.4746501445770264
e:  18   train_loss:  644.2846592842319   time:  1.44633150100708
e:  19   train_loss:  644.0446377879276   time:  1.4669458866119385
e:  20   train_loss:  603.0193002906921   time:  1.6084117889404297
e:  20   train_loss:  603.0193002906921   val_loss:  544.0858312601933   time:  1.716848373413086
e:  21   train_loss:  619.2218984335975   time:  1.4759962558746338
e:  22   train_loss:  611.5318945765749   time:  1.472447156906128
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  23   train_loss:  607.6529442483409   time:  1.6059815883636475
e:  24   train_loss:  616.2234614704116   time:  1.557784080505371
e:  25   train_loss:  605.8783770077985   time:  1.5907785892486572
e:  25   train_loss:  605.8783770077985   val_loss:  523.807472913625   time:  1.6990718841552734
e:  26   train_loss:  650.0381341397394   time:  1.8163013458251953
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  994.2004094531419   time:  1.4654300212860107
e:  0   train_loss:  994.2004094531419   val_loss:  907.1603414856027   time:  1.581022024154663
e:  1   train_loss:  979.112713171287   time:  1.375260829925537
e:  2   train_loss:  945.0704964619756   time:  1.3662035465240479
e:  3   train_loss:  887.0577477105763   time:  1.3677153587341309
e:  4   train_loss:  813.78512168264   time:  1.3705012798309326
e:  5   train_loss:  753.1139659800341   time:  1.370760202407837
e:  5   train_loss:  753.1139659800341   val_loss:  741.8357876255883   time:  1.483518362045288
e:  6   train_loss:  700.5215479790284   time:  1.3711247444152832
e:  7   train_loss:  670.5189260655106   time:  1.3715221881866455
e:  8   train_loss:  647.2936124036671   time:  1.3684003353118896
e:  9   train_loss:  621.5102347790944   time:  1.3667075634002686
e:  10   train_loss:  608.4781113307022   time:  1.3676824569702148
e:  10   train_loss:  608.4781113307022   val_loss:  817.1814848599065   time:  1.6027405261993408
e:  11   train_loss:  610.1499946240397   time:  1.3485043048858643
e:  12   train_loss:  598.9398928255216   time:  1.3387043476104736
e:  13   train_loss:  581.7192727204422   time:  1.3663136959075928
e:  14   train_loss:  581.6903901431032   time:  1.3661000728607178
e:  15   train_loss:  581.8867988067418   time:  1.3666861057281494
e:  15   train_loss:  581.8867988067418   val_loss:  1214.8623456514574   time:  1.4789795875549316
e:  16   train_loss:  573.3010361239519   time:  1.3692066669464111
e:  17   train_loss:  563.2052794318389   time:  1.3606719970703125
e:  18   train_loss:  584.7733154312019   time:  1.3694088459014893
e:  19   train_loss:  576.3912679549373   time:  1.365319013595581
e:  20   train_loss:  564.5090232373782   time:  1.4920063018798828
e:  20   train_loss:  564.5090232373782   val_loss:  758.2409521110292   time:  1.6050653457641602
e:  21   train_loss:  558.6478194968971   time:  1.366713285446167
e:  22   train_loss:  560.8330963223232   time:  1.3711421489715576
e:  23   train_loss:  562.6333194291476   time:  1.3719499111175537
e:  24   train_loss:  559.5255903166333   time:  1.3644566535949707
e:  25   train_loss:  557.5444233744308   time:  1.3759465217590332
e:  25   train_loss:  557.5444233744308   val_loss:  891.0515276815071   time:  1.489386796951294
e:  26   train_loss:  555.2852025061912   time:  1.3837380409240723
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1073.4560458310038   time:  1.5114028453826904
e:  0   train_loss:  1073.4560458310038   val_loss:  679.3386442247926   time:  1.618058681488037
e:  1   train_loss:  1038.915700939903   time:  1.6475019454956055
e:  2   train_loss:  1018.3476962338066   time:  1.5071451663970947
e:  3   train_loss:  911.6199523000006   time:  1.4910392761230469
e:  4   train_loss:  799.2761885173147   time:  1.4886438846588135
e:  5   train_loss:  717.5670133695108   time:  1.458564043045044
e:  5   train_loss:  717.5670133695108   val_loss:  556.1864736072974   time:  1.5630154609680176
e:  6   train_loss:  689.9245583846532   time:  1.4759705066680908
e:  7   train_loss:  652.6708034073424   time:  1.490574598312378
e:  8   train_loss:  652.3349393404379   time:  1.6349666118621826
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  9   train_loss:  640.67256649952   time:  1.4988484382629395
e:  10   train_loss:  656.7283228797576   time:  1.6256186962127686
e:  10   train_loss:  656.7283228797576   val_loss:  618.098809156028   time:  1.871755838394165
e:  11   train_loss:  618.1918381112556   time:  1.626758098602295
e:  12   train_loss:  616.1404876107168   time:  1.6317150592803955
e:  13   train_loss:  621.3312378578837   time:  1.724118709564209
e:  14   train_loss:  612.1300406445557   time:  1.6218371391296387
e:  15   train_loss:  610.5383346723611   time:  1.6325316429138184
e:  15   train_loss:  610.5383346723611   val_loss:  618.3100558800992   time:  1.7393879890441895
e:  16   train_loss:  603.1062843634833   time:  1.48734712600708
e:  17   train_loss:  596.5654804536175   time:  1.490501880645752
e:  18   train_loss:  605.8700701824612   time:  1.4899766445159912
e:  19   train_loss:  606.5999464926118   time:  1.4870777130126953
e:  20   train_loss:  611.9478464595718   time:  1.6175472736358643
e:  20   train_loss:  611.9478464595718   val_loss:  605.8710151827552   time:  1.7169361114501953
e:  21   train_loss:  596.6340380398518   time:  1.5707027912139893
e:  22   train_loss:  600.4629238902543   time:  1.5100579261779785
e:  23   train_loss:  600.4804473063376   time:  1.4911267757415771
e:  24   train_loss:  600.3210464577829   time:  1.4984514713287354
e:  25   train_loss:  599.6156751938621   time:  1.4855988025665283
e:  25   train_loss:  599.6156751938621   val_loss:  654.552616680659   time:  1.5918846130371094
e:  26   train_loss:  589.8543347933472   time:  1.4998645782470703
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 1), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 1) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 1) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 1) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 1)
kwargs: {'config': {'batch_norm': True, 'ff_0': 100, 'ff_num_layers': 1, 'gnn_0': 328, 'gnn_dropout': 0.18922446459404368, 'gnn_num_layers': 2, 'hid_0': 785, 'hid_dropout_rate': 0.2708897224252819, 'in_dropout_rate': 0.3710342355439332, 'lr': 0.00011939153447737812, 'num_hid_layers': 1, 'optimizer': 'SGD', 'gnn_1': 228, 'sgd_momentum': 0.7051705200345821}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 734.6096834573426, 'n_epochs': 27.0, 'info': {'validation loss': 734.6096834573426}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 1) started
DEBUG:hpbandster:job_callback for (0, 0, 1) got condition
DEBUG:hpbandster:Only 2 run(s) for budget 27.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 1) finished
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 2) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 2) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 2)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 2) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 2) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 2)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 334, 'ff_num_layers': 1, 'gnn_0': 115, 'gnn_dropout': 0.36093280378861975, 'gnn_num_layers': 3, 'hid_0': 287, 'hid_dropout_rate': 0.4106022389610257, 'in_dropout_rate': 0.159431981485876, 'lr': 0.0027433667469244786, 'num_hid_layers': 1, 'optimizer': 'Adam', 'gnn_1': 223, 'gnn_2': 306}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  630.6558112315165   time:  1.4483678340911865
e:  0   train_loss:  630.6558112315165   val_loss:  1422.7865263931476   time:  1.55971360206604
e:  1   train_loss:  592.2885921755992   time:  1.3262083530426025
e:  2   train_loss:  584.5339787350237   time:  1.3269813060760498
e:  3   train_loss:  573.5144237273415   time:  1.3956599235534668
e:  4   train_loss:  560.3903951463543   time:  1.2685692310333252
e:  5   train_loss:  546.750863861461   time:  1.2694134712219238
e:  5   train_loss:  546.750863861461   val_loss:  1393.7311261305454   time:  1.3796286582946777
e:  6   train_loss:  527.4048878759395   time:  1.2768316268920898
e:  7   train_loss:  510.44180445630855   time:  1.2762494087219238
e:  8   train_loss:  495.581348108182   time:  1.273848295211792
e:  9   train_loss:  480.53416500643897   time:  1.2694263458251953
e:  10   train_loss:  462.3499707063949   time:  1.2641136646270752
e:  10   train_loss:  462.3499707063949   val_loss:  1386.5074488585055   time:  1.373448371887207
e:  11   train_loss:  450.0379608484152   time:  1.2803153991699219
e:  12   train_loss:  443.670153770383   time:  1.4003422260284424
e:  13   train_loss:  434.0069149214185   time:  1.260030746459961
e:  14   train_loss:  427.3362810073648   time:  1.274733066558838
e:  15   train_loss:  424.9447939167587   time:  1.274003505706787
e:  15   train_loss:  424.9447939167587   val_loss:  1430.329410169908   time:  1.3831171989440918
e:  16   train_loss:  421.2757127997038   time:  1.2721867561340332
e:  17   train_loss:  421.0499867694643   time:  1.2645905017852783
e:  18   train_loss:  418.1989478160586   time:  1.2719202041625977
e:  19   train_loss:  414.8812075065283   time:  1.3773305416107178
e:  20   train_loss:  413.3436773099677   time:  1.2947561740875244
e:  20   train_loss:  413.3436773099677   val_loss:  1436.3745256825105   time:  1.4049084186553955
e:  21   train_loss:  412.4645408113994   time:  1.4017088413238525
e:  22   train_loss:  411.4529435202807   time:  1.2747321128845215
e:  23   train_loss:  412.8279379816654   time:  1.3193447589874268
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  24   train_loss:  412.49540329000496   time:  1.2675361633300781
e:  25   train_loss:  411.1379678896597   time:  1.2644221782684326
e:  25   train_loss:  411.1379678896597   val_loss:  1444.259415267878   time:  1.374481201171875
e:  26   train_loss:  411.1447878317225   time:  1.2732551097869873
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  956.9047492642886   time:  1.3982443809509277
e:  0   train_loss:  956.9047492642886   val_loss:  536.9030588269229   time:  1.5016226768493652
e:  1   train_loss:  890.0868254685855   time:  1.3952994346618652
e:  2   train_loss:  840.3121695334271   time:  1.531620979309082
e:  3   train_loss:  737.592329366315   time:  1.384504795074463
e:  4   train_loss:  732.0540829498736   time:  1.3995106220245361
e:  5   train_loss:  707.3207534848295   time:  1.3919625282287598
e:  5   train_loss:  707.3207534848295   val_loss:  906.8228393845279   time:  1.4961357116699219
e:  6   train_loss:  695.1629947808357   time:  1.3985862731933594
e:  7   train_loss:  672.7953888932733   time:  1.3991684913635254
e:  8   train_loss:  658.8300063689064   time:  1.5085794925689697
e:  9   train_loss:  642.7266040149358   time:  1.3986282348632812
e:  10   train_loss:  622.8103550204926   time:  1.3992419242858887
e:  10   train_loss:  622.8103550204926   val_loss:  754.0743961915554   time:  1.5024244785308838
e:  11   train_loss:  610.4891637365685   time:  1.3969752788543701
e:  12   train_loss:  602.247571853865   time:  1.394550085067749
e:  13   train_loss:  595.5563924495941   time:  1.385589599609375
e:  14   train_loss:  585.3090858011793   time:  1.3588790893554688
e:  15   train_loss:  588.479146504586   time:  1.5320088863372803
e:  15   train_loss:  588.479146504586   val_loss:  709.5988201547091   time:  1.6354081630706787
e:  16   train_loss:  569.211607623848   time:  1.3969154357910156
e:  17   train_loss:  570.8275565993945   time:  1.394373893737793
e:  18   train_loss:  559.5710010563521   time:  1.3910515308380127
e:  19   train_loss:  561.2835397042477   time:  1.3952159881591797
e:  20   train_loss:  560.0945129865385   time:  1.395845651626587
e:  20   train_loss:  560.0945129865385   val_loss:  626.8140228682338   time:  1.499586820602417
e:  21   train_loss:  582.4730998063209   time:  1.5369548797607422
e:  22   train_loss:  573.3297003612734   time:  1.3937487602233887
e:  23   train_loss:  557.8209763981199   time:  1.3976497650146484
e:  24   train_loss:  548.5382436639358   time:  1.3918547630310059
e:  25   train_loss:  556.2800344719603   time:  1.3864977359771729
e:  25   train_loss:  556.2800344719603   val_loss:  728.2506758048797   time:  1.4898738861083984
e:  26   train_loss:  550.4168601793064   time:  1.3924298286437988
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1041.5194437130892   time:  1.3775098323822021
e:  0   train_loss:  1041.5194437130892   val_loss:  491.4279123992672   time:  1.4834420680999756
e:  1   train_loss:  865.9424775599774   time:  1.5144224166870117
e:  2   train_loss:  806.9116784482865   time:  1.3797755241394043
e:  3   train_loss:  728.823419800116   time:  1.3771204948425293
e:  4   train_loss:  720.3657754152817   time:  1.364213466644287
e:  5   train_loss:  747.7807225015054   time:  1.4429583549499512
e:  5   train_loss:  747.7807225015054   val_loss:  487.8364569223027   time:  1.550529956817627
e:  6   train_loss:  695.4926956725908   time:  1.3875887393951416
e:  7   train_loss:  709.7425008932785   time:  1.4824714660644531
e:  8   train_loss:  688.3566473559798   time:  1.3578205108642578
e:  9   train_loss:  695.6304974391822   time:  1.371295690536499
e:  10   train_loss:  637.428066714376   time:  1.3790788650512695
e:  10   train_loss:  637.428066714376   val_loss:  488.75438212287935   time:  1.4852840900421143
e:  11   train_loss:  636.286407523665   time:  1.375744342803955
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  12   train_loss:  632.3460069042872   time:  1.3684258460998535
e:  13   train_loss:  609.6291181408078   time:  1.371896505355835
e:  14   train_loss:  644.805366790392   time:  1.368471384048462
e:  15   train_loss:  613.8833406353514   time:  1.4861009120941162
e:  15   train_loss:  613.8833406353514   val_loss:  461.2707795053524   time:  1.5854787826538086
e:  16   train_loss:  636.8586208465023   time:  1.3608300685882568
e:  17   train_loss:  631.1195080295141   time:  1.3666999340057373
e:  18   train_loss:  592.7346086294008   time:  1.3718996047973633
e:  19   train_loss:  581.6929003312945   time:  1.3763370513916016
e:  20   train_loss:  584.446280672832   time:  1.3903238773345947
e:  20   train_loss:  584.446280672832   val_loss:  503.7697124660295   time:  1.4958698749542236
e:  21   train_loss:  599.2415904097325   time:  1.3734922409057617
e:  22   train_loss:  574.1457927018905   time:  1.3716819286346436
e:  23   train_loss:  611.4167656516352   time:  1.5063714981079102
e:  24   train_loss:  583.6966358340297   time:  1.360588788986206
e:  25   train_loss:  585.8054202711207   time:  1.3677599430084229
e:  25   train_loss:  585.8054202711207   val_loss:  490.01214526221054   time:  1.4728262424468994
e:  26   train_loss:  587.5581752697636   time:  1.3645577430725098
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  892.6301531868904   time:  1.2642812728881836
e:  0   train_loss:  892.6301531868904   val_loss:  745.8198527795598   time:  1.3738527297973633
e:  1   train_loss:  829.7079384489565   time:  1.2561802864074707
e:  2   train_loss:  787.4072057099045   time:  1.2524573802947998
e:  3   train_loss:  730.5149220243966   time:  1.390150547027588
e:  4   train_loss:  701.5674308172439   time:  1.256603717803955
e:  5   train_loss:  681.7415714765057   time:  1.272298812866211
e:  5   train_loss:  681.7415714765057   val_loss:  722.3091541858896   time:  1.3825373649597168
e:  6   train_loss:  668.4355778709265   time:  1.2739818096160889
e:  7   train_loss:  656.618034072072   time:  1.274764060974121
e:  8   train_loss:  644.0288937057824   time:  1.2634434700012207
e:  9   train_loss:  629.6482591788579   time:  1.2695417404174805
e:  10   train_loss:  615.925454562569   time:  1.3904013633728027
e:  10   train_loss:  615.925454562569   val_loss:  699.9863991656405   time:  1.500859022140503
e:  11   train_loss:  605.2454166791678   time:  1.270538091659546
e:  12   train_loss:  594.0306840977306   time:  1.2730050086975098
e:  13   train_loss:  588.0052047766794   time:  1.276496410369873
e:  14   train_loss:  573.4652303430215   time:  1.2737095355987549
e:  15   train_loss:  571.017827729682   time:  1.2721755504608154
e:  15   train_loss:  571.017827729682   val_loss:  693.8965961729671   time:  1.5116605758666992
e:  16   train_loss:  563.5280786776518   time:  1.2738406658172607
e:  17   train_loss:  553.8832114711787   time:  1.2719666957855225
e:  18   train_loss:  544.8851139814537   time:  1.27176833152771
e:  19   train_loss:  543.7855099266976   time:  1.2732470035552979
e:  20   train_loss:  538.9598749443369   time:  1.2700614929199219
e:  20   train_loss:  538.9598749443369   val_loss:  704.2666333065703   time:  1.3808529376983643
e:  21   train_loss:  537.4176489957498   time:  1.3345587253570557
e:  22   train_loss:  535.7146745515003   time:  1.3553621768951416
e:  23   train_loss:  533.3020668895552   time:  1.2740566730499268
e:  24   train_loss:  532.8589870492531   time:  1.4314243793487549
e:  25   train_loss:  534.5148285202874   time:  1.2381665706634521
e:  25   train_loss:  534.5148285202874   val_loss:  699.5403013282624   time:  1.3398609161376953
e:  26   train_loss:  535.4093817316908   time:  1.2707960605621338
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  955.5632533885289   time:  1.4462895393371582
e:  0   train_loss:  955.5632533885289   val_loss:  554.4677576794367   time:  1.5512259006500244
e:  1   train_loss:  860.7545755844984   time:  1.4538705348968506
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  2   train_loss:  780.714931676036   time:  1.4099628925323486
e:  3   train_loss:  721.9730162547962   time:  1.5105130672454834
e:  4   train_loss:  700.308906156562   time:  1.472287654876709
e:  5   train_loss:  692.396684795533   time:  1.8151111602783203
e:  5   train_loss:  692.396684795533   val_loss:  567.5426457615149   time:  1.9180045127868652
e:  6   train_loss:  687.5389502951342   time:  1.382300853729248
e:  7   train_loss:  656.003543944758   time:  1.4969162940979004
e:  8   train_loss:  654.2134542783515   time:  1.5018870830535889
e:  9   train_loss:  629.307172031053   time:  1.3944859504699707
e:  10   train_loss:  614.547649201631   time:  1.3920214176177979
e:  10   train_loss:  614.547649201631   val_loss:  566.6662290363587   time:  1.5066492557525635
e:  11   train_loss:  615.8487104226338   time:  1.5566792488098145
e:  12   train_loss:  609.8003374699919   time:  1.5352323055267334
e:  13   train_loss:  613.8992569547368   time:  1.3964192867279053
e:  14   train_loss:  604.4262014461488   time:  1.392927646636963
e:  15   train_loss:  613.6252655882776   time:  1.3952655792236328
e:  15   train_loss:  613.6252655882776   val_loss:  574.7440408452036   time:  1.5002448558807373
e:  16   train_loss:  593.4012505794233   time:  1.3931536674499512
e:  17   train_loss:  594.6424210619303   time:  1.3821384906768799
e:  18   train_loss:  581.4492474878506   time:  1.4991562366485596
e:  19   train_loss:  577.0963794244055   time:  1.3762454986572266
e:  20   train_loss:  574.7557530447531   time:  1.3913588523864746
e:  20   train_loss:  574.7557530447531   val_loss:  561.803110994437   time:  1.4954664707183838
e:  21   train_loss:  578.1898727325492   time:  1.3925116062164307
e:  22   train_loss:  576.2431162342971   time:  1.3847095966339111
e:  23   train_loss:  582.487967455735   time:  1.3939399719238281
e:  24   train_loss:  566.7971587708852   time:  1.5187320709228516
e:  25   train_loss:  567.8030916994703   time:  1.389308214187622
e:  25   train_loss:  567.8030916994703   val_loss:  571.6834519020565   time:  1.4940268993377686
e:  26   train_loss:  562.8288865826637   time:  1.3859210014343262
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 2), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 2) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 2) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 2) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 2)
kwargs: {'config': {'batch_norm': False, 'ff_0': 334, 'ff_num_layers': 1, 'gnn_0': 115, 'gnn_dropout': 0.36093280378861975, 'gnn_num_layers': 3, 'hid_0': 287, 'hid_dropout_rate': 0.4106022389610257, 'in_dropout_rate': 0.159431981485876, 'lr': 0.0027433667469244786, 'num_hid_layers': 1, 'optimizer': 'Adam', 'gnn_1': 223, 'gnn_2': 306}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 726.6091282086369, 'n_epochs': 27.0, 'info': {'validation loss': 726.6091282086369}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 2) started
DEBUG:hpbandster:job_callback for (0, 0, 2) got condition
DEBUG:hpbandster:Only 3 run(s) for budget 27.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 2) finished
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 3) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 3) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 3)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 3) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 3) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 3)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 101, 'ff_num_layers': 2, 'gnn_0': 1172, 'gnn_dropout': 0.37720306195872705, 'gnn_num_layers': 3, 'hid_0': 338, 'hid_dropout_rate': 0.4568705085958342, 'in_dropout_rate': 0.4203181928135119, 'lr': 0.002652366363658988, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 1111, 'gnn_1': 1032, 'gnn_2': 562, 'hid_1': 448, 'hid_2': 1934}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  844.4940808077698   time:  1.5680725574493408
e:  0   train_loss:  844.4940808077698   val_loss:  1671.5285737001443   time:  1.6862661838531494
e:  1   train_loss:  702.9379606048792   time:  1.6178443431854248
e:  2   train_loss:  685.8388893964272   time:  1.4694063663482666
e:  3   train_loss:  643.4622504851443   time:  1.4718818664550781
e:  4   train_loss:  627.5393199633143   time:  1.4775571823120117
e:  5   train_loss:  616.3815855586561   time:  1.601243495941162
e:  5   train_loss:  616.3815855586561   val_loss:  1452.8105384672212   time:  1.7131710052490234
e:  6   train_loss:  601.9437910463101   time:  1.4731640815734863
e:  7   train_loss:  589.5674967497172   time:  1.479703426361084
e:  8   train_loss:  586.010007574132   time:  1.5386261940002441
e:  9   train_loss:  582.4611183644136   time:  1.4811937808990479
e:  10   train_loss:  572.0643004692174   time:  1.4781787395477295
e:  10   train_loss:  572.0643004692174   val_loss:  1415.6902405789644   time:  1.5975534915924072
e:  11   train_loss:  563.3185484005824   time:  1.4296956062316895
e:  12   train_loss:  553.9907709900657   time:  1.4617671966552734
e:  13   train_loss:  546.0882149823539   time:  1.47114896774292
e:  14   train_loss:  537.3812407887364   time:  1.4765715599060059
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  15   train_loss:  531.8690185597393   time:  1.6044681072235107
e:  15   train_loss:  531.8690185597393   val_loss:  1411.9797915253732   time:  1.7156872749328613
e:  16   train_loss:  527.830303806546   time:  1.477426290512085
e:  17   train_loss:  516.1362881914147   time:  1.4778778553009033
e:  18   train_loss:  504.95116378480316   time:  1.478933572769165
e:  19   train_loss:  503.3889956185712   time:  1.5114190578460693
e:  20   train_loss:  505.0504774161249   time:  1.4946975708007812
e:  20   train_loss:  505.0504774161249   val_loss:  1483.8264978064044   time:  1.6133859157562256
e:  21   train_loss:  496.20618591711326   time:  1.474898338317871
e:  22   train_loss:  501.46425550351734   time:  1.4775097370147705
e:  23   train_loss:  499.5005362431848   time:  1.476755142211914
e:  24   train_loss:  501.33978182929405   time:  1.4812219142913818
e:  25   train_loss:  497.5719289522042   time:  1.4822146892547607
e:  25   train_loss:  497.5719289522042   val_loss:  1528.2395626737277   time:  1.719057321548462
e:  26   train_loss:  496.54491645835316   time:  1.4794082641601562
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1137.671966416282   time:  1.6273398399353027
e:  0   train_loss:  1137.671966416282   val_loss:  626.0555186240595   time:  1.7396397590637207
e:  1   train_loss:  1071.1033386155793   time:  1.6153442859649658
e:  2   train_loss:  929.3257239009266   time:  1.6155033111572266
e:  3   train_loss:  837.3434769481727   time:  1.5845293998718262
e:  4   train_loss:  827.9075002075755   time:  1.5848453044891357
e:  5   train_loss:  769.4672818420833   time:  1.749889850616455
e:  5   train_loss:  769.4672818420833   val_loss:  614.2384823092829   time:  1.8619911670684814
e:  6   train_loss:  758.7015924232785   time:  1.6128087043762207
e:  7   train_loss:  740.6314496574114   time:  1.614727258682251
e:  8   train_loss:  706.1664852832878   time:  1.6195871829986572
e:  9   train_loss:  667.5862165551198   time:  1.6143906116485596
e:  10   train_loss:  736.1278896937849   time:  1.6156609058380127
e:  10   train_loss:  736.1278896937849   val_loss:  589.4331552680203   time:  1.727064609527588
e:  11   train_loss:  710.6042926290525   time:  1.6126413345336914
e:  12   train_loss:  679.6824827353199   time:  1.7434406280517578
e:  13   train_loss:  642.3302072984982   time:  1.6147754192352295
e:  14   train_loss:  630.9940316671859   time:  1.6129252910614014
e:  15   train_loss:  617.679905744168   time:  1.6142914295196533
e:  15   train_loss:  617.679905744168   val_loss:  672.4214000292408   time:  1.7268040180206299
e:  16   train_loss:  625.6157145707078   time:  1.6191306114196777
e:  17   train_loss:  597.7028686612855   time:  1.6189649105072021
e:  18   train_loss:  621.8627342094024   time:  1.7723562717437744
e:  19   train_loss:  607.3822362871474   time:  1.6161539554595947
e:  20   train_loss:  584.2453648021868   time:  1.6188740730285645
e:  20   train_loss:  584.2453648021868   val_loss:  600.670603006126   time:  1.731104850769043
e:  21   train_loss:  596.7422044960525   time:  1.589310884475708
e:  22   train_loss:  573.6425563908198   time:  1.5853338241577148
e:  23   train_loss:  569.2549483559299   time:  1.615140676498413
e:  24   train_loss:  568.6822815200132   time:  1.6169159412384033
e:  25   train_loss:  553.0875874900861   time:  1.7674674987792969
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  25   train_loss:  553.0875874900861   val_loss:  587.0190887541237   time:  1.882890224456787
e:  26   train_loss:  550.8057444987562   time:  1.6149566173553467
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1143.4679547249182   time:  1.610419750213623
e:  0   train_loss:  1143.4679547249182   val_loss:  537.6917128341254   time:  1.7259151935577393
e:  1   train_loss:  1062.2862283165202   time:  1.6049673557281494
e:  2   train_loss:  1013.9056724876207   time:  1.6040048599243164
e:  3   train_loss:  876.9183123184955   time:  1.6004211902618408
e:  4   train_loss:  814.9554702479204   time:  1.7238290309906006
e:  5   train_loss:  757.6672080343042   time:  1.6065032482147217
e:  5   train_loss:  757.6672080343042   val_loss:  491.5114684659572   time:  1.7214784622192383
e:  6   train_loss:  795.5996511567488   time:  1.6040425300598145
e:  7   train_loss:  738.5474216911678   time:  1.602522373199463
e:  8   train_loss:  729.477592047214   time:  1.6009047031402588
e:  9   train_loss:  692.6032949310548   time:  1.5968708992004395
e:  10   train_loss:  682.8657401569957   time:  1.605804443359375
e:  10   train_loss:  682.8657401569957   val_loss:  509.23476164091596   time:  1.8417489528656006
e:  11   train_loss:  658.2369356126792   time:  1.6233162879943848
e:  12   train_loss:  636.1393665015285   time:  1.582895040512085
e:  13   train_loss:  617.6098562468027   time:  1.5685136318206787
e:  14   train_loss:  629.5510000828267   time:  1.600557804107666
e:  15   train_loss:  585.3828725527316   time:  1.5968339443206787
e:  15   train_loss:  585.3828725527316   val_loss:  507.0510130459244   time:  1.7120132446289062
e:  16   train_loss:  589.893124274589   time:  1.6009647846221924
e:  17   train_loss:  576.0532903061323   time:  1.599928617477417
e:  18   train_loss:  587.3484021888297   time:  1.7242798805236816
e:  19   train_loss:  605.5836448211099   time:  1.597463846206665
e:  20   train_loss:  564.8676809727278   time:  1.597780466079712
e:  20   train_loss:  564.8676809727278   val_loss:  507.1726156449076   time:  1.7127573490142822
e:  21   train_loss:  575.7461038373943   time:  1.6012704372406006
e:  22   train_loss:  570.835905045896   time:  1.5988600254058838
e:  23   train_loss:  544.8840655625213   time:  1.6032390594482422
e:  24   train_loss:  526.5980978406164   time:  1.6045575141906738
e:  25   train_loss:  530.5726389256007   time:  1.7338404655456543
e:  25   train_loss:  530.5726389256007   val_loss:  578.84673504758   time:  1.848606824874878
e:  26   train_loss:  497.7022077226688   time:  1.6018729209899902
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  1109.0054100980922   time:  1.4623613357543945
e:  0   train_loss:  1109.0054100980922   val_loss:  914.5511565669219   time:  1.5815632343292236
e:  1   train_loss:  993.3224087308045   time:  1.4775547981262207
e:  2   train_loss:  921.5946964543884   time:  1.4726972579956055
e:  3   train_loss:  825.2303581818371   time:  1.475001335144043
e:  4   train_loss:  768.8439995786367   time:  1.441361665725708
e:  5   train_loss:  778.9596831029232   time:  1.4907736778259277
e:  5   train_loss:  778.9596831029232   val_loss:  808.3133857717248   time:  1.6105773448944092
e:  6   train_loss:  765.1255071404281   time:  1.4793457984924316
e:  7   train_loss:  754.3993402105601   time:  1.4756982326507568
e:  8   train_loss:  754.1133383211684   time:  1.4767215251922607
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  9   train_loss:  740.9912808065661   time:  1.4751896858215332
e:  10   train_loss:  732.4378898355333   time:  1.595311164855957
e:  10   train_loss:  732.4378898355333   val_loss:  752.5144317408141   time:  1.7153329849243164
e:  11   train_loss:  714.5740382732271   time:  1.4734292030334473
e:  12   train_loss:  703.2266378119215   time:  1.4783573150634766
e:  13   train_loss:  699.5731298196731   time:  1.4771349430084229
e:  14   train_loss:  669.5377033825126   time:  1.4777700901031494
e:  15   train_loss:  673.6787526926688   time:  1.4776694774627686
e:  15   train_loss:  673.6787526926688   val_loss:  763.2118732328238   time:  1.597945213317871
e:  16   train_loss:  646.9717941669728   time:  1.4733147621154785
e:  17   train_loss:  638.6996066132458   time:  1.473935604095459
e:  18   train_loss:  612.0472439047751   time:  1.473952293395996
e:  19   train_loss:  625.9242252482317   time:  1.5945947170257568
e:  20   train_loss:  588.11928214482   time:  1.4745373725891113
e:  20   train_loss:  588.11928214482   val_loss:  745.1027883907791   time:  1.593947172164917
e:  21   train_loss:  595.4054659155044   time:  1.4777653217315674
e:  22   train_loss:  587.2950716764241   time:  1.4766006469726562
e:  23   train_loss:  577.6413863881472   time:  1.475135087966919
e:  24   train_loss:  570.1047875724253   time:  1.4333758354187012
e:  25   train_loss:  570.3343781807807   time:  1.4551692008972168
e:  25   train_loss:  570.3343781807807   val_loss:  756.0487065519077   time:  1.574659824371338
e:  26   train_loss:  565.702227039045   time:  1.477776288986206
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1158.5215653586004   time:  1.618053913116455
e:  0   train_loss:  1158.5215653586004   val_loss:  686.5526023322035   time:  1.730994701385498
e:  1   train_loss:  1048.9350568778796   time:  1.618840217590332
e:  2   train_loss:  973.2220913484184   time:  1.7689430713653564
e:  3   train_loss:  886.2707743813967   time:  1.614717960357666
e:  4   train_loss:  837.8268583524418   time:  1.6170597076416016
e:  5   train_loss:  763.9211134355668   time:  1.614206314086914
e:  5   train_loss:  763.9211134355668   val_loss:  562.2264089647674   time:  1.7274465560913086
e:  6   train_loss:  773.8165949776293   time:  1.6138432025909424
e:  7   train_loss:  795.2109037622226   time:  1.6165719032287598
e:  8   train_loss:  750.4995342365778   time:  1.7675135135650635
e:  9   train_loss:  699.5470500283222   time:  1.6149792671203613
e:  10   train_loss:  708.8198883602547   time:  1.612905740737915
e:  10   train_loss:  708.8198883602547   val_loss:  569.4118811998088   time:  1.726426362991333
e:  11   train_loss:  693.4471299248802   time:  1.6105453968048096
e:  12   train_loss:  674.6900157052071   time:  1.614858865737915
e:  13   train_loss:  698.6362110055699   time:  1.619755506515503
e:  14   train_loss:  675.8172818182237   time:  1.766718864440918
e:  15   train_loss:  667.4194865718003   time:  1.5819787979125977
e:  15   train_loss:  667.4194865718003   val_loss:  561.6615386718868   time:  1.69325852394104
e:  16   train_loss:  653.2963993522395   time:  1.6001255512237549
e:  17   train_loss:  629.5302951360387   time:  1.6185598373413086
e:  18   train_loss:  616.5459096597691   time:  1.620208501815796
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  19   train_loss:  607.6186551739065   time:  1.6190495491027832
e:  20   train_loss:  607.2398326776548   time:  1.618013620376587
e:  20   train_loss:  607.2398326776548   val_loss:  562.8289110629453   time:  1.7313928604125977
e:  21   train_loss:  594.1483014461924   time:  1.7585439682006836
e:  22   train_loss:  585.5369433121996   time:  1.6199989318847656
e:  23   train_loss:  591.5848131098578   time:  1.6440792083740234
e:  24   train_loss:  583.2358456495971   time:  1.6155765056610107
e:  25   train_loss:  582.4381476802658   time:  1.611649751663208
e:  25   train_loss:  582.4381476802658   val_loss:  565.3778877880665   time:  1.72495436668396
e:  26   train_loss:  575.1654616600666   time:  1.616652488708496
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 3), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 3) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 3) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 3) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 3)
kwargs: {'config': {'batch_norm': False, 'ff_0': 101, 'ff_num_layers': 2, 'gnn_0': 1172, 'gnn_dropout': 0.37720306195872705, 'gnn_num_layers': 3, 'hid_0': 338, 'hid_dropout_rate': 0.4568705085958342, 'in_dropout_rate': 0.4203181928135119, 'lr': 0.002652366363658988, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 1111, 'gnn_1': 1032, 'gnn_2': 562, 'hid_1': 448, 'hid_2': 1934}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 759.454935161624, 'n_epochs': 27.0, 'info': {'validation loss': 759.454935161624}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 3) started
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:job_callback for (0, 0, 3) got condition
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:Only 4 run(s) for budget 27.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 3) finished
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 4) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 4) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 4)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 4) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 4) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 4)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 216, 'ff_num_layers': 2, 'gnn_0': 1111, 'gnn_dropout': 0.16010050076341198, 'gnn_num_layers': 1, 'hid_0': 360, 'hid_dropout_rate': 0.049554151083727904, 'in_dropout_rate': 0.15877344600072363, 'lr': 0.0029990863349426376, 'num_hid_layers': 1, 'optimizer': 'SGD', 'ff_1': 25, 'sgd_momentum': 0.03355041864634011}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  649.5940697382389   time:  1.6204760074615479
e:  0   train_loss:  649.5940697382389   val_loss:  1404.2938726298357   time:  1.7238316535949707
e:  1   train_loss:  574.7518822360136   time:  1.394423246383667
e:  2   train_loss:  548.3126828465994   time:  1.3754522800445557
e:  3   train_loss:  529.660089933714   time:  1.3611388206481934
e:  4   train_loss:  516.5197413862104   time:  1.3520166873931885
e:  5   train_loss:  508.1211739427921   time:  1.3420376777648926
e:  5   train_loss:  508.1211739427921   val_loss:  1448.36087129782   time:  1.4522130489349365
e:  6   train_loss:  488.37625547208506   time:  1.3509643077850342
e:  7   train_loss:  485.3675419462619   time:  1.3484201431274414
e:  8   train_loss:  476.93229214717286   time:  1.3420166969299316
e:  9   train_loss:  467.2251389929633   time:  1.5819182395935059
e:  10   train_loss:  460.99603486332575   time:  1.3476040363311768
e:  10   train_loss:  460.99603486332575   val_loss:  1455.7906073376023   time:  1.4491147994995117
e:  11   train_loss:  463.072519721745   time:  1.3597853183746338
e:  12   train_loss:  453.65941058533116   time:  1.346245527267456
e:  13   train_loss:  458.3089137719014   time:  1.3521173000335693
e:  14   train_loss:  447.8350739313293   time:  1.3454675674438477
e:  15   train_loss:  447.3548018120502   time:  1.3938853740692139
e:  15   train_loss:  447.3548018120502   val_loss:  1392.2774759227852   time:  1.5050888061523438
e:  16   train_loss:  450.7472517913871   time:  1.3711779117584229
e:  17   train_loss:  449.2968932975342   time:  1.3438363075256348
e:  18   train_loss:  444.8095039679526   time:  1.350579023361206
e:  19   train_loss:  439.93377167564415   time:  1.574331283569336
e:  20   train_loss:  438.6720977474007   time:  1.377753496170044
e:  20   train_loss:  438.6720977474007   val_loss:  1431.6248148425339   time:  1.4896011352539062
e:  21   train_loss:  432.50439966110054   time:  1.3466832637786865
e:  22   train_loss:  438.0666099004269   time:  1.3686821460723877
e:  23   train_loss:  438.3926090962208   time:  1.3354275226593018
e:  24   train_loss:  442.72776278155214   time:  1.3686938285827637
e:  25   train_loss:  442.6500177745438   time:  1.3631656169891357
e:  25   train_loss:  442.6500177745438   val_loss:  1365.3827757779995   time:  1.4753868579864502
e:  26   train_loss:  436.4127612170344   time:  1.3496479988098145
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  950.0055013207681   time:  1.5039381980895996
e:  0   train_loss:  950.0055013207681   val_loss:  553.2801763612651   time:  1.6096174716949463
e:  1   train_loss:  749.4939564896183   time:  1.4673962593078613
e:  2   train_loss:  715.0645915397296   time:  1.6804583072662354
e:  3   train_loss:  678.5440479870555   time:  1.4717133045196533
e:  4   train_loss:  676.180058207076   time:  1.5078589916229248
e:  5   train_loss:  634.7084144736522   time:  1.4439921379089355
e:  5   train_loss:  634.7084144736522   val_loss:  11135.952044613145   time:  1.549448013305664
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  6   train_loss:  655.6250942410227   time:  1.473022222518921
e:  7   train_loss:  643.9118870695004   time:  1.4788999557495117
e:  8   train_loss:  644.6781693362158   time:  1.4907622337341309
e:  9   train_loss:  623.0977983900161   time:  1.7198102474212646
e:  10   train_loss:  636.0932793535502   time:  1.4716479778289795
e:  10   train_loss:  636.0932793535502   val_loss:  765.3154995934128   time:  1.5751714706420898
e:  11   train_loss:  609.1436975151969   time:  1.515171766281128
e:  12   train_loss:  618.6397825439104   time:  1.5026040077209473
e:  13   train_loss:  616.8285121871987   time:  1.5053775310516357
e:  14   train_loss:  604.4033522409148   time:  1.4708340167999268
e:  15   train_loss:  620.3035528725554   time:  1.5090818405151367
e:  15   train_loss:  620.3035528725554   val_loss:  948.4381048829299   time:  1.8016841411590576
e:  16   train_loss:  595.9411453140367   time:  1.4688994884490967
e:  17   train_loss:  637.5989244546462   time:  1.5122907161712646
e:  18   train_loss:  612.5872991857108   time:  1.5069739818572998
e:  19   train_loss:  619.614768932319   time:  1.511246919631958
e:  20   train_loss:  602.1076705371623   time:  1.4686224460601807
e:  20   train_loss:  602.1076705371623   val_loss:  629.8114255879491   time:  1.5713310241699219
e:  21   train_loss:  589.2336582772891   time:  1.462259292602539
e:  22   train_loss:  612.2400925574952   time:  1.465172529220581
e:  23   train_loss:  593.9315952748069   time:  1.7381269931793213
e:  24   train_loss:  587.5025980641898   time:  1.4659299850463867
e:  25   train_loss:  605.0061837619156   time:  1.4727773666381836
e:  25   train_loss:  605.0061837619156   val_loss:  641.5138608083039   time:  1.5756518840789795
e:  26   train_loss:  580.329525351242   time:  1.503997564315796
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  951.4050513091029   time:  1.4942119121551514
e:  0   train_loss:  951.4050513091029   val_loss:  593.400525595417   time:  1.6015691757202148
e:  1   train_loss:  793.1512687822632   time:  1.7369987964630127
e:  2   train_loss:  727.1071949011595   time:  1.4595856666564941
e:  3   train_loss:  701.866813326275   time:  1.4559237957000732
e:  4   train_loss:  688.5209801795228   time:  1.4650487899780273
e:  5   train_loss:  677.7507201286456   time:  1.4515256881713867
e:  5   train_loss:  677.7507201286456   val_loss:  496.84546777175615   time:  1.5575218200683594
e:  6   train_loss:  643.255550535244   time:  1.4435443878173828
e:  7   train_loss:  642.4420202873512   time:  1.4877350330352783
e:  8   train_loss:  638.9905463291178   time:  1.6508333683013916
e:  9   train_loss:  644.6414828475413   time:  1.4675753116607666
e:  10   train_loss:  656.2485721084495   time:  1.4518795013427734
e:  10   train_loss:  656.2485721084495   val_loss:  510.13690644559745   time:  1.5578317642211914
e:  11   train_loss:  669.1206331609123   time:  1.503528356552124
e:  12   train_loss:  630.3821328777577   time:  1.4974229335784912
e:  13   train_loss:  638.1241832840037   time:  1.4789445400238037
e:  14   train_loss:  657.6756063888104   time:  1.4437618255615234
e:  15   train_loss:  658.3151818625234   time:  1.6562974452972412
e:  15   train_loss:  658.3151818625234   val_loss:  560.5521504556343   time:  1.7619061470031738
e:  16   train_loss:  630.2950888432064   time:  1.4657478332519531
e:  17   train_loss:  628.9214518317831   time:  1.492600917816162
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  18   train_loss:  621.556533150489   time:  1.462071180343628
e:  19   train_loss:  631.830274521272   time:  1.4565293788909912
e:  20   train_loss:  595.711240524869   time:  1.4605133533477783
e:  20   train_loss:  595.711240524869   val_loss:  545.5452505405196   time:  1.5678431987762451
e:  21   train_loss:  659.5569531644873   time:  1.4706778526306152
e:  22   train_loss:  678.3135044963279   time:  1.6990389823913574
e:  23   train_loss:  659.1767790624167   time:  1.4945335388183594
e:  24   train_loss:  614.0891103306857   time:  1.5054361820220947
e:  25   train_loss:  628.9926823810109   time:  1.5007479190826416
e:  25   train_loss:  628.9926823810109   val_loss:  1114.6880851225892   time:  1.6070213317871094
e:  26   train_loss:  596.3000195858872   time:  1.4412577152252197
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  903.1329515596603   time:  1.3250648975372314
e:  0   train_loss:  903.1329515596603   val_loss:  745.5504801198997   time:  1.4347648620605469
e:  1   train_loss:  739.7943620722212   time:  1.376807451248169
e:  2   train_loss:  671.8829288382045   time:  1.3514149188995361
e:  3   train_loss:  661.8427661930356   time:  1.3506102561950684
e:  4   train_loss:  626.6607714217173   time:  1.357191801071167
e:  5   train_loss:  641.4046623903973   time:  1.3534972667694092
e:  5   train_loss:  641.4046623903973   val_loss:  729.8924234127188   time:  1.465928316116333
e:  6   train_loss:  616.3326726451951   time:  1.6027543544769287
e:  7   train_loss:  629.217888146814   time:  1.3534555435180664
e:  8   train_loss:  598.0571061992638   time:  1.3968210220336914
e:  9   train_loss:  605.3292951934537   time:  1.5488910675048828
e:  10   train_loss:  600.8807757678205   time:  1.3979477882385254
e:  10   train_loss:  600.8807757678205   val_loss:  1192.6506631501231   time:  1.5094943046569824
e:  11   train_loss:  589.8450486009124   time:  1.2812955379486084
e:  12   train_loss:  574.9854553302215   time:  1.2931227684020996
e:  13   train_loss:  594.7166953224425   time:  1.292686939239502
e:  14   train_loss:  583.3308759350846   time:  1.2912428379058838
e:  15   train_loss:  589.196562964424   time:  1.4206745624542236
e:  15   train_loss:  589.196562964424   val_loss:  854.33025928724   time:  1.5243701934814453
e:  16   train_loss:  594.9188113280579   time:  1.2878215312957764
e:  17   train_loss:  574.3728549204387   time:  1.2908399105072021
e:  18   train_loss:  578.3368887645833   time:  1.3131518363952637
e:  19   train_loss:  555.2820255836849   time:  1.3228864669799805
e:  20   train_loss:  558.4108890167873   time:  1.3497397899627686
e:  20   train_loss:  558.4108890167873   val_loss:  770.178356635237   time:  1.5496118068695068
e:  21   train_loss:  559.4341449877513   time:  1.3002314567565918
e:  22   train_loss:  563.8045812462316   time:  1.3032174110412598
e:  23   train_loss:  562.2230662141305   time:  1.2902541160583496
e:  24   train_loss:  556.8527570183045   time:  1.4799466133117676
e:  25   train_loss:  549.4020026956928   time:  1.4730920791625977
e:  25   train_loss:  549.4020026956928   val_loss:  756.1488658947743   time:  1.583700180053711
e:  26   train_loss:  562.4573474699496   time:  1.3015363216400146
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  974.7590043576151   time:  1.4238579273223877
e:  0   train_loss:  974.7590043576151   val_loss:  556.5363274776744   time:  1.528843641281128
e:  1   train_loss:  777.5359802104507   time:  1.4032459259033203
e:  2   train_loss:  728.3545642237369   time:  1.3957738876342773
e:  3   train_loss:  692.5475009360198   time:  1.4199299812316895
e:  4   train_loss:  677.3782451706923   time:  1.4210925102233887
e:  5   train_loss:  653.2140638309652   time:  1.4231154918670654
e:  5   train_loss:  653.2140638309652   val_loss:  818.7843847429259   time:  1.6678423881530762
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  6   train_loss:  744.5078494093881   time:  1.432802438735962
e:  7   train_loss:  644.5673437126165   time:  1.4273664951324463
e:  8   train_loss:  644.9782290756698   time:  1.4122803211212158
e:  9   train_loss:  623.5090659307177   time:  1.423863410949707
e:  10   train_loss:  615.8875434494444   time:  1.4226977825164795
e:  10   train_loss:  615.8875434494444   val_loss:  631.9677387378376   time:  1.5282680988311768
e:  11   train_loss:  642.2621545943762   time:  1.4262731075286865
e:  12   train_loss:  611.5172327038704   time:  1.4130346775054932
e:  13   train_loss:  623.2618226390181   time:  1.5842797756195068
e:  14   train_loss:  607.1129218188669   time:  1.4212169647216797
e:  15   train_loss:  595.741819473481   time:  1.4191291332244873
e:  15   train_loss:  595.741819473481   val_loss:  821.4720262147916   time:  1.523881196975708
e:  16   train_loss:  606.4753578352622   time:  1.418809175491333
e:  17   train_loss:  599.8243137321224   time:  1.4087183475494385
e:  18   train_loss:  621.5294060134335   time:  1.427936315536499
e:  19   train_loss:  621.6713268404056   time:  1.5734591484069824
e:  20   train_loss:  608.9729275515214   time:  1.4234898090362549
e:  20   train_loss:  608.9729275515214   val_loss:  665.8561699567855   time:  1.5294926166534424
e:  21   train_loss:  606.2041569372042   time:  1.4153563976287842
e:  22   train_loss:  612.1654005722484   time:  1.3949894905090332
e:  23   train_loss:  595.4233910553899   time:  1.4209930896759033
e:  24   train_loss:  597.9041383171966   time:  1.4199333190917969
e:  25   train_loss:  592.5661023782591   time:  1.543302297592163
e:  25   train_loss:  592.5661023782591   val_loss:  673.9286559530474   time:  1.6490509510040283
e:  26   train_loss:  600.7185572439748   time:  1.4253394603729248
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 4), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 4) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 4) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 4) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 4)
kwargs: {'config': {'batch_norm': True, 'ff_0': 216, 'ff_num_layers': 2, 'gnn_0': 1111, 'gnn_dropout': 0.16010050076341198, 'gnn_num_layers': 1, 'hid_0': 360, 'hid_dropout_rate': 0.049554151083727904, 'in_dropout_rate': 0.15877344600072363, 'lr': 0.0029990863349426376, 'num_hid_layers': 1, 'optimizer': 'SGD', 'ff_1': 25, 'sgd_momentum': 0.03355041864634011}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 740.3874341602829, 'n_epochs': 27.0, 'info': {'validation loss': 740.3874341602829}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 4) started
DEBUG:hpbandster:job_callback for (0, 0, 4) got condition
DEBUG:hpbandster:Only 5 run(s) for budget 27.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 4) finished
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 5) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 5) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 5)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 5) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 5) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 5)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 324, 'ff_num_layers': 3, 'gnn_0': 1653, 'gnn_dropout': 0.23286673446355421, 'gnn_num_layers': 1, 'hid_0': 103, 'hid_dropout_rate': 0.33770489723971736, 'in_dropout_rate': 0.2952165136936906, 'lr': 0.0001007677459882193, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 903, 'ff_2': 25, 'hid_1': 121, 'hid_2': 1191}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  705.2685573332094   time:  1.3398218154907227
e:  0   train_loss:  705.2685573332094   val_loss:  1672.350422900299   time:  1.451615810394287
e:  1   train_loss:  703.1715554994685   time:  1.347825288772583
e:  2   train_loss:  699.654265805516   time:  1.317702054977417
e:  3   train_loss:  692.8308818262333   time:  1.3832128047943115
e:  4   train_loss:  682.3887023566168   time:  1.311572790145874
e:  5   train_loss:  662.440756545843   time:  1.2880046367645264
e:  5   train_loss:  662.440756545843   val_loss:  1595.2142804726404   time:  1.3991248607635498
e:  6   train_loss:  632.8005763466717   time:  1.4498014450073242
e:  7   train_loss:  593.8678621792197   time:  1.3033981323242188
e:  8   train_loss:  556.5517035030489   time:  1.3034634590148926
e:  9   train_loss:  532.713794689713   time:  1.2906920909881592
e:  10   train_loss:  513.5942038912092   time:  1.3021883964538574
e:  10   train_loss:  513.5942038912092   val_loss:  1393.5661002308382   time:  1.4135611057281494
e:  11   train_loss:  493.85258705311435   time:  1.3047850131988525
e:  12   train_loss:  473.2489697895187   time:  1.308929443359375
e:  13   train_loss:  458.8625541290723   time:  1.3026375770568848
e:  14   train_loss:  450.1583799886739   time:  1.2887928485870361
e:  15   train_loss:  446.0242511385107   time:  1.3018319606781006
e:  15   train_loss:  446.0242511385107   val_loss:  1515.3050401912747   time:  1.4130547046661377
e:  16   train_loss:  441.41798889339765   time:  1.417025089263916
e:  17   train_loss:  439.7091776061501   time:  1.283484697341919
e:  18   train_loss:  437.44285347396556   time:  1.3046557903289795
e:  19   train_loss:  436.98672921076405   time:  1.3043735027313232
e:  20   train_loss:  436.70690279801113   time:  1.2936336994171143
e:  20   train_loss:  436.70690279801113   val_loss:  1343.8983137668529   time:  1.405590295791626
e:  21   train_loss:  438.1576728772205   time:  1.304020881652832
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  22   train_loss:  436.87625133812156   time:  1.3013718128204346
e:  23   train_loss:  433.8641819828262   time:  1.2902109622955322
e:  24   train_loss:  431.86821085738   time:  1.2853009700775146
e:  25   train_loss:  431.52722152772475   time:  1.290788173675537
e:  25   train_loss:  431.52722152772475   val_loss:  1312.5173511366547   time:  1.5347120761871338
e:  26   train_loss:  430.5031312678275   time:  1.2743432521820068
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1080.1245244936883   time:  1.4105658531188965
e:  0   train_loss:  1080.1245244936883   val_loss:  626.4031840643263   time:  1.5159378051757812
e:  1   train_loss:  1076.240163029855   time:  1.4052929878234863
e:  2   train_loss:  1073.3620036218572   time:  1.409273386001587
e:  3   train_loss:  1046.0931634181022   time:  1.4104421138763428
e:  4   train_loss:  1037.1156384327028   time:  1.4096336364746094
e:  5   train_loss:  986.1401707623149   time:  1.3969571590423584
e:  5   train_loss:  986.1401707623149   val_loss:  576.3689390272335   time:  1.5016911029815674
e:  6   train_loss:  937.9906116268188   time:  1.5529427528381348
e:  7   train_loss:  858.731623551004   time:  1.3960626125335693
e:  8   train_loss:  790.6797750293814   time:  1.4079132080078125
e:  9   train_loss:  739.4131809504729   time:  1.4046502113342285
e:  10   train_loss:  695.2138650961967   time:  1.3961856365203857
e:  10   train_loss:  695.2138650961967   val_loss:  597.9199469768372   time:  1.5001461505889893
e:  11   train_loss:  650.7328697184926   time:  1.3757219314575195
e:  12   train_loss:  624.8541292429412   time:  1.5431749820709229
e:  13   train_loss:  613.9766838815935   time:  1.4080429077148438
e:  14   train_loss:  590.6177898195   time:  1.408905029296875
e:  15   train_loss:  597.7797165154099   time:  1.4048805236816406
e:  15   train_loss:  597.7797165154099   val_loss:  741.8864667072799   time:  1.5095758438110352
e:  16   train_loss:  591.0498108053091   time:  1.406578779220581
e:  17   train_loss:  601.9402612209657   time:  1.4096884727478027
e:  18   train_loss:  589.4850720206638   time:  1.5461838245391846
e:  19   train_loss:  589.9855786274534   time:  1.40501070022583
e:  20   train_loss:  587.5191721521044   time:  1.3947386741638184
e:  20   train_loss:  587.5191721521044   val_loss:  670.3157436534149   time:  1.499211072921753
e:  21   train_loss:  582.3400871023564   time:  1.4066383838653564
e:  22   train_loss:  576.6161126727849   time:  1.4068036079406738
e:  23   train_loss:  581.918969622648   time:  1.4080781936645508
e:  24   train_loss:  581.1999419883986   time:  1.4153289794921875
e:  25   train_loss:  577.9947204014165   time:  1.562920331954956
e:  25   train_loss:  577.9947204014165   val_loss:  559.8665972382865   time:  1.6675338745117188
e:  26   train_loss:  581.1255974558911   time:  1.404221534729004
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1085.2833649152599   time:  1.3841793537139893
e:  0   train_loss:  1085.2833649152599   val_loss:  539.0856693639312   time:  1.490572214126587
e:  1   train_loss:  1115.031663614401   time:  1.3897473812103271
e:  2   train_loss:  1153.7004213391674   time:  1.3930015563964844
e:  3   train_loss:  1101.5150886504266   time:  1.397428035736084
e:  4   train_loss:  1057.7859273345102   time:  1.4158353805541992
e:  5   train_loss:  1001.0309769799379   time:  1.5334711074829102
e:  5   train_loss:  1001.0309769799379   val_loss:  511.7369397076988   time:  1.6409265995025635
e:  6   train_loss:  933.0585261157697   time:  1.4022150039672852
e:  7   train_loss:  877.183695828378   time:  1.398991346359253
e:  8   train_loss:  796.5259407916442   time:  1.3874835968017578
e:  9   train_loss:  747.0406915375713   time:  1.402374029159546
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  10   train_loss:  717.6055866483267   time:  1.4075348377227783
e:  10   train_loss:  717.6055866483267   val_loss:  482.3537066237716   time:  1.514451503753662
e:  11   train_loss:  689.6795902712363   time:  1.5552856922149658
e:  12   train_loss:  679.1494839744207   time:  1.397773265838623
e:  13   train_loss:  630.2577653719784   time:  1.3999176025390625
e:  14   train_loss:  606.4673174581676   time:  1.3987483978271484
e:  15   train_loss:  604.1064388656481   time:  1.394312858581543
e:  15   train_loss:  604.1064388656481   val_loss:  1119.4113129769542   time:  1.5007288455963135
e:  16   train_loss:  612.4180482874549   time:  1.3937244415283203
e:  17   train_loss:  613.531558335676   time:  1.3989078998565674
e:  18   train_loss:  629.6863168417227   time:  1.394373893737793
e:  19   train_loss:  610.6304323484883   time:  1.5387580394744873
e:  20   train_loss:  606.5903324601652   time:  1.3839805126190186
e:  20   train_loss:  606.5903324601652   val_loss:  1011.6654670201922   time:  1.4908509254455566
e:  21   train_loss:  613.3292121132987   time:  1.3937311172485352
e:  22   train_loss:  607.8865411007482   time:  1.3931503295898438
e:  23   train_loss:  621.6558958409024   time:  1.396803617477417
e:  24   train_loss:  618.2559767541009   time:  1.3863308429718018
e:  25   train_loss:  616.238074503474   time:  1.3864362239837646
e:  25   train_loss:  616.238074503474   val_loss:  578.3109844600581   time:  1.4931671619415283
e:  26   train_loss:  584.2540642085377   time:  1.5283617973327637
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  998.2406851299534   time:  1.2830791473388672
e:  0   train_loss:  998.2406851299534   val_loss:  915.7991815163767   time:  1.393481969833374
e:  1   train_loss:  995.2228356476825   time:  1.283700942993164
e:  2   train_loss:  989.386094338111   time:  1.281360149383545
e:  3   train_loss:  977.4575868913902   time:  1.2800226211547852
e:  4   train_loss:  964.3805660490568   time:  1.2818386554718018
e:  5   train_loss:  935.8767607918987   time:  1.281961441040039
e:  5   train_loss:  935.8767607918987   val_loss:  858.0274639742713   time:  1.3926162719726562
e:  6   train_loss:  890.1642869196146   time:  1.2830989360809326
e:  7   train_loss:  824.0079662955187   time:  1.2711787223815918
e:  8   train_loss:  763.3745416900465   time:  1.2810850143432617
e:  9   train_loss:  715.2807005440869   time:  1.274906873703003
e:  10   train_loss:  681.5686930479956   time:  1.4102892875671387
e:  10   train_loss:  681.5686930479956   val_loss:  737.037296949222   time:  1.5214898586273193
e:  11   train_loss:  635.8244412270021   time:  1.276486873626709
e:  12   train_loss:  603.9038320644634   time:  1.2816202640533447
e:  13   train_loss:  584.3366292514052   time:  1.2869033813476562
e:  14   train_loss:  575.3388132997771   time:  1.2719979286193848
e:  15   train_loss:  558.7201258141954   time:  1.2795295715332031
e:  15   train_loss:  558.7201258141954   val_loss:  742.6008673963144   time:  1.3908429145812988
e:  16   train_loss:  562.7264008692862   time:  1.2738134860992432
e:  17   train_loss:  557.5365908825977   time:  1.2806406021118164
e:  18   train_loss:  563.5968449537055   time:  1.2792878150939941
e:  19   train_loss:  551.6406405765966   time:  1.4044241905212402
e:  20   train_loss:  552.275885679019   time:  1.2640223503112793
e:  20   train_loss:  552.275885679019   val_loss:  881.6469700672573   time:  1.3748812675476074
e:  21   train_loss:  548.3767569741543   time:  1.2652184963226318
e:  22   train_loss:  554.3396805275066   time:  1.2719440460205078
e:  23   train_loss:  555.4024611265781   time:  1.2707459926605225
e:  24   train_loss:  556.7463629528443   time:  1.2803244590759277
e:  25   train_loss:  547.2239951485309   time:  1.2743265628814697
e:  25   train_loss:  547.2239951485309   val_loss:  778.9794338435064   time:  1.384544849395752
e:  26   train_loss:  549.6749302889667   time:  1.277430772781372
FOLD:  4
Model initialization done
Model training starts
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  0   train_loss:  1096.4611077197749   time:  1.4022951126098633
e:  0   train_loss:  1096.4611077197749   val_loss:  688.8427842310452   time:  1.6368637084960938
e:  1   train_loss:  1051.254175827388   time:  1.399853229522705
e:  2   train_loss:  1077.1915329860794   time:  1.400562047958374
e:  3   train_loss:  1037.42882587015   time:  1.39729642868042
e:  4   train_loss:  1024.394547619702   time:  1.389470100402832
e:  5   train_loss:  992.0806400000781   time:  1.396733045578003
e:  5   train_loss:  992.0806400000781   val_loss:  627.6381861759012   time:  1.5020880699157715
e:  6   train_loss:  915.0156093793584   time:  1.4006147384643555
e:  7   train_loss:  848.6943868021925   time:  1.5435633659362793
e:  8   train_loss:  791.2652924267963   time:  1.3888137340545654
e:  9   train_loss:  727.7430490929796   time:  1.395784616470337
e:  10   train_loss:  701.2842047342821   time:  1.3948800563812256
e:  10   train_loss:  701.2842047342821   val_loss:  640.4930441349969   time:  1.4999756813049316
e:  11   train_loss:  661.2670082249645   time:  1.3970015048980713
e:  12   train_loss:  635.540492088294   time:  1.3995444774627686
e:  13   train_loss:  605.4116713397711   time:  1.4015791416168213
e:  14   train_loss:  606.4388482396864   time:  1.544499397277832
e:  15   train_loss:  593.6117543101094   time:  1.3804271221160889
e:  15   train_loss:  593.6117543101094   val_loss:  610.2627295501692   time:  1.4844276905059814
e:  16   train_loss:  595.8584936038634   time:  1.387312889099121
e:  17   train_loss:  596.4038728745912   time:  1.389272689819336
e:  18   train_loss:  596.6634227646681   time:  1.3970732688903809
e:  19   train_loss:  589.9311758349205   time:  1.3987760543823242
e:  20   train_loss:  595.7457959887023   time:  1.4003088474273682
e:  20   train_loss:  595.7457959887023   val_loss:  596.39631360301   time:  1.6365094184875488
e:  21   train_loss:  588.8874576504032   time:  1.3994827270507812
e:  22   train_loss:  592.548848351698   time:  1.403893232345581
e:  23   train_loss:  594.3039468295958   time:  1.3876161575317383
e:  24   train_loss:  588.0054861244946   time:  1.4017229080200195
e:  25   train_loss:  613.8345018608813   time:  1.3991625308990479
e:  25   train_loss:  613.8345018608813   val_loss:  609.3163489797006   time:  1.504375696182251
e:  26   train_loss:  593.1270901076451   time:  1.4008827209472656
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 5), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 5) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 5) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 5) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 5)
kwargs: {'config': {'batch_norm': True, 'ff_0': 324, 'ff_num_layers': 3, 'gnn_0': 1653, 'gnn_dropout': 0.23286673446355421, 'gnn_num_layers': 1, 'hid_0': 103, 'hid_dropout_rate': 0.33770489723971736, 'in_dropout_rate': 0.2952165136936906, 'lr': 0.0001007677459882193, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 903, 'ff_2': 25, 'hid_1': 121, 'hid_2': 1191}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 737.6342531101889, 'n_epochs': 27.0, 'info': {'validation loss': 737.6342531101889}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 5) started
DEBUG:hpbandster:job_callback for (0, 0, 5) got condition
DEBUG:hpbandster:Only 6 run(s) for budget 27.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 5) finished
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 6) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 6) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 6)
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 6) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 6) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 6)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 36, 'ff_num_layers': 2, 'gnn_0': 66, 'gnn_dropout': 0.07483469321738212, 'gnn_num_layers': 3, 'hid_0': 1455, 'hid_dropout_rate': 0.2246851715661135, 'in_dropout_rate': 0.4826292861135588, 'lr': 0.0002037490116532657, 'num_hid_layers': 2, 'optimizer': 'SGD', 'ff_1': 468, 'gnn_1': 1261, 'gnn_2': 92, 'hid_1': 301, 'sgd_momentum': 0.19699728682544104}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  705.1445301361483   time:  1.6298789978027344
e:  0   train_loss:  705.1445301361483   val_loss:  1673.479102858527   time:  1.7474658489227295
e:  1   train_loss:  701.6893436737979   time:  1.775038242340088
e:  2   train_loss:  697.7323534923663   time:  1.6140780448913574
e:  3   train_loss:  692.8693401115677   time:  1.6090166568756104
e:  4   train_loss:  685.1926278839306   time:  1.6119794845581055
e:  5   train_loss:  672.2306957550929   time:  1.6176912784576416
e:  5   train_loss:  672.2306957550929   val_loss:  1636.842069951266   time:  1.7347736358642578
e:  6   train_loss:  651.5590886826875   time:  1.610060453414917
e:  7   train_loss:  613.6387941342698   time:  1.606835126876831
e:  8   train_loss:  564.5318132107697   time:  1.770247220993042
e:  9   train_loss:  527.8939331227562   time:  1.647463321685791
e:  10   train_loss:  503.35388465609105   time:  1.949092149734497
e:  10   train_loss:  503.35388465609105   val_loss:  1530.5920595802486   time:  2.059008836746216
e:  11   train_loss:  492.3158225481564   time:  1.8480861186981201
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  12   train_loss:  474.7732843516523   time:  1.7101218700408936
e:  13   train_loss:  484.353986237649   time:  1.6311655044555664
e:  14   train_loss:  464.78495123873813   time:  1.7693297863006592
e:  15   train_loss:  459.2100908396468   time:  1.682347059249878
e:  15   train_loss:  459.2100908396468   val_loss:  1419.1145729646485   time:  1.800666332244873
e:  16   train_loss:  459.1694193592392   time:  1.6810009479522705
e:  17   train_loss:  459.27585571227803   time:  1.6152682304382324
e:  18   train_loss:  453.59252107084   time:  1.6006958484649658
e:  19   train_loss:  445.23587093047894   time:  1.7115967273712158
e:  20   train_loss:  446.587771051044   time:  1.6230859756469727
e:  20   train_loss:  446.587771051044   val_loss:  1389.8102071955946   time:  1.8953797817230225
e:  21   train_loss:  444.34793169938723   time:  1.598583459854126
e:  22   train_loss:  444.05891362424336   time:  1.6207749843597412
e:  23   train_loss:  442.47024179706665   time:  1.6101775169372559
e:  24   train_loss:  439.81108812875925   time:  1.6200604438781738
e:  25   train_loss:  439.3369967854477   time:  1.5737459659576416
e:  25   train_loss:  439.3369967854477   val_loss:  1423.450713080887   time:  1.688600778579712
e:  26   train_loss:  437.7932349048938   time:  1.5722119808197021
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1070.3196105617528   time:  1.7573184967041016
e:  0   train_loss:  1070.3196105617528   val_loss:  627.6401491982791   time:  1.8664686679840088
e:  1   train_loss:  1073.4511587335069   time:  1.7545647621154785
e:  2   train_loss:  1069.1316033573194   time:  1.9428930282592773
e:  3   train_loss:  1035.6183684852317   time:  1.7416236400604248
e:  4   train_loss:  945.7334899298291   time:  1.7134594917297363
e:  5   train_loss:  729.0878019592499   time:  1.7626605033874512
e:  5   train_loss:  729.0878019592499   val_loss:  595.3087252090099   time:  1.8717577457427979
e:  6   train_loss:  689.1116097618456   time:  1.7298328876495361
e:  7   train_loss:  660.7165158081971   time:  1.7566392421722412
e:  8   train_loss:  655.6619001188085   time:  1.945366382598877
e:  9   train_loss:  664.3784434695217   time:  1.7577524185180664
e:  10   train_loss:  629.4494673300719   time:  1.756605863571167
e:  10   train_loss:  629.4494673300719   val_loss:  1013.6519953914328   time:  1.8668773174285889
e:  11   train_loss:  620.0559107960412   time:  1.7436869144439697
e:  12   train_loss:  608.4653553786749   time:  1.7494139671325684
e:  13   train_loss:  620.7563891809342   time:  1.7202839851379395
e:  14   train_loss:  603.8868235657233   time:  1.945810317993164
e:  15   train_loss:  603.3190241269763   time:  1.7049586772918701
e:  15   train_loss:  603.3190241269763   val_loss:  832.2809183259816   time:  1.8128106594085693
e:  16   train_loss:  595.8493493634733   time:  1.7591516971588135
e:  17   train_loss:  584.8391582003119   time:  1.7375569343566895
e:  18   train_loss:  582.9432878283784   time:  1.754239559173584
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  19   train_loss:  590.3116756549736   time:  1.774871826171875
e:  20   train_loss:  590.2003633650659   time:  1.7548818588256836
e:  20   train_loss:  590.2003633650659   val_loss:  8517.307193940762   time:  1.8642725944519043
e:  21   train_loss:  598.8181652259987   time:  1.91666841506958
e:  22   train_loss:  594.1525539894152   time:  1.4957489967346191
e:  23   train_loss:  591.5420258572857   time:  1.7170188426971436
e:  24   train_loss:  585.5334526066814   time:  1.7386243343353271
e:  25   train_loss:  585.2076909338739   time:  1.7360436916351318
e:  25   train_loss:  585.2076909338739   val_loss:  822.7025042395029   time:  1.8474555015563965
e:  26   train_loss:  591.5080520903399   time:  1.7434570789337158
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1083.8570473212812   time:  1.7200593948364258
e:  0   train_loss:  1083.8570473212812   val_loss:  536.9039599541334   time:  1.833590030670166
e:  1   train_loss:  1131.2482709014423   time:  1.8635849952697754
e:  2   train_loss:  1105.6103434789102   time:  1.717954397201538
e:  3   train_loss:  1027.541697455833   time:  1.7219347953796387
e:  4   train_loss:  874.4324827717672   time:  1.7195861339569092
e:  5   train_loss:  761.498297789241   time:  1.6349177360534668
e:  5   train_loss:  761.498297789241   val_loss:  513.9053231982537   time:  1.7469654083251953
e:  6   train_loss:  683.6995625077972   time:  1.7060201168060303
e:  7   train_loss:  671.1118305552916   time:  1.7186009883880615
e:  8   train_loss:  658.3999951264365   time:  1.7178981304168701
e:  9   train_loss:  632.2900410562104   time:  1.8608298301696777
e:  10   train_loss:  627.915873537035   time:  1.724046230316162
e:  10   train_loss:  627.915873537035   val_loss:  1028.8469105651325   time:  1.8385858535766602
e:  11   train_loss:  640.9648430992568   time:  1.7242546081542969
e:  12   train_loss:  656.1792611786865   time:  1.7231874465942383
e:  13   train_loss:  634.9447118987388   time:  1.722001552581787
e:  14   train_loss:  632.2611876472837   time:  1.7170259952545166
e:  15   train_loss:  595.3552157468945   time:  1.8397693634033203
e:  15   train_loss:  595.3552157468945   val_loss:  646.4795835413779   time:  1.9534168243408203
e:  16   train_loss:  603.757633918081   time:  1.7158424854278564
e:  17   train_loss:  607.3023034813904   time:  1.7172048091888428
e:  18   train_loss:  599.2894547055597   time:  1.7194130420684814
e:  19   train_loss:  591.8931611276098   time:  1.7825167179107666
e:  20   train_loss:  591.5579399477524   time:  1.762408971786499
e:  20   train_loss:  591.5579399477524   val_loss:  589.7811061690304   time:  1.875368356704712
e:  21   train_loss:  592.6651170622288   time:  1.705461025238037
e:  22   train_loss:  591.4392499847992   time:  1.7473535537719727
e:  23   train_loss:  595.9645066810878   time:  1.7715363502502441
e:  24   train_loss:  602.5434784471262   time:  1.8359456062316895
e:  25   train_loss:  583.5652315606822   time:  1.7565314769744873
e:  25   train_loss:  583.5652315606822   val_loss:  621.1803865094017   time:  1.8838598728179932
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  26   train_loss:  591.3273694504788   time:  1.7343578338623047
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  1000.2548822462298   time:  1.618304967880249
e:  0   train_loss:  1000.2548822462298   val_loss:  916.3892516073512   time:  1.7903852462768555
e:  1   train_loss:  993.4354408159194   time:  1.602546215057373
e:  2   train_loss:  984.302655994524   time:  1.5950829982757568
e:  3   train_loss:  970.6131823438772   time:  1.7616207599639893
e:  4   train_loss:  927.742782090037   time:  1.7551982402801514
e:  5   train_loss:  819.7967021297752   time:  1.6447410583496094
e:  5   train_loss:  819.7967021297752   val_loss:  853.7970616442487   time:  1.7625737190246582
e:  6   train_loss:  706.1038705055805   time:  1.671600341796875
e:  7   train_loss:  655.136315765045   time:  1.6265621185302734
e:  8   train_loss:  641.4961214967688   time:  1.6117730140686035
e:  9   train_loss:  610.5136437195919   time:  1.634556770324707
e:  10   train_loss:  591.085392173243   time:  1.7271091938018799
e:  10   train_loss:  591.085392173243   val_loss:  741.4022365036029   time:  1.84629487991333
e:  11   train_loss:  585.4002806401629   time:  1.6844031810760498
e:  12   train_loss:  577.8210609498035   time:  1.5941507816314697
e:  13   train_loss:  571.0293797551428   time:  1.5606849193572998
e:  14   train_loss:  572.0592868268255   time:  1.6115443706512451
e:  15   train_loss:  567.4051136163523   time:  1.730459451675415
e:  15   train_loss:  567.4051136163523   val_loss:  866.4368721982319   time:  1.8502521514892578
e:  16   train_loss:  563.6749358637825   time:  1.615990400314331
e:  17   train_loss:  561.2331195361434   time:  1.6111245155334473
e:  18   train_loss:  551.8057066781823   time:  1.6078999042510986
e:  19   train_loss:  557.7137345719201   time:  1.6108677387237549
e:  20   train_loss:  554.1379754520325   time:  1.614222526550293
e:  20   train_loss:  554.1379754520325   val_loss:  931.3697768453228   time:  1.7348849773406982
e:  21   train_loss:  549.0509290110144   time:  1.6081392765045166
e:  22   train_loss:  549.3107747424268   time:  1.6058480739593506
e:  23   train_loss:  553.5256528815582   time:  1.612056016921997
e:  24   train_loss:  546.6844753219339   time:  1.7598474025726318
e:  25   train_loss:  553.6845995352486   time:  1.5672833919525146
e:  25   train_loss:  553.6845995352486   val_loss:  756.9343086180266   time:  1.6861214637756348
e:  26   train_loss:  547.9587977992601   time:  1.6082518100738525
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1060.7282376009432   time:  1.7867822647094727
e:  0   train_loss:  1060.7282376009432   val_loss:  688.1571683779264   time:  1.9020812511444092
e:  1   train_loss:  1083.6967721961655   time:  1.9883136749267578
e:  2   train_loss:  1070.0511875372094   time:  1.7162580490112305
e:  3   train_loss:  1005.1075680619264   time:  1.9395554065704346
e:  4   train_loss:  861.1355619809439   time:  1.9686009883880615
e:  5   train_loss:  716.9014929853106   time:  1.7942066192626953
e:  5   train_loss:  716.9014929853106   val_loss:  561.674032995008   time:  1.905745506286621
e:  6   train_loss:  652.5607473800248   time:  1.7457313537597656
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  7   train_loss:  636.7609871510898   time:  1.9254610538482666
e:  8   train_loss:  632.3826162506823   time:  1.864520788192749
e:  9   train_loss:  637.3586699663381   time:  1.7210428714752197
e:  10   train_loss:  616.2364262940523   time:  1.722224473953247
e:  10   train_loss:  616.2364262940523   val_loss:  574.0681579913695   time:  1.836026668548584
e:  11   train_loss:  619.1556875568059   time:  1.893559455871582
e:  12   train_loss:  604.9476952295136   time:  1.7433745861053467
e:  13   train_loss:  615.8667874583111   time:  1.875727891921997
e:  14   train_loss:  603.109188970014   time:  1.782789945602417
e:  15   train_loss:  594.4940437219178   time:  1.7388291358947754
e:  15   train_loss:  594.4940437219178   val_loss:  806.0843473961238   time:  1.8512775897979736
e:  16   train_loss:  608.8289212647861   time:  1.7442548274993896
e:  17   train_loss:  592.3679307452749   time:  1.7410824298858643
e:  18   train_loss:  605.0615346660076   time:  1.8657114505767822
e:  19   train_loss:  604.5735301972462   time:  1.6945528984069824
e:  20   train_loss:  597.3423504393736   time:  1.7010548114776611
e:  20   train_loss:  597.3423504393736   val_loss:  653.663257087222   time:  1.8128688335418701
e:  21   train_loss:  597.3930594031929   time:  1.7436463832855225
e:  22   train_loss:  592.0415790262351   time:  1.776378870010376
e:  23   train_loss:  592.2812516879962   time:  1.815868854522705
e:  24   train_loss:  597.6971984765232   time:  1.826927661895752
e:  25   train_loss:  589.8802582765015   time:  2.11856746673584
e:  25   train_loss:  589.8802582765015   val_loss:  938.2685439321973   time:  2.2289702892303467
e:  26   train_loss:  589.4226093855964   time:  1.8501789569854736
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 6), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 6) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 6) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 6) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 6)
kwargs: {'config': {'batch_norm': True, 'ff_0': 36, 'ff_num_layers': 2, 'gnn_0': 66, 'gnn_dropout': 0.07483469321738212, 'gnn_num_layers': 3, 'hid_0': 1455, 'hid_dropout_rate': 0.2246851715661135, 'in_dropout_rate': 0.4826292861135588, 'lr': 0.0002037490116532657, 'num_hid_layers': 2, 'optimizer': 'SGD', 'ff_1': 468, 'gnn_1': 1261, 'gnn_2': 92, 'hid_1': 301, 'sgd_momentum': 0.19699728682544104}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 760.4201050202938, 'n_epochs': 27.0, 'info': {'validation loss': 760.4201050202938}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 6) started
DEBUG:hpbandster:job_callback for (0, 0, 6) got condition
DEBUG:hpbandster:Only 7 run(s) for budget 27.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:job_callback for (0, 0, 6) finished
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 7) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 7) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 7)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 7) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 7) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 7)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 351, 'ff_num_layers': 1, 'gnn_0': 76, 'gnn_dropout': 0.33786464287987167, 'gnn_num_layers': 3, 'hid_0': 1506, 'hid_dropout_rate': 0.24481989584067265, 'in_dropout_rate': 0.35081274817707464, 'lr': 0.0007822271330631045, 'num_hid_layers': 2, 'optimizer': 'Adam', 'gnn_1': 99, 'gnn_2': 328, 'hid_1': 66}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  669.1584750194768   time:  1.6055004596710205
e:  0   train_loss:  669.1584750194768   val_loss:  1415.6610117805606   time:  1.720646858215332
e:  1   train_loss:  606.1849949883717   time:  1.650686264038086
e:  2   train_loss:  599.3714148224432   time:  1.5951247215270996
e:  3   train_loss:  590.2771315580212   time:  1.5973241329193115
e:  4   train_loss:  585.1415674819107   time:  1.643772840499878
e:  5   train_loss:  576.430020286539   time:  1.7448174953460693
e:  5   train_loss:  576.430020286539   val_loss:  1378.6998566462419   time:  1.8536977767944336
e:  6   train_loss:  566.7286537007308   time:  1.5965766906738281
e:  7   train_loss:  555.030591904382   time:  1.6280641555786133
e:  8   train_loss:  541.0214359822467   time:  1.6149623394012451
e:  9   train_loss:  521.5815341481332   time:  1.5624477863311768
e:  10   train_loss:  503.27345249422405   time:  1.5347626209259033
e:  10   train_loss:  503.27345249422405   val_loss:  1379.4407518939443   time:  1.6507413387298584
e:  11   train_loss:  485.7129530191594   time:  1.593308687210083
e:  12   train_loss:  468.8440589091145   time:  1.6948058605194092
e:  13   train_loss:  452.41192178209707   time:  1.8596713542938232
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  14   train_loss:  442.1245486090337   time:  1.654280424118042
e:  15   train_loss:  433.11211694708874   time:  1.6924519538879395
e:  15   train_loss:  433.11211694708874   val_loss:  1409.656104598642   time:  1.807645559310913
e:  16   train_loss:  427.224806996022   time:  1.5675106048583984
e:  17   train_loss:  426.4649445689376   time:  1.5865869522094727
e:  18   train_loss:  418.9483186671891   time:  1.5827281475067139
e:  19   train_loss:  415.9129822443036   time:  1.618279218673706
e:  20   train_loss:  416.685541446909   time:  1.6581156253814697
e:  20   train_loss:  416.685541446909   val_loss:  1427.909308524918   time:  1.773498296737671
e:  21   train_loss:  415.1217182979552   time:  1.7231378555297852
e:  22   train_loss:  412.2082599915326   time:  1.7309536933898926
e:  23   train_loss:  414.64062314068303   time:  1.568269968032837
e:  24   train_loss:  414.2183480358296   time:  1.5694127082824707
e:  25   train_loss:  410.04159999635976   time:  1.7047150135040283
e:  25   train_loss:  410.04159999635976   val_loss:  1422.2459446373803   time:  1.8137266635894775
e:  26   train_loss:  408.99648625401466   time:  1.5706923007965088
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1022.5423492888084   time:  1.6794383525848389
e:  0   train_loss:  1022.5423492888084   val_loss:  631.0856413828812   time:  1.787024736404419
e:  1   train_loss:  903.6833031281133   time:  1.8524539470672607
e:  2   train_loss:  887.7630419829512   time:  1.8903212547302246
e:  3   train_loss:  860.5213361237027   time:  1.757516860961914
e:  4   train_loss:  799.385872931454   time:  1.741769790649414
e:  5   train_loss:  732.1438386041513   time:  1.9136171340942383
e:  5   train_loss:  732.1438386041513   val_loss:  1083.011304073845   time:  2.023362874984741
e:  6   train_loss:  695.1483540388789   time:  1.7172672748565674
e:  7   train_loss:  677.2257457715302   time:  1.7250127792358398
e:  8   train_loss:  655.0805509024549   time:  1.7429308891296387
e:  9   train_loss:  631.2049608570679   time:  1.723134994506836
e:  10   train_loss:  617.02640359114   time:  1.7248632907867432
e:  10   train_loss:  617.02640359114   val_loss:  866.7401754741928   time:  1.8337123394012451
e:  11   train_loss:  597.9255067850289   time:  1.7278811931610107
e:  12   train_loss:  587.5849421070111   time:  1.8833975791931152
e:  13   train_loss:  580.1100551450803   time:  1.7176158428192139
e:  14   train_loss:  560.8198049019944   time:  1.7376434803009033
e:  15   train_loss:  564.4143033465543   time:  1.7121968269348145
e:  15   train_loss:  564.4143033465543   val_loss:  831.8335346899022   time:  1.8202006816864014
e:  16   train_loss:  561.3415248442493   time:  1.8024487495422363
e:  17   train_loss:  565.3778156925486   time:  1.716301441192627
e:  18   train_loss:  565.5838667638279   time:  1.8797721862792969
e:  19   train_loss:  551.5174002214924   time:  1.718292474746704
e:  20   train_loss:  549.2954957676274   time:  1.8679211139678955
e:  20   train_loss:  549.2954957676274   val_loss:  788.4552084370873   time:  1.998758316040039
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  21   train_loss:  551.4785288939355   time:  2.0025408267974854
e:  22   train_loss:  546.4842187166568   time:  1.9075703620910645
e:  23   train_loss:  543.5564629706059   time:  1.6748764514923096
e:  24   train_loss:  551.7478585243888   time:  1.7072198390960693
e:  25   train_loss:  541.097866752492   time:  1.9630961418151855
e:  25   train_loss:  541.097866752492   val_loss:  846.8042130156603   time:  2.071100950241089
e:  26   train_loss:  546.0937351907534   time:  1.7449960708618164
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1040.9210073999918   time:  1.6596698760986328
e:  0   train_loss:  1040.9210073999918   val_loss:  486.18727876159494   time:  1.7722713947296143
e:  1   train_loss:  925.9454771529674   time:  1.780585765838623
e:  2   train_loss:  1035.1413144079959   time:  1.7360098361968994
e:  3   train_loss:  886.4147645231175   time:  1.7083320617675781
e:  4   train_loss:  853.758252734473   time:  1.9692695140838623
e:  5   train_loss:  846.6635164449885   time:  1.8383631706237793
e:  5   train_loss:  846.6635164449885   val_loss:  505.9966334274805   time:  2.0109522342681885
e:  6   train_loss:  782.6945968345867   time:  1.8380186557769775
e:  7   train_loss:  729.6253830275301   time:  1.6520745754241943
e:  8   train_loss:  702.1715664728564   time:  1.681178092956543
e:  9   train_loss:  669.1688646807017   time:  1.7908263206481934
e:  10   train_loss:  688.3689481269433   time:  1.9703292846679688
e:  10   train_loss:  688.3689481269433   val_loss:  530.1277828413699   time:  2.2096340656280518
e:  11   train_loss:  677.3733869435188   time:  1.6823382377624512
e:  12   train_loss:  630.5886528303122   time:  1.6806707382202148
e:  13   train_loss:  626.038930376033   time:  1.679412603378296
e:  14   train_loss:  634.379285883658   time:  1.702251672744751
e:  15   train_loss:  599.5879631870624   time:  1.9123082160949707
e:  15   train_loss:  599.5879631870624   val_loss:  504.23190410167155   time:  2.0556912422180176
e:  16   train_loss:  600.6741924821949   time:  1.6619501113891602
e:  17   train_loss:  585.953483732847   time:  1.6791815757751465
e:  18   train_loss:  589.4366113197524   time:  1.807401180267334
e:  19   train_loss:  583.9104244198568   time:  1.6827576160430908
e:  20   train_loss:  604.1111290668832   time:  1.6785993576049805
e:  20   train_loss:  604.1111290668832   val_loss:  559.0077857674834   time:  1.7903220653533936
e:  21   train_loss:  598.024729873307   time:  1.6810977458953857
e:  22   train_loss:  582.9272834620897   time:  1.6814661026000977
e:  23   train_loss:  570.350343697112   time:  1.6357808113098145
e:  24   train_loss:  583.8062879624555   time:  1.6220202445983887
e:  25   train_loss:  575.5585648157249   time:  1.816084623336792
e:  25   train_loss:  575.5585648157249   val_loss:  493.1569342228677   time:  1.9274578094482422
e:  26   train_loss:  585.2294149178574   time:  1.682962417602539
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  932.6884754350001   time:  1.5524013042449951
e:  0   train_loss:  932.6884754350001   val_loss:  739.2568781884604   time:  1.6696360111236572
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  1   train_loss:  848.6820327356252   time:  1.5735936164855957
e:  2   train_loss:  837.8183806050458   time:  1.5672571659088135
e:  3   train_loss:  821.8764066148046   time:  1.5775854587554932
e:  4   train_loss:  796.8982421838615   time:  1.5646002292633057
e:  5   train_loss:  758.9963575622738   time:  1.7723262310028076
e:  5   train_loss:  758.9963575622738   val_loss:  713.7804331092117   time:  1.8811700344085693
e:  6   train_loss:  714.0739721032244   time:  1.8088138103485107
e:  7   train_loss:  672.4575633239158   time:  1.5923972129821777
e:  8   train_loss:  640.2602797360837   time:  1.5754764080047607
e:  9   train_loss:  622.403622149056   time:  1.571904182434082
e:  10   train_loss:  608.6518993822173   time:  1.6974992752075195
e:  10   train_loss:  608.6518993822173   val_loss:  699.7781244394259   time:  1.8157904148101807
e:  11   train_loss:  594.5929433142708   time:  1.5705673694610596
e:  12   train_loss:  583.7436166031322   time:  1.5726144313812256
e:  13   train_loss:  569.2652410403906   time:  1.5704514980316162
e:  14   train_loss:  558.8907236743871   time:  1.5354492664337158
e:  15   train_loss:  548.989179658891   time:  1.5239777565002441
e:  15   train_loss:  548.989179658891   val_loss:  694.5442715153113   time:  1.6413953304290771
e:  16   train_loss:  547.4449521406435   time:  1.5678343772888184
e:  17   train_loss:  542.6891852719714   time:  1.5701472759246826
e:  18   train_loss:  542.1300956654078   time:  1.5677838325500488
e:  19   train_loss:  536.5948066688844   time:  1.6961307525634766
e:  20   train_loss:  533.1692164772512   time:  1.5677275657653809
e:  20   train_loss:  533.1692164772512   val_loss:  705.1813828691804   time:  1.6844677925109863
e:  21   train_loss:  538.2652708876132   time:  1.5697035789489746
e:  22   train_loss:  535.9889755096368   time:  1.5703725814819336
e:  23   train_loss:  533.036909988477   time:  1.5678551197052002
e:  24   train_loss:  531.268704480206   time:  1.5665667057037354
e:  25   train_loss:  528.8562408681753   time:  1.566558837890625
e:  25   train_loss:  528.8562408681753   val_loss:  718.3458684282834   time:  1.6836340427398682
e:  26   train_loss:  532.2084968369186   time:  1.6364736557006836
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1005.4399213025811   time:  1.856665849685669
e:  0   train_loss:  1005.4399213025811   val_loss:  573.3385603301174   time:  1.9653141498565674
e:  1   train_loss:  900.5055434425603   time:  1.821258544921875
e:  2   train_loss:  887.2303925391067   time:  1.8706996440887451
e:  3   train_loss:  870.3804766342566   time:  1.7975022792816162
e:  4   train_loss:  818.992670433059   time:  1.8665320873260498
e:  5   train_loss:  770.8434314840365   time:  1.7317471504211426
e:  5   train_loss:  770.8434314840365   val_loss:  573.083313379436   time:  1.839010238647461
e:  6   train_loss:  724.376613820683   time:  1.8251266479492188
e:  7   train_loss:  675.784823816722   time:  1.956120252609253
e:  8   train_loss:  656.5251718522399   time:  1.9255561828613281
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  9   train_loss:  657.997952755855   time:  1.706202507019043
e:  10   train_loss:  627.444532628338   time:  1.703294277191162
e:  10   train_loss:  627.444532628338   val_loss:  566.4351393731561   time:  1.8139216899871826
e:  11   train_loss:  623.9982548897756   time:  1.6999990940093994
e:  12   train_loss:  596.9646082523109   time:  1.7054011821746826
e:  13   train_loss:  595.452649963016   time:  1.786909818649292
e:  14   train_loss:  593.7376146649528   time:  1.872201681137085
e:  15   train_loss:  590.0220706742243   time:  1.694584846496582
e:  15   train_loss:  590.0220706742243   val_loss:  573.6295376500318   time:  1.8032312393188477
e:  16   train_loss:  581.8785935618849   time:  1.7178034782409668
e:  17   train_loss:  586.7933200389809   time:  1.7037734985351562
e:  18   train_loss:  578.2365997996479   time:  1.7066795825958252
e:  19   train_loss:  574.6526526442794   time:  1.7042417526245117
e:  20   train_loss:  571.9963851686039   time:  1.7082102298736572
e:  20   train_loss:  571.9963851686039   val_loss:  573.0789582215846   time:  1.8176031112670898
e:  21   train_loss:  567.4908966100004   time:  1.8551883697509766
e:  22   train_loss:  574.6665801600251   time:  1.6354644298553467
e:  23   train_loss:  572.8414051791337   time:  1.6924355030059814
e:  24   train_loss:  568.7012048220445   time:  1.705467939376831
e:  25   train_loss:  559.5176692720411   time:  1.7011396884918213
e:  25   train_loss:  559.5176692720411   val_loss:  581.4810629376586   time:  1.81138277053833
e:  26   train_loss:  566.9798050520296   time:  1.7060582637786865
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 7), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 7) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 7) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 7) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 7)
kwargs: {'config': {'batch_norm': False, 'ff_0': 351, 'ff_num_layers': 1, 'gnn_0': 76, 'gnn_dropout': 0.33786464287987167, 'gnn_num_layers': 3, 'hid_0': 1506, 'hid_dropout_rate': 0.24481989584067265, 'in_dropout_rate': 0.35081274817707464, 'lr': 0.0007822271330631045, 'num_hid_layers': 2, 'optimizer': 'Adam', 'gnn_1': 99, 'gnn_2': 328, 'hid_1': 66}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 751.390437535837, 'n_epochs': 27.0, 'info': {'validation loss': 751.390437535837}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 7) started
DEBUG:hpbandster:job_callback for (0, 0, 7) got condition
DEBUG:hpbandster:Only 8 run(s) for budget 27.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 7) finished
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 8) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 8) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 8)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 8) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 8) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 8)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 333, 'ff_num_layers': 2, 'gnn_0': 883, 'gnn_dropout': 0.4721198668347737, 'gnn_num_layers': 2, 'hid_0': 740, 'hid_dropout_rate': 0.3223703964163512, 'in_dropout_rate': 0.34241713738218177, 'lr': 0.00012267994908297922, 'num_hid_layers': 2, 'optimizer': 'SGD', 'ff_1': 183, 'gnn_1': 172, 'hid_1': 339, 'sgd_momentum': 0.5796323574619938}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  704.7917755852773   time:  1.4668290615081787
e:  0   train_loss:  704.7917755852773   val_loss:  1671.654127592458   time:  1.5789923667907715
e:  1   train_loss:  701.8201633462149   time:  1.6545064449310303
e:  2   train_loss:  699.1199657561185   time:  1.4054481983184814
e:  3   train_loss:  696.4620435765867   time:  1.3996632099151611
e:  4   train_loss:  692.6079880291381   time:  1.3991711139678955
e:  5   train_loss:  687.5513136411032   time:  1.4005742073059082
e:  5   train_loss:  687.5513136411032   val_loss:  1640.048039109243   time:  1.5120158195495605
e:  6   train_loss:  678.8222352041522   time:  1.44321870803833
e:  7   train_loss:  666.9190032134486   time:  1.390026569366455
e:  8   train_loss:  647.8449955133343   time:  1.4009065628051758
e:  9   train_loss:  621.3975679008156   time:  1.3929667472839355
e:  10   train_loss:  590.3222329923101   time:  1.3994708061218262
e:  10   train_loss:  590.3222329923101   val_loss:  1464.037938343774   time:  1.5116634368896484
e:  11   train_loss:  567.1011002221752   time:  1.5313541889190674
e:  12   train_loss:  544.6045282194302   time:  1.442699909210205
e:  13   train_loss:  528.5873175033191   time:  1.5173094272613525
e:  14   train_loss:  515.1209221415223   time:  1.426853895187378
e:  15   train_loss:  511.6221294516228   time:  1.387096881866455
e:  15   train_loss:  511.6221294516228   val_loss:  1431.8825899489937   time:  1.4996764659881592
e:  16   train_loss:  497.74552477543443   time:  1.4414281845092773
e:  17   train_loss:  500.00115592012   time:  1.4376835823059082
e:  18   train_loss:  489.77201042111597   time:  1.4180078506469727
e:  19   train_loss:  484.6308865336195   time:  1.4240944385528564
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  20   train_loss:  480.1408416874353   time:  1.430180311203003
e:  20   train_loss:  480.1408416874353   val_loss:  1410.205043886908   time:  1.7249245643615723
e:  21   train_loss:  485.35091333416676   time:  1.4248974323272705
e:  22   train_loss:  482.15198447491196   time:  1.4311892986297607
e:  23   train_loss:  462.42756953982234   time:  1.4276835918426514
e:  24   train_loss:  467.86430380053594   time:  1.4235186576843262
e:  25   train_loss:  467.3329728309086   time:  1.42490553855896
e:  25   train_loss:  467.3329728309086   val_loss:  1536.3801005015337   time:  1.5367522239685059
e:  26   train_loss:  467.443552615519   time:  1.4415130615234375
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1090.2846789338698   time:  1.567415475845337
e:  0   train_loss:  1090.2846789338698   val_loss:  625.310621871323   time:  1.6750836372375488
e:  1   train_loss:  1077.8597943529567   time:  1.7878150939941406
e:  2   train_loss:  1057.623304951513   time:  1.7893249988555908
e:  3   train_loss:  1059.5137777583855   time:  1.5841703414916992
e:  4   train_loss:  1051.502917155409   time:  1.6177265644073486
e:  5   train_loss:  973.0371731320533   time:  1.5520730018615723
e:  5   train_loss:  973.0371731320533   val_loss:  567.7441770008975   time:  1.65732741355896
e:  6   train_loss:  837.7170288960466   time:  1.539011001586914
e:  7   train_loss:  723.006995577358   time:  1.499800443649292
e:  8   train_loss:  695.0277889175077   time:  1.71217942237854
e:  9   train_loss:  670.9186445726211   time:  1.551971435546875
e:  10   train_loss:  659.7271292469991   time:  1.547203779220581
e:  10   train_loss:  659.7271292469991   val_loss:  2157.4397857866957   time:  1.6528327465057373
e:  11   train_loss:  666.6494650212001   time:  1.5674552917480469
e:  12   train_loss:  651.3467569349829   time:  1.6990008354187012
e:  13   train_loss:  645.4420425919191   time:  1.6482243537902832
e:  14   train_loss:  624.733229624343   time:  1.6437900066375732
e:  15   train_loss:  617.131373396499   time:  1.7400426864624023
e:  15   train_loss:  617.131373396499   val_loss:  661.4743318925468   time:  1.8446815013885498
e:  16   train_loss:  611.1798145533392   time:  1.5446209907531738
e:  17   train_loss:  616.8614411131188   time:  1.543135643005371
e:  18   train_loss:  612.5963413041904   time:  1.5359406471252441
e:  19   train_loss:  611.6151530124979   time:  1.5449507236480713
e:  20   train_loss:  609.3288201781386   time:  1.545670747756958
e:  20   train_loss:  609.3288201781386   val_loss:  879.9211744644409   time:  1.652359962463379
e:  21   train_loss:  609.6233502563986   time:  1.5666923522949219
e:  22   train_loss:  606.8246538525871   time:  1.7145061492919922
e:  23   train_loss:  611.446068121051   time:  1.547443151473999
e:  24   train_loss:  599.8106082277784   time:  1.55271577835083
e:  25   train_loss:  596.3995995747232   time:  1.527677297592163
e:  25   train_loss:  596.3995995747232   val_loss:  647.3617952397288   time:  1.6332440376281738
e:  26   train_loss:  604.1361846962934   time:  1.5144422054290771
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1081.4203522683738   time:  1.5256409645080566
e:  0   train_loss:  1081.4203522683738   val_loss:  538.0438776417005   time:  1.6335468292236328
e:  1   train_loss:  1065.3653647982756   time:  1.7063894271850586
e:  2   train_loss:  1068.1387099145452   time:  1.5255348682403564
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  3   train_loss:  1066.1719996882036   time:  1.5385181903839111
e:  4   train_loss:  1045.352142491847   time:  1.5584344863891602
e:  5   train_loss:  1035.7559223018818   time:  1.52347993850708
e:  5   train_loss:  1035.7559223018818   val_loss:  505.45424098433756   time:  1.6323721408843994
e:  6   train_loss:  876.7263202611025   time:  1.5218226909637451
e:  7   train_loss:  767.7572011509423   time:  1.7758431434631348
e:  8   train_loss:  717.5759119752578   time:  1.6232566833496094
e:  9   train_loss:  713.6533710722949   time:  1.787691593170166
e:  10   train_loss:  690.9068528234031   time:  1.5665767192840576
e:  10   train_loss:  690.9068528234031   val_loss:  1540.6535203383771   time:  1.6752526760101318
e:  11   train_loss:  669.8582266545299   time:  1.5694866180419922
e:  12   train_loss:  679.4747085968278   time:  1.56789231300354
e:  13   train_loss:  672.1746379075731   time:  1.586333990097046
e:  14   train_loss:  645.8977966239912   time:  1.5724728107452393
e:  15   train_loss:  635.8412669959462   time:  1.5636672973632812
e:  15   train_loss:  635.8412669959462   val_loss:  1368.0481860446068   time:  1.6723124980926514
e:  16   train_loss:  644.3272006806917   time:  1.7798688411712646
e:  17   train_loss:  641.1733141678227   time:  1.523926019668579
e:  18   train_loss:  656.4829069144195   time:  1.5558416843414307
e:  19   train_loss:  647.2033260521038   time:  1.5582091808319092
e:  20   train_loss:  633.3770055848928   time:  1.5638468265533447
e:  20   train_loss:  633.3770055848928   val_loss:  537.7541235367315   time:  1.6716101169586182
e:  21   train_loss:  627.9247913823618   time:  1.5664341449737549
e:  22   train_loss:  625.4855965880048   time:  1.5662744045257568
e:  23   train_loss:  644.8691532529142   time:  1.5935828685760498
e:  24   train_loss:  614.0973225439078   time:  1.782344102859497
e:  25   train_loss:  621.615681988081   time:  1.565821647644043
e:  25   train_loss:  621.615681988081   val_loss:  564.9851553152976   time:  1.67344331741333
e:  26   train_loss:  636.9734897933181   time:  1.566556453704834
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  1000.353730922109   time:  1.6013157367706299
e:  0   train_loss:  1000.353730922109   val_loss:  916.645154761308   time:  1.7164456844329834
e:  1   train_loss:  998.12617086716   time:  1.4583351612091064
e:  2   train_loss:  990.3061570427   time:  1.4517266750335693
e:  3   train_loss:  981.2277125789062   time:  1.45997953414917
e:  4   train_loss:  970.5271342573226   time:  1.4524223804473877
e:  5   train_loss:  953.8649906420051   time:  1.4607853889465332
e:  5   train_loss:  953.8649906420051   val_loss:  874.7391603744495   time:  1.5740487575531006
e:  6   train_loss:  918.1173568744123   time:  1.4564716815948486
e:  7   train_loss:  848.718028271107   time:  1.4591763019561768
e:  8   train_loss:  731.949256206038   time:  1.6559128761291504
e:  9   train_loss:  680.7241099647601   time:  1.416417121887207
e:  10   train_loss:  650.8735488712617   time:  1.4392337799072266
e:  10   train_loss:  650.8735488712617   val_loss:  759.8814004928796   time:  1.5528416633605957
e:  11   train_loss:  637.9530208312533   time:  1.5537025928497314
e:  12   train_loss:  622.4029184753632   time:  1.5636382102966309
e:  13   train_loss:  607.8955628063467   time:  1.7149548530578613
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  14   train_loss:  605.3181680531802   time:  1.4527909755706787
e:  15   train_loss:  608.2398383331803   time:  1.4562761783599854
e:  15   train_loss:  608.2398383331803   val_loss:  759.533650108508   time:  1.5695490837097168
e:  16   train_loss:  588.6304783349212   time:  1.4580812454223633
e:  17   train_loss:  611.3251752274974   time:  1.4564638137817383
e:  18   train_loss:  586.5478230410408   time:  1.455620288848877
e:  19   train_loss:  585.039360471768   time:  1.4551153182983398
e:  20   train_loss:  585.5885284328696   time:  1.4542467594146729
e:  20   train_loss:  585.5885284328696   val_loss:  858.0575307817348   time:  1.7626042366027832
e:  21   train_loss:  594.3709647848106   time:  1.4562726020812988
e:  22   train_loss:  580.0643660744645   time:  1.67529296875
e:  23   train_loss:  585.8266439169953   time:  1.6399595737457275
e:  24   train_loss:  571.6842786075447   time:  1.4794197082519531
e:  25   train_loss:  575.0178688923161   time:  1.4803330898284912
e:  25   train_loss:  575.0178688923161   val_loss:  824.7578095542314   time:  1.5922935009002686
e:  26   train_loss:  574.5623007273892   time:  1.482560157775879
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1097.3389423488838   time:  1.612192153930664
e:  0   train_loss:  1097.3389423488838   val_loss:  688.3298113409959   time:  1.718282699584961
e:  1   train_loss:  1070.6842000185804   time:  1.6459994316101074
e:  2   train_loss:  1039.3427410702982   time:  1.8365511894226074
e:  3   train_loss:  1053.8568172692378   time:  1.6130330562591553
e:  4   train_loss:  1037.451219506845   time:  1.5964956283569336
e:  5   train_loss:  978.9764867635723   time:  1.5848252773284912
e:  5   train_loss:  978.9764867635723   val_loss:  628.9762749855307   time:  1.6914784908294678
e:  6   train_loss:  875.5137111278458   time:  1.5691699981689453
e:  7   train_loss:  741.9042479962341   time:  1.5949819087982178
e:  8   train_loss:  695.2666233258108   time:  1.793102741241455
e:  9   train_loss:  683.2073141819809   time:  1.590320348739624
e:  10   train_loss:  665.5336848697336   time:  1.5784423351287842
e:  10   train_loss:  665.5336848697336   val_loss:  634.4931563030159   time:  1.6847009658813477
e:  11   train_loss:  674.9986944292084   time:  1.5818216800689697
e:  12   train_loss:  663.5017425135098   time:  1.5805368423461914
e:  13   train_loss:  651.1681913579079   time:  1.596275806427002
e:  14   train_loss:  632.800544018425   time:  1.6013429164886475
e:  15   train_loss:  634.4973311657852   time:  1.84822678565979
e:  15   train_loss:  634.4973311657852   val_loss:  648.901049531569   time:  1.9544994831085205
e:  16   train_loss:  620.5681156869546   time:  1.6056244373321533
e:  17   train_loss:  628.3766046489986   time:  1.608809471130371
e:  18   train_loss:  620.5732185083492   time:  1.6083745956420898
e:  19   train_loss:  616.4225937792608   time:  1.5921473503112793
e:  20   train_loss:  629.5761043225656   time:  1.598534345626831
e:  20   train_loss:  629.5761043225656   val_loss:  646.5205874798128   time:  1.7050559520721436
e:  21   train_loss:  611.6548278952188   time:  1.6273510456085205
e:  22   train_loss:  625.184641522128   time:  1.835134744644165
e:  23   train_loss:  629.5599758206289   time:  1.5992872714996338
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  24   train_loss:  609.764371801186   time:  1.5979986190795898
e:  25   train_loss:  621.8736462786361   time:  1.5997793674468994
e:  25   train_loss:  621.8736462786361   val_loss:  642.0082340820056   time:  1.7063536643981934
e:  26   train_loss:  621.6843281467784   time:  1.5976543426513672
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 8), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 8) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 8) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 8) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 8)
kwargs: {'config': {'batch_norm': True, 'ff_0': 333, 'ff_num_layers': 2, 'gnn_0': 883, 'gnn_dropout': 0.4721198668347737, 'gnn_num_layers': 2, 'hid_0': 740, 'hid_dropout_rate': 0.3223703964163512, 'in_dropout_rate': 0.34241713738218177, 'lr': 0.00012267994908297922, 'num_hid_layers': 2, 'optimizer': 'SGD', 'ff_1': 183, 'gnn_1': 172, 'hid_1': 339, 'sgd_momentum': 0.5796323574619938}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 774.3826773932363, 'n_epochs': 27.0, 'info': {'validation loss': 774.3826773932363}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 8) started
DEBUG:hpbandster:job_callback for (0, 0, 8) got condition
DEBUG:hpbandster:Only 9 run(s) for budget 27.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 8) finished
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 9) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 9) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 9)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 9) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 9) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 9)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 335, 'ff_num_layers': 2, 'gnn_0': 1453, 'gnn_dropout': 0.22102438194645968, 'gnn_num_layers': 2, 'hid_0': 1457, 'hid_dropout_rate': 0.2512213720771454, 'in_dropout_rate': 0.20085035908813104, 'lr': 7.827393907381799e-05, 'num_hid_layers': 3, 'optimizer': 'SGD', 'ff_1': 1425, 'gnn_1': 71, 'hid_1': 749, 'hid_2': 124, 'sgd_momentum': 0.19500952581934372}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  706.5181576067096   time:  1.794616460800171
e:  0   train_loss:  706.5181576067096   val_loss:  1676.7159374883163   time:  2.006481409072876
e:  1   train_loss:  706.3176318528338   time:  1.8230535984039307
e:  2   train_loss:  706.2336556502286   time:  1.9656944274902344
e:  3   train_loss:  705.7152793140815   time:  1.8148815631866455
e:  4   train_loss:  704.5042822163938   time:  1.7894797325134277
e:  5   train_loss:  704.7059707307172   time:  1.7872648239135742
e:  5   train_loss:  704.7059707307172   val_loss:  1672.8851282037142   time:  1.925433874130249
e:  6   train_loss:  704.215455400455   time:  1.7912073135375977
e:  7   train_loss:  703.9194045744376   time:  1.7675600051879883
e:  8   train_loss:  703.0229069462038   time:  1.7656893730163574
e:  9   train_loss:  703.0989636898694   time:  1.6980338096618652
e:  10   train_loss:  701.5429199432026   time:  1.7120826244354248
e:  10   train_loss:  701.5429199432026   val_loss:  1669.07293062836   time:  1.8311982154846191
e:  11   train_loss:  701.8795947963447   time:  1.7752742767333984
e:  12   train_loss:  701.5148609594321   time:  1.7673611640930176
e:  13   train_loss:  700.8229228385744   time:  1.961667537689209
e:  14   train_loss:  701.7757318447793   time:  1.7500150203704834
e:  15   train_loss:  700.1065840699983   time:  1.7871270179748535
e:  15   train_loss:  700.1065840699983   val_loss:  1665.2281411613797   time:  1.9068212509155273
e:  16   train_loss:  699.9121705760464   time:  1.7271997928619385
e:  17   train_loss:  700.1917026997535   time:  1.7462570667266846
e:  18   train_loss:  699.1116491084085   time:  1.7447335720062256
e:  19   train_loss:  697.7127953544128   time:  1.733271598815918
e:  20   train_loss:  698.2622412884102   time:  1.7482678890228271
e:  20   train_loss:  698.2622412884102   val_loss:  1661.2772057108507   time:  1.8684568405151367
e:  21   train_loss:  696.9946813487317   time:  1.8148698806762695
e:  22   train_loss:  697.6568159077518   time:  2.0570881366729736
e:  23   train_loss:  697.4868726601642   time:  1.77964448928833
e:  24   train_loss:  696.1172123251213   time:  1.7564146518707275
e:  25   train_loss:  695.3344375269556   time:  1.7631583213806152
e:  25   train_loss:  695.3344375269556   val_loss:  1657.0763044641285   time:  1.880584478378296
e:  26   train_loss:  695.9014109576624   time:  1.6659271717071533
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1088.6703877360478   time:  1.8974518775939941
e:  0   train_loss:  1088.6703877360478   val_loss:  628.6832828107327   time:  2.0090558528900146
e:  1   train_loss:  1084.4730014533789   time:  1.9093284606933594
e:  2   train_loss:  1079.0474215764289   time:  1.918398141860962
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  3   train_loss:  1076.4524477497466   time:  2.1038055419921875
e:  4   train_loss:  1069.4502469014888   time:  1.9046828746795654
e:  5   train_loss:  1070.8761244956243   time:  1.875699520111084
e:  5   train_loss:  1070.8761244956243   val_loss:  625.7312233801428   time:  1.9877362251281738
e:  6   train_loss:  1068.7985133119907   time:  1.8959064483642578
e:  7   train_loss:  1081.0110781908725   time:  1.8808567523956299
e:  8   train_loss:  1075.1368160570983   time:  1.964543104171753
e:  9   train_loss:  1068.860149221356   time:  2.213926315307617
e:  10   train_loss:  1078.8045269002507   time:  1.92018723487854
e:  10   train_loss:  1078.8045269002507   val_loss:  622.8034971073146   time:  2.0309927463531494
e:  11   train_loss:  1089.4162063411832   time:  1.9092931747436523
e:  12   train_loss:  1074.4281476716287   time:  1.869476556777954
e:  13   train_loss:  1067.386624565268   time:  1.9098014831542969
e:  14   train_loss:  1069.9297293997222   time:  1.9060890674591064
e:  15   train_loss:  1085.8741530658888   time:  1.9189763069152832
e:  15   train_loss:  1085.8741530658888   val_loss:  619.7358622392618   time:  2.032088041305542
e:  16   train_loss:  1057.3122646863428   time:  2.2010273933410645
e:  17   train_loss:  1070.3688492044328   time:  2.0160305500030518
e:  18   train_loss:  1069.269876919713   time:  1.9145755767822266
e:  19   train_loss:  1057.8935991786218   time:  1.9066340923309326
e:  20   train_loss:  1049.8280837013917   time:  1.9022893905639648
e:  20   train_loss:  1049.8280837013917   val_loss:  616.2622411653543   time:  2.0144379138946533
e:  21   train_loss:  1070.8064349784975   time:  1.9130396842956543
e:  22   train_loss:  1067.444809610287   time:  1.9072751998901367
e:  23   train_loss:  1066.294581656246   time:  2.0668296813964844
e:  24   train_loss:  1087.0526854709822   time:  1.9063854217529297
e:  25   train_loss:  1078.39964870326   time:  1.8321897983551025
e:  25   train_loss:  1078.39964870326   val_loss:  611.7641231901796   time:  1.9424858093261719
e:  26   train_loss:  1069.450802654111   time:  1.9064908027648926
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1087.1225078954308   time:  1.8803517818450928
e:  0   train_loss:  1087.1225078954308   val_loss:  540.1939127078513   time:  1.995471477508545
e:  1   train_loss:  1078.704944474485   time:  1.8804361820220947
e:  2   train_loss:  1117.6622210140922   time:  2.0080018043518066
e:  3   train_loss:  1067.8494484747962   time:  1.8053991794586182
e:  4   train_loss:  1069.8342658467218   time:  1.8825023174285889
e:  5   train_loss:  1107.1932384117817   time:  1.8733665943145752
e:  5   train_loss:  1107.1932384117817   val_loss:  537.4375453948318   time:  1.9880869388580322
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  6   train_loss:  1066.7006287819231   time:  1.8739097118377686
e:  7   train_loss:  1077.7499487154596   time:  1.8273093700408936
e:  8   train_loss:  1073.4369140043596   time:  1.8635919094085693
e:  9   train_loss:  1059.86387026188   time:  1.8730871677398682
e:  10   train_loss:  1148.8993922571244   time:  2.1177141666412354
e:  10   train_loss:  1148.8993922571244   val_loss:  534.6983241855534   time:  2.2255401611328125
e:  11   train_loss:  1069.1719795919837   time:  2.0159215927124023
e:  12   train_loss:  1068.8445361831782   time:  1.886950969696045
e:  13   train_loss:  1113.4185263050258   time:  1.8475520610809326
e:  14   train_loss:  1058.4006611017128   time:  1.8319191932678223
e:  15   train_loss:  1075.2259450503898   time:  1.8350558280944824
e:  15   train_loss:  1075.2259450503898   val_loss:  531.6642708948453   time:  1.9507153034210205
e:  16   train_loss:  1072.7193713431996   time:  1.825953722000122
e:  17   train_loss:  1144.074404999171   time:  1.831202745437622
e:  18   train_loss:  1079.2589722964783   time:  1.910161018371582
e:  19   train_loss:  1058.8968570945356   time:  1.8947808742523193
e:  20   train_loss:  1057.3522767754148   time:  1.8810575008392334
e:  20   train_loss:  1057.3522767754148   val_loss:  527.8477776704627   time:  1.9954586029052734
e:  21   train_loss:  1110.1543251447301   time:  1.887962818145752
e:  22   train_loss:  1088.919226628308   time:  1.92930006980896
e:  23   train_loss:  1067.4028025732034   time:  1.811877965927124
e:  24   train_loss:  1053.4994581741953   time:  1.8097693920135498
e:  25   train_loss:  1050.3913170956548   time:  1.7795343399047852
e:  25   train_loss:  1050.3913170956548   val_loss:  521.9557137644772   time:  2.054457187652588
e:  26   train_loss:  1063.7475748504662   time:  1.8266282081604004
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  998.527761410547   time:  1.694378137588501
e:  0   train_loss:  998.527761410547   val_loss:  916.6264498715901   time:  1.8155858516693115
e:  1   train_loss:  997.0451913125514   time:  1.7084741592407227
e:  2   train_loss:  997.6395782114006   time:  1.7100896835327148
e:  3   train_loss:  1000.3514239606967   time:  1.7069134712219238
e:  4   train_loss:  994.0156044745463   time:  1.7083301544189453
e:  5   train_loss:  994.5624889725525   time:  1.7029399871826172
e:  5   train_loss:  994.5624889725525   val_loss:  913.1558549247566   time:  1.824531078338623
e:  6   train_loss:  995.005088569058   time:  1.698908805847168
e:  7   train_loss:  992.2411829214568   time:  1.7909245491027832
e:  8   train_loss:  993.7185371162119   time:  1.6557960510253906
e:  9   train_loss:  993.437857575241   time:  1.7140707969665527
e:  10   train_loss:  992.4850575120224   time:  1.7256507873535156
e:  10   train_loss:  992.4850575120224   val_loss:  909.6941711675789   time:  1.8442432880401611
e:  11   train_loss:  992.5277852091042   time:  1.6369147300720215
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  12   train_loss:  987.0463267891771   time:  1.7000811100006104
e:  13   train_loss:  990.3425634856449   time:  1.7080461978912354
e:  14   train_loss:  985.3038866302009   time:  1.704639196395874
e:  15   train_loss:  990.0389818083602   time:  1.7501134872436523
e:  15   train_loss:  990.0389818083602   val_loss:  906.0771176041903   time:  1.9398388862609863
e:  16   train_loss:  987.4516420156749   time:  1.7253146171569824
e:  17   train_loss:  987.8041611280269   time:  1.7156922817230225
e:  18   train_loss:  986.9241893938681   time:  1.8597350120544434
e:  19   train_loss:  986.4662158762993   time:  1.6384596824645996
e:  20   train_loss:  983.5073600954773   time:  1.6766610145568848
e:  20   train_loss:  983.5073600954773   val_loss:  902.0019771889596   time:  1.7978062629699707
e:  21   train_loss:  986.1746359996749   time:  1.7093334197998047
e:  22   train_loss:  982.5547324384374   time:  1.7042367458343506
e:  23   train_loss:  981.0951908053366   time:  1.7008376121520996
e:  24   train_loss:  978.7809021987754   time:  1.6584274768829346
e:  25   train_loss:  979.2247029047608   time:  1.6390490531921387
e:  25   train_loss:  979.2247029047608   val_loss:  896.9737490830709   time:  1.7596540451049805
e:  26   train_loss:  978.1632414815399   time:  1.6709609031677246
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1065.8743592933274   time:  1.8469369411468506
e:  0   train_loss:  1065.8743592933274   val_loss:  688.7593450786164   time:  1.9594221115112305
e:  1   train_loss:  1057.408600329058   time:  1.85772705078125
e:  2   train_loss:  1081.6979622333808   time:  2.0306782722473145
e:  3   train_loss:  1053.5315723317528   time:  1.7693018913269043
e:  4   train_loss:  1066.2047313198925   time:  1.8265466690063477
e:  5   train_loss:  1072.63507016331   time:  1.8498773574829102
e:  5   train_loss:  1072.63507016331   val_loss:  685.0423339998694   time:  1.9615163803100586
e:  6   train_loss:  1069.4976983655226   time:  1.7721755504608154
e:  7   train_loss:  1063.6813182545422   time:  1.8003859519958496
e:  8   train_loss:  1067.718047073877   time:  1.9956917762756348
e:  9   train_loss:  1068.462673065808   time:  1.85176420211792
e:  10   train_loss:  1070.5905036796476   time:  1.8480510711669922
e:  10   train_loss:  1070.5905036796476   val_loss:  681.2811912426416   time:  1.9605886936187744
e:  11   train_loss:  1069.4543941696143   time:  1.8486733436584473
e:  12   train_loss:  1068.7566764967833   time:  1.8181238174438477
e:  13   train_loss:  1063.3942626317314   time:  1.7881138324737549
e:  14   train_loss:  1057.158057764574   time:  1.9480786323547363
e:  15   train_loss:  1082.1115270300168   time:  1.847527265548706
e:  15   train_loss:  1082.1115270300168   val_loss:  677.0940705645876   time:  1.960883617401123
e:  16   train_loss:  1063.8076301819042   time:  1.8463146686553955
e:  17   train_loss:  1042.3838262472748   time:  1.949239730834961
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  18   train_loss:  1065.9050641340305   time:  1.931715726852417
e:  19   train_loss:  1042.3164755595046   time:  1.8178002834320068
e:  20   train_loss:  1073.5762706342148   time:  1.9257488250732422
e:  20   train_loss:  1073.5762706342148   val_loss:  671.7215887240478   time:  2.038738250732422
e:  21   train_loss:  1056.0554630331023   time:  1.8154363632202148
e:  22   train_loss:  1068.0266378870358   time:  1.818817377090454
e:  23   train_loss:  1043.575459088773   time:  1.8140108585357666
e:  24   train_loss:  1043.8039812339493   time:  1.815850019454956
e:  25   train_loss:  1057.2889083511152   time:  2.2582643032073975
e:  25   train_loss:  1057.2889083511152   val_loss:  662.9540882255582   time:  2.3636715412139893
e:  26   train_loss:  1039.5033128164953   time:  1.9177141189575195
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 9), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 9) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 9) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 9) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 9)
kwargs: {'config': {'batch_norm': False, 'ff_0': 335, 'ff_num_layers': 2, 'gnn_0': 1453, 'gnn_dropout': 0.22102438194645968, 'gnn_num_layers': 2, 'hid_0': 1457, 'hid_dropout_rate': 0.2512213720771454, 'in_dropout_rate': 0.20085035908813104, 'lr': 7.827393907381799e-05, 'num_hid_layers': 3, 'optimizer': 'SGD', 'ff_1': 1425, 'gnn_1': 71, 'hid_1': 749, 'hid_2': 124, 'sgd_momentum': 0.19500952581934372}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 870.1447957454827, 'n_epochs': 27.0, 'info': {'validation loss': 870.1447957454827}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 9) started
DEBUG:hpbandster:job_callback for (0, 0, 9) got condition
DEBUG:hpbandster:Only 10 run(s) for budget 27.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 9) finished
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 10) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 10) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 10)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 10) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 10) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 10)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 39, 'ff_num_layers': 2, 'gnn_0': 71, 'gnn_dropout': 0.4680205928046692, 'gnn_num_layers': 2, 'hid_0': 253, 'hid_dropout_rate': 0.33231583631114886, 'in_dropout_rate': 0.4318697065068356, 'lr': 0.00790707314326263, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 235, 'gnn_1': 488, 'hid_1': 215, 'hid_2': 1034}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  935.5739688441708   time:  1.5361804962158203
e:  0   train_loss:  935.5739688441708   val_loss:  1670.475678371371   time:  1.6447744369506836
e:  1   train_loss:  686.8586402775215   time:  1.3237221240997314
e:  2   train_loss:  630.0903039202636   time:  1.3219656944274902
e:  3   train_loss:  610.2939083212992   time:  1.384087324142456
e:  4   train_loss:  590.139727468611   time:  1.350980520248413
e:  5   train_loss:  568.7485419994811   time:  1.3203628063201904
e:  5   train_loss:  568.7485419994811   val_loss:  1501.43826226144   time:  1.4289746284484863
e:  6   train_loss:  549.3208437341115   time:  1.3197722434997559
e:  7   train_loss:  547.0961764665167   time:  1.3094630241394043
e:  8   train_loss:  531.8571148204869   time:  1.31691575050354
e:  9   train_loss:  528.3907688480206   time:  1.314988374710083
e:  10   train_loss:  513.3119519715751   time:  1.3013129234313965
e:  10   train_loss:  513.3119519715751   val_loss:  1463.3984283054008   time:  1.4092473983764648
e:  11   train_loss:  507.10439869219465   time:  1.3159065246582031
e:  12   train_loss:  501.9614115991718   time:  1.4739964008331299
e:  13   train_loss:  492.1719855059278   time:  1.3089640140533447
e:  14   train_loss:  493.41537115802987   time:  1.3210902214050293
e:  15   train_loss:  473.38044746619613   time:  1.3369994163513184
e:  15   train_loss:  473.38044746619613   val_loss:  1438.2248297452259   time:  1.4447021484375
e:  16   train_loss:  472.85876197552534   time:  1.2725768089294434
e:  17   train_loss:  482.08968908802706   time:  1.2657618522644043
e:  18   train_loss:  468.12850128299965   time:  1.2747397422790527
e:  19   train_loss:  465.6111684457868   time:  1.28261399269104
e:  20   train_loss:  449.37118865902943   time:  1.2675893306732178
e:  20   train_loss:  449.37118865902943   val_loss:  1329.67525916514   time:  1.376344919204712
e:  21   train_loss:  441.7479322756794   time:  1.409311294555664
e:  22   train_loss:  436.27363411239713   time:  1.2765936851501465
e:  23   train_loss:  432.09948867570176   time:  1.2763526439666748
e:  24   train_loss:  420.191006738415   time:  1.2667996883392334
e:  25   train_loss:  413.14067730150066   time:  1.2579798698425293
e:  25   train_loss:  413.14067730150066   val_loss:  1199.3446503342088   time:  1.3664052486419678
e:  26   train_loss:  409.8631010936148   time:  1.2561659812927246
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1253.5355356725827   time:  1.400564432144165
e:  0   train_loss:  1253.5355356725827   val_loss:  624.3558826056335   time:  1.5034544467926025
e:  1   train_loss:  911.6911948172005   time:  1.3985660076141357
e:  2   train_loss:  832.023753858058   time:  1.3958373069763184
e:  3   train_loss:  772.864163280531   time:  1.5308716297149658
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  4   train_loss:  778.728670841999   time:  1.3889002799987793
e:  5   train_loss:  736.1985070175967   time:  1.39689040184021
e:  5   train_loss:  736.1985070175967   val_loss:  892.7537021883451   time:  1.4994633197784424
e:  6   train_loss:  716.2743666913861   time:  1.3962090015411377
e:  7   train_loss:  684.5511369657255   time:  1.386274814605713
e:  8   train_loss:  696.5015206403434   time:  1.39430832862854
e:  9   train_loss:  690.1886051279598   time:  1.5410199165344238
e:  10   train_loss:  658.3661414167148   time:  1.390557050704956
e:  10   train_loss:  658.3661414167148   val_loss:  1988.0900604594149   time:  1.4924595355987549
e:  11   train_loss:  659.3863138082893   time:  1.398010492324829
e:  12   train_loss:  685.590211075396   time:  1.3972992897033691
e:  13   train_loss:  656.848389417753   time:  1.5404517650604248
e:  14   train_loss:  632.8660911300757   time:  1.3890292644500732
e:  15   train_loss:  648.0995909291568   time:  1.4153997898101807
e:  15   train_loss:  648.0995909291568   val_loss:  1257.4242576386346   time:  1.6491990089416504
e:  16   train_loss:  649.2038510489131   time:  1.3968720436096191
e:  17   train_loss:  633.7620483024928   time:  1.3895368576049805
e:  18   train_loss:  605.7905897762336   time:  1.3993809223175049
e:  19   train_loss:  689.8382154925661   time:  1.3858659267425537
e:  20   train_loss:  632.2484652242384   time:  1.3711237907409668
e:  20   train_loss:  632.2484652242384   val_loss:  1210.3520677469282   time:  1.47459077835083
e:  21   train_loss:  610.5655737969887   time:  1.5242030620574951
e:  22   train_loss:  584.0528458942883   time:  1.3998193740844727
e:  23   train_loss:  625.0945758650803   time:  1.3877339363098145
e:  24   train_loss:  591.3559721318131   time:  1.419238805770874
e:  25   train_loss:  619.5691203577904   time:  1.4517557621002197
e:  25   train_loss:  619.5691203577904   val_loss:  777.5698041764508   time:  1.5533413887023926
e:  26   train_loss:  608.9813791688005   time:  1.4470171928405762
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1277.2271503880854   time:  1.3937175273895264
e:  0   train_loss:  1277.2271503880854   val_loss:  536.4878742739414   time:  1.6303081512451172
e:  1   train_loss:  968.6861470221417   time:  1.3748679161071777
e:  2   train_loss:  813.8311363219796   time:  1.3797690868377686
e:  3   train_loss:  806.0237799366465   time:  1.3710873126983643
e:  4   train_loss:  804.7319227980649   time:  1.3765535354614258
e:  5   train_loss:  828.6400070660286   time:  1.3801586627960205
e:  5   train_loss:  828.6400070660286   val_loss:  2626.1974237368236   time:  1.484816551208496
e:  6   train_loss:  775.9670357328833   time:  1.3800227642059326
e:  7   train_loss:  757.5403218187824   time:  1.3786108493804932
e:  8   train_loss:  725.8798306435367   time:  1.5174932479858398
e:  9   train_loss:  703.1009514619495   time:  1.3686401844024658
e:  10   train_loss:  719.1983598857765   time:  1.379204511642456
e:  10   train_loss:  719.1983598857765   val_loss:  469.06873529900184   time:  1.483640432357788
e:  11   train_loss:  727.5619850344452   time:  1.3767237663269043
e:  12   train_loss:  729.5150987699586   time:  1.3829810619354248
e:  13   train_loss:  676.8294265057381   time:  1.3658256530761719
e:  14   train_loss:  684.3375333716988   time:  1.3869671821594238
e:  15   train_loss:  704.8242116100276   time:  1.5200748443603516
e:  15   train_loss:  704.8242116100276   val_loss:  465.92577969171055   time:  1.625946044921875
e:  16   train_loss:  689.2289488130386   time:  1.3820960521697998
e:  17   train_loss:  684.192659919507   time:  1.3780558109283447
e:  18   train_loss:  683.7231119458677   time:  1.3710768222808838
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  19   train_loss:  677.267811933335   time:  1.3883118629455566
e:  20   train_loss:  658.9795820475847   time:  1.3834784030914307
e:  20   train_loss:  658.9795820475847   val_loss:  464.4965133699932   time:  1.488945484161377
e:  21   train_loss:  656.0967333790218   time:  1.7406330108642578
e:  22   train_loss:  669.4986127022697   time:  1.5372731685638428
e:  23   train_loss:  646.7521634734009   time:  1.6777219772338867
e:  24   train_loss:  675.7732194695056   time:  1.4288713932037354
e:  25   train_loss:  725.8984044464743   time:  1.4330902099609375
e:  25   train_loss:  725.8984044464743   val_loss:  477.772614179282   time:  1.5407743453979492
e:  26   train_loss:  638.272859734686   time:  1.3804147243499756
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  1273.6971656336327   time:  1.2776918411254883
e:  0   train_loss:  1273.6971656336327   val_loss:  912.5602906670618   time:  1.387141466140747
e:  1   train_loss:  943.60190717547   time:  1.2864866256713867
e:  2   train_loss:  874.540133288923   time:  1.406512975692749
e:  3   train_loss:  804.0021780453653   time:  1.275569200515747
e:  4   train_loss:  756.3989164316558   time:  1.2685372829437256
e:  5   train_loss:  723.180933142512   time:  1.2860186100006104
e:  5   train_loss:  723.180933142512   val_loss:  795.2064878983733   time:  1.3955259323120117
e:  6   train_loss:  734.342886756647   time:  1.2761404514312744
e:  7   train_loss:  721.1338202319295   time:  1.2653446197509766
e:  8   train_loss:  696.4932142105389   time:  1.2683501243591309
e:  9   train_loss:  678.4991183523875   time:  1.279012680053711
e:  10   train_loss:  651.8337043956658   time:  1.2678842544555664
e:  10   train_loss:  651.8337043956658   val_loss:  722.6876278352966   time:  1.3778455257415771
e:  11   train_loss:  644.0060883359365   time:  1.2812047004699707
e:  12   train_loss:  646.4336794116714   time:  1.286684274673462
e:  13   train_loss:  620.9943741870425   time:  1.277693510055542
e:  14   train_loss:  626.7201201692066   time:  1.4095547199249268
e:  15   train_loss:  603.6224988378119   time:  1.2765552997589111
e:  15   train_loss:  603.6224988378119   val_loss:  821.0824018113175   time:  1.3858554363250732
e:  16   train_loss:  594.1786801717367   time:  1.2794713973999023
e:  17   train_loss:  584.8019367724688   time:  1.2834300994873047
e:  18   train_loss:  580.413057807229   time:  1.2790162563323975
e:  19   train_loss:  581.2658343716246   time:  1.279021978378296
e:  20   train_loss:  564.1370564146015   time:  1.2786295413970947
e:  20   train_loss:  564.1370564146015   val_loss:  700.4123327452915   time:  1.3879477977752686
e:  21   train_loss:  600.5454265794588   time:  1.2800161838531494
e:  22   train_loss:  556.8580428647062   time:  1.2677390575408936
e:  23   train_loss:  569.5656961699336   time:  1.2812244892120361
e:  24   train_loss:  535.6072541542152   time:  1.2745208740234375
e:  25   train_loss:  527.7825833879842   time:  1.4091780185699463
e:  25   train_loss:  527.7825833879842   val_loss:  721.3892923235304   time:  1.519019365310669
e:  26   train_loss:  569.4038932531043   time:  1.274801254272461
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1325.4116107066939   time:  1.4038357734680176
e:  0   train_loss:  1325.4116107066939   val_loss:  688.5623375906365   time:  1.5078599452972412
e:  1   train_loss:  952.6806385818321   time:  1.390073299407959
e:  2   train_loss:  801.1394184593885   time:  1.4006123542785645
e:  3   train_loss:  960.3761446018614   time:  1.3810193538665771
e:  4   train_loss:  821.0826572206961   time:  1.5410454273223877
e:  5   train_loss:  809.7180663637164   time:  1.4026250839233398
e:  5   train_loss:  809.7180663637164   val_loss:  1529.1603987837611   time:  1.5064420700073242
e:  6   train_loss:  783.0062924132167   time:  1.4015836715698242
e:  7   train_loss:  757.356082109346   time:  1.3901243209838867
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
e:  8   train_loss:  745.4277514959808   time:  1.406944751739502
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  9   train_loss:  701.577864051461   time:  1.4042794704437256
e:  10   train_loss:  691.6463399169832   time:  1.4017260074615479
e:  10   train_loss:  691.6463399169832   val_loss:  575.9542393014852   time:  1.6347455978393555
e:  11   train_loss:  743.7574518633776   time:  1.4028232097625732
e:  12   train_loss:  688.1246638363737   time:  1.403461217880249
e:  13   train_loss:  664.3213937885981   time:  1.3994629383087158
e:  14   train_loss:  643.2541539043926   time:  1.3998515605926514
e:  15   train_loss:  637.7147022892716   time:  1.3897960186004639
e:  15   train_loss:  637.7147022892716   val_loss:  564.022963986709   time:  1.4955286979675293
e:  16   train_loss:  623.9537936117905   time:  1.5445890426635742
e:  17   train_loss:  643.8350193290664   time:  1.4016444683074951
e:  18   train_loss:  624.0962053089729   time:  1.4021010398864746
e:  19   train_loss:  645.0505982906551   time:  1.399409294128418
e:  20   train_loss:  623.9487041711064   time:  1.394662618637085
e:  20   train_loss:  623.9487041711064   val_loss:  626.100662439606   time:  1.4987828731536865
e:  21   train_loss:  603.5607233918872   time:  1.4023334980010986
e:  22   train_loss:  593.0929113968836   time:  1.399034023284912
e:  23   train_loss:  589.1192969590143   time:  1.510810375213623
e:  24   train_loss:  574.2958335351877   time:  1.3864519596099854
e:  25   train_loss:  567.0997182335435   time:  1.4073152542114258
e:  25   train_loss:  567.0997182335435   val_loss:  576.2739928901206   time:  1.5097482204437256
e:  26   train_loss:  565.2132384821373   time:  1.4082624912261963
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 10), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 10) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 10) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 10) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 10)
kwargs: {'config': {'batch_norm': True, 'ff_0': 39, 'ff_num_layers': 2, 'gnn_0': 71, 'gnn_dropout': 0.4680205928046692, 'gnn_num_layers': 2, 'hid_0': 253, 'hid_dropout_rate': 0.33231583631114886, 'in_dropout_rate': 0.4318697065068356, 'lr': 0.00790707314326263, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 235, 'gnn_1': 488, 'hid_1': 215, 'hid_2': 1034}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 710.5264686083672, 'n_epochs': 27.0, 'info': {'validation loss': 710.5264686083672}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 10) started
DEBUG:hpbandster:job_callback for (0, 0, 10) got condition
DEBUG:hpbandster:Only 11 run(s) for budget 27.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 10) finished
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 11) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 11) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 11)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 11) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 11) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 11)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 1799, 'ff_num_layers': 2, 'gnn_0': 1276, 'gnn_dropout': 0.3070962140299131, 'gnn_num_layers': 3, 'hid_0': 335, 'hid_dropout_rate': 0.11225455628017156, 'in_dropout_rate': 0.45302179100494605, 'lr': 8.230774805378948e-05, 'num_hid_layers': 1, 'optimizer': 'Adam', 'ff_1': 304, 'gnn_1': 247, 'gnn_2': 289}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  700.937550768721   time:  1.370976448059082
e:  0   train_loss:  700.937550768721   val_loss:  1662.9011622091039   time:  1.4842023849487305
e:  1   train_loss:  691.3279594772248   time:  1.3789381980895996
e:  2   train_loss:  677.8649224117737   time:  1.3801264762878418
e:  3   train_loss:  658.0616519635214   time:  1.5203967094421387
e:  4   train_loss:  630.4487544158798   time:  1.3309621810913086
e:  5   train_loss:  595.1199883344585   time:  1.438270092010498
e:  5   train_loss:  595.1199883344585   val_loss:  1602.6181396776597   time:  1.5562348365783691
e:  6   train_loss:  557.7280669574614   time:  1.4044926166534424
e:  7   train_loss:  521.4425286198516   time:  1.366680383682251
e:  8   train_loss:  489.5085015589348   time:  1.349968671798706
e:  9   train_loss:  467.7271117874211   time:  1.3406257629394531
e:  10   train_loss:  454.3483036935816   time:  1.3382203578948975
e:  10   train_loss:  454.3483036935816   val_loss:  1656.6288567143824   time:  1.4506518840789795
e:  11   train_loss:  448.15220962231325   time:  1.348789930343628
e:  12   train_loss:  441.8576401833931   time:  1.3478131294250488
e:  13   train_loss:  438.13133219835197   time:  1.3510172367095947
e:  14   train_loss:  436.54920463164945   time:  1.4817254543304443
e:  15   train_loss:  437.43275186417515   time:  1.3295800685882568
e:  15   train_loss:  437.43275186417515   val_loss:  1615.3360059566573   time:  1.4423935413360596
e:  16   train_loss:  435.46918783439395   time:  1.3391122817993164
e:  17   train_loss:  433.9407593089042   time:  1.336022138595581
e:  18   train_loss:  432.74739260727836   time:  1.3170993328094482
e:  19   train_loss:  432.0898299965644   time:  1.3323383331298828
e:  20   train_loss:  430.66786188344076   time:  1.3487730026245117
e:  20   train_loss:  430.66786188344076   val_loss:  1664.2249289027116   time:  1.4618666172027588
e:  21   train_loss:  431.55651618401953   time:  1.3478813171386719
e:  22   train_loss:  431.73837097455845   time:  1.3504559993743896
e:  23   train_loss:  432.22087914600536   time:  1.4784259796142578
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  24   train_loss:  429.73716919499395   time:  1.339087724685669
e:  25   train_loss:  432.3348039477472   time:  1.3094654083251953
e:  25   train_loss:  432.3348039477472   val_loss:  1590.1638792894169   time:  1.4225258827209473
e:  26   train_loss:  431.83405948558993   time:  1.3425567150115967
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1068.6971805401   time:  1.4796864986419678
e:  0   train_loss:  1068.6971805401   val_loss:  621.9935324338994   time:  1.5858523845672607
e:  1   train_loss:  1058.9196032611273   time:  1.4769573211669922
e:  2   train_loss:  1030.616151922692   time:  1.4681951999664307
e:  3   train_loss:  978.8933502329635   time:  1.4716427326202393
e:  4   train_loss:  913.1463212455595   time:  1.4711503982543945
e:  5   train_loss:  859.040503600471   time:  1.585010051727295
e:  5   train_loss:  859.040503600471   val_loss:  588.0584287007335   time:  1.7115967273712158
e:  6   train_loss:  768.2133806085862   time:  1.586890697479248
e:  7   train_loss:  710.8768501329428   time:  1.4734859466552734
e:  8   train_loss:  647.9133851372153   time:  1.469818115234375
e:  9   train_loss:  617.2440468079832   time:  1.4729290008544922
e:  10   train_loss:  608.4942098026863   time:  1.4782764911651611
e:  10   train_loss:  608.4942098026863   val_loss:  606.9969917098778   time:  1.7166221141815186
e:  11   train_loss:  593.3931297114664   time:  1.4537310600280762
e:  12   train_loss:  587.9071359304062   time:  1.4480910301208496
e:  13   train_loss:  592.4760973214159   time:  1.4731600284576416
e:  14   train_loss:  589.8612949870981   time:  1.4746484756469727
e:  15   train_loss:  584.7772500383682   time:  1.4682674407958984
e:  15   train_loss:  584.7772500383682   val_loss:  613.5239375116622   time:  1.5744831562042236
e:  16   train_loss:  577.656345258592   time:  1.6128239631652832
e:  17   train_loss:  579.2037208860907   time:  1.467252492904663
e:  18   train_loss:  570.9496733381534   time:  1.4778270721435547
e:  19   train_loss:  569.1498182627375   time:  1.4733970165252686
e:  20   train_loss:  570.0894926266614   time:  1.4835786819458008
e:  20   train_loss:  570.0894926266614   val_loss:  611.0801850446516   time:  1.5901715755462646
e:  21   train_loss:  574.8216951351072   time:  1.467656135559082
e:  22   train_loss:  576.0665761920592   time:  1.4747753143310547
e:  23   train_loss:  584.1109523251645   time:  1.6195125579833984
e:  24   train_loss:  569.6045691297945   time:  1.4721362590789795
e:  25   train_loss:  566.7738500012468   time:  1.4777343273162842
e:  25   train_loss:  566.7738500012468   val_loss:  629.4218912724585   time:  1.5861592292785645
e:  26   train_loss:  575.5443915369816   time:  1.4794540405273438
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1076.539725056619   time:  1.456946611404419
e:  0   train_loss:  1076.539725056619   val_loss:  535.516932320717   time:  1.565725564956665
e:  1   train_loss:  1054.4757458089148   time:  1.4487063884735107
e:  2   train_loss:  1068.4374643965302   time:  1.4543397426605225
e:  3   train_loss:  992.5502820049237   time:  1.6017520427703857
e:  4   train_loss:  945.3189519230813   time:  1.430896520614624
e:  5   train_loss:  848.14865821541   time:  1.445580244064331
e:  5   train_loss:  848.14865821541   val_loss:  506.3607870694158   time:  1.555191993713379
e:  6   train_loss:  783.8667496396794   time:  1.4472391605377197
e:  7   train_loss:  754.5697940892219   time:  1.4565911293029785
e:  8   train_loss:  678.5499352828673   time:  1.4553940296173096
e:  9   train_loss:  646.514865747728   time:  1.453965425491333
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  10   train_loss:  636.8403368234808   time:  1.628166913986206
e:  10   train_loss:  636.8403368234808   val_loss:  514.437096293449   time:  1.7598209381103516
e:  11   train_loss:  635.6117371691653   time:  1.595844030380249
e:  12   train_loss:  618.9581559633574   time:  1.4467120170593262
e:  13   train_loss:  608.8224442702348   time:  1.4535958766937256
e:  14   train_loss:  622.7035013378508   time:  1.4547011852264404
e:  15   train_loss:  624.7439894178023   time:  1.4565677642822266
e:  15   train_loss:  624.7439894178023   val_loss:  519.5553775896653   time:  1.565335750579834
e:  16   train_loss:  596.1432546027384   time:  1.4572186470031738
e:  17   train_loss:  618.9409347800299   time:  1.4549734592437744
e:  18   train_loss:  620.6401115926275   time:  1.5956933498382568
e:  19   train_loss:  603.0326745636133   time:  1.4480445384979248
e:  20   train_loss:  596.1140418603011   time:  1.4539763927459717
e:  20   train_loss:  596.1140418603011   val_loss:  513.6999892408863   time:  1.562699317932129
e:  21   train_loss:  598.1112494790233   time:  1.450688362121582
e:  22   train_loss:  606.4792435397655   time:  1.459733247756958
e:  23   train_loss:  610.4702670835221   time:  1.4543635845184326
e:  24   train_loss:  581.054675985382   time:  1.4441730976104736
e:  25   train_loss:  606.5794761147998   time:  1.5863502025604248
e:  25   train_loss:  606.5794761147998   val_loss:  512.9456972957223   time:  1.6961584091186523
e:  26   train_loss:  607.48469792303   time:  1.4571630954742432
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  997.207333680263   time:  1.3304674625396729
e:  0   train_loss:  997.207333680263   val_loss:  912.8838304677532   time:  1.4442205429077148
e:  1   train_loss:  976.3262776836264   time:  1.3423919677734375
e:  2   train_loss:  957.3135724695575   time:  1.3423278331756592
e:  3   train_loss:  925.4656190068584   time:  1.3409771919250488
e:  4   train_loss:  879.3028152434215   time:  1.3443686962127686
e:  5   train_loss:  827.5602470828642   time:  1.340179681777954
e:  5   train_loss:  827.5602470828642   val_loss:  864.0611338964425   time:  1.4529500007629395
e:  6   train_loss:  768.6485184875542   time:  1.4774417877197266
e:  7   train_loss:  707.9532467422421   time:  1.3259398937225342
e:  8   train_loss:  654.9324048424529   time:  1.3434216976165771
e:  9   train_loss:  617.675164735247   time:  1.3489346504211426
e:  10   train_loss:  589.0384734766848   time:  1.3429806232452393
e:  10   train_loss:  589.0384734766848   val_loss:  866.6253262972173   time:  1.4564149379730225
e:  11   train_loss:  571.8717531210181   time:  1.3440461158752441
e:  12   train_loss:  560.3157189891177   time:  1.3343820571899414
e:  13   train_loss:  552.5480337643397   time:  1.3401577472686768
e:  14   train_loss:  549.3550706493672   time:  1.33270263671875
e:  15   train_loss:  547.9403481507669   time:  1.3424184322357178
e:  15   train_loss:  547.9403481507669   val_loss:  892.0036293913203   time:  1.456061840057373
e:  16   train_loss:  550.1974079748992   time:  1.3430840969085693
e:  17   train_loss:  550.4745438875608   time:  1.3435173034667969
e:  18   train_loss:  545.2099671951913   time:  1.3263695240020752
e:  19   train_loss:  543.8816622319376   time:  1.3151192665100098
e:  20   train_loss:  544.6013880465509   time:  1.4902904033660889
e:  20   train_loss:  544.6013880465509   val_loss:  897.1143349051373   time:  1.666022539138794
e:  21   train_loss:  543.4447285667778   time:  1.3578119277954102
e:  22   train_loss:  544.6781975650954   time:  1.3450355529785156
e:  23   train_loss:  543.523495455119   time:  1.3480041027069092
e:  24   train_loss:  545.0517391131629   time:  1.3423395156860352
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  25   train_loss:  542.2324407070709   time:  1.3509128093719482
e:  25   train_loss:  542.2324407070709   val_loss:  897.6265224391567   time:  1.4644386768341064
e:  26   train_loss:  541.5757284474547   time:  1.698396921157837
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1070.14101393114   time:  1.6416561603546143
e:  0   train_loss:  1070.14101393114   val_loss:  681.5706428008612   time:  1.992934226989746
e:  1   train_loss:  1027.8405298887683   time:  1.522519826889038
e:  2   train_loss:  1005.584438549331   time:  1.5147621631622314
e:  3   train_loss:  962.833027144347   time:  1.5147991180419922
e:  4   train_loss:  894.8398845465035   time:  1.5216848850250244
e:  5   train_loss:  828.2933983824754   time:  1.4782028198242188
e:  5   train_loss:  828.2933983824754   val_loss:  634.1761351130493   time:  1.5855607986450195
e:  6   train_loss:  754.5028774718284   time:  1.4726533889770508
e:  7   train_loss:  673.4120756232161   time:  1.5631239414215088
e:  8   train_loss:  636.7301824949975   time:  1.606536626815796
e:  9   train_loss:  611.2040614712051   time:  1.6543374061584473
e:  10   train_loss:  612.3936568081043   time:  1.464322805404663
e:  10   train_loss:  612.3936568081043   val_loss:  672.5147953666988   time:  1.5721135139465332
e:  11   train_loss:  599.2871548528933   time:  1.4572601318359375
e:  12   train_loss:  594.4786106987585   time:  1.4664866924285889
e:  13   train_loss:  584.6752368413794   time:  1.4812264442443848
e:  14   train_loss:  592.7967689435656   time:  1.4826381206512451
e:  15   train_loss:  590.4057708689063   time:  1.634176254272461
e:  15   train_loss:  590.4057708689063   val_loss:  674.8946280564988   time:  1.74271559715271
e:  16   train_loss:  589.6474767737176   time:  1.4735562801361084
e:  17   train_loss:  592.7422892663652   time:  1.478623628616333
e:  18   train_loss:  598.9085367565156   time:  1.4793379306793213
e:  19   train_loss:  601.6365628996404   time:  1.4705326557159424
e:  20   train_loss:  591.1197025269531   time:  1.4775397777557373
e:  20   train_loss:  591.1197025269531   val_loss:  682.5301609806351   time:  1.7175602912902832
e:  21   train_loss:  591.6017363656312   time:  1.485159158706665
e:  22   train_loss:  588.8678658323716   time:  1.4813199043273926
e:  23   train_loss:  586.1737116855844   time:  1.4798517227172852
e:  24   train_loss:  593.2433217104503   time:  1.6907439231872559
e:  25   train_loss:  587.5973092607603   time:  1.4717259407043457
e:  25   train_loss:  587.5973092607603   val_loss:  678.3123439508863   time:  1.5786354541778564
e:  26   train_loss:  584.309172959364   time:  1.4743640422821045
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 11), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 11) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 11) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 11) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 11)
kwargs: {'config': {'batch_norm': True, 'ff_0': 1799, 'ff_num_layers': 2, 'gnn_0': 1276, 'gnn_dropout': 0.3070962140299131, 'gnn_num_layers': 3, 'hid_0': 335, 'hid_dropout_rate': 0.11225455628017156, 'in_dropout_rate': 0.45302179100494605, 'lr': 8.230774805378948e-05, 'num_hid_layers': 1, 'optimizer': 'Adam', 'ff_1': 304, 'gnn_1': 247, 'gnn_2': 289}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 836.5640728138117, 'n_epochs': 27.0, 'info': {'validation loss': 836.5640728138117}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 11) started
DEBUG:hpbandster:job_callback for (0, 0, 11) got condition
DEBUG:hpbandster:Only 12 run(s) for budget 27.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 11) finished
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 12) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 12) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 12)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 12) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 12) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 12)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 16, 'ff_num_layers': 3, 'gnn_0': 74, 'gnn_dropout': 0.025182456396660613, 'gnn_num_layers': 1, 'hid_0': 85, 'hid_dropout_rate': 0.1720855829121078, 'in_dropout_rate': 0.13383103265402857, 'lr': 1.3960006068852374e-05, 'num_hid_layers': 1, 'optimizer': 'Adam', 'ff_1': 90, 'ff_2': 501}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  705.1293900925964   time:  1.269108533859253
e:  0   train_loss:  705.1293900925964   val_loss:  1673.6422807225988   time:  1.5473206043243408
e:  1   train_loss:  705.3504525692844   time:  1.2180476188659668
e:  2   train_loss:  704.0434195460634   time:  1.2249271869659424
e:  3   train_loss:  702.2530640460591   time:  1.2437036037445068
e:  4   train_loss:  702.0447611209053   time:  1.2397677898406982
e:  5   train_loss:  700.941782086574   time:  1.235814094543457
e:  5   train_loss:  700.941782086574   val_loss:  1666.6027818864663   time:  1.3409693241119385
e:  6   train_loss:  700.8913729300659   time:  1.2431607246398926
e:  7   train_loss:  699.7800772838038   time:  1.3653724193572998
e:  8   train_loss:  698.2410098770196   time:  1.2371909618377686
e:  9   train_loss:  697.6549892917454   time:  1.3629014492034912
e:  10   train_loss:  697.3922067352371   time:  1.2275254726409912
e:  10   train_loss:  697.3922067352371   val_loss:  1657.9612016050837   time:  1.3338782787322998
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  11   train_loss:  695.7291496959972   time:  1.3330466747283936
e:  12   train_loss:  695.0824672747972   time:  1.2852401733398438
e:  13   train_loss:  693.1702879857346   time:  1.2984225749969482
e:  14   train_loss:  692.6367949144247   time:  1.2277638912200928
e:  15   train_loss:  692.2220325949281   time:  1.2363574504852295
e:  15   train_loss:  692.2220325949281   val_loss:  1648.854296701764   time:  1.3424656391143799
e:  16   train_loss:  690.8661638335897   time:  1.2143137454986572
e:  17   train_loss:  689.5027784447313   time:  1.2340092658996582
e:  18   train_loss:  687.4761133500024   time:  1.3977999687194824
e:  19   train_loss:  688.6557636951037   time:  1.216097354888916
e:  20   train_loss:  686.0629157564583   time:  1.23081636428833
e:  20   train_loss:  686.0629157564583   val_loss:  1638.7710784752855   time:  1.3363251686096191
e:  21   train_loss:  684.6470152497558   time:  1.242753028869629
e:  22   train_loss:  684.3304598560389   time:  1.2436184883117676
e:  23   train_loss:  682.9773365779657   time:  1.2309093475341797
e:  24   train_loss:  680.8800814440857   time:  1.2179768085479736
e:  25   train_loss:  679.6520431888785   time:  1.233672857284546
e:  25   train_loss:  679.6520431888785   val_loss:  1627.3172940025129   time:  1.338954210281372
e:  26   train_loss:  678.2437727589936   time:  1.2440273761749268
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1088.2457530695403   time:  1.3099126815795898
e:  0   train_loss:  1088.2457530695403   val_loss:  629.6207917254994   time:  1.4090254306793213
e:  1   train_loss:  1078.302281863173   time:  1.3055670261383057
e:  2   train_loss:  1093.9560963420759   time:  1.4608070850372314
e:  3   train_loss:  1079.456955780918   time:  1.2952589988708496
e:  4   train_loss:  1095.4348567705388   time:  1.344740629196167
e:  5   train_loss:  1071.6824232200195   time:  1.2554130554199219
e:  5   train_loss:  1071.6824232200195   val_loss:  624.7181733826147   time:  1.3543202877044678
e:  6   train_loss:  1072.1603608264898   time:  1.3406054973602295
e:  7   train_loss:  1089.7577600773725   time:  1.3790900707244873
e:  8   train_loss:  1070.960617393923   time:  1.5590438842773438
e:  9   train_loss:  1069.755773708651   time:  1.353372573852539
e:  10   train_loss:  1070.3117315048   time:  1.4090723991394043
e:  10   train_loss:  1070.3117315048   val_loss:  619.5188665469944   time:  1.5083129405975342
e:  11   train_loss:  1067.3720060204312   time:  1.303785800933838
e:  12   train_loss:  1060.8789481585825   time:  1.2908437252044678
e:  13   train_loss:  1067.9951919956359   time:  1.3115026950836182
e:  14   train_loss:  1060.1711567222285   time:  1.4480791091918945
e:  15   train_loss:  1066.022867033375   time:  1.306886911392212
e:  15   train_loss:  1066.022867033375   val_loss:  614.0938274556675   time:  1.4062161445617676
e:  16   train_loss:  1059.4033236552905   time:  1.3116085529327393
e:  17   train_loss:  1052.1707154749943   time:  1.3096725940704346
e:  18   train_loss:  1060.8052340307547   time:  1.311094045639038
e:  19   train_loss:  1063.1053940583124   time:  1.2964744567871094
e:  20   train_loss:  1041.1754491207805   time:  1.3080906867980957
e:  20   train_loss:  1041.1754491207805   val_loss:  608.0546990202603   time:  1.407846450805664
e:  21   train_loss:  1066.6630818206543   time:  1.4555437564849854
e:  22   train_loss:  1052.2319212085224   time:  1.3070530891418457
e:  23   train_loss:  1037.7977129418728   time:  1.300873041152954
e:  24   train_loss:  1044.5758914243372   time:  1.3085739612579346
e:  25   train_loss:  1042.9099032844529   time:  1.3007724285125732
e:  25   train_loss:  1042.9099032844529   val_loss:  601.1943389967971   time:  1.4011592864990234
e:  26   train_loss:  1035.2903296670768   time:  1.3123559951782227
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1062.2041107109649   time:  1.424391508102417
e:  0   train_loss:  1062.2041107109649   val_loss:  539.4379345936114   time:  1.5200951099395752
e:  1   train_loss:  1056.3761239364253   time:  1.297278881072998
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  2   train_loss:  1099.5081240931024   time:  1.302295446395874
e:  3   train_loss:  1092.7697521317782   time:  1.286323070526123
e:  4   train_loss:  1094.9201390374153   time:  1.2813420295715332
e:  5   train_loss:  1122.727413842339   time:  1.2977650165557861
e:  5   train_loss:  1122.727413842339   val_loss:  535.4708042403586   time:  1.3994734287261963
e:  6   train_loss:  1063.747078780746   time:  1.2944297790527344
e:  7   train_loss:  1054.6525188327682   time:  1.3068537712097168
e:  8   train_loss:  1126.2153544847743   time:  1.4329602718353271
e:  9   train_loss:  1047.9795501382105   time:  1.2907769680023193
e:  10   train_loss:  1108.6060442375483   time:  1.2970411777496338
e:  10   train_loss:  1108.6060442375483   val_loss:  531.0847971948236   time:  1.3992297649383545
e:  11   train_loss:  1089.9109911075398   time:  1.2851510047912598
e:  12   train_loss:  1053.9448028997933   time:  1.2939293384552002
e:  13   train_loss:  1088.5512314783164   time:  1.2828736305236816
e:  14   train_loss:  1084.9372469132686   time:  1.4125030040740967
e:  15   train_loss:  1062.40618260779   time:  1.2967402935028076
e:  15   train_loss:  1062.40618260779   val_loss:  526.5179599837305   time:  1.399282693862915
e:  16   train_loss:  1070.306229021659   time:  1.3021254539489746
e:  17   train_loss:  1055.4440745734619   time:  1.2863514423370361
e:  18   train_loss:  1057.7157014067398   time:  1.2853453159332275
e:  19   train_loss:  1030.8069501226048   time:  1.294304370880127
e:  20   train_loss:  1045.4303020756684   time:  1.2938742637634277
e:  20   train_loss:  1045.4303020756684   val_loss:  521.5459661412567   time:  1.3959059715270996
e:  21   train_loss:  1090.6604302797564   time:  1.2969355583190918
e:  22   train_loss:  1111.845696163252   time:  1.4394407272338867
e:  23   train_loss:  1047.619768877703   time:  1.2853660583496094
e:  24   train_loss:  1108.714460185053   time:  1.2901611328125
e:  25   train_loss:  1049.9272428753632   time:  1.2973265647888184
e:  25   train_loss:  1049.9272428753632   val_loss:  515.9847183841374   time:  1.3989264965057373
e:  26   train_loss:  1064.4622095217958   time:  1.3004446029663086
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  1000.705256152694   time:  1.2000198364257812
e:  0   train_loss:  1000.705256152694   val_loss:  920.4758342895884   time:  1.3068468570709229
e:  1   train_loss:  1002.3165582715051   time:  1.1912147998809814
e:  2   train_loss:  1001.7226480474361   time:  1.3318607807159424
e:  3   train_loss:  996.1356001973035   time:  1.199678897857666
e:  4   train_loss:  998.5550523385762   time:  1.199587106704712
e:  5   train_loss:  998.4924438942318   time:  1.2916440963745117
e:  5   train_loss:  998.4924438942318   val_loss:  915.9162681196258   time:  1.3990938663482666
e:  6   train_loss:  996.1029415081872   time:  1.2913880348205566
e:  7   train_loss:  996.6200836394078   time:  1.1927814483642578
e:  8   train_loss:  996.0950558331747   time:  1.2650344371795654
e:  9   train_loss:  993.6830045154603   time:  1.1991651058197021
e:  10   train_loss:  992.0003615119355   time:  1.2126669883728027
e:  10   train_loss:  992.0003615119355   val_loss:  910.0995243354823   time:  1.319188117980957
e:  11   train_loss:  991.8712596800365   time:  1.2341558933258057
e:  12   train_loss:  993.7155497252002   time:  1.3535103797912598
e:  13   train_loss:  988.2548662211857   time:  1.22102952003479
e:  14   train_loss:  988.7284352401541   time:  1.194183349609375
e:  15   train_loss:  988.2767775951158   time:  1.2480602264404297
e:  15   train_loss:  988.2767775951158   val_loss:  904.0868593030634   time:  1.3536577224731445
e:  16   train_loss:  983.230485073467   time:  1.1973061561584473
e:  17   train_loss:  983.5139472394235   time:  1.1807589530944824
e:  18   train_loss:  980.8960305177434   time:  1.2103476524353027
e:  19   train_loss:  981.1084999465986   time:  1.1979222297668457
e:  20   train_loss:  981.8398465135324   time:  1.2047441005706787
e:  20   train_loss:  981.8398465135324   val_loss:  897.5314727522122   time:  1.3112764358520508
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  21   train_loss:  977.8940446657635   time:  1.206373691558838
e:  22   train_loss:  977.9217993345512   time:  1.1975653171539307
e:  23   train_loss:  977.2832867525659   time:  1.405226469039917
e:  24   train_loss:  975.5198013028739   time:  1.1869778633117676
e:  25   train_loss:  976.2230162399849   time:  1.1979660987854004
e:  25   train_loss:  976.2230162399849   val_loss:  890.1763848552589   time:  1.3048157691955566
e:  26   train_loss:  972.2031634902311   time:  1.199948787689209
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1077.9404554790444   time:  1.3110156059265137
e:  0   train_loss:  1077.9404554790444   val_loss:  689.1139670785238   time:  1.4123437404632568
e:  1   train_loss:  1093.246082742878   time:  1.3097152709960938
e:  2   train_loss:  1055.075022188329   time:  1.305710792541504
e:  3   train_loss:  1056.510785785661   time:  1.2947044372558594
e:  4   train_loss:  1075.8461002947854   time:  1.3210773468017578
e:  5   train_loss:  1090.6355972980075   time:  1.4532785415649414
e:  5   train_loss:  1090.6355972980075   val_loss:  684.4383968276735   time:  1.5533597469329834
e:  6   train_loss:  1061.9049118794358   time:  1.3088178634643555
e:  7   train_loss:  1072.6933316166546   time:  1.2945199012756348
e:  8   train_loss:  1056.6489700118293   time:  1.309230089187622
e:  9   train_loss:  1072.1637980682904   time:  1.295438289642334
e:  10   train_loss:  1054.7081120090047   time:  1.3031964302062988
e:  10   train_loss:  1054.7081120090047   val_loss:  679.023542413897   time:  1.4033939838409424
e:  11   train_loss:  1045.4940433385912   time:  1.4485890865325928
e:  12   train_loss:  1065.5333288823313   time:  1.3105933666229248
e:  13   train_loss:  1062.9716006278804   time:  1.3106040954589844
e:  14   train_loss:  1050.6699687540683   time:  1.308762788772583
e:  15   train_loss:  1050.2639655421212   time:  1.298675537109375
e:  15   train_loss:  1050.2639655421212   val_loss:  673.345539502383   time:  1.3998408317565918
e:  16   train_loss:  1070.3553762542235   time:  1.3108818531036377
e:  17   train_loss:  1053.338877824638   time:  1.3057453632354736
e:  18   train_loss:  1045.0320543856246   time:  1.4266314506530762
e:  19   train_loss:  1038.7942518311525   time:  1.3095943927764893
e:  20   train_loss:  1042.9497303369778   time:  1.3113555908203125
e:  20   train_loss:  1042.9497303369778   val_loss:  667.0311372532134   time:  1.4114279747009277
e:  21   train_loss:  1050.4952818975275   time:  1.3108789920806885
e:  22   train_loss:  1034.017473539528   time:  1.3109023571014404
e:  23   train_loss:  1042.384711855054   time:  1.3088970184326172
e:  24   train_loss:  1034.9690996982401   time:  1.2933590412139893
e:  25   train_loss:  1055.9532521095653   time:  1.4537851810455322
e:  25   train_loss:  1055.9532521095653   val_loss:  659.8366555075274   time:  1.5540916919708252
e:  26   train_loss:  1034.6673726323907   time:  1.3094687461853027
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 12), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 12) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 12) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 12) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 12)
kwargs: {'config': {'batch_norm': False, 'ff_0': 16, 'ff_num_layers': 3, 'gnn_0': 74, 'gnn_dropout': 0.025182456396660613, 'gnn_num_layers': 1, 'hid_0': 85, 'hid_dropout_rate': 0.1720855829121078, 'in_dropout_rate': 0.13383103265402857, 'lr': 1.3960006068852374e-05, 'num_hid_layers': 1, 'optimizer': 'Adam', 'ff_1': 90, 'ff_2': 501}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 858.9018783492468, 'n_epochs': 27.0, 'info': {'validation loss': 858.9018783492468}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 12) started
DEBUG:hpbandster:job_callback for (0, 0, 12) got condition
DEBUG:hpbandster:Only 13 run(s) for budget 27.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:job_callback for (0, 0, 12) finished
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 13) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 13) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 13)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 13) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 13) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 13)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 27, 'ff_num_layers': 1, 'gnn_0': 2016, 'gnn_dropout': 0.10158588776384547, 'gnn_num_layers': 3, 'hid_0': 542, 'hid_dropout_rate': 0.004908279784812952, 'in_dropout_rate': 0.057383681500467576, 'lr': 0.0004466525120963965, 'num_hid_layers': 3, 'optimizer': 'Adam', 'gnn_1': 83, 'gnn_2': 141, 'hid_1': 214, 'hid_2': 105}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  701.994686806178   time:  1.4263861179351807
e:  0   train_loss:  701.994686806178   val_loss:  1651.144985664897   time:  1.539886474609375
e:  1   train_loss:  670.7730164845328   time:  1.4628925323486328
e:  2   train_loss:  609.8445082424269   time:  1.4082975387573242
e:  3   train_loss:  597.711369645931   time:  1.4172337055206299
e:  4   train_loss:  595.2762654313218   time:  1.4465248584747314
e:  5   train_loss:  588.3424205840079   time:  1.6491355895996094
e:  5   train_loss:  588.3424205840079   val_loss:  1376.3482348393115   time:  1.7676339149475098
e:  6   train_loss:  584.4703860617734   time:  1.4264864921569824
e:  7   train_loss:  580.0022456546975   time:  1.4875967502593994
e:  8   train_loss:  573.1601756124597   time:  1.3835861682891846
e:  9   train_loss:  563.7448786709506   time:  1.4917376041412354
e:  10   train_loss:  552.7230064372301   time:  1.3773748874664307
e:  10   train_loss:  552.7230064372301   val_loss:  1376.8264305323569   time:  1.4910612106323242
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  11   train_loss:  537.8803181746839   time:  1.5510623455047607
e:  12   train_loss:  520.2414705603017   time:  1.5820937156677246
e:  13   train_loss:  499.621041898939   time:  1.6865227222442627
e:  14   train_loss:  479.9731431877721   time:  1.3592162132263184
e:  15   train_loss:  463.70880641886066   time:  1.3709099292755127
e:  15   train_loss:  463.70880641886066   val_loss:  1387.4596935210195   time:  1.483816385269165
e:  16   train_loss:  451.51058444713465   time:  1.5525383949279785
e:  17   train_loss:  439.1534211662422   time:  1.3991823196411133
e:  18   train_loss:  430.37567878603863   time:  1.378147840499878
e:  19   train_loss:  423.2496366021659   time:  1.4458284378051758
e:  20   train_loss:  418.0168312823221   time:  1.48604416847229
e:  20   train_loss:  418.0168312823221   val_loss:  1420.6963991351122   time:  1.6003203392028809
e:  21   train_loss:  415.76621878901386   time:  1.501575231552124
e:  22   train_loss:  412.80836443443707   time:  1.3831415176391602
e:  23   train_loss:  410.3733791723786   time:  1.487292766571045
e:  24   train_loss:  408.3981504896618   time:  1.6291072368621826
e:  25   train_loss:  406.9577788312313   time:  1.3585195541381836
e:  25   train_loss:  406.9577788312313   val_loss:  1441.0323267112808   time:  1.471588373184204
e:  26   train_loss:  405.86793563103026   time:  1.3710060119628906
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1069.7646829723678   time:  1.5063021183013916
e:  0   train_loss:  1069.7646829723678   val_loss:  609.4172521164011   time:  1.6137738227844238
e:  1   train_loss:  1007.8017375954065   time:  1.5165660381317139
e:  2   train_loss:  915.3256562719099   time:  1.5158073902130127
e:  3   train_loss:  904.6941901666021   time:  1.666947841644287
e:  4   train_loss:  885.4746084496225   time:  1.5063767433166504
e:  5   train_loss:  883.1286529693236   time:  1.696105718612671
e:  5   train_loss:  883.1286529693236   val_loss:  562.6038105086963   time:  1.8681535720825195
e:  6   train_loss:  877.3395825045664   time:  1.5118963718414307
e:  7   train_loss:  848.7055965224577   time:  1.5072040557861328
e:  8   train_loss:  773.8985541451462   time:  1.5091204643249512
e:  9   train_loss:  709.9411302790284   time:  1.5944364070892334
e:  10   train_loss:  690.6714045862977   time:  1.6553926467895508
e:  10   train_loss:  690.6714045862977   val_loss:  970.1056814053869   time:  1.761885404586792
e:  11   train_loss:  682.5894083062502   time:  1.5060040950775146
e:  12   train_loss:  651.8852530549773   time:  1.513261318206787
e:  13   train_loss:  628.9060817857094   time:  1.5142602920532227
e:  14   train_loss:  622.8856602810531   time:  1.5098130702972412
e:  15   train_loss:  596.8758289766331   time:  1.5113284587860107
e:  15   train_loss:  596.8758289766331   val_loss:  801.9934563766437   time:  1.6186795234680176
e:  16   train_loss:  591.1810069864697   time:  1.5058872699737549
e:  17   train_loss:  584.7546705570089   time:  1.6378123760223389
e:  18   train_loss:  569.7322991235757   time:  1.6605453491210938
e:  19   train_loss:  556.2203625483862   time:  1.5087835788726807
e:  20   train_loss:  558.8404929026271   time:  1.5618197917938232
e:  20   train_loss:  558.8404929026271   val_loss:  787.5115247016139   time:  1.6697463989257812
e:  21   train_loss:  560.4158407051486   time:  1.503509521484375
e:  22   train_loss:  550.6372602881803   time:  1.5135993957519531
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  23   train_loss:  550.004858657784   time:  1.650153398513794
e:  24   train_loss:  552.9233110951352   time:  1.5113036632537842
e:  25   train_loss:  545.9765241131   time:  1.5186572074890137
e:  25   train_loss:  545.9765241131   val_loss:  850.4782824645216   time:  1.6255743503570557
e:  26   train_loss:  548.3049933482464   time:  1.51448655128479
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1059.0923605991018   time:  1.4942388534545898
e:  0   train_loss:  1059.0923605991018   val_loss:  528.5356250375943   time:  1.6046247482299805
e:  1   train_loss:  1029.908208717699   time:  1.6208133697509766
e:  2   train_loss:  920.5217784366445   time:  1.4954376220703125
e:  3   train_loss:  868.6600525670592   time:  1.5388309955596924
e:  4   train_loss:  908.5802211056774   time:  1.610748052597046
e:  5   train_loss:  877.910640123845   time:  1.5269083976745605
e:  5   train_loss:  877.910640123845   val_loss:  509.1554821727241   time:  1.6364188194274902
e:  6   train_loss:  857.2848041256713   time:  1.4902074337005615
e:  7   train_loss:  857.6141971846095   time:  1.492908239364624
e:  8   train_loss:  845.6781891903545   time:  1.6385459899902344
e:  9   train_loss:  784.6216814147192   time:  1.4701290130615234
e:  10   train_loss:  750.3881549338612   time:  1.4719569683074951
e:  10   train_loss:  750.3881549338612   val_loss:  481.75328961863704   time:  1.581115961074829
e:  11   train_loss:  733.9543663549564   time:  1.493959903717041
e:  12   train_loss:  682.4871852117225   time:  1.4964625835418701
e:  13   train_loss:  653.1884621808754   time:  1.4958553314208984
e:  14   train_loss:  630.2671783509898   time:  1.4154229164123535
e:  15   train_loss:  625.4125011196797   time:  1.4527759552001953
e:  15   train_loss:  625.4125011196797   val_loss:  502.74143301133756   time:  1.5627589225769043
e:  16   train_loss:  634.593130647309   time:  1.7319700717926025
e:  17   train_loss:  616.8726860911314   time:  1.542283535003662
e:  18   train_loss:  610.1974793902009   time:  1.5282971858978271
e:  19   train_loss:  582.1439783471887   time:  1.5408923625946045
e:  20   train_loss:  605.544865363191   time:  1.5280964374542236
e:  20   train_loss:  605.544865363191   val_loss:  512.0402542237341   time:  1.6379024982452393
e:  21   train_loss:  593.1389133167726   time:  1.5707578659057617
e:  22   train_loss:  581.3549277603997   time:  1.498521327972412
e:  23   train_loss:  570.5880539155872   time:  1.5737147331237793
e:  24   train_loss:  576.8799296558799   time:  1.5719048976898193
e:  25   train_loss:  557.533568206805   time:  1.6965012550354004
e:  25   train_loss:  557.533568206805   val_loss:  501.8411742604891   time:  1.806276798248291
e:  26   train_loss:  570.0041304656261   time:  1.4872982501983643
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  992.5051336718619   time:  1.3658347129821777
e:  0   train_loss:  992.5051336718619   val_loss:  891.6164114626275   time:  1.4802296161651611
e:  1   train_loss:  936.29860667788   time:  1.372877836227417
e:  2   train_loss:  852.6818920064445   time:  1.5462379455566406
e:  3   train_loss:  841.7422423438484   time:  1.527714490890503
e:  4   train_loss:  834.4578256884092   time:  1.3643105030059814
e:  5   train_loss:  823.5727936641572   time:  1.3780255317687988
e:  5   train_loss:  823.5727936641572   val_loss:  735.2436008835889   time:  1.4922966957092285
e:  6   train_loss:  814.7882915824414   time:  1.3771405220031738
e:  7   train_loss:  798.3248388601136   time:  1.377692461013794
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  8   train_loss:  764.0044954459611   time:  1.379328727722168
e:  9   train_loss:  732.4521197074833   time:  1.375288486480713
e:  10   train_loss:  698.4179676098078   time:  1.5027344226837158
e:  10   train_loss:  698.4179676098078   val_loss:  717.5075947930416   time:  1.617279291152954
e:  11   train_loss:  659.2886343692762   time:  1.3690757751464844
e:  12   train_loss:  632.8049940524787   time:  1.3783085346221924
e:  13   train_loss:  619.8976293802775   time:  1.3768620491027832
e:  14   train_loss:  602.8542648533706   time:  1.3765044212341309
e:  15   train_loss:  587.0830381460156   time:  1.3782923221588135
e:  15   train_loss:  587.0830381460156   val_loss:  707.5121112581352   time:  1.4926214218139648
e:  16   train_loss:  574.331295321238   time:  1.3735682964324951
e:  17   train_loss:  562.2985951656807   time:  1.3773720264434814
e:  18   train_loss:  554.2145173392516   time:  1.3712053298950195
e:  19   train_loss:  546.7220120216093   time:  1.5028231143951416
e:  20   train_loss:  542.0727315019026   time:  1.3764057159423828
e:  20   train_loss:  542.0727315019026   val_loss:  706.3112986574209   time:  1.4902992248535156
e:  21   train_loss:  535.6082110843944   time:  1.3777575492858887
e:  22   train_loss:  533.9142036943314   time:  1.3691694736480713
e:  23   train_loss:  529.8159124058193   time:  1.3422622680664062
e:  24   train_loss:  528.5026015449347   time:  1.3720061779022217
e:  25   train_loss:  524.4127947974955   time:  1.3760573863983154
e:  25   train_loss:  524.4127947974955   val_loss:  721.9898794469784   time:  1.4898319244384766
e:  26   train_loss:  524.181454480235   time:  1.3786492347717285
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1046.351809586125   time:  1.5107526779174805
e:  0   train_loss:  1046.351809586125   val_loss:  670.9872317370019   time:  1.6184687614440918
e:  1   train_loss:  996.2565231802307   time:  1.5128700733184814
e:  2   train_loss:  910.4098110433551   time:  1.6602990627288818
e:  3   train_loss:  910.0895032699477   time:  1.498711109161377
e:  4   train_loss:  896.5806706911779   time:  1.507087230682373
e:  5   train_loss:  884.6832928095517   time:  1.5043938159942627
e:  5   train_loss:  884.6832928095517   val_loss:  554.424276058059   time:  1.6124792098999023
e:  6   train_loss:  872.2291531400278   time:  1.498199462890625
e:  7   train_loss:  853.7245020107677   time:  1.5103678703308105
e:  8   train_loss:  793.3472671314325   time:  1.7419719696044922
e:  9   train_loss:  765.9365548119409   time:  1.5088732242584229
e:  10   train_loss:  712.7151346277371   time:  1.5100228786468506
e:  10   train_loss:  712.7151346277371   val_loss:  565.9498571089941   time:  1.6190016269683838
e:  11   train_loss:  669.2695409172458   time:  1.504683494567871
e:  12   train_loss:  648.9305656715106   time:  1.5018136501312256
e:  13   train_loss:  642.2669114544217   time:  1.5085549354553223
e:  14   train_loss:  635.7855386653142   time:  1.6562955379486084
e:  15   train_loss:  613.3311464252891   time:  1.4863779544830322
e:  15   train_loss:  613.3311464252891   val_loss:  562.1899935127468   time:  1.5933201313018799
e:  16   train_loss:  609.0274937246451   time:  1.4904940128326416
e:  17   train_loss:  589.5645876848196   time:  1.5099012851715088
e:  18   train_loss:  595.6289767110336   time:  1.515516757965088
e:  19   train_loss:  583.4920483039292   time:  1.7239711284637451
e:  20   train_loss:  593.1293233652733   time:  1.5302112102508545
e:  20   train_loss:  593.1293233652733   val_loss:  565.3851359237344   time:  1.638395071029663
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  21   train_loss:  586.8347084391648   time:  1.6553339958190918
e:  22   train_loss:  568.9345050950185   time:  1.5075860023498535
e:  23   train_loss:  570.6840290616504   time:  1.5094294548034668
e:  24   train_loss:  575.6640285840249   time:  1.5081632137298584
e:  25   train_loss:  566.4445352841121   time:  1.5049867630004883
e:  25   train_loss:  566.4445352841121   val_loss:  570.3090245739588   time:  1.6138904094696045
e:  26   train_loss:  570.7606148455411   time:  1.5256562232971191
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 13), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 13) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 13) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 13) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 13)
kwargs: {'config': {'batch_norm': False, 'ff_0': 27, 'ff_num_layers': 1, 'gnn_0': 2016, 'gnn_dropout': 0.10158588776384547, 'gnn_num_layers': 3, 'hid_0': 542, 'hid_dropout_rate': 0.004908279784812952, 'in_dropout_rate': 0.057383681500467576, 'lr': 0.0004466525120963965, 'num_hid_layers': 3, 'optimizer': 'Adam', 'gnn_1': 83, 'gnn_2': 141, 'hid_1': 214, 'hid_2': 105}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 736.288181936425, 'n_epochs': 27.0, 'info': {'validation loss': 736.288181936425}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 13) started
DEBUG:hpbandster:job_callback for (0, 0, 13) got condition
DEBUG:hpbandster:Only 14 run(s) for budget 27.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 13) finished
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 14) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 14) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 14)
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 14) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 14) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 14)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 214, 'ff_num_layers': 1, 'gnn_0': 1421, 'gnn_dropout': 0.48575232412252367, 'gnn_num_layers': 1, 'hid_0': 366, 'hid_dropout_rate': 0.16943484925922442, 'in_dropout_rate': 0.16962245313039404, 'lr': 0.000645480083493207, 'num_hid_layers': 2, 'optimizer': 'Adam', 'hid_1': 244}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  682.4824660481931   time:  1.5481572151184082
e:  0   train_loss:  682.4824660481931   val_loss:  1493.125458219168   time:  1.6559154987335205
e:  1   train_loss:  606.1565079080732   time:  1.316032886505127
e:  2   train_loss:  598.4356956308958   time:  1.2989137172698975
e:  3   train_loss:  592.0196814196721   time:  1.3015148639678955
e:  4   train_loss:  588.2554163331426   time:  1.3089830875396729
e:  5   train_loss:  584.1824059625959   time:  1.3069572448730469
e:  5   train_loss:  584.1824059625959   val_loss:  1370.8421571195374   time:  1.417766809463501
e:  6   train_loss:  579.1688507165436   time:  1.3127009868621826
e:  7   train_loss:  573.2985051881893   time:  1.312392234802246
e:  8   train_loss:  566.3870945378033   time:  1.3010258674621582
e:  9   train_loss:  556.7371148689227   time:  1.4112498760223389
e:  10   train_loss:  544.8238561193388   time:  1.3556609153747559
e:  10   train_loss:  544.8238561193388   val_loss:  1381.5897037688155   time:  1.4578852653503418
e:  11   train_loss:  528.6579664795777   time:  1.3089654445648193
e:  12   train_loss:  512.5005091205649   time:  1.307511568069458
e:  13   train_loss:  497.4153246798747   time:  1.3002853393554688
e:  14   train_loss:  482.21104498097765   time:  1.3011300563812256
e:  15   train_loss:  471.31553338165565   time:  1.3001160621643066
e:  15   train_loss:  471.31553338165565   val_loss:  1370.6108965927128   time:  1.4103164672851562
e:  16   train_loss:  455.6447166375771   time:  1.301405668258667
e:  17   train_loss:  447.78888324486473   time:  1.3041951656341553
e:  18   train_loss:  439.4229041606112   time:  1.3119935989379883
e:  19   train_loss:  431.8769457335036   time:  1.592200517654419
e:  20   train_loss:  426.5758047529573   time:  1.3315072059631348
e:  20   train_loss:  426.5758047529573   val_loss:  1420.8174306555795   time:  1.4928722381591797
e:  21   train_loss:  421.8573640606606   time:  1.4099352359771729
e:  22   train_loss:  420.0967608451   time:  1.4106764793395996
e:  23   train_loss:  417.6276370532911   time:  1.3182499408721924
e:  24   train_loss:  415.97408493561176   time:  1.3105409145355225
e:  25   train_loss:  416.76487916820406   time:  1.3163270950317383
e:  25   train_loss:  416.76487916820406   val_loss:  1439.3378605025284   time:  1.426633596420288
e:  26   train_loss:  414.1474277599175   time:  1.3131465911865234
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1044.9101990791928   time:  1.7023868560791016
e:  0   train_loss:  1044.9101990791928   val_loss:  539.7482021704989   time:  1.8069586753845215
e:  1   train_loss:  910.2814922192782   time:  1.4390439987182617
e:  2   train_loss:  911.0951114299324   time:  1.5895109176635742
e:  3   train_loss:  889.9690459716517   time:  1.4096999168395996
e:  4   train_loss:  887.3311508477075   time:  1.4308288097381592
e:  5   train_loss:  864.3794391843494   time:  1.4348249435424805
e:  5   train_loss:  864.3794391843494   val_loss:  563.5516514950182   time:  1.539442539215088
e:  6   train_loss:  847.1754403243488   time:  1.4351248741149902
e:  7   train_loss:  799.8345933276136   time:  1.431868314743042
e:  8   train_loss:  754.5848010235003   time:  1.433192253112793
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  9   train_loss:  704.7243831869769   time:  1.6122832298278809
e:  10   train_loss:  669.8258304195116   time:  1.4330134391784668
e:  10   train_loss:  669.8258304195116   val_loss:  931.1048222949725   time:  1.5364203453063965
e:  11   train_loss:  657.651461914865   time:  1.4339966773986816
e:  12   train_loss:  628.7943146491084   time:  1.4335405826568604
e:  13   train_loss:  626.4423150471525   time:  1.4357154369354248
e:  14   train_loss:  611.1202285617807   time:  1.4341766834259033
e:  15   train_loss:  597.5299069297813   time:  1.437013864517212
e:  15   train_loss:  597.5299069297813   val_loss:  897.6059918444596   time:  1.6845903396606445
e:  16   train_loss:  586.5606081509827   time:  1.4321093559265137
e:  17   train_loss:  587.2313622985948   time:  1.43257474899292
e:  18   train_loss:  583.2210636953481   time:  1.4284498691558838
e:  19   train_loss:  568.8883807738089   time:  1.4337620735168457
e:  20   train_loss:  571.8605433345126   time:  1.4336023330688477
e:  20   train_loss:  571.8605433345126   val_loss:  1024.8104491721722   time:  1.5378262996673584
e:  21   train_loss:  557.2396090166147   time:  1.432455062866211
e:  22   train_loss:  561.3970073888091   time:  1.4311347007751465
e:  23   train_loss:  560.3364346263834   time:  1.5746588706970215
e:  24   train_loss:  554.3236341369253   time:  1.4222166538238525
e:  25   train_loss:  548.2325709822732   time:  1.4362306594848633
e:  25   train_loss:  548.2325709822732   val_loss:  959.4028235824027   time:  1.5396325588226318
e:  26   train_loss:  549.7982155037658   time:  1.4378960132598877
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1103.8603183508453   time:  1.420097827911377
e:  0   train_loss:  1103.8603183508453   val_loss:  473.6552894053316   time:  1.5272624492645264
e:  1   train_loss:  946.6798251021274   time:  1.5692808628082275
e:  2   train_loss:  894.4848448110911   time:  1.42118501663208
e:  3   train_loss:  911.7119676555984   time:  1.4218847751617432
e:  4   train_loss:  888.0833729479795   time:  1.4239728450775146
e:  5   train_loss:  849.2918605564581   time:  1.4225504398345947
e:  5   train_loss:  849.2918605564581   val_loss:  503.0889098711595   time:  1.5299301147460938
e:  6   train_loss:  848.2347661917406   time:  1.4196014404296875
e:  7   train_loss:  839.9075135370869   time:  1.4233503341674805
e:  8   train_loss:  819.5887022798593   time:  1.5693755149841309
e:  9   train_loss:  738.8704855302454   time:  1.4200191497802734
e:  10   train_loss:  716.9335538646019   time:  1.4235289096832275
e:  10   train_loss:  716.9335538646019   val_loss:  517.7727411839929   time:  1.5304358005523682
e:  11   train_loss:  687.893814631893   time:  1.4234952926635742
e:  12   train_loss:  698.935129640468   time:  1.4138033390045166
e:  13   train_loss:  657.6919722249203   time:  1.4231131076812744
e:  14   train_loss:  639.5236509447742   time:  1.4213042259216309
e:  15   train_loss:  640.2581662263084   time:  1.5759551525115967
e:  15   train_loss:  640.2581662263084   val_loss:  548.2199920587395   time:  1.6818280220031738
e:  16   train_loss:  625.1512946421907   time:  1.4071156978607178
e:  17   train_loss:  638.3084248498141   time:  1.4059085845947266
e:  18   train_loss:  601.7982861393134   time:  1.4183268547058105
e:  19   train_loss:  596.8824455225105   time:  1.4214258193969727
e:  20   train_loss:  595.3962090645368   time:  1.4194152355194092
e:  20   train_loss:  595.3962090645368   val_loss:  507.3817459769534   time:  1.525928020477295
e:  21   train_loss:  599.894505193212   time:  1.4183659553527832
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  22   train_loss:  581.5500572692989   time:  1.5734593868255615
e:  23   train_loss:  586.3777320900923   time:  1.4184412956237793
e:  24   train_loss:  596.4535577503199   time:  1.418278455734253
e:  25   train_loss:  597.353495328594   time:  1.4185845851898193
e:  25   train_loss:  597.353495328594   val_loss:  491.12662900349613   time:  1.5253946781158447
e:  26   train_loss:  607.3111736508847   time:  1.420992136001587
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  978.3997787830042   time:  1.3104074001312256
e:  0   train_loss:  978.3997787830042   val_loss:  830.2465119871237   time:  1.4208202362060547
e:  1   train_loss:  864.9280176529512   time:  1.312431812286377
e:  2   train_loss:  838.1700282084958   time:  1.3153648376464844
e:  3   train_loss:  832.2627613040153   time:  1.315678358078003
e:  4   train_loss:  823.5827744931838   time:  1.3130743503570557
e:  5   train_loss:  818.253865552658   time:  1.314333438873291
e:  5   train_loss:  818.253865552658   val_loss:  733.9668907622412   time:  1.424971342086792
e:  6   train_loss:  804.6878503599761   time:  1.4509618282318115
e:  7   train_loss:  794.9477437295401   time:  1.3144259452819824
e:  8   train_loss:  777.3713552863688   time:  1.3142149448394775
e:  9   train_loss:  745.656900590207   time:  1.31404447555542
e:  10   train_loss:  707.9034404683307   time:  1.3154056072235107
e:  10   train_loss:  707.9034404683307   val_loss:  708.3858715750043   time:  1.425504446029663
e:  11   train_loss:  680.9701668577777   time:  1.285398006439209
e:  12   train_loss:  648.2446004703131   time:  1.3049845695495605
e:  13   train_loss:  631.8662880694659   time:  1.31337308883667
e:  14   train_loss:  609.1241241823005   time:  1.314711332321167
e:  15   train_loss:  599.2204665976776   time:  1.4556469917297363
e:  15   train_loss:  599.2204665976776   val_loss:  712.6420917699185   time:  1.5592632293701172
e:  16   train_loss:  586.9636247568616   time:  1.316467523574829
e:  17   train_loss:  581.0316395755995   time:  1.3139894008636475
e:  18   train_loss:  577.9288348636848   time:  1.3122689723968506
e:  19   train_loss:  572.8032231998714   time:  1.3152618408203125
e:  20   train_loss:  564.0871496393795   time:  1.3145055770874023
e:  20   train_loss:  564.0871496393795   val_loss:  715.4571565778857   time:  1.4257183074951172
e:  21   train_loss:  557.5923657155912   time:  1.316032886505127
e:  22   train_loss:  550.5650842738848   time:  1.3150081634521484
e:  23   train_loss:  544.9345836024211   time:  1.3080387115478516
e:  24   train_loss:  543.7160241043107   time:  1.4512360095977783
e:  25   train_loss:  544.3579022526953   time:  1.3139686584472656
e:  25   train_loss:  544.3579022526953   val_loss:  717.2494035879777   time:  1.4242289066314697
e:  26   train_loss:  541.7347341964874   time:  1.3103768825531006
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1043.3251940573534   time:  1.4368603229522705
e:  0   train_loss:  1043.3251940573534   val_loss:  578.4369875131938   time:  1.5417006015777588
e:  1   train_loss:  913.8429534739278   time:  1.4360110759735107
e:  2   train_loss:  893.6465249323484   time:  1.43412446975708
e:  3   train_loss:  879.9118774069939   time:  1.4359774589538574
e:  4   train_loss:  874.2679062542373   time:  1.4391553401947021
e:  5   train_loss:  866.9248545771483   time:  1.4241857528686523
e:  5   train_loss:  866.9248545771483   val_loss:  554.9595606215324   time:  1.6708991527557373
e:  6   train_loss:  835.0029921609266   time:  1.4115688800811768
e:  7   train_loss:  802.0874342969508   time:  1.4357068538665771
e:  8   train_loss:  755.4215597822069   time:  1.4294838905334473
e:  9   train_loss:  710.7281088156835   time:  1.4389667510986328
e:  10   train_loss:  680.8851577314114   time:  1.4397766590118408
e:  10   train_loss:  680.8851577314114   val_loss:  582.132748604099   time:  1.5453386306762695
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  11   train_loss:  661.3255204456611   time:  1.438725471496582
e:  12   train_loss:  644.4788519167247   time:  1.4307653903961182
e:  13   train_loss:  626.3223390376786   time:  1.6035287380218506
e:  14   train_loss:  628.0294321125685   time:  1.4346959590911865
e:  15   train_loss:  606.0979629196165   time:  1.4368610382080078
e:  15   train_loss:  606.0979629196165   val_loss:  573.5231396426988   time:  1.5413894653320312
e:  16   train_loss:  608.2035134612811   time:  1.4376673698425293
e:  17   train_loss:  590.0341948459076   time:  1.4312481880187988
e:  18   train_loss:  586.1374672930651   time:  1.4376749992370605
e:  19   train_loss:  585.3192373334437   time:  1.592555284500122
e:  20   train_loss:  582.2078916279673   time:  1.4381732940673828
e:  20   train_loss:  582.2078916279673   val_loss:  580.5977951635884   time:  1.5433788299560547
e:  21   train_loss:  578.4431775046465   time:  1.4413142204284668
e:  22   train_loss:  576.9367562992288   time:  1.4357495307922363
e:  23   train_loss:  576.8940693162377   time:  1.432924509048462
e:  24   train_loss:  579.9005006005307   time:  1.4364769458770752
e:  25   train_loss:  565.7027713819248   time:  1.5593211650848389
e:  25   train_loss:  565.7027713819248   val_loss:  584.1561162784525   time:  1.6635897159576416
e:  26   train_loss:  564.9780521015418   time:  1.40427565574646
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 14), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 14) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 14) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 14) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 14)
kwargs: {'config': {'batch_norm': False, 'ff_0': 214, 'ff_num_layers': 1, 'gnn_0': 1421, 'gnn_dropout': 0.48575232412252367, 'gnn_num_layers': 1, 'hid_0': 366, 'hid_dropout_rate': 0.16943484925922442, 'in_dropout_rate': 0.16962245313039404, 'lr': 0.000645480083493207, 'num_hid_layers': 2, 'optimizer': 'Adam', 'hid_1': 244}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 729.4719640730161, 'n_epochs': 27.0, 'info': {'validation loss': 729.4719640730161}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 14) started
DEBUG:hpbandster:job_callback for (0, 0, 14) got condition
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:Only 15 run(s) for budget 27.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 14) finished
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 15) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 15) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 15)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 15) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 15) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 15)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 30, 'ff_num_layers': 1, 'gnn_0': 1724, 'gnn_dropout': 0.16203243204750928, 'gnn_num_layers': 3, 'hid_0': 1259, 'hid_dropout_rate': 0.4895906060940636, 'in_dropout_rate': 0.17717454867023485, 'lr': 0.001508840596256224, 'num_hid_layers': 3, 'optimizer': 'SGD', 'gnn_1': 1662, 'gnn_2': 71, 'hid_1': 1500, 'hid_2': 256, 'sgd_momentum': 0.6568930593605463}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  701.035115315065   time:  1.7804417610168457
e:  0   train_loss:  701.035115315065   val_loss:  1645.3416659194058   time:  1.9061541557312012
e:  1   train_loss:  654.0695965293189   time:  1.725426197052002
e:  2   train_loss:  578.0796799523682   time:  1.7214035987854004
e:  3   train_loss:  566.3071485824094   time:  1.8052010536193848
e:  4   train_loss:  542.3255404793376   time:  1.806687593460083
e:  5   train_loss:  522.4815466816402   time:  1.7828426361083984
e:  5   train_loss:  522.4815466816402   val_loss:  1422.8542266717407   time:  1.9078712463378906
e:  6   train_loss:  499.16502812065727   time:  1.879845142364502
e:  7   train_loss:  495.1169824796013   time:  1.679408073425293
e:  8   train_loss:  468.24410406408157   time:  1.694833755493164
e:  9   train_loss:  502.84001723315345   time:  1.724266767501831
e:  10   train_loss:  504.8472914325551   time:  1.718120813369751
e:  10   train_loss:  504.8472914325551   val_loss:  1576.6807508023592   time:  1.8442327976226807
e:  11   train_loss:  521.391962727428   time:  1.7190587520599365
e:  12   train_loss:  462.0724999904577   time:  1.7193360328674316
e:  13   train_loss:  458.92731565258913   time:  1.7200534343719482
e:  14   train_loss:  445.49900684959755   time:  1.7253656387329102
e:  15   train_loss:  439.55922660830464   time:  1.7204937934875488
e:  15   train_loss:  439.55922660830464   val_loss:  1584.430063366889   time:  1.933138132095337
e:  16   train_loss:  494.9159047524445   time:  1.702962875366211
e:  17   train_loss:  528.0569885286941   time:  1.8761582374572754
e:  18   train_loss:  520.5772064152521   time:  1.7317440509796143
e:  19   train_loss:  437.7096084918103   time:  1.7234172821044922
e:  20   train_loss:  429.40885004574125   time:  1.7303853034973145
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  20   train_loss:  429.40885004574125   val_loss:  1366.8954999772602   time:  1.8573777675628662
e:  21   train_loss:  424.76322014455747   time:  1.7691473960876465
e:  22   train_loss:  418.2995227707769   time:  1.7153098583221436
e:  23   train_loss:  429.16696022933206   time:  1.7377426624298096
e:  24   train_loss:  408.6668240980021   time:  1.7738604545593262
e:  25   train_loss:  423.23778600159727   time:  1.737168550491333
e:  25   train_loss:  423.23778600159727   val_loss:  1435.7074120701855   time:  1.8638885021209717
e:  26   train_loss:  494.0091260203637   time:  1.761246919631958
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1066.1990218205697   time:  1.9839770793914795
e:  0   train_loss:  1066.1990218205697   val_loss:  603.3192346845653   time:  2.0998804569244385
e:  1   train_loss:  954.36257782089   time:  1.8817174434661865
e:  2   train_loss:  805.0955431460085   time:  1.878309965133667
e:  3   train_loss:  747.3287671003447   time:  1.8504133224487305
e:  4   train_loss:  788.0652005640646   time:  1.900010347366333
e:  5   train_loss:  769.1806086531925   time:  1.788785457611084
e:  5   train_loss:  769.1806086531925   val_loss:  1141.2279054297221   time:  1.9037902355194092
e:  6   train_loss:  729.3472848352216   time:  2.030954599380493
e:  7   train_loss:  753.007844239393   time:  1.8780505657196045
e:  8   train_loss:  962.4451893394918   time:  1.8556303977966309
e:  9   train_loss:  816.5360959535906   time:  1.8814537525177002
e:  10   train_loss:  721.5057821892495   time:  1.8836851119995117
e:  10   train_loss:  721.5057821892495   val_loss:  562.0029767358131   time:  2.0006041526794434
e:  11   train_loss:  791.2860452756288   time:  1.8284456729888916
e:  12   train_loss:  761.2785578286529   time:  1.8731472492218018
e:  13   train_loss:  801.5813802533806   time:  1.9501652717590332
e:  14   train_loss:  782.0182728804705   time:  1.881044626235962
e:  15   train_loss:  761.1760768388075   time:  1.8481547832489014
e:  15   train_loss:  761.1760768388075   val_loss:  1349.1104274556587   time:  1.9653205871582031
e:  16   train_loss:  772.2689919442613   time:  1.8773977756500244
e:  17   train_loss:  919.0405096378319   time:  1.8779652118682861
e:  18   train_loss:  915.0974923142736   time:  1.8787627220153809
e:  19   train_loss:  912.965711527272   time:  1.8050029277801514
e:  20   train_loss:  909.2650761950745   time:  1.9270551204681396
e:  20   train_loss:  909.2650761950745   val_loss:  686.9719486799011   time:  2.0420074462890625
e:  21   train_loss:  781.9237807842775   time:  1.8023438453674316
e:  22   train_loss:  814.430862589196   time:  1.7941734790802002
e:  23   train_loss:  847.303412669452   time:  1.7771921157836914
e:  24   train_loss:  769.6090718498654   time:  1.8461308479309082
e:  25   train_loss:  863.9968015529428   time:  1.7918307781219482
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  25   train_loss:  863.9968015529428   val_loss:  1161.0924691286507   time:  1.9111599922180176
e:  26   train_loss:  780.2031223874395   time:  2.037991762161255
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1066.3449950479314   time:  1.8542194366455078
e:  0   train_loss:  1066.3449950479314   val_loss:  514.5914514989973   time:  1.9744617938995361
e:  1   train_loss:  899.5829805658228   time:  1.8490800857543945
e:  2   train_loss:  796.2852708475051   time:  1.855644941329956
e:  3   train_loss:  797.2410991140991   time:  1.8308045864105225
e:  4   train_loss:  1155.899370397245   time:  1.7598052024841309
e:  5   train_loss:  1012.6034250126108   time:  1.8312408924102783
e:  5   train_loss:  1012.6034250126108   val_loss:  497.6928309488871   time:  1.9528241157531738
e:  6   train_loss:  1012.6006628380003   time:  1.9324421882629395
e:  7   train_loss:  982.0377405411954   time:  1.775026798248291
e:  8   train_loss:  860.0768675792269   time:  1.7555742263793945
e:  9   train_loss:  783.1170465089458   time:  1.8223841190338135
e:  10   train_loss:  847.017855772902   time:  1.763334035873413
e:  10   train_loss:  847.017855772902   val_loss:  481.2090470170756   time:  1.8816239833831787
e:  11   train_loss:  839.3583542101476   time:  1.770735263824463
e:  12   train_loss:  833.8811224705235   time:  1.8477530479431152
e:  13   train_loss:  774.946019127115   time:  1.8983454704284668
e:  14   train_loss:  826.8086805664645   time:  1.8432772159576416
e:  15   train_loss:  786.7784733540316   time:  1.8548433780670166
e:  15   train_loss:  786.7784733540316   val_loss:  596.0204954694802   time:  1.9755547046661377
e:  16   train_loss:  741.0993419140718   time:  1.8560271263122559
e:  17   train_loss:  775.8178316076701   time:  1.8564143180847168
e:  18   train_loss:  757.6615306258426   time:  1.8243329524993896
e:  19   train_loss:  741.2807907458716   time:  1.7626278400421143
e:  20   train_loss:  716.4599199225115   time:  1.8258450031280518
e:  20   train_loss:  716.4599199225115   val_loss:  501.5213937261227   time:  1.9471933841705322
e:  21   train_loss:  717.9252658505836   time:  2.004061460494995
e:  22   train_loss:  677.3488440573711   time:  1.8587136268615723
e:  23   train_loss:  653.0466412114921   time:  1.8568270206451416
e:  24   train_loss:  677.0724938452669   time:  1.8114778995513916
e:  25   train_loss:  865.9055974091007   time:  1.8469526767730713
e:  25   train_loss:  865.9055974091007   val_loss:  489.652733404559   time:  1.9655704498291016
e:  26   train_loss:  802.0942359779497   time:  1.7603294849395752
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  989.9684638246003   time:  1.6574890613555908
e:  0   train_loss:  989.9684638246003   val_loss:  890.4770133260456   time:  1.9115843772888184
e:  1   train_loss:  905.9830180307796   time:  1.7270019054412842
e:  2   train_loss:  728.6427177533451   time:  1.721592903137207
e:  3   train_loss:  746.931230489195   time:  1.6633961200714111
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  4   train_loss:  731.6943492391963   time:  1.7045180797576904
e:  5   train_loss:  752.2486811393521   time:  1.717315912246704
e:  5   train_loss:  752.2486811393521   val_loss:  749.9352436535193   time:  1.8435189723968506
e:  6   train_loss:  745.4123123642204   time:  1.720895528793335
e:  7   train_loss:  706.5115897400461   time:  1.7203505039215088
e:  8   train_loss:  664.7917314574349   time:  1.7192189693450928
e:  9   train_loss:  640.2255819171263   time:  1.7187416553497314
e:  10   train_loss:  684.2658571904477   time:  1.717109203338623
e:  10   train_loss:  684.2658571904477   val_loss:  702.7648053728785   time:  1.8429243564605713
e:  11   train_loss:  662.7246240897637   time:  1.860675573348999
e:  12   train_loss:  648.2032139220108   time:  1.727766752243042
e:  13   train_loss:  683.0243936310136   time:  1.6555838584899902
e:  14   train_loss:  659.944150009106   time:  1.7173705101013184
e:  15   train_loss:  619.9902136149608   time:  1.6832847595214844
e:  15   train_loss:  619.9902136149608   val_loss:  673.835369153394   time:  1.8064625263214111
e:  16   train_loss:  622.6237446479682   time:  1.6296746730804443
e:  17   train_loss:  622.3756448257194   time:  1.683018684387207
e:  18   train_loss:  686.8958738384911   time:  1.7210795879364014
e:  19   train_loss:  726.1911082538144   time:  1.7193405628204346
e:  20   train_loss:  646.1420970598182   time:  1.7184088230133057
e:  20   train_loss:  646.1420970598182   val_loss:  700.9169777164361   time:  1.8451275825500488
e:  21   train_loss:  683.2897901743562   time:  1.7192206382751465
e:  22   train_loss:  684.9355297533866   time:  1.7201483249664307
e:  23   train_loss:  654.516149509216   time:  1.8389496803283691
e:  24   train_loss:  621.550486750991   time:  1.719280481338501
e:  25   train_loss:  613.6212325947612   time:  1.7161285877227783
e:  25   train_loss:  613.6212325947612   val_loss:  672.6214652410995   time:  1.8431870937347412
e:  26   train_loss:  599.7150960192707   time:  1.7197799682617188
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1071.6762203470882   time:  1.893373966217041
e:  0   train_loss:  1071.6762203470882   val_loss:  656.379710792856   time:  2.0129966735839844
e:  1   train_loss:  921.2172270582655   time:  1.8784537315368652
e:  2   train_loss:  774.1522391679176   time:  1.8824183940887451
e:  3   train_loss:  722.6892292727559   time:  2.0252561569213867
e:  4   train_loss:  893.6292549332795   time:  1.8575665950775146
e:  5   train_loss:  980.5764827956536   time:  1.8070392608642578
e:  5   train_loss:  980.5764827956536   val_loss:  557.7473602636245   time:  1.9237639904022217
e:  6   train_loss:  902.3215925180407   time:  1.8228867053985596
e:  7   train_loss:  810.2718859510087   time:  1.8755526542663574
e:  8   train_loss:  769.9908036417564   time:  1.8025403022766113
e:  9   train_loss:  733.2597364168369   time:  1.7770450115203857
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  10   train_loss:  782.1619044509788   time:  1.99391508102417
e:  10   train_loss:  782.1619044509788   val_loss:  588.8187106853194   time:  2.113121271133423
e:  11   train_loss:  801.737515530814   time:  1.8824748992919922
e:  12   train_loss:  736.3372049422053   time:  1.8850297927856445
e:  13   train_loss:  723.0857968295485   time:  1.8205363750457764
e:  14   train_loss:  742.4289451301129   time:  1.8636078834533691
e:  15   train_loss:  962.5271975695812   time:  1.8779373168945312
e:  15   train_loss:  962.5271975695812   val_loss:  557.6609821065974   time:  1.9972918033599854
e:  16   train_loss:  773.5356164023607   time:  1.907909870147705
e:  17   train_loss:  744.2087385461067   time:  2.028404951095581
e:  18   train_loss:  750.0610353891844   time:  1.8206157684326172
e:  19   train_loss:  713.3104895261882   time:  1.7797887325286865
e:  20   train_loss:  690.3338366999362   time:  1.8486871719360352
e:  20   train_loss:  690.3338366999362   val_loss:  557.7932743290781   time:  1.9657049179077148
e:  21   train_loss:  680.0485501847058   time:  1.7815544605255127
e:  22   train_loss:  664.3300956509448   time:  1.8231215476989746
e:  23   train_loss:  731.5174610566584   time:  1.8459582328796387
e:  24   train_loss:  744.5855631906935   time:  2.023256540298462
e:  25   train_loss:  695.109449480324   time:  1.8815338611602783
e:  25   train_loss:  695.109449480324   val_loss:  568.0946243480832   time:  1.9981307983398438
e:  26   train_loss:  775.6419214728205   time:  1.8019967079162598
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 15), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 15) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 15) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 15) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 15)
kwargs: {'config': {'batch_norm': True, 'ff_0': 30, 'ff_num_layers': 1, 'gnn_0': 1724, 'gnn_dropout': 0.16203243204750928, 'gnn_num_layers': 3, 'hid_0': 1259, 'hid_dropout_rate': 0.4895906060940636, 'in_dropout_rate': 0.17717454867023485, 'lr': 0.001508840596256224, 'num_hid_layers': 3, 'optimizer': 'SGD', 'gnn_1': 1662, 'gnn_2': 71, 'hid_1': 1500, 'hid_2': 256, 'sgd_momentum': 0.6568930593605463}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 728.0779942155692, 'n_epochs': 27.0, 'info': {'validation loss': 728.0779942155692}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 15) started
DEBUG:hpbandster:job_callback for (0, 0, 15) got condition
DEBUG:hpbandster:Only 16 run(s) for budget 27.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:job_callback for (0, 0, 15) finished
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 16) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 16) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 16)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 16) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 16) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 16)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 455, 'ff_num_layers': 2, 'gnn_0': 1251, 'gnn_dropout': 0.20395971160240467, 'gnn_num_layers': 3, 'hid_0': 650, 'hid_dropout_rate': 0.13942129792862107, 'in_dropout_rate': 0.1608907178961747, 'lr': 0.0009490287408787803, 'num_hid_layers': 1, 'optimizer': 'SGD', 'ff_1': 47, 'gnn_1': 254, 'gnn_2': 178, 'sgd_momentum': 0.5692253051349879}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  682.9166750270158   time:  1.438462495803833
e:  0   train_loss:  682.9166750270158   val_loss:  1517.5688115479013   time:  1.5523343086242676
e:  1   train_loss:  602.2498802502383   time:  1.4493801593780518
e:  2   train_loss:  594.6475010465101   time:  1.4527053833007812
e:  3   train_loss:  591.4983703604909   time:  1.645676612854004
e:  4   train_loss:  589.2140216143115   time:  1.4533159732818604
e:  5   train_loss:  586.3427778433562   time:  1.4226102828979492
e:  5   train_loss:  586.3427778433562   val_loss:  1391.592842586935   time:  1.5361640453338623
e:  6   train_loss:  582.3786002747843   time:  1.4503097534179688
e:  7   train_loss:  578.7626351640706   time:  1.4510126113891602
e:  8   train_loss:  574.3697035763821   time:  1.4515209197998047
e:  9   train_loss:  569.2364504554466   time:  1.433454990386963
e:  10   train_loss:  565.2472471206097   time:  1.5518293380737305
e:  10   train_loss:  565.2472471206097   val_loss:  1386.5236257703555   time:  1.667630672454834
e:  11   train_loss:  560.2863745151677   time:  1.4166395664215088
e:  12   train_loss:  555.4744071513038   time:  1.4032952785491943
e:  13   train_loss:  550.2109440527158   time:  1.3726348876953125
e:  14   train_loss:  546.048850603745   time:  1.4164249897003174
e:  15   train_loss:  542.2429071788666   time:  1.5677826404571533
e:  15   train_loss:  542.2429071788666   val_loss:  1372.6473271802815   time:  1.6740527153015137
e:  16   train_loss:  538.5210966459997   time:  1.4244327545166016
e:  17   train_loss:  534.4803118013743   time:  1.497046709060669
e:  18   train_loss:  530.3440883378536   time:  1.4714863300323486
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  19   train_loss:  527.307715136171   time:  1.4538593292236328
e:  20   train_loss:  524.7796944877452   time:  1.431373119354248
e:  20   train_loss:  524.7796944877452   val_loss:  1367.1072743721104   time:  1.547431230545044
e:  21   train_loss:  520.3411347126391   time:  1.4181859493255615
e:  22   train_loss:  517.1765065543959   time:  1.519406795501709
e:  23   train_loss:  513.9379135584292   time:  1.4548473358154297
e:  24   train_loss:  510.45665942816123   time:  1.607067584991455
e:  25   train_loss:  507.4230810082154   time:  1.4347069263458252
e:  25   train_loss:  507.4230810082154   val_loss:  1380.2897593395023   time:  1.5492784976959229
e:  26   train_loss:  504.886819990357   time:  1.4136006832122803
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1023.5410387990489   time:  1.5470311641693115
e:  0   train_loss:  1023.5410387990489   val_loss:  548.1960824256704   time:  1.6566739082336426
e:  1   train_loss:  908.8358344411615   time:  1.5379490852355957
e:  2   train_loss:  889.2520817694782   time:  1.5419676303863525
e:  3   train_loss:  899.8593099715754   time:  1.711763620376587
e:  4   train_loss:  911.7093061082376   time:  1.5289030075073242
e:  5   train_loss:  864.6765044265667   time:  1.512929916381836
e:  5   train_loss:  864.6765044265667   val_loss:  545.4045419554695   time:  1.619798183441162
e:  6   train_loss:  857.8766354495771   time:  1.5181632041931152
e:  7   train_loss:  838.6560993695206   time:  1.5299887657165527
e:  8   train_loss:  810.2952105398771   time:  1.5310945510864258
e:  9   train_loss:  797.9312260215514   time:  1.7032947540283203
e:  10   train_loss:  775.2904769351665   time:  1.5322351455688477
e:  10   train_loss:  775.2904769351665   val_loss:  551.8399320866127   time:  1.6391940116882324
e:  11   train_loss:  758.2364156367007   time:  1.530825138092041
e:  12   train_loss:  737.6177661581625   time:  1.5320115089416504
e:  13   train_loss:  711.7348105854712   time:  1.5314750671386719
e:  14   train_loss:  707.678813354116   time:  1.5458359718322754
e:  15   train_loss:  693.0859770312329   time:  1.5289509296417236
e:  15   train_loss:  693.0859770312329   val_loss:  571.0516976669037   time:  1.636432409286499
e:  16   train_loss:  674.9857514399318   time:  1.6840238571166992
e:  17   train_loss:  667.7813901033336   time:  1.5305500030517578
e:  18   train_loss:  653.4319906886275   time:  1.53061842918396
e:  19   train_loss:  647.9676417155415   time:  1.533402919769287
e:  20   train_loss:  637.7951061651052   time:  1.5433416366577148
e:  20   train_loss:  637.7951061651052   val_loss:  572.0651243721501   time:  1.651400089263916
e:  21   train_loss:  633.7488150427776   time:  1.5335681438446045
e:  22   train_loss:  635.9606543929381   time:  1.5331120491027832
e:  23   train_loss:  623.5290598623715   time:  1.6643853187561035
e:  24   train_loss:  617.1497586192364   time:  1.5165791511535645
e:  25   train_loss:  618.8476772743084   time:  1.4980716705322266
e:  25   train_loss:  618.8476772743084   val_loss:  564.1533819902212   time:  1.6047821044921875
e:  26   train_loss:  609.3356461276355   time:  1.5312316417694092
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1036.6819752997794   time:  1.514674425125122
e:  0   train_loss:  1036.6819752997794   val_loss:  491.5021802102289   time:  1.6267297267913818
e:  1   train_loss:  891.6160833717571   time:  1.4964823722839355
e:  2   train_loss:  915.7800149889349   time:  1.5237839221954346
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  3   train_loss:  923.2657771350132   time:  1.6427366733551025
e:  4   train_loss:  876.0651098432845   time:  1.5070087909698486
e:  5   train_loss:  872.8936377133421   time:  1.5032665729522705
e:  5   train_loss:  872.8936377133421   val_loss:  490.201848054594   time:  1.61279296875
e:  6   train_loss:  831.3504547022276   time:  1.5046634674072266
e:  7   train_loss:  867.932767927879   time:  1.504944086074829
e:  8   train_loss:  798.7673278733387   time:  1.5040934085845947
e:  9   train_loss:  803.5592769287482   time:  1.5061759948730469
e:  10   train_loss:  779.8431565002178   time:  1.647538185119629
e:  10   train_loss:  779.8431565002178   val_loss:  500.9440116319258   time:  1.7514216899871826
e:  11   train_loss:  763.3900459984305   time:  1.4966998100280762
e:  12   train_loss:  738.4264328641552   time:  1.4964344501495361
e:  13   train_loss:  732.5538348661942   time:  1.4984211921691895
e:  14   train_loss:  743.3886997582792   time:  1.5034582614898682
e:  15   train_loss:  711.7431154099515   time:  1.5059525966644287
e:  15   train_loss:  711.7431154099515   val_loss:  509.7363464711458   time:  1.6162762641906738
e:  16   train_loss:  717.4812092516778   time:  1.4930908679962158
e:  17   train_loss:  696.5733115986355   time:  1.6117548942565918
e:  18   train_loss:  701.6184253319809   time:  1.4974353313446045
e:  19   train_loss:  690.9079756966977   time:  1.5081632137298584
e:  20   train_loss:  694.0027354991383   time:  1.5063025951385498
e:  20   train_loss:  694.0027354991383   val_loss:  496.668400886634   time:  1.6163842678070068
e:  21   train_loss:  696.1316132708562   time:  1.5061123371124268
e:  22   train_loss:  690.2412303173828   time:  1.5016448497772217
e:  23   train_loss:  697.8739786494116   time:  1.5053322315216064
e:  24   train_loss:  650.4862207242871   time:  1.5031466484069824
e:  25   train_loss:  664.682614615323   time:  1.6528022289276123
e:  25   train_loss:  664.682614615323   val_loss:  559.134947253179   time:  1.762096881866455
e:  26   train_loss:  654.1127965577525   time:  1.5037226676940918
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  964.0876775436258   time:  1.3756654262542725
e:  0   train_loss:  964.0876775436258   val_loss:  773.6297334518044   time:  1.4900104999542236
e:  1   train_loss:  845.1553473684398   time:  1.5724620819091797
e:  2   train_loss:  835.7935603645413   time:  1.4040606021881104
e:  3   train_loss:  832.1804927256695   time:  1.4051198959350586
e:  4   train_loss:  823.3574918614062   time:  1.4076857566833496
e:  5   train_loss:  818.4365041956696   time:  1.401463270187378
e:  5   train_loss:  818.4365041956696   val_loss:  730.4432844052495   time:  1.5162725448608398
e:  6   train_loss:  813.8671665027912   time:  1.405956506729126
e:  7   train_loss:  803.9578505916959   time:  1.408125400543213
e:  8   train_loss:  795.0076577882146   time:  1.4067790508270264
e:  9   train_loss:  780.8277588873204   time:  1.4009675979614258
e:  10   train_loss:  767.2451906691334   time:  1.4976332187652588
e:  10   train_loss:  767.2451906691334   val_loss:  709.7480779733796   time:  1.6124565601348877
e:  11   train_loss:  757.1069040547538   time:  1.4113948345184326
e:  12   train_loss:  742.9663162745228   time:  1.4017949104309082
e:  13   train_loss:  731.3128266463348   time:  1.4020636081695557
e:  14   train_loss:  721.2201774516424   time:  1.4115021228790283
e:  15   train_loss:  709.5797254100603   time:  1.4022276401519775
e:  15   train_loss:  709.5797254100603   val_loss:  702.1893069484449   time:  1.517385721206665
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  16   train_loss:  699.2545542515102   time:  1.4070611000061035
e:  17   train_loss:  687.9733564110448   time:  1.4053983688354492
e:  18   train_loss:  682.5778995874235   time:  1.4041132926940918
e:  19   train_loss:  671.2574184560278   time:  1.5572443008422852
e:  20   train_loss:  663.4797963970618   time:  1.3851845264434814
e:  20   train_loss:  663.4797963970618   val_loss:  702.9199039481774   time:  1.499704360961914
e:  21   train_loss:  656.40451060675   time:  1.4000091552734375
e:  22   train_loss:  646.8216784072108   time:  1.403252124786377
e:  23   train_loss:  640.9456644875114   time:  1.4093918800354004
e:  24   train_loss:  635.1931899020722   time:  1.4016032218933105
e:  25   train_loss:  628.7961224013173   time:  1.4098618030548096
e:  25   train_loss:  628.7961224013173   val_loss:  705.4287050793986   time:  1.5239689350128174
e:  26   train_loss:  623.7180908011642   time:  1.4051074981689453
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1038.7427020786135   time:  1.530456304550171
e:  0   train_loss:  1038.7427020786135   val_loss:  559.0611592956215   time:  1.639277696609497
e:  1   train_loss:  900.5624967073321   time:  1.6842384338378906
e:  2   train_loss:  885.2066329889674   time:  1.530623435974121
e:  3   train_loss:  895.1566405676703   time:  1.493851900100708
e:  4   train_loss:  886.7596561890746   time:  1.5213432312011719
e:  5   train_loss:  869.7357793399831   time:  1.530590295791626
e:  5   train_loss:  869.7357793399831   val_loss:  554.3965345435744   time:  1.6385862827301025
e:  6   train_loss:  842.6104053115897   time:  1.5379252433776855
e:  7   train_loss:  837.9137304095007   time:  1.679410457611084
e:  8   train_loss:  821.4904035068007   time:  1.5346248149871826
e:  9   train_loss:  789.4419996030805   time:  1.5281529426574707
e:  10   train_loss:  782.7268615196857   time:  1.5357646942138672
e:  10   train_loss:  782.7268615196857   val_loss:  573.2821733850076   time:  1.644634485244751
e:  11   train_loss:  759.6343042701576   time:  1.529223918914795
e:  12   train_loss:  740.495391162679   time:  1.5294690132141113
e:  13   train_loss:  727.3061639252865   time:  1.6792583465576172
e:  14   train_loss:  723.2418708042883   time:  1.530085563659668
e:  15   train_loss:  710.6765437488991   time:  1.5337400436401367
e:  15   train_loss:  710.6765437488991   val_loss:  576.4783296814164   time:  1.6421942710876465
e:  16   train_loss:  693.8600025130474   time:  1.528775691986084
e:  17   train_loss:  678.4870433142793   time:  1.530756950378418
e:  18   train_loss:  687.6605727745031   time:  1.5325429439544678
e:  19   train_loss:  669.3422199321033   time:  1.5350046157836914
e:  20   train_loss:  655.9960069849278   time:  1.6805284023284912
e:  20   train_loss:  655.9960069849278   val_loss:  571.3738932508492   time:  1.7887611389160156
e:  21   train_loss:  655.023236580078   time:  1.542849063873291
e:  22   train_loss:  654.3146701254626   time:  1.4930286407470703
e:  23   train_loss:  649.5326841009337   time:  1.5115594863891602
e:  24   train_loss:  643.07523560874   time:  1.5263135433197021
e:  25   train_loss:  650.9019339911315   time:  1.5274949073791504
e:  25   train_loss:  650.9019339911315   val_loss:  563.1483047341538   time:  1.6359517574310303
e:  26   train_loss:  635.4600725669725   time:  1.547961950302124
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 16), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 16) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 16) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 16) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 16)
kwargs: {'config': {'batch_norm': False, 'ff_0': 455, 'ff_num_layers': 2, 'gnn_0': 1251, 'gnn_dropout': 0.20395971160240467, 'gnn_num_layers': 3, 'hid_0': 650, 'hid_dropout_rate': 0.13942129792862107, 'in_dropout_rate': 0.1608907178961747, 'lr': 0.0009490287408787803, 'num_hid_layers': 1, 'optimizer': 'SGD', 'ff_1': 47, 'gnn_1': 254, 'gnn_2': 178, 'sgd_momentum': 0.5692253051349879}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 731.8599011748387, 'n_epochs': 27.0, 'info': {'validation loss': 731.8599011748387}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 16) started
DEBUG:hpbandster:job_callback for (0, 0, 16) got condition
DEBUG:hpbandster:Only 17 run(s) for budget 27.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 16) finished
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 17) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 17) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 17)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 17) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 17) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 17)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 24, 'ff_num_layers': 2, 'gnn_0': 139, 'gnn_dropout': 0.12219687494896797, 'gnn_num_layers': 1, 'hid_0': 546, 'hid_dropout_rate': 0.24131815388748024, 'in_dropout_rate': 0.3912890202980011, 'lr': 0.00013185819337055256, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 416, 'hid_1': 85, 'hid_2': 128}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  704.0105254614244   time:  1.4930651187896729
e:  0   train_loss:  704.0105254614244   val_loss:  1667.9402755082085   time:  1.6004517078399658
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  1   train_loss:  700.5395630647962   time:  1.378007411956787
e:  2   train_loss:  693.4405294072994   time:  1.3544018268585205
e:  3   train_loss:  681.9189057296289   time:  1.351952075958252
e:  4   train_loss:  661.9808700209148   time:  1.383918285369873
e:  5   train_loss:  633.6043416687285   time:  1.3705370426177979
e:  5   train_loss:  633.6043416687285   val_loss:  1489.4355823256935   time:  1.4778032302856445
e:  6   train_loss:  605.7219657080561   time:  1.3692700862884521
e:  7   train_loss:  597.7978044203758   time:  1.3750026226043701
e:  8   train_loss:  597.5501439779817   time:  1.3471970558166504
e:  9   train_loss:  594.810715143178   time:  1.3731305599212646
e:  10   train_loss:  594.2693154679929   time:  1.376565933227539
e:  10   train_loss:  594.2693154679929   val_loss:  1404.5459976098439   time:  1.6511545181274414
e:  11   train_loss:  593.2587160027246   time:  1.3585896492004395
e:  12   train_loss:  592.7418919985104   time:  1.3783595561981201
e:  13   train_loss:  591.8790586817712   time:  1.354750633239746
e:  14   train_loss:  590.8226454292517   time:  1.3647830486297607
e:  15   train_loss:  590.4282287339711   time:  1.3716964721679688
e:  15   train_loss:  590.4282287339711   val_loss:  1393.664622257928   time:  1.4791724681854248
e:  16   train_loss:  588.7213879166734   time:  1.3462648391723633
e:  17   train_loss:  588.0241573668651   time:  1.3755338191986084
e:  18   train_loss:  587.5643010379649   time:  1.3769049644470215
e:  19   train_loss:  585.1750060281843   time:  1.3877363204956055
e:  20   train_loss:  584.0894114606027   time:  1.4874889850616455
e:  20   train_loss:  584.0894114606027   val_loss:  1391.023640449941   time:  1.588090181350708
e:  21   train_loss:  581.9594189541978   time:  1.3321690559387207
e:  22   train_loss:  579.5745679901852   time:  1.3358960151672363
e:  23   train_loss:  577.879196083266   time:  1.3197143077850342
e:  24   train_loss:  574.7155014477001   time:  1.3151576519012451
e:  25   train_loss:  571.2587232900419   time:  1.3307652473449707
e:  25   train_loss:  571.2587232900419   val_loss:  1385.786394878027   time:  1.438387393951416
e:  26   train_loss:  567.9812109830509   time:  1.3321998119354248
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1074.659881395265   time:  1.4519891738891602
e:  0   train_loss:  1074.659881395265   val_loss:  623.0988153441378   time:  1.5558898448944092
e:  1   train_loss:  1070.874590027746   time:  1.5812861919403076
e:  2   train_loss:  1072.7373697295475   time:  1.4236750602722168
e:  3   train_loss:  1029.654762662903   time:  1.4208755493164062
e:  4   train_loss:  977.6225296010743   time:  1.425431251525879
e:  5   train_loss:  918.871681315728   time:  1.4342687129974365
e:  5   train_loss:  918.871681315728   val_loss:  539.8149790063148   time:  1.5377788543701172
e:  6   train_loss:  895.4528790915083   time:  1.4393253326416016
e:  7   train_loss:  896.8974884001351   time:  1.5777852535247803
e:  8   train_loss:  895.8594665155744   time:  1.423124074935913
e:  9   train_loss:  895.9066585370431   time:  1.433321475982666
e:  10   train_loss:  899.1820382617813   time:  1.413759469985962
e:  10   train_loss:  899.1820382617813   val_loss:  553.5786651478059   time:  1.5154039859771729
e:  11   train_loss:  898.4125770907191   time:  1.4340195655822754
e:  12   train_loss:  897.6723027232869   time:  1.4349141120910645
e:  13   train_loss:  886.3994807742708   time:  1.4361140727996826
e:  14   train_loss:  889.3489214773488   time:  1.5808441638946533
e:  15   train_loss:  874.8091124889437   time:  1.4272358417510986
e:  15   train_loss:  874.8091124889437   val_loss:  548.8687974000931   time:  1.528921127319336
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  16   train_loss:  877.7435457943034   time:  1.4423649311065674
e:  17   train_loss:  874.1681986794401   time:  1.433769702911377
e:  18   train_loss:  868.0553874856136   time:  1.4335272312164307
e:  19   train_loss:  858.7649052885246   time:  1.43515944480896
e:  20   train_loss:  868.6616353947107   time:  1.438284158706665
e:  20   train_loss:  868.6616353947107   val_loss:  546.2989345032698   time:  1.6703460216522217
e:  21   train_loss:  855.4005859168287   time:  1.4379897117614746
e:  22   train_loss:  867.437119104556   time:  1.4370195865631104
e:  23   train_loss:  818.7252549000738   time:  1.4265272617340088
e:  24   train_loss:  796.9927137009988   time:  1.4370558261871338
e:  25   train_loss:  776.3911000061728   time:  1.4327058792114258
e:  25   train_loss:  776.3911000061728   val_loss:  554.1028361049515   time:  1.5361628532409668
e:  26   train_loss:  742.1372825546118   time:  1.4347262382507324
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1118.7147575729316   time:  1.4113929271697998
e:  0   train_loss:  1118.7147575729316   val_loss:  539.1261201859404   time:  1.6475720405578613
e:  1   train_loss:  1125.0154391574335   time:  1.41489577293396
e:  2   train_loss:  1068.222666011308   time:  1.413872480392456
e:  3   train_loss:  1068.4418884096385   time:  1.3676464557647705
e:  4   train_loss:  1033.2552021099102   time:  1.4000635147094727
e:  5   train_loss:  988.2123495053906   time:  1.4159619808197021
e:  5   train_loss:  988.2123495053906   val_loss:  472.83799352103205   time:  1.5202369689941406
e:  6   train_loss:  916.6568489587842   time:  1.4143431186676025
e:  7   train_loss:  889.1669359065766   time:  1.4123854637145996
e:  8   train_loss:  938.5390223293377   time:  1.550403118133545
e:  9   train_loss:  900.1828790957095   time:  1.4062919616699219
e:  10   train_loss:  923.2150632973901   time:  1.4110209941864014
e:  10   train_loss:  923.2150632973901   val_loss:  494.7399743102243   time:  1.5151143074035645
e:  11   train_loss:  903.1955867656363   time:  1.4088575839996338
e:  12   train_loss:  903.3178528636805   time:  1.4126157760620117
e:  13   train_loss:  897.1217795947539   time:  1.413496971130371
e:  14   train_loss:  876.6094240474554   time:  1.4297881126403809
e:  15   train_loss:  891.6406245606979   time:  1.5457484722137451
e:  15   train_loss:  891.6406245606979   val_loss:  496.80103280171227   time:  1.6507809162139893
e:  16   train_loss:  877.8137963523787   time:  1.413750410079956
e:  17   train_loss:  865.3788398953867   time:  1.4094200134277344
e:  18   train_loss:  906.418813028765   time:  1.4056620597839355
e:  19   train_loss:  940.4578243345275   time:  1.419156551361084
e:  20   train_loss:  882.6205555153311   time:  1.4160385131835938
e:  20   train_loss:  882.6205555153311   val_loss:  498.807134566621   time:  1.520714521408081
e:  21   train_loss:  859.169209506784   time:  1.559823989868164
e:  22   train_loss:  874.5935347487954   time:  1.4188499450683594
e:  23   train_loss:  861.673649945771   time:  1.4089019298553467
e:  24   train_loss:  853.5600514139907   time:  1.386084794998169
e:  25   train_loss:  823.4173688359582   time:  1.4115869998931885
e:  25   train_loss:  823.4173688359582   val_loss:  496.4881350981495   time:  1.515918493270874
e:  26   train_loss:  886.4819992565485   time:  1.4191758632659912
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  1000.7554219078304   time:  1.2938711643218994
e:  0   train_loss:  1000.7554219078304   val_loss:  916.0309649911263   time:  1.4044373035430908
e:  1   train_loss:  997.1711353134534   time:  1.3166065216064453
e:  2   train_loss:  985.541058886725   time:  1.4437766075134277
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  3   train_loss:  970.7235764372268   time:  1.3112444877624512
e:  4   train_loss:  944.8118460751457   time:  1.3066494464874268
e:  5   train_loss:  904.4999696023657   time:  1.3081533908843994
e:  5   train_loss:  904.4999696023657   val_loss:  787.8072553015243   time:  1.4172260761260986
e:  6   train_loss:  856.8559761979395   time:  1.3091676235198975
e:  7   train_loss:  839.7928117264004   time:  1.3026962280273438
e:  8   train_loss:  839.595529169289   time:  1.3062872886657715
e:  9   train_loss:  835.5925713277688   time:  1.3125452995300293
e:  10   train_loss:  835.6747852734787   time:  1.304466724395752
e:  10   train_loss:  835.6747852734787   val_loss:  742.2250932231742   time:  1.412816047668457
e:  11   train_loss:  835.3660328334838   time:  1.3193418979644775
e:  12   train_loss:  832.323030333363   time:  1.3150520324707031
e:  13   train_loss:  829.8440928940116   time:  1.433816909790039
e:  14   train_loss:  831.596769395158   time:  1.2977395057678223
e:  15   train_loss:  830.7557907213293   time:  1.311199426651001
e:  15   train_loss:  830.7557907213293   val_loss:  737.712976284258   time:  1.4205679893493652
e:  16   train_loss:  828.2658822725001   time:  1.3787899017333984
e:  17   train_loss:  821.8087901997968   time:  1.3355414867401123
e:  18   train_loss:  824.8723948318026   time:  1.3192102909088135
e:  19   train_loss:  822.1175916831195   time:  1.2994866371154785
e:  20   train_loss:  815.5361225402111   time:  1.332993507385254
e:  20   train_loss:  815.5361225402111   val_loss:  733.2739706891009   time:  1.442685604095459
e:  21   train_loss:  816.2733594254883   time:  1.3337287902832031
e:  22   train_loss:  809.129775835732   time:  1.3476893901824951
e:  23   train_loss:  803.9969092763396   time:  1.3398633003234863
e:  24   train_loss:  802.0855979096941   time:  1.3357465267181396
e:  25   train_loss:  791.9225272176546   time:  1.49454665184021
e:  25   train_loss:  791.9225272176546   val_loss:  723.7588005093567   time:  1.6040971279144287
e:  26   train_loss:  787.0095733606827   time:  1.3184990882873535
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1073.2319770156998   time:  1.5122969150543213
e:  0   train_loss:  1073.2319770156998   val_loss:  686.5421229437544   time:  1.6169276237487793
e:  1   train_loss:  1065.7177489541682   time:  1.4244155883789062
e:  2   train_loss:  1049.7005412896228   time:  1.4186108112335205
e:  3   train_loss:  1042.0730987279937   time:  1.4220495223999023
e:  4   train_loss:  1000.5927257266443   time:  1.4231336116790771
e:  5   train_loss:  953.313547308176   time:  1.5723121166229248
e:  5   train_loss:  953.313547308176   val_loss:  571.1694740809979   time:  1.6740832328796387
e:  6   train_loss:  915.6445351453177   time:  1.416661262512207
e:  7   train_loss:  936.0197147058869   time:  1.4348876476287842
e:  8   train_loss:  894.236328875567   time:  1.4321484565734863
e:  9   train_loss:  893.0630357350783   time:  1.4302978515625
e:  10   train_loss:  911.2206558059866   time:  1.4315967559814453
e:  10   train_loss:  911.2206558059866   val_loss:  557.0485889845605   time:  1.5343449115753174
e:  11   train_loss:  887.5373188505075   time:  1.4246680736541748
e:  12   train_loss:  900.6839994787015   time:  1.571855068206787
e:  13   train_loss:  899.5041646524674   time:  1.411966323852539
e:  14   train_loss:  876.9239369780369   time:  1.431121826171875
e:  15   train_loss:  883.4981270832928   time:  1.4205906391143799
e:  15   train_loss:  883.4981270832928   val_loss:  556.8012299342386   time:  1.5239744186401367
e:  16   train_loss:  880.1484602417717   time:  1.4201202392578125
e:  17   train_loss:  901.0307759692745   time:  1.4331471920013428
e:  18   train_loss:  868.4644340007436   time:  1.5671613216400146
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  19   train_loss:  871.4078088974339   time:  1.4313075542449951
e:  20   train_loss:  851.3926457605833   time:  1.430175542831421
e:  20   train_loss:  851.3926457605833   val_loss:  557.315507575383   time:  1.532153844833374
e:  21   train_loss:  877.6368557851102   time:  1.4297308921813965
e:  22   train_loss:  885.7728279607024   time:  1.4266269207000732
e:  23   train_loss:  835.8767167680492   time:  1.4292902946472168
e:  24   train_loss:  829.7533773872392   time:  1.5640206336975098
e:  25   train_loss:  817.2540335177829   time:  1.426769733428955
e:  25   train_loss:  817.2540335177829   val_loss:  560.7781492818119   time:  1.529432773590088
e:  26   train_loss:  805.8054395150214   time:  1.427546501159668
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 17), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 17) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 17) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 17) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 17)
kwargs: {'config': {'batch_norm': False, 'ff_0': 24, 'ff_num_layers': 2, 'gnn_0': 139, 'gnn_dropout': 0.12219687494896797, 'gnn_num_layers': 1, 'hid_0': 546, 'hid_dropout_rate': 0.24131815388748024, 'in_dropout_rate': 0.3912890202980011, 'lr': 0.00013185819337055256, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 416, 'hid_1': 85, 'hid_2': 128}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 735.7998795697938, 'n_epochs': 27.0, 'info': {'validation loss': 735.7998795697938}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 17) started
DEBUG:hpbandster:job_callback for (0, 0, 17) got condition
DEBUG:hpbandster:Only 18 run(s) for budget 27.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 17) finished
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 18) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 18) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 18)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 18) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 18) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 18)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 387, 'ff_num_layers': 3, 'gnn_0': 64, 'gnn_dropout': 0.001174030428866768, 'gnn_num_layers': 2, 'hid_0': 262, 'hid_dropout_rate': 0.31991942390847544, 'in_dropout_rate': 0.09208501515037804, 'lr': 1.7799334063630976e-05, 'num_hid_layers': 3, 'optimizer': 'SGD', 'ff_1': 1431, 'ff_2': 23, 'gnn_1': 783, 'hid_1': 72, 'hid_2': 161, 'sgd_momentum': 0.1596829357715209}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  705.8742522106921   time:  1.3390181064605713
e:  0   train_loss:  705.8742522106921   val_loss:  1675.182726620255   time:  1.4468863010406494
e:  1   train_loss:  705.5523627684694   time:  1.3601620197296143
e:  2   train_loss:  705.9192387651722   time:  1.3620648384094238
e:  3   train_loss:  705.5695048601416   time:  1.3398480415344238
e:  4   train_loss:  705.4605029155587   time:  1.316028118133545
e:  5   train_loss:  705.6975376610552   time:  1.315204381942749
e:  5   train_loss:  705.6975376610552   val_loss:  1674.0990864804469   time:  1.4241702556610107
e:  6   train_loss:  704.764213585024   time:  1.4540045261383057
e:  7   train_loss:  705.3052513273942   time:  1.3023052215576172
e:  8   train_loss:  705.2457553641507   time:  1.2994308471679688
e:  9   train_loss:  705.7995639558482   time:  1.295564889907837
e:  10   train_loss:  705.1754727439347   time:  1.3041906356811523
e:  10   train_loss:  705.1754727439347   val_loss:  1673.0263371466574   time:  1.4141197204589844
e:  11   train_loss:  703.995409335765   time:  1.2923510074615479
e:  12   train_loss:  703.7151204038905   time:  1.3133578300476074
e:  13   train_loss:  703.8568628830017   time:  1.3914124965667725
e:  14   train_loss:  703.8793774262986   time:  1.2727124691009521
e:  15   train_loss:  703.6657650046536   time:  1.333028793334961
e:  15   train_loss:  703.6657650046536   val_loss:  1671.963468181657   time:  1.506894826889038
e:  16   train_loss:  703.1715935361066   time:  1.3742430210113525
e:  17   train_loss:  703.3235121362281   time:  1.5547316074371338
e:  18   train_loss:  703.1654826286605   time:  1.3678102493286133
e:  19   train_loss:  703.6266171898865   time:  1.3819396495819092
e:  20   train_loss:  703.7420657979411   time:  1.3903648853302002
e:  20   train_loss:  703.7420657979411   val_loss:  1670.9093887684467   time:  1.499213457107544
e:  21   train_loss:  703.0230524425465   time:  1.284811019897461
e:  22   train_loss:  703.0183219672012   time:  1.4697258472442627
e:  23   train_loss:  703.121060852632   time:  1.3887152671813965
e:  24   train_loss:  702.734791867685   time:  1.3754069805145264
e:  25   train_loss:  702.8459702512326   time:  1.3064823150634766
e:  25   train_loss:  702.8459702512326   val_loss:  1669.862839057464   time:  1.4150111675262451
e:  26   train_loss:  702.3175114988913   time:  1.3709805011749268
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1076.5439692276611   time:  1.3804011344909668
e:  0   train_loss:  1076.5439692276611   val_loss:  628.7989781757681   time:  1.6598436832427979
e:  1   train_loss:  1097.833930347969   time:  1.3832287788391113
e:  2   train_loss:  1082.3341486879842   time:  1.3936681747436523
e:  3   train_loss:  1080.2721387699967   time:  1.3927650451660156
e:  4   train_loss:  1083.0249435091275   time:  1.3844177722930908
e:  5   train_loss:  1096.4592265109359   time:  1.383349895477295
e:  5   train_loss:  1096.4592265109359   val_loss:  627.9448514567364   time:  1.4864203929901123
e:  6   train_loss:  1094.33654495475   time:  1.3839669227600098
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  7   train_loss:  1071.9175008784682   time:  1.5323717594146729
e:  8   train_loss:  1096.6855012130886   time:  1.395369052886963
e:  9   train_loss:  1084.152188085877   time:  1.3946380615234375
e:  10   train_loss:  1067.386986365093   time:  1.3920972347259521
e:  10   train_loss:  1067.386986365093   val_loss:  627.1010958908153   time:  1.4952616691589355
e:  11   train_loss:  1091.5853781910653   time:  1.391251802444458
e:  12   train_loss:  1084.4907801375846   time:  1.3952136039733887
e:  13   train_loss:  1083.6298026968664   time:  1.52968168258667
e:  14   train_loss:  1075.0876321717437   time:  1.3940660953521729
e:  15   train_loss:  1091.492559772615   time:  1.3830459117889404
e:  15   train_loss:  1091.492559772615   val_loss:  626.2677140712717   time:  1.4863510131835938
e:  16   train_loss:  1094.845154276989   time:  1.4004530906677246
e:  17   train_loss:  1083.870003476101   time:  1.3938567638397217
e:  18   train_loss:  1068.9852426430386   time:  1.3945457935333252
e:  19   train_loss:  1084.1349552842594   time:  1.3924133777618408
e:  20   train_loss:  1085.980383086405   time:  1.5252745151519775
e:  20   train_loss:  1085.980383086405   val_loss:  625.4407641509702   time:  1.628140926361084
e:  21   train_loss:  1089.0815161758562   time:  1.379746437072754
e:  22   train_loss:  1072.183888609599   time:  1.3775827884674072
e:  23   train_loss:  1079.6039862693374   time:  1.3836390972137451
e:  24   train_loss:  1085.9243160615088   time:  1.394643783569336
e:  25   train_loss:  1074.168921090878   time:  1.395829677581787
e:  25   train_loss:  1074.168921090878   val_loss:  624.6170744082286   time:  1.4992971420288086
e:  26   train_loss:  1078.2123589810597   time:  1.4046807289123535
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1153.4571454842694   time:  1.5157153606414795
e:  0   train_loss:  1153.4571454842694   val_loss:  539.966827738588   time:  1.614427089691162
e:  1   train_loss:  1090.3882369888552   time:  1.3769538402557373
e:  2   train_loss:  1098.437277717282   time:  1.3667609691619873
e:  3   train_loss:  1093.4541879824026   time:  1.3711955547332764
e:  4   train_loss:  1093.0660225480015   time:  1.374082326889038
e:  5   train_loss:  1156.6655490474814   time:  1.3738689422607422
e:  5   train_loss:  1156.6655490474814   val_loss:  539.1873343964246   time:  1.4802203178405762
e:  6   train_loss:  1086.5396710028808   time:  1.3687994480133057
e:  7   train_loss:  1076.8134720510302   time:  1.3733305931091309
e:  8   train_loss:  1100.7410163980296   time:  1.5070407390594482
e:  9   train_loss:  1097.1997782315525   time:  1.373624563217163
e:  10   train_loss:  1107.6714104676655   time:  1.3653647899627686
e:  10   train_loss:  1107.6714104676655   val_loss:  538.4119974283403   time:  1.4709141254425049
e:  11   train_loss:  1066.741216947462   time:  1.3745505809783936
e:  12   train_loss:  1210.6292954967375   time:  1.3745317459106445
e:  13   train_loss:  1107.8843811380682   time:  1.3719775676727295
e:  14   train_loss:  1085.3699136344032   time:  1.3684730529785156
e:  15   train_loss:  1056.453821812616   time:  1.3721532821655273
e:  15   train_loss:  1056.453821812616   val_loss:  537.6348209073838   time:  1.6045703887939453
e:  16   train_loss:  1134.3308937585398   time:  1.3499507904052734
e:  17   train_loss:  1082.5611046453491   time:  1.371539831161499
e:  18   train_loss:  1072.2909013569504   time:  1.3744277954101562
e:  19   train_loss:  1116.5389515125078   time:  1.362433671951294
e:  20   train_loss:  1130.8599814783827   time:  1.3714230060577393
e:  20   train_loss:  1130.8599814783827   val_loss:  536.8568593538198   time:  1.4769022464752197
e:  21   train_loss:  1061.9928469232682   time:  1.3693180084228516
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  22   train_loss:  1057.3676783796177   time:  1.5065371990203857
e:  23   train_loss:  1084.1054281284783   time:  1.3749208450317383
e:  24   train_loss:  1076.843368965159   time:  1.3749902248382568
e:  25   train_loss:  1057.304184158853   time:  1.3711209297180176
e:  25   train_loss:  1057.304184158853   val_loss:  536.0759685511733   time:  1.4775192737579346
e:  26   train_loss:  1147.1743605422619   time:  1.375148057937622
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  1000.5971293594821   time:  1.2534699440002441
e:  0   train_loss:  1000.5971293594821   val_loss:  918.5013169687461   time:  1.363424301147461
e:  1   train_loss:  998.2206611307439   time:  1.380795955657959
e:  2   train_loss:  999.3310560041252   time:  1.2675135135650635
e:  3   train_loss:  1002.5501984594191   time:  1.2674260139465332
e:  4   train_loss:  1000.7304763137154   time:  1.2683792114257812
e:  5   train_loss:  997.1582074417379   time:  1.2669677734375
e:  5   train_loss:  997.1582074417379   val_loss:  917.5202728571493   time:  1.3766870498657227
e:  6   train_loss:  1000.5668842786733   time:  1.268693447113037
e:  7   train_loss:  998.744272912442   time:  1.2558603286743164
e:  8   train_loss:  998.9516274294477   time:  1.2670538425445557
e:  9   train_loss:  999.1919966423587   time:  1.2675559520721436
e:  10   train_loss:  998.7417577740384   time:  1.2671763896942139
e:  10   train_loss:  998.7417577740384   val_loss:  916.544527983824   time:  1.3760795593261719
e:  11   train_loss:  997.8848609033291   time:  1.2473981380462646
e:  12   train_loss:  997.9030284074638   time:  1.2641358375549316
e:  13   train_loss:  997.7138454912978   time:  1.397089958190918
e:  14   train_loss:  994.8969119052908   time:  1.2430150508880615
e:  15   train_loss:  998.6866238752375   time:  1.2642312049865723
e:  15   train_loss:  998.6866238752375   val_loss:  915.5756873506444   time:  1.3749721050262451
e:  16   train_loss:  996.6913153512926   time:  1.2672972679138184
e:  17   train_loss:  995.311461979377   time:  1.2651965618133545
e:  18   train_loss:  1000.1836856834143   time:  1.2644164562225342
e:  19   train_loss:  997.1330851418428   time:  1.2677433490753174
e:  20   train_loss:  999.4729219200169   time:  1.2684993743896484
e:  20   train_loss:  999.4729219200169   val_loss:  914.61028588579   time:  1.3793883323669434
e:  21   train_loss:  994.7761487332335   time:  1.2680282592773438
e:  22   train_loss:  999.2645787858143   time:  1.2583091259002686
e:  23   train_loss:  995.3125337463938   time:  1.2664296627044678
e:  24   train_loss:  994.1847130101676   time:  1.2698068618774414
e:  25   train_loss:  995.2259274926064   time:  1.257768154144287
e:  25   train_loss:  995.2259274926064   val_loss:  913.6453942323172   time:  1.3679497241973877
e:  26   train_loss:  995.2377398548231   time:  1.3965537548065186
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1065.7574530664144   time:  1.392124891281128
e:  0   train_loss:  1065.7574530664144   val_loss:  689.2630697082244   time:  1.4956636428833008
e:  1   train_loss:  1071.4891118208327   time:  1.3832216262817383
e:  2   train_loss:  1064.5404551228853   time:  1.3889539241790771
e:  3   train_loss:  1095.7531676622484   time:  1.390650749206543
e:  4   train_loss:  1075.2910583996318   time:  1.389561414718628
e:  5   train_loss:  1054.9066627866198   time:  1.388624906539917
e:  5   train_loss:  1054.9066627866198   val_loss:  688.2782280619787   time:  1.621107816696167
e:  6   train_loss:  1060.468070041548   time:  1.3701660633087158
e:  7   train_loss:  1089.3040824419743   time:  1.380159854888916
e:  8   train_loss:  1064.767099552496   time:  1.3899705410003662
e:  9   train_loss:  1073.200970277122   time:  1.3799500465393066
e:  10   train_loss:  1091.4527639106218   time:  1.3873584270477295
e:  10   train_loss:  1091.4527639106218   val_loss:  687.306854888152   time:  1.4918360710144043
e:  11   train_loss:  1078.9167694713494   time:  1.3888332843780518
e:  12   train_loss:  1065.725702167604   time:  1.5287730693817139
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  13   train_loss:  1069.6401229294079   time:  1.3814659118652344
e:  14   train_loss:  1078.5983266814974   time:  1.3864548206329346
e:  15   train_loss:  1062.8323773765962   time:  1.384293556213379
e:  15   train_loss:  1062.8323773765962   val_loss:  686.3374430151803   time:  1.4884834289550781
e:  16   train_loss:  1059.7752965062793   time:  1.3874425888061523
e:  17   train_loss:  1054.655332919153   time:  1.3882935047149658
e:  18   train_loss:  1075.7218631502374   time:  1.3903307914733887
e:  19   train_loss:  1085.650668473321   time:  1.5297045707702637
e:  20   train_loss:  1078.7952013389813   time:  1.3763513565063477
e:  20   train_loss:  1078.7952013389813   val_loss:  685.3724664385987   time:  1.480175256729126
e:  21   train_loss:  1067.453661515473   time:  1.3854575157165527
e:  22   train_loss:  1053.7089491765562   time:  1.3780303001403809
e:  23   train_loss:  1072.1687228207231   time:  1.3835549354553223
e:  24   train_loss:  1059.3366684339326   time:  1.3864333629608154
e:  25   train_loss:  1062.4767461868344   time:  1.3882086277008057
e:  25   train_loss:  1062.4767461868344   val_loss:  684.4070790062714   time:  1.6211810111999512
e:  26   train_loss:  1044.710276741501   time:  1.3879168033599854
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 18), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 18) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 18) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 18) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 18)
kwargs: {'config': {'batch_norm': False, 'ff_0': 387, 'ff_num_layers': 3, 'gnn_0': 64, 'gnn_dropout': 0.001174030428866768, 'gnn_num_layers': 2, 'hid_0': 262, 'hid_dropout_rate': 0.31991942390847544, 'in_dropout_rate': 0.09208501515037804, 'lr': 1.7799334063630976e-05, 'num_hid_layers': 3, 'optimizer': 'SGD', 'ff_1': 1431, 'ff_2': 23, 'gnn_1': 783, 'hid_1': 72, 'hid_2': 161, 'sgd_momentum': 0.1596829357715209}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 885.7216710510909, 'n_epochs': 27.0, 'info': {'validation loss': 885.7216710510909}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 18) started
DEBUG:hpbandster:job_callback for (0, 0, 18) got condition
DEBUG:hpbandster:Only 19 run(s) for budget 27.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 18) finished
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 19) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 19) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 19)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 19) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 19) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 19)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 51, 'ff_num_layers': 3, 'gnn_0': 211, 'gnn_dropout': 0.28240710443757133, 'gnn_num_layers': 2, 'hid_0': 93, 'hid_dropout_rate': 0.43465603854272794, 'in_dropout_rate': 0.4593577270846191, 'lr': 0.0009550186716688268, 'num_hid_layers': 1, 'optimizer': 'SGD', 'ff_1': 78, 'ff_2': 766, 'gnn_1': 1001, 'sgd_momentum': 0.24448863427366296}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  686.9597608413958   time:  1.3038954734802246
e:  0   train_loss:  686.9597608413958   val_loss:  1589.0618873687092   time:  1.4134254455566406
e:  1   train_loss:  589.9294841941831   time:  1.3010783195495605
e:  2   train_loss:  541.0539078763211   time:  1.3219578266143799
e:  3   train_loss:  524.7169777631295   time:  1.327239990234375
e:  4   train_loss:  511.83677766914974   time:  1.3110620975494385
e:  5   train_loss:  497.01265004206846   time:  1.3062074184417725
e:  5   train_loss:  497.01265004206846   val_loss:  1381.0655060166453   time:  1.4146513938903809
e:  6   train_loss:  496.03273999074054   time:  1.3205742835998535
e:  7   train_loss:  477.70952557524504   time:  1.3191211223602295
e:  8   train_loss:  474.3594499718551   time:  1.3268322944641113
e:  9   train_loss:  464.60426380255365   time:  1.3186330795288086
e:  10   train_loss:  466.54817172704117   time:  1.5270459651947021
e:  10   train_loss:  466.54817172704117   val_loss:  1681.8598713829078   time:  1.6283984184265137
e:  11   train_loss:  467.26315221020724   time:  1.301663875579834
e:  12   train_loss:  458.7475643758241   time:  1.3188326358795166
e:  13   train_loss:  455.1262954173292   time:  1.3256440162658691
e:  14   train_loss:  456.9606276550986   time:  1.3219292163848877
e:  15   train_loss:  457.6357021534318   time:  1.3107831478118896
e:  15   train_loss:  457.6357021534318   val_loss:  1498.928343207667   time:  1.420074462890625
e:  16   train_loss:  452.9384967280689   time:  1.3186304569244385
e:  17   train_loss:  449.4069349022621   time:  1.3225867748260498
e:  18   train_loss:  448.35492987237023   time:  1.3114290237426758
e:  19   train_loss:  445.5777404750165   time:  1.3234598636627197
e:  20   train_loss:  447.9632778728126   time:  1.49552583694458
e:  20   train_loss:  447.9632778728126   val_loss:  1395.5970345171102   time:  1.597301721572876
e:  21   train_loss:  448.79547439534   time:  1.308934211730957
e:  22   train_loss:  445.21430656719286   time:  1.3137540817260742
e:  23   train_loss:  447.4154441405547   time:  1.30002760887146
e:  24   train_loss:  445.76622457659033   time:  1.3239963054656982
e:  25   train_loss:  445.5382838530908   time:  1.3162550926208496
e:  25   train_loss:  445.5382838530908   val_loss:  1436.9551990063032   time:  1.4249770641326904
e:  26   train_loss:  442.9501668815713   time:  1.3136215209960938
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  975.4244949323521   time:  1.4508552551269531
e:  0   train_loss:  975.4244949323521   val_loss:  701.5261663855997   time:  1.5537819862365723
e:  1   train_loss:  785.8626992213922   time:  1.617286205291748
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  2   train_loss:  719.8949926916272   time:  1.4254415035247803
e:  3   train_loss:  732.578910173313   time:  1.414278268814087
e:  4   train_loss:  731.6526795511553   time:  1.4450690746307373
e:  5   train_loss:  692.5830022110838   time:  1.4307658672332764
e:  5   train_loss:  692.5830022110838   val_loss:  601.4789158115917   time:  1.5340256690979004
e:  6   train_loss:  678.7374001307355   time:  1.4068942070007324
e:  7   train_loss:  687.2855919162416   time:  1.4426124095916748
e:  8   train_loss:  657.5143672167452   time:  1.6502196788787842
e:  9   train_loss:  660.67252387664   time:  1.4349017143249512
e:  10   train_loss:  646.7187223076916   time:  1.4361422061920166
e:  10   train_loss:  646.7187223076916   val_loss:  1105.3010736977997   time:  1.5401761531829834
e:  11   train_loss:  635.0673524034728   time:  1.4407329559326172
e:  12   train_loss:  672.279541750744   time:  1.436563491821289
e:  13   train_loss:  658.2477623576932   time:  1.4378621578216553
e:  14   train_loss:  638.6920002104553   time:  1.444948673248291
e:  15   train_loss:  658.1400889280799   time:  1.6350092887878418
e:  15   train_loss:  658.1400889280799   val_loss:  1224.2223444437118   time:  1.7367148399353027
e:  16   train_loss:  650.6527640037602   time:  1.4148013591766357
e:  17   train_loss:  636.4278544155288   time:  1.401350975036621
e:  18   train_loss:  639.3977545639515   time:  1.4332139492034912
e:  19   train_loss:  627.4346711678122   time:  1.4187140464782715
e:  20   train_loss:  633.7027297648536   time:  1.433971881866455
e:  20   train_loss:  633.7027297648536   val_loss:  920.4165074805039   time:  1.536790132522583
e:  21   train_loss:  625.7812250080823   time:  1.6315233707427979
e:  22   train_loss:  630.1621136857791   time:  1.4129681587219238
e:  23   train_loss:  627.1377513738897   time:  1.423553705215454
e:  24   train_loss:  614.9634517955536   time:  1.4113919734954834
e:  25   train_loss:  611.4009132727538   time:  1.4044759273529053
e:  25   train_loss:  611.4009132727538   val_loss:  688.8727832057517   time:  1.5078072547912598
e:  26   train_loss:  614.101492512144   time:  1.4282352924346924
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  999.5925733813128   time:  1.4230637550354004
e:  0   train_loss:  999.5925733813128   val_loss:  494.02838519300946   time:  1.5281291007995605
e:  1   train_loss:  822.9012077514247   time:  1.4295647144317627
e:  2   train_loss:  759.1725294981854   time:  1.611579418182373
e:  3   train_loss:  738.3656346909058   time:  1.4066340923309326
e:  4   train_loss:  751.947897229911   time:  1.4232723712921143
e:  5   train_loss:  744.0009107969499   time:  1.4003067016601562
e:  5   train_loss:  744.0009107969499   val_loss:  5061.538700532875   time:  1.504969596862793
e:  6   train_loss:  736.0641924834414   time:  1.3953194618225098
e:  7   train_loss:  699.5185133724132   time:  1.40944242477417
e:  8   train_loss:  743.2207135906153   time:  1.617316484451294
e:  9   train_loss:  754.9037843208145   time:  1.400667428970337
e:  10   train_loss:  739.3836157200016   time:  1.4055798053741455
e:  10   train_loss:  739.3836157200016   val_loss:  69933477.36941826   time:  1.5118093490600586
e:  11   train_loss:  727.0996134127455   time:  1.4026126861572266
e:  12   train_loss:  701.4763599328676   time:  1.4076786041259766
e:  13   train_loss:  683.0934998158117   time:  1.3970139026641846
e:  14   train_loss:  683.5046599654169   time:  1.4134647846221924
e:  15   train_loss:  736.9427367927967   time:  1.40635347366333
e:  15   train_loss:  736.9427367927967   val_loss:  77368.20377388567   time:  1.5118052959442139
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  16   train_loss:  710.3040978115059   time:  1.6096489429473877
e:  17   train_loss:  703.7369311583309   time:  1.4064393043518066
e:  18   train_loss:  696.3327350019961   time:  1.4258065223693848
e:  19   train_loss:  651.3232744883836   time:  1.4276504516601562
e:  20   train_loss:  649.0064034827724   time:  1.4014134407043457
e:  20   train_loss:  649.0064034827724   val_loss:  546.0734780376331   time:  1.5064685344696045
e:  21   train_loss:  670.9382250823015   time:  1.4144306182861328
e:  22   train_loss:  669.3330443557116   time:  1.428070068359375
e:  23   train_loss:  650.1902463730094   time:  1.4267196655273438
e:  24   train_loss:  658.3197540349461   time:  1.6496574878692627
e:  25   train_loss:  669.8665065721907   time:  1.3968985080718994
e:  25   train_loss:  669.8665065721907   val_loss:  515.3401795207951   time:  1.5025882720947266
e:  26   train_loss:  639.8596761778476   time:  1.4243030548095703
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  957.4199350244339   time:  1.2946243286132812
e:  0   train_loss:  957.4199350244339   val_loss:  860.7047972032883   time:  1.4056622982025146
e:  1   train_loss:  766.1466186505635   time:  1.274000883102417
e:  2   train_loss:  704.0535647716343   time:  1.2936561107635498
e:  3   train_loss:  687.1093328672229   time:  1.3093645572662354
e:  4   train_loss:  688.0656662662198   time:  1.3167598247528076
e:  5   train_loss:  665.5950250893993   time:  1.311312198638916
e:  5   train_loss:  665.5950250893993   val_loss:  796.2372546132465   time:  1.420879602432251
e:  6   train_loss:  651.011548263328   time:  1.5033981800079346
e:  7   train_loss:  630.980504478557   time:  1.3103373050689697
e:  8   train_loss:  628.7588733692502   time:  1.313666582107544
e:  9   train_loss:  626.6028334766715   time:  1.2883837223052979
e:  10   train_loss:  610.9779892669364   time:  1.3218519687652588
e:  10   train_loss:  610.9779892669364   val_loss:  1850.3650630573138   time:  1.4318249225616455
e:  11   train_loss:  620.792297747162   time:  1.31563401222229
e:  12   train_loss:  605.0730616998172   time:  1.321903944015503
e:  13   train_loss:  606.9376183720971   time:  1.3098266124725342
e:  14   train_loss:  617.4884522693976   time:  1.320399522781372
e:  15   train_loss:  596.6904006419397   time:  1.3115622997283936
e:  15   train_loss:  596.6904006419397   val_loss:  727.4552723978643   time:  1.6169049739837646
e:  16   train_loss:  595.4074498192107   time:  1.309124231338501
e:  17   train_loss:  580.8933642791017   time:  1.3192694187164307
e:  18   train_loss:  590.1793729683961   time:  1.2943580150604248
e:  19   train_loss:  589.4924274848399   time:  1.3189852237701416
e:  20   train_loss:  573.4298059529777   time:  1.3120508193969727
e:  20   train_loss:  573.4298059529777   val_loss:  758.5924821165198   time:  1.4218153953552246
e:  21   train_loss:  596.7948370581464   time:  1.2981507778167725
e:  22   train_loss:  599.4733799707221   time:  1.297515630722046
e:  23   train_loss:  582.7912029032542   time:  1.3090269565582275
e:  24   train_loss:  577.3900145533057   time:  1.324873447418213
e:  25   train_loss:  569.1760423738313   time:  1.308483600616455
e:  25   train_loss:  569.1760423738313   val_loss:  739.606543544716   time:  1.4173593521118164
e:  26   train_loss:  573.424325191249   time:  1.4919021129608154
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1002.3868432327274   time:  1.4136161804199219
e:  0   train_loss:  1002.3868432327274   val_loss:  655.4068960136962   time:  1.5177924633026123
e:  1   train_loss:  767.8358214429073   time:  1.4209339618682861
e:  2   train_loss:  723.616374544662   time:  1.432741403579712
e:  3   train_loss:  689.1508930708728   time:  1.4244685173034668
e:  4   train_loss:  685.7933869371097   time:  1.4412531852722168
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  5   train_loss:  679.2953943384695   time:  1.642066240310669
e:  5   train_loss:  679.2953943384695   val_loss:  46527.72530365522   time:  1.7466773986816406
e:  6   train_loss:  657.8714712359996   time:  1.4044194221496582
e:  7   train_loss:  645.2490294454633   time:  1.4327304363250732
e:  8   train_loss:  661.99360351623   time:  1.412830114364624
e:  9   train_loss:  649.7739957857447   time:  1.4221599102020264
e:  10   train_loss:  637.5125212357694   time:  1.4288079738616943
e:  10   train_loss:  637.5125212357694   val_loss:  3470.3100381773766   time:  1.742664098739624
e:  11   train_loss:  639.784504403502   time:  1.4311749935150146
e:  12   train_loss:  618.6325500925363   time:  1.4253859519958496
e:  13   train_loss:  623.0256011611325   time:  1.4403729438781738
e:  14   train_loss:  622.0919349352388   time:  1.4194738864898682
e:  15   train_loss:  632.8666224410863   time:  1.4387567043304443
e:  15   train_loss:  632.8666224410863   val_loss:  806.1953576932988   time:  1.5424931049346924
e:  16   train_loss:  611.2698063612194   time:  1.4327421188354492
e:  17   train_loss:  617.6261658712594   time:  1.411846399307251
e:  18   train_loss:  615.6826283736771   time:  1.403008222579956
e:  19   train_loss:  627.3196977165221   time:  1.6030428409576416
e:  20   train_loss:  660.5367290814299   time:  1.3998746871948242
e:  20   train_loss:  660.5367290814299   val_loss:  935.3564843268516   time:  1.5036745071411133
e:  21   train_loss:  608.7744419078094   time:  1.4222221374511719
e:  22   train_loss:  613.4861705734423   time:  1.4260504245758057
e:  23   train_loss:  642.2428742963629   time:  1.4339568614959717
e:  24   train_loss:  615.2675445287347   time:  1.4418449401855469
e:  25   train_loss:  605.0692252807346   time:  1.6381282806396484
e:  25   train_loss:  605.0692252807346   val_loss:  593.5194939878965   time:  1.7429530620574951
e:  26   train_loss:  609.5554113709092   time:  1.4290978908538818
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 19), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 19) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 19) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 19) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 19)
kwargs: {'config': {'batch_norm': True, 'ff_0': 51, 'ff_num_layers': 3, 'gnn_0': 211, 'gnn_dropout': 0.28240710443757133, 'gnn_num_layers': 2, 'hid_0': 93, 'hid_dropout_rate': 0.43465603854272794, 'in_dropout_rate': 0.4593577270846191, 'lr': 0.0009550186716688268, 'num_hid_layers': 1, 'optimizer': 'SGD', 'ff_1': 78, 'ff_2': 766, 'gnn_1': 1001, 'sgd_momentum': 0.24448863427366296}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 759.5095146814014, 'n_epochs': 27.0, 'info': {'validation loss': 759.5095146814014}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 19) started
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:job_callback for (0, 0, 19) got condition
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 19) finished
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 20) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 20) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 20)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 20) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 20) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 20)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 805, 'ff_num_layers': 3, 'gnn_0': 220, 'gnn_dropout': 0.19454045762827982, 'gnn_num_layers': 3, 'hid_0': 76, 'hid_dropout_rate': 0.07494184450785518, 'in_dropout_rate': 0.346182704640951, 'lr': 4.052982526092989e-05, 'num_hid_layers': 1, 'optimizer': 'Adam', 'ff_1': 989, 'ff_2': 630, 'gnn_1': 159, 'gnn_2': 459}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  702.3600752153125   time:  1.3135008811950684
e:  0   train_loss:  702.3600752153125   val_loss:  1670.3029770960127   time:  1.4222853183746338
e:  1   train_loss:  699.4270388705138   time:  1.3277606964111328
e:  2   train_loss:  695.4445798539306   time:  1.297043800354004
e:  3   train_loss:  690.2088726197246   time:  1.3244431018829346
e:  4   train_loss:  684.5144628969214   time:  1.3147835731506348
e:  5   train_loss:  676.3755371780619   time:  1.2939026355743408
e:  5   train_loss:  676.3755371780619   val_loss:  1655.6148890286179   time:  1.40285062789917
e:  6   train_loss:  664.6271353647833   time:  1.512129783630371
e:  7   train_loss:  651.1140312779376   time:  1.3087682723999023
e:  8   train_loss:  633.8271496507246   time:  1.3327295780181885
e:  9   train_loss:  613.5082988601789   time:  1.2716162204742432
e:  10   train_loss:  590.4822362853038   time:  1.24615478515625
e:  10   train_loss:  590.4822362853038   val_loss:  1649.7294953130154   time:  1.356555461883545
e:  11   train_loss:  568.7021876413581   time:  1.2685632705688477
e:  12   train_loss:  548.8366953883937   time:  1.2557308673858643
e:  13   train_loss:  529.9170495003737   time:  1.2490029335021973
e:  14   train_loss:  512.6516002844907   time:  1.2508232593536377
e:  15   train_loss:  497.6371727154368   time:  1.260200023651123
e:  15   train_loss:  497.6371727154368   val_loss:  1658.756660688851   time:  1.4987332820892334
e:  16   train_loss:  486.1757330189019   time:  1.2395362854003906
e:  17   train_loss:  476.35124222310793   time:  1.2463288307189941
e:  18   train_loss:  466.687462245454   time:  1.2471325397491455
e:  19   train_loss:  461.57144342831697   time:  1.2548201084136963
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  20   train_loss:  457.2592454429004   time:  1.2555608749389648
e:  20   train_loss:  457.2592454429004   val_loss:  1662.9700825949958   time:  1.3654334545135498
e:  21   train_loss:  454.8054814970442   time:  1.2600328922271729
e:  22   train_loss:  450.7672196674478   time:  1.2849161624908447
e:  23   train_loss:  447.59250414244167   time:  1.2579345703125
e:  24   train_loss:  444.72508421832754   time:  1.278228759765625
e:  25   train_loss:  442.9798821188946   time:  1.2462189197540283
e:  25   train_loss:  442.9798821188946   val_loss:  1659.9694359733166   time:  1.3543617725372314
e:  26   train_loss:  440.95229591193385   time:  1.4172754287719727
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1059.6943634323136   time:  1.3954100608825684
e:  0   train_loss:  1059.6943634323136   val_loss:  625.9080895213938   time:  1.4991378784179688
e:  1   train_loss:  1060.8891411268892   time:  1.4580490589141846
e:  2   train_loss:  1066.6419494284355   time:  1.391737699508667
e:  3   train_loss:  1059.8324610291975   time:  1.3897910118103027
e:  4   train_loss:  1029.7006232587544   time:  1.38749361038208
e:  5   train_loss:  1026.5703092429108   time:  1.3952915668487549
e:  5   train_loss:  1026.5703092429108   val_loss:  620.9487074034256   time:  1.49837327003479
e:  6   train_loss:  975.5311012308593   time:  1.5602185726165771
e:  7   train_loss:  957.5703666301288   time:  1.3926424980163574
e:  8   train_loss:  913.1266202444951   time:  1.3767504692077637
e:  9   train_loss:  898.9034619759075   time:  1.3896217346191406
e:  10   train_loss:  846.3730364421637   time:  1.3870697021484375
e:  10   train_loss:  846.3730364421637   val_loss:  607.4554286296909   time:  1.4913578033447266
e:  11   train_loss:  797.4272294939352   time:  1.3921289443969727
e:  12   train_loss:  769.7304372170601   time:  1.391880750656128
e:  13   train_loss:  739.4780253015996   time:  1.595506191253662
e:  14   train_loss:  702.6542321813145   time:  1.385758638381958
e:  15   train_loss:  690.86365086428   time:  1.3890759944915771
e:  15   train_loss:  690.86365086428   val_loss:  616.5373332183622   time:  1.4925568103790283
e:  16   train_loss:  665.1308969383792   time:  1.3922438621520996
e:  17   train_loss:  651.0706513400771   time:  1.39687180519104
e:  18   train_loss:  640.2491647659124   time:  1.3937394618988037
e:  19   train_loss:  636.0993533069769   time:  1.3905675411224365
e:  20   train_loss:  617.4899115186953   time:  1.5509033203125
e:  20   train_loss:  617.4899115186953   val_loss:  609.9280522670349   time:  1.653881549835205
e:  21   train_loss:  616.3290725131098   time:  1.3877651691436768
e:  22   train_loss:  610.6268023251697   time:  1.388906478881836
e:  23   train_loss:  606.3075354982983   time:  1.395115613937378
e:  24   train_loss:  609.6281019030206   time:  1.3928203582763672
e:  25   train_loss:  599.0727370448544   time:  1.3919639587402344
e:  25   train_loss:  599.0727370448544   val_loss:  613.7083745964915   time:  1.4958784580230713
e:  26   train_loss:  603.3242787581422   time:  1.3904037475585938
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1074.8789194432381   time:  1.5386366844177246
e:  0   train_loss:  1074.8789194432381   val_loss:  540.5632227297102   time:  1.644843578338623
e:  1   train_loss:  1055.042016588838   time:  1.3793821334838867
e:  2   train_loss:  1107.7068640576986   time:  1.3655624389648438
e:  3   train_loss:  1081.172508596863   time:  1.373189926147461
e:  4   train_loss:  1056.2032005818733   time:  1.3910036087036133
e:  5   train_loss:  1026.6847207528194   time:  1.375629186630249
e:  5   train_loss:  1026.6847207528194   val_loss:  540.7249534221511   time:  1.4815893173217773
e:  6   train_loss:  1007.093704935591   time:  1.5732429027557373
e:  7   train_loss:  1004.3465493363884   time:  1.3747310638427734
e:  8   train_loss:  930.7844668950843   time:  1.3788440227508545
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  9   train_loss:  948.922366707085   time:  1.389594554901123
e:  10   train_loss:  914.6844633827982   time:  1.3748013973236084
e:  10   train_loss:  914.6844633827982   val_loss:  536.5195166771769   time:  1.480320692062378
e:  11   train_loss:  857.4679479390993   time:  1.3727357387542725
e:  12   train_loss:  812.745583221102   time:  1.3777976036071777
e:  13   train_loss:  825.1824295682337   time:  1.5577080249786377
e:  14   train_loss:  749.1894337654807   time:  1.376420021057129
e:  15   train_loss:  728.8238814079135   time:  1.374234914779663
e:  15   train_loss:  728.8238814079135   val_loss:  535.1313976810503   time:  1.4794917106628418
e:  16   train_loss:  734.5883992771354   time:  1.3785908222198486
e:  17   train_loss:  700.4196737526119   time:  1.3684256076812744
e:  18   train_loss:  690.4243920162558   time:  1.3820698261260986
e:  19   train_loss:  718.1121894265427   time:  1.3737070560455322
e:  20   train_loss:  667.6110194376555   time:  1.3710205554962158
e:  20   train_loss:  667.6110194376555   val_loss:  537.4155777686793   time:  1.4776113033294678
e:  21   train_loss:  672.8045587197507   time:  1.5510075092315674
e:  22   train_loss:  685.5462532822262   time:  1.3714475631713867
e:  23   train_loss:  647.0625373727003   time:  1.3632652759552002
e:  24   train_loss:  629.2205951781484   time:  1.3733584880828857
e:  25   train_loss:  646.4904081008913   time:  1.379931926727295
e:  25   train_loss:  646.4904081008913   val_loss:  538.8112992400103   time:  1.485926628112793
e:  26   train_loss:  634.0273972696968   time:  1.3709805011749268
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  1002.3693286327892   time:  1.2650916576385498
e:  0   train_loss:  1002.3693286327892   val_loss:  920.4317372293192   time:  1.3753108978271484
e:  1   train_loss:  996.6800219733091   time:  1.2765183448791504
e:  2   train_loss:  989.6098281895609   time:  1.2761306762695312
e:  3   train_loss:  984.6146179339268   time:  1.2676701545715332
e:  4   train_loss:  974.1935833836448   time:  1.2612907886505127
e:  5   train_loss:  964.0041884625443   time:  1.428966999053955
e:  5   train_loss:  964.0041884625443   val_loss:  919.0741400581759   time:  1.5311791896820068
e:  6   train_loss:  951.7717891486741   time:  1.268035888671875
e:  7   train_loss:  929.699574486567   time:  1.2737383842468262
e:  8   train_loss:  910.6165048080065   time:  1.27012300491333
e:  9   train_loss:  886.5900963143378   time:  1.2661397457122803
e:  10   train_loss:  859.6423971397095   time:  1.2765703201293945
e:  10   train_loss:  859.6423971397095   val_loss:  912.6444366477197   time:  1.3869922161102295
e:  11   train_loss:  833.0247189535519   time:  1.271510124206543
e:  12   train_loss:  799.3724131265444   time:  1.2745118141174316
e:  13   train_loss:  770.5528472134207   time:  1.2772200107574463
e:  14   train_loss:  737.5695292060477   time:  1.2718493938446045
e:  15   train_loss:  713.3184939272672   time:  1.2713322639465332
e:  15   train_loss:  713.3184939272672   val_loss:  910.2684770327846   time:  1.381382942199707
e:  16   train_loss:  683.727043959359   time:  1.4226360321044922
e:  17   train_loss:  664.0873150779723   time:  1.2726783752441406
e:  18   train_loss:  649.2698570647883   time:  1.2459466457366943
e:  19   train_loss:  633.7173641186216   time:  1.251830816268921
e:  20   train_loss:  617.7699518404422   time:  1.272594928741455
e:  20   train_loss:  617.7699518404422   val_loss:  918.0938875953392   time:  1.3824303150177002
e:  21   train_loss:  608.2227987289659   time:  1.2742996215820312
e:  22   train_loss:  600.7593994238847   time:  1.2805397510528564
e:  23   train_loss:  592.4291347141216   time:  1.2652010917663574
e:  24   train_loss:  584.7346345853368   time:  1.2733409404754639
e:  25   train_loss:  580.0942659356327   time:  1.2659270763397217
e:  25   train_loss:  580.0942659356327   val_loss:  920.207437439218   time:  1.3761565685272217
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  26   train_loss:  574.1563331126083   time:  1.2791738510131836
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1076.3748555382206   time:  1.3996849060058594
e:  0   train_loss:  1076.3748555382206   val_loss:  691.3567934395736   time:  1.5043838024139404
e:  1   train_loss:  1061.2567614550578   time:  1.5611052513122559
e:  2   train_loss:  1073.0128574907142   time:  1.3927476406097412
e:  3   train_loss:  1054.1462370042957   time:  1.3972504138946533
e:  4   train_loss:  1032.3011130520363   time:  1.3848373889923096
e:  5   train_loss:  1016.8792946194023   time:  1.3826305866241455
e:  5   train_loss:  1016.8792946194023   val_loss:  683.9892503537417   time:  1.487757682800293
e:  6   train_loss:  1003.7905057152487   time:  1.390383005142212
e:  7   train_loss:  969.4615317921655   time:  1.3967976570129395
e:  8   train_loss:  936.1234393573777   time:  1.5286860466003418
e:  9   train_loss:  891.8228378525159   time:  1.387364149093628
e:  10   train_loss:  850.4782797344609   time:  1.388016939163208
e:  10   train_loss:  850.4782797344609   val_loss:  685.384759127675   time:  1.4920763969421387
e:  11   train_loss:  811.6578724216595   time:  1.2155101299285889
e:  12   train_loss:  768.9926746556173   time:  1.373304843902588
e:  13   train_loss:  748.5252896344937   time:  1.3604609966278076
e:  14   train_loss:  714.568232960421   time:  1.3515279293060303
e:  15   train_loss:  697.369429670001   time:  1.5101165771484375
e:  15   train_loss:  697.369429670001   val_loss:  691.59613615362   time:  1.6141366958618164
e:  16   train_loss:  678.6153167294219   time:  1.3731327056884766
e:  17   train_loss:  664.2973810194546   time:  1.3760805130004883
e:  18   train_loss:  655.723463752837   time:  1.3725776672363281
e:  19   train_loss:  636.783140012212   time:  1.3760080337524414
e:  20   train_loss:  637.0301818646201   time:  1.3765459060668945
e:  20   train_loss:  637.0301818646201   val_loss:  692.5813438626725   time:  1.481480360031128
e:  21   train_loss:  614.1870259008782   time:  1.5167360305786133
e:  22   train_loss:  618.5097618027698   time:  1.377716064453125
e:  23   train_loss:  609.9171437518784   time:  1.3722796440124512
e:  24   train_loss:  614.9825157832922   time:  1.3757197856903076
e:  25   train_loss:  611.2080277307336   time:  1.3701865673065186
e:  25   train_loss:  611.2080277307336   val_loss:  688.7502032007139   time:  1.4751508235931396
e:  26   train_loss:  598.5884982413735   time:  1.3754608631134033
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 20), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 20) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 20) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 20) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 20)
kwargs: {'config': {'batch_norm': True, 'ff_0': 805, 'ff_num_layers': 3, 'gnn_0': 220, 'gnn_dropout': 0.19454045762827982, 'gnn_num_layers': 3, 'hid_0': 76, 'hid_dropout_rate': 0.07494184450785518, 'in_dropout_rate': 0.346182704640951, 'lr': 4.052982526092989e-05, 'num_hid_layers': 1, 'optimizer': 'Adam', 'ff_1': 989, 'ff_2': 630, 'gnn_1': 159, 'gnn_2': 459}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 877.3148098020567, 'n_epochs': 27.0, 'info': {'validation loss': 877.3148098020567}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 20) started
DEBUG:hpbandster:job_callback for (0, 0, 20) got condition
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 20) finished
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 21) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 21) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 21)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 21) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 21) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 21)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 136, 'ff_num_layers': 3, 'gnn_0': 104, 'gnn_dropout': 0.09105864397368119, 'gnn_num_layers': 1, 'hid_0': 1098, 'hid_dropout_rate': 0.2950418713601814, 'in_dropout_rate': 0.4290437273961989, 'lr': 0.0008127555244333852, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 72, 'ff_2': 877, 'hid_1': 1783, 'hid_2': 73}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  647.3791373762347   time:  1.7188856601715088
e:  0   train_loss:  647.3791373762347   val_loss:  1400.6185951019013   time:  2.0367393493652344
e:  1   train_loss:  596.0040174538948   time:  1.6867649555206299
e:  2   train_loss:  585.7654002516157   time:  1.6482961177825928
e:  3   train_loss:  569.6683046492273   time:  1.5566694736480713
e:  4   train_loss:  542.9481325606025   time:  1.546935796737671
e:  5   train_loss:  508.24385159254007   time:  1.539829969406128
e:  5   train_loss:  508.24385159254007   val_loss:  1366.0780391084681   time:  1.7427504062652588
e:  6   train_loss:  476.9201518181241   time:  1.5896496772766113
e:  7   train_loss:  449.388673604991   time:  1.5185856819152832
e:  8   train_loss:  433.2448136573724   time:  1.5297636985778809
e:  9   train_loss:  424.5102597498804   time:  1.5275983810424805
e:  10   train_loss:  419.9087576572766   time:  1.5284178256988525
e:  10   train_loss:  419.9087576572766   val_loss:  1405.9917238764847   time:  1.6421358585357666
e:  11   train_loss:  417.71970181448694   time:  1.5438120365142822
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  12   train_loss:  411.94565794319203   time:  1.660573959350586
e:  13   train_loss:  404.93987310147645   time:  1.5145416259765625
e:  14   train_loss:  402.8345986035795   time:  1.5299413204193115
e:  15   train_loss:  397.27825816024387   time:  1.5307118892669678
e:  15   train_loss:  397.27825816024387   val_loss:  1402.060452488928   time:  1.6441376209259033
e:  16   train_loss:  388.7195905159631   time:  1.5291969776153564
e:  17   train_loss:  383.6818807110331   time:  1.532688856124878
e:  18   train_loss:  374.9267299956506   time:  1.6803646087646484
e:  19   train_loss:  368.63699468105017   time:  1.7578134536743164
e:  20   train_loss:  361.20845311899177   time:  1.7252569198608398
e:  20   train_loss:  361.20845311899177   val_loss:  1403.8177673044422   time:  1.8315980434417725
e:  21   train_loss:  359.39648340031647   time:  1.7021949291229248
e:  22   train_loss:  351.2112939897172   time:  1.6740972995758057
e:  23   train_loss:  339.2793989363807   time:  1.6254262924194336
e:  24   train_loss:  333.5224171953281   time:  1.549759864807129
e:  25   train_loss:  328.13232006125554   time:  1.4856033325195312
e:  25   train_loss:  328.13232006125554   val_loss:  1417.4351849518603   time:  1.5978550910949707
e:  26   train_loss:  325.0937853898041   time:  1.5387852191925049
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  986.4940894879393   time:  1.7166378498077393
e:  0   train_loss:  986.4940894879393   val_loss:  537.4117655654339   time:  1.8228404521942139
e:  1   train_loss:  899.404560369636   time:  1.6843421459197998
e:  2   train_loss:  868.2045656596038   time:  1.679581880569458
e:  3   train_loss:  820.9533377319799   time:  1.835392951965332
e:  4   train_loss:  698.8184543797513   time:  1.6827566623687744
e:  5   train_loss:  624.4014826245408   time:  1.6635785102844238
e:  5   train_loss:  624.4014826245408   val_loss:  560.4877136377442   time:  1.7688045501708984
e:  6   train_loss:  597.093849731315   time:  1.6780524253845215
e:  7   train_loss:  585.0705431044645   time:  1.6778335571289062
e:  8   train_loss:  560.5599478824471   time:  1.6783862113952637
e:  9   train_loss:  552.4652773035816   time:  1.8277394771575928
e:  10   train_loss:  544.3901703339218   time:  1.6759800910949707
e:  10   train_loss:  544.3901703339218   val_loss:  567.7047468056348   time:  1.7818894386291504
e:  11   train_loss:  543.4404170594174   time:  1.68690824508667
e:  12   train_loss:  539.5522948887364   time:  1.6746556758880615
e:  13   train_loss:  533.3124189724799   time:  1.6766409873962402
e:  14   train_loss:  533.7761965164277   time:  1.677544116973877
e:  15   train_loss:  506.2174561417635   time:  1.6323504447937012
e:  15   train_loss:  506.2174561417635   val_loss:  589.3451867291697   time:  1.9023690223693848
e:  16   train_loss:  506.97017146233276   time:  1.6470234394073486
e:  17   train_loss:  497.97057479255756   time:  1.6965272426605225
e:  18   train_loss:  492.3158238615314   time:  1.6893937587738037
e:  19   train_loss:  484.18354487091085   time:  1.6699507236480713
e:  20   train_loss:  468.73722901575326   time:  1.6899464130401611
e:  20   train_loss:  468.73722901575326   val_loss:  575.5369530335174   time:  1.7950561046600342
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  21   train_loss:  462.57592899824226   time:  1.7105412483215332
e:  22   train_loss:  449.0949365623522   time:  1.6737034320831299
e:  23   train_loss:  447.39953144277683   time:  1.6826064586639404
e:  24   train_loss:  427.13027506551066   time:  1.8465015888214111
e:  25   train_loss:  410.68922207819725   time:  1.680250644683838
e:  25   train_loss:  410.68922207819725   val_loss:  588.3811207410614   time:  1.7856879234313965
e:  26   train_loss:  398.07905861915174   time:  1.686194896697998
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  994.112788438261   time:  1.6511237621307373
e:  0   train_loss:  994.112788438261   val_loss:  478.896471050367   time:  1.7595438957214355
e:  1   train_loss:  925.112109130639   time:  1.6486482620239258
e:  2   train_loss:  902.1338985322722   time:  1.6677484512329102
e:  3   train_loss:  828.5926985628777   time:  1.6611661911010742
e:  4   train_loss:  753.5448586266352   time:  1.8105878829956055
e:  5   train_loss:  692.2163127367887   time:  1.6317760944366455
e:  5   train_loss:  692.2163127367887   val_loss:  508.8217021884501   time:  1.7394859790802002
e:  6   train_loss:  641.2688297638733   time:  1.601670503616333
e:  7   train_loss:  610.3987690168134   time:  1.6548798084259033
e:  8   train_loss:  600.4607594207027   time:  1.6485202312469482
e:  9   train_loss:  576.1218397914291   time:  1.6535630226135254
e:  10   train_loss:  584.6924949392966   time:  1.63960599899292
e:  10   train_loss:  584.6924949392966   val_loss:  519.6160720556379   time:  1.7478926181793213
e:  11   train_loss:  599.352029315076   time:  1.6594254970550537
e:  12   train_loss:  572.9996519323893   time:  1.818526029586792
e:  13   train_loss:  578.3248221342035   time:  1.6469306945800781
e:  14   train_loss:  577.4065849740153   time:  1.6655752658843994
e:  15   train_loss:  563.502931845858   time:  1.645355224609375
e:  15   train_loss:  563.502931845858   val_loss:  629.3294921624945   time:  1.7529969215393066
e:  16   train_loss:  582.0659770945846   time:  1.623788833618164
e:  17   train_loss:  576.882202363896   time:  1.64939284324646
e:  18   train_loss:  546.1385058251864   time:  1.653177261352539
e:  19   train_loss:  536.2696137094936   time:  1.6817200183868408
e:  20   train_loss:  542.7424153749722   time:  1.8036255836486816
e:  20   train_loss:  542.7424153749722   val_loss:  543.430014979926   time:  1.911865472793579
e:  21   train_loss:  521.2111966569651   time:  1.660313367843628
e:  22   train_loss:  528.917316886325   time:  1.6680152416229248
e:  23   train_loss:  521.1106846920445   time:  1.6141905784606934
e:  24   train_loss:  514.1679690161244   time:  1.628760576248169
e:  25   train_loss:  523.7667264359059   time:  1.6362972259521484
e:  25   train_loss:  523.7667264359059   val_loss:  494.1198981863118   time:  1.7454161643981934
e:  26   train_loss:  508.0137837804634   time:  1.76265287399292
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  915.3639649400915   time:  1.5409622192382812
e:  0   train_loss:  915.3639649400915   val_loss:  740.1292065158766   time:  1.6552190780639648
e:  1   train_loss:  839.2117608795929   time:  1.5708112716674805
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  2   train_loss:  820.8111691116313   time:  1.5457055568695068
e:  3   train_loss:  794.2906907391376   time:  1.5342867374420166
e:  4   train_loss:  729.1575008058724   time:  1.5359728336334229
e:  5   train_loss:  643.1814600121573   time:  1.5377018451690674
e:  5   train_loss:  643.1814600121573   val_loss:  715.4455453934635   time:  1.652031421661377
e:  6   train_loss:  597.137107515648   time:  1.5566530227661133
e:  7   train_loss:  572.4610093514659   time:  1.5574560165405273
e:  8   train_loss:  557.6363177799753   time:  1.5456137657165527
e:  9   train_loss:  541.4383765420469   time:  1.5482447147369385
e:  10   train_loss:  534.852285031999   time:  1.5489532947540283
e:  10   train_loss:  534.852285031999   val_loss:  731.5626044330435   time:  1.663550853729248
e:  11   train_loss:  537.8580533320984   time:  1.5548572540283203
e:  12   train_loss:  533.6943095469203   time:  1.6921160221099854
e:  13   train_loss:  528.4377043059608   time:  1.544581413269043
e:  14   train_loss:  521.1145309218792   time:  1.5348668098449707
e:  15   train_loss:  520.7147075561288   time:  1.4675467014312744
e:  15   train_loss:  520.7147075561288   val_loss:  737.4884222777587   time:  1.5813488960266113
e:  16   train_loss:  516.3640389721962   time:  1.5378937721252441
e:  17   train_loss:  510.4044355632207   time:  1.5582935810089111
e:  18   train_loss:  503.45278489641936   time:  1.544067621231079
e:  19   train_loss:  497.1117482750379   time:  1.5458331108093262
e:  20   train_loss:  497.8311692633213   time:  1.5419020652770996
e:  20   train_loss:  497.8311692633213   val_loss:  739.6024213091274   time:  1.6567647457122803
e:  21   train_loss:  485.89471590786997   time:  1.5469279289245605
e:  22   train_loss:  481.44582785019253   time:  1.6812992095947266
e:  23   train_loss:  470.89089850542007   time:  1.560398817062378
e:  24   train_loss:  461.0766062836247   time:  1.5528583526611328
e:  25   train_loss:  454.48160420217005   time:  1.5459797382354736
e:  25   train_loss:  454.48160420217005   val_loss:  769.5128448486429   time:  1.6604609489440918
e:  26   train_loss:  443.8658241187191   time:  1.5481767654418945
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  981.6678292563356   time:  1.6782002449035645
e:  0   train_loss:  981.6678292563356   val_loss:  556.4634528982749   time:  1.7859258651733398
e:  1   train_loss:  899.4991167810408   time:  1.675346851348877
e:  2   train_loss:  885.3476569267584   time:  1.678126335144043
e:  3   train_loss:  848.6948186608829   time:  1.8619115352630615
e:  4   train_loss:  750.2559348212855   time:  1.7108395099639893
e:  5   train_loss:  663.3397482165531   time:  1.6533141136169434
e:  5   train_loss:  663.3397482165531   val_loss:  576.3767641534004   time:  1.7606315612792969
e:  6   train_loss:  644.9894786319362   time:  1.6013305187225342
e:  7   train_loss:  617.6971988452292   time:  1.637190341949463
e:  8   train_loss:  590.9292704167486   time:  1.789968729019165
e:  9   train_loss:  583.0391585340892   time:  1.6566534042358398
e:  10   train_loss:  563.4025442402498   time:  1.6529381275177002
e:  10   train_loss:  563.4025442402498   val_loss:  556.5935043597777   time:  1.7591416835784912
e:  11   train_loss:  557.7267570074008   time:  1.639723777770996
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  12   train_loss:  552.8446314966955   time:  1.6686275005340576
e:  13   train_loss:  557.1135270171953   time:  1.6633131504058838
e:  14   train_loss:  539.6336500907477   time:  1.6635863780975342
e:  15   train_loss:  534.2041288253132   time:  1.7971420288085938
e:  15   train_loss:  534.2041288253132   val_loss:  556.6761983376143   time:  1.9045944213867188
e:  16   train_loss:  529.5102945490453   time:  1.6579248905181885
e:  17   train_loss:  527.5450546844045   time:  1.6636981964111328
e:  18   train_loss:  519.4234036534793   time:  1.6465635299682617
e:  19   train_loss:  506.37683539385995   time:  1.6293034553527832
e:  20   train_loss:  491.4583290584283   time:  1.6581063270568848
e:  20   train_loss:  491.4583290584283   val_loss:  557.1115252913157   time:  1.7652902603149414
e:  21   train_loss:  480.4908080721237   time:  1.6795401573181152
e:  22   train_loss:  468.2820129515998   time:  1.7945997714996338
e:  23   train_loss:  444.48266475917944   time:  1.6591968536376953
e:  24   train_loss:  432.36945683284716   time:  1.5822334289550781
e:  25   train_loss:  401.98300732342744   time:  1.6481645107269287
e:  25   train_loss:  401.98300732342744   val_loss:  583.0879895861156   time:  1.7552344799041748
e:  26   train_loss:  382.770046699821   time:  1.6572401523590088
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 21), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 21) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 21) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 21) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 21)
kwargs: {'config': {'batch_norm': False, 'ff_0': 136, 'ff_num_layers': 3, 'gnn_0': 104, 'gnn_dropout': 0.09105864397368119, 'gnn_num_layers': 1, 'hid_0': 1098, 'hid_dropout_rate': 0.2950418713601814, 'in_dropout_rate': 0.4290437273961989, 'lr': 0.0008127555244333852, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 72, 'ff_2': 877, 'hid_1': 1783, 'hid_2': 73}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 730.8590548032014, 'n_epochs': 27.0, 'info': {'validation loss': 730.8590548032014}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 21) started
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:job_callback for (0, 0, 21) got condition
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 21) finished
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 22) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 22) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 22)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 22) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 22) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 22)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 17, 'ff_num_layers': 1, 'gnn_0': 281, 'gnn_dropout': 0.3279737195479306, 'gnn_num_layers': 1, 'hid_0': 593, 'hid_dropout_rate': 0.20414696252923964, 'in_dropout_rate': 0.4386659901915775, 'lr': 0.0015707457967605017, 'num_hid_layers': 3, 'optimizer': 'SGD', 'hid_1': 511, 'hid_2': 271, 'sgd_momentum': 0.6094637896459667}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  700.7710330580833   time:  1.3051049709320068
e:  0   train_loss:  700.7710330580833   val_loss:  1648.4539220819681   time:  1.4144048690795898
e:  1   train_loss:  672.5645814131299   time:  1.3065686225891113
e:  2   train_loss:  599.6585278344394   time:  1.4453706741333008
e:  3   train_loss:  590.7236996924072   time:  1.3408973217010498
e:  4   train_loss:  580.2832295522766   time:  1.3142991065979004
e:  5   train_loss:  562.4487792614137   time:  1.5093772411346436
e:  5   train_loss:  562.4487792614137   val_loss:  1363.7700916902852   time:  1.618950366973877
e:  6   train_loss:  554.7963014313624   time:  1.3403325080871582
e:  7   train_loss:  569.8383091407073   time:  1.3524019718170166
e:  8   train_loss:  542.2941775983361   time:  1.5002307891845703
e:  9   train_loss:  548.116266172192   time:  1.3141369819641113
e:  10   train_loss:  577.4702731427254   time:  1.3270442485809326
e:  10   train_loss:  577.4702731427254   val_loss:  1373.9511420888123   time:  1.4361040592193604
e:  11   train_loss:  540.7020660332626   time:  1.3212347030639648
e:  12   train_loss:  566.6778188585788   time:  1.3302199840545654
e:  13   train_loss:  552.5930540424177   time:  1.4503874778747559
e:  14   train_loss:  543.1296286555412   time:  1.3251760005950928
e:  15   train_loss:  549.2766483842743   time:  1.3162686824798584
e:  15   train_loss:  549.2766483842743   val_loss:  1432.9509833308798   time:  1.4242615699768066
e:  16   train_loss:  522.8572260472037   time:  1.3213310241699219
e:  17   train_loss:  525.2001188413008   time:  1.3245000839233398
e:  18   train_loss:  556.5593588013414   time:  1.2806963920593262
e:  19   train_loss:  542.1134306580886   time:  1.3095438480377197
e:  20   train_loss:  507.0407807157489   time:  1.3225548267364502
e:  20   train_loss:  507.0407807157489   val_loss:  1356.1895747967023   time:  1.4317655563354492
e:  21   train_loss:  539.9594024711448   time:  1.3216028213500977
e:  22   train_loss:  521.8800808477924   time:  1.4525744915008545
e:  23   train_loss:  506.6076318703833   time:  1.306980848312378
e:  24   train_loss:  587.1887715367   time:  1.3153295516967773
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  25   train_loss:  558.5544369926741   time:  1.3156204223632812
e:  25   train_loss:  558.5544369926741   val_loss:  1451.4438543767071   time:  1.4250681400299072
e:  26   train_loss:  573.7450381525732   time:  1.3191030025482178
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1065.6667930832925   time:  1.4354026317596436
e:  0   train_loss:  1065.6667930832925   val_loss:  599.7141832155942   time:  1.5384154319763184
e:  1   train_loss:  962.3004254280357   time:  1.4278748035430908
e:  2   train_loss:  887.7210058780125   time:  1.439863920211792
e:  3   train_loss:  849.0822741123843   time:  1.5696666240692139
e:  4   train_loss:  908.5834708038203   time:  1.4355089664459229
e:  5   train_loss:  836.5658299104546   time:  1.4392893314361572
e:  5   train_loss:  836.5658299104546   val_loss:  531.2355234021605   time:  1.5412163734436035
e:  6   train_loss:  834.6661146752551   time:  1.4401097297668457
e:  7   train_loss:  761.0313603823432   time:  1.436115026473999
e:  8   train_loss:  912.0418378200452   time:  1.4424734115600586
e:  9   train_loss:  804.5319074233755   time:  1.5708317756652832
e:  10   train_loss:  824.8734972881018   time:  1.4335095882415771
e:  10   train_loss:  824.8734972881018   val_loss:  533.9522264554338   time:  1.535966157913208
e:  11   train_loss:  820.5719763491244   time:  1.4340267181396484
e:  12   train_loss:  784.570260632489   time:  1.399749755859375
e:  13   train_loss:  709.9744838654634   time:  1.418945074081421
e:  14   train_loss:  706.1946454811707   time:  1.4365932941436768
e:  15   train_loss:  741.4537682475179   time:  1.4272820949554443
e:  15   train_loss:  741.4537682475179   val_loss:  539.9621430067489   time:  1.6596481800079346
e:  16   train_loss:  732.3020960002472   time:  1.4418919086456299
e:  17   train_loss:  656.7625254457098   time:  1.4328663349151611
e:  18   train_loss:  686.7366010923599   time:  1.4290308952331543
e:  19   train_loss:  745.298268844743   time:  1.4380497932434082
e:  20   train_loss:  838.8251957785529   time:  1.439227819442749
e:  20   train_loss:  838.8251957785529   val_loss:  531.3302052349253   time:  1.5407252311706543
e:  21   train_loss:  729.1174033939606   time:  1.4316260814666748
e:  22   train_loss:  735.4440425270545   time:  1.4379870891571045
e:  23   train_loss:  681.7757621609037   time:  1.4355027675628662
e:  24   train_loss:  780.1576818908522   time:  1.5655326843261719
e:  25   train_loss:  719.2527039739173   time:  1.4280555248260498
e:  25   train_loss:  719.2527039739173   val_loss:  534.0408590915781   time:  1.529994249343872
e:  26   train_loss:  653.114929196385   time:  1.4383573532104492
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1066.2248038827488   time:  1.4217188358306885
e:  0   train_loss:  1066.2248038827488   val_loss:  514.4347308983964   time:  1.5259239673614502
e:  1   train_loss:  961.4184801728338   time:  1.4223377704620361
e:  2   train_loss:  892.238205297455   time:  1.4127397537231445
e:  3   train_loss:  883.3160743066562   time:  1.4185411930084229
e:  4   train_loss:  1079.8239589934208   time:  1.559429407119751
e:  5   train_loss:  1002.2285961905129   time:  1.3945062160491943
e:  5   train_loss:  1002.2285961905129   val_loss:  473.5270454379538   time:  1.4984211921691895
e:  6   train_loss:  966.1294851482962   time:  1.3979406356811523
e:  7   train_loss:  902.1812414980647   time:  1.4201841354370117
e:  8   train_loss:  895.6775136593068   time:  1.4185583591461182
e:  9   train_loss:  931.2574800824732   time:  1.420353651046753
e:  10   train_loss:  873.8949808832926   time:  1.4103477001190186
e:  10   train_loss:  873.8949808832926   val_loss:  493.0140603101716   time:  1.5151169300079346
e:  11   train_loss:  840.254189287818   time:  1.4311463832855225
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  12   train_loss:  841.5417999234378   time:  1.558326005935669
e:  13   train_loss:  818.0386581903035   time:  1.4170339107513428
e:  14   train_loss:  786.4146508959388   time:  1.4130711555480957
e:  15   train_loss:  783.590310214761   time:  1.4091384410858154
e:  15   train_loss:  783.590310214761   val_loss:  485.9508936984851   time:  1.513336420059204
e:  16   train_loss:  813.5956177386547   time:  1.4173436164855957
e:  17   train_loss:  806.1941830860718   time:  1.4172239303588867
e:  18   train_loss:  783.4216764176998   time:  1.4171006679534912
e:  19   train_loss:  840.3321345174718   time:  1.4324181079864502
e:  20   train_loss:  799.8737444326975   time:  1.5536201000213623
e:  20   train_loss:  799.8737444326975   val_loss:  471.0935087941124   time:  1.6576662063598633
e:  21   train_loss:  834.2863857276423   time:  1.4156887531280518
e:  22   train_loss:  811.9802467683653   time:  1.4084203243255615
e:  23   train_loss:  795.7790439375856   time:  1.411466121673584
e:  24   train_loss:  716.4451852926999   time:  1.4085168838500977
e:  25   train_loss:  736.3518513651286   time:  1.4093048572540283
e:  25   train_loss:  736.3518513651286   val_loss:  477.23889277197696   time:  1.5138473510742188
e:  26   train_loss:  834.6775841432241   time:  1.4980149269104004
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  990.6624962173105   time:  1.2940142154693604
e:  0   train_loss:  990.6624962173105   val_loss:  889.1508125841541   time:  1.402911901473999
e:  1   train_loss:  905.9416043984894   time:  1.3052210807800293
e:  2   train_loss:  834.9161021170717   time:  1.3123269081115723
e:  3   train_loss:  819.5167144729776   time:  1.3156194686889648
e:  4   train_loss:  807.7509962645928   time:  1.3145976066589355
e:  5   train_loss:  877.8580620930821   time:  1.3156027793884277
e:  5   train_loss:  877.8580620930821   val_loss:  747.2891572880809   time:  1.4251060485839844
e:  6   train_loss:  831.5088148622647   time:  1.3154473304748535
e:  7   train_loss:  808.1422149107996   time:  1.304596185684204
e:  8   train_loss:  756.2371070016978   time:  1.3132455348968506
e:  9   train_loss:  818.4507786734945   time:  1.316237211227417
e:  10   train_loss:  784.4375925454184   time:  1.313704013824463
e:  10   train_loss:  784.4375925454184   val_loss:  770.3550776317542   time:  1.4241127967834473
e:  11   train_loss:  744.8094998409046   time:  1.3078882694244385
e:  12   train_loss:  722.15614332406   time:  1.4390454292297363
e:  13   train_loss:  740.0099995188401   time:  1.315159797668457
e:  14   train_loss:  707.151913161412   time:  1.3156700134277344
e:  15   train_loss:  693.4219775115047   time:  1.3191142082214355
e:  15   train_loss:  693.4219775115047   val_loss:  754.3776631768682   time:  1.4294140338897705
e:  16   train_loss:  660.4356548275161   time:  1.3131170272827148
e:  17   train_loss:  638.3209665358964   time:  1.3124089241027832
e:  18   train_loss:  707.159688473176   time:  1.3147716522216797
e:  19   train_loss:  671.6432462440582   time:  1.315110206604004
e:  20   train_loss:  637.599028815768   time:  1.3169617652893066
e:  20   train_loss:  637.599028815768   val_loss:  731.2193931261047   time:  1.4260854721069336
e:  21   train_loss:  633.7231853615954   time:  1.2940001487731934
e:  22   train_loss:  664.2427524133868   time:  1.4361724853515625
e:  23   train_loss:  614.5342830240207   time:  1.3147895336151123
e:  24   train_loss:  612.1917060851665   time:  1.3148939609527588
e:  25   train_loss:  614.9601822595407   time:  1.3142917156219482
e:  25   train_loss:  614.9601822595407   val_loss:  714.6601132600575   time:  1.4234874248504639
e:  26   train_loss:  599.8171617223032   time:  1.317640781402588
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1054.0261719480293   time:  1.4361011981964111
e:  0   train_loss:  1054.0261719480293   val_loss:  657.2540036647284   time:  1.5391426086425781
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  1   train_loss:  970.9741683920727   time:  1.4685604572296143
e:  2   train_loss:  921.9531849710917   time:  1.4377293586730957
e:  3   train_loss:  862.2467462090128   time:  1.5763804912567139
e:  4   train_loss:  909.86493744832   time:  1.43345308303833
e:  5   train_loss:  861.9048946820201   time:  1.425175428390503
e:  5   train_loss:  861.9048946820201   val_loss:  583.4422830056003   time:  1.5285334587097168
e:  6   train_loss:  780.7795048454277   time:  1.4351706504821777
e:  7   train_loss:  810.2882674853776   time:  1.4298920631408691
e:  8   train_loss:  942.8311585401591   time:  1.5646555423736572
e:  9   train_loss:  820.1245590257957   time:  1.4315555095672607
e:  10   train_loss:  849.8972693959918   time:  1.426969051361084
e:  10   train_loss:  849.8972693959918   val_loss:  561.1565017852738   time:  1.5295979976654053
e:  11   train_loss:  743.2529257580608   time:  1.4354145526885986
e:  12   train_loss:  763.267353233406   time:  1.4362547397613525
e:  13   train_loss:  792.0746455919564   time:  1.4341354370117188
e:  14   train_loss:  759.9793026002651   time:  1.4184110164642334
e:  15   train_loss:  731.2422218050359   time:  1.5350966453552246
e:  15   train_loss:  731.2422218050359   val_loss:  569.8157643879389   time:  1.6373944282531738
e:  16   train_loss:  727.9905599029571   time:  1.5511696338653564
e:  17   train_loss:  693.2325684908493   time:  1.510509729385376
e:  18   train_loss:  685.9684331975233   time:  1.4911675453186035
e:  19   train_loss:  672.6313971473936   time:  1.4955859184265137
e:  20   train_loss:  718.2305313199905   time:  1.4960873126983643
e:  20   train_loss:  718.2305313199905   val_loss:  566.6605514676913   time:  1.5997459888458252
e:  21   train_loss:  682.8518157238536   time:  1.7067694664001465
e:  22   train_loss:  666.6847375109265   time:  1.4902031421661377
e:  23   train_loss:  626.6888184134491   time:  1.4858965873718262
e:  24   train_loss:  624.5512457276585   time:  1.4926700592041016
e:  25   train_loss:  659.053006286113   time:  1.4875133037567139
e:  25   train_loss:  659.053006286113   val_loss:  564.7970601398442   time:  1.590815782546997
e:  26   train_loss:  657.4109883019905   time:  1.4942283630371094
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 22), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 22) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 22) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 22) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 22)
kwargs: {'config': {'batch_norm': False, 'ff_0': 17, 'ff_num_layers': 1, 'gnn_0': 281, 'gnn_dropout': 0.3279737195479306, 'gnn_num_layers': 1, 'hid_0': 593, 'hid_dropout_rate': 0.20414696252923964, 'in_dropout_rate': 0.4386659901915775, 'lr': 0.0015707457967605017, 'num_hid_layers': 3, 'optimizer': 'SGD', 'hid_1': 511, 'hid_2': 271, 'sgd_momentum': 0.6094637896459667}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 726.8670444076613, 'n_epochs': 27.0, 'info': {'validation loss': 726.8670444076613}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 22) started
DEBUG:hpbandster:job_callback for (0, 0, 22) got condition
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 22) finished
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 23) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 23) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 23)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 23) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 23) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 23)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 153, 'ff_num_layers': 2, 'gnn_0': 119, 'gnn_dropout': 0.14301754056973098, 'gnn_num_layers': 2, 'hid_0': 745, 'hid_dropout_rate': 0.23559505514761803, 'in_dropout_rate': 0.44029043103421833, 'lr': 4.787768678407055e-05, 'num_hid_layers': 1, 'optimizer': 'SGD', 'ff_1': 895, 'gnn_1': 306, 'sgd_momentum': 0.19216701227464988}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  704.2203428950028   time:  1.4321601390838623
e:  0   train_loss:  704.2203428950028   val_loss:  1671.2950269153077   time:  1.5436017513275146
e:  1   train_loss:  703.4654788322443   time:  1.5990841388702393
e:  2   train_loss:  701.7303985183935   time:  1.435187578201294
e:  3   train_loss:  699.073840711996   time:  1.455378770828247
e:  4   train_loss:  697.5096611313744   time:  1.4260635375976562
e:  5   train_loss:  696.0061811000121   time:  1.4390220642089844
e:  5   train_loss:  696.0061811000121   val_loss:  1655.5109471231508   time:  1.5499980449676514
e:  6   train_loss:  694.1426518703231   time:  1.4493787288665771
e:  7   train_loss:  691.1016624772836   time:  1.4173345565795898
e:  8   train_loss:  689.8645955864347   time:  1.4564573764801025
e:  9   train_loss:  686.0439783931686   time:  1.4458034038543701
e:  10   train_loss:  682.6004226385057   time:  1.442159652709961
e:  10   train_loss:  682.6004226385057   val_loss:  1631.796841864524   time:  1.552583932876587
e:  11   train_loss:  680.5632705656739   time:  1.421417474746704
e:  12   train_loss:  676.9843869529693   time:  1.466407060623169
e:  13   train_loss:  674.2499556163327   time:  1.5040547847747803
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  14   train_loss:  670.5548816818191   time:  1.4847354888916016
e:  15   train_loss:  666.441213648997   time:  1.3749847412109375
e:  15   train_loss:  666.441213648997   val_loss:  1596.2138855314238   time:  1.4849178791046143
e:  16   train_loss:  661.8864116627981   time:  1.370600938796997
e:  17   train_loss:  657.4951864941205   time:  1.3753314018249512
e:  18   train_loss:  653.7368810467221   time:  1.3746237754821777
e:  19   train_loss:  648.9821705024265   time:  1.3791961669921875
e:  20   train_loss:  643.6965819538516   time:  1.3726701736450195
e:  20   train_loss:  643.6965819538516   val_loss:  1549.2808704449535   time:  1.484318733215332
e:  21   train_loss:  639.0902773015807   time:  1.3729968070983887
e:  22   train_loss:  634.6432640241837   time:  1.3782215118408203
e:  23   train_loss:  631.8268356209637   time:  1.3795368671417236
e:  24   train_loss:  627.522511122514   time:  1.4893312454223633
e:  25   train_loss:  623.2015871350048   time:  1.3753864765167236
e:  25   train_loss:  623.2015871350048   val_loss:  1499.4790242753882   time:  1.486720085144043
e:  26   train_loss:  619.3932252520559   time:  1.3762414455413818
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1098.0249351874497   time:  1.4950644969940186
e:  0   train_loss:  1098.0249351874497   val_loss:  627.6201822500688   time:  1.5988779067993164
e:  1   train_loss:  1080.622898269839   time:  1.459486961364746
e:  2   train_loss:  1072.4317346767293   time:  1.4847404956817627
e:  3   train_loss:  1080.4890897874636   time:  1.4974722862243652
e:  4   train_loss:  1051.4802957066877   time:  1.6300876140594482
e:  5   train_loss:  1078.1152217161698   time:  1.4969935417175293
e:  5   train_loss:  1078.1152217161698   val_loss:  614.2283323208292   time:  1.6004793643951416
e:  6   train_loss:  1089.5421714717554   time:  1.4965622425079346
e:  7   train_loss:  1055.336542821084   time:  1.492593765258789
e:  8   train_loss:  1057.0714817879775   time:  1.4987659454345703
e:  9   train_loss:  1025.561687825679   time:  1.496875286102295
e:  10   train_loss:  1042.758484039583   time:  1.495497703552246
e:  10   train_loss:  1042.758484039583   val_loss:  591.4714714030273   time:  1.7220399379730225
e:  11   train_loss:  1013.5482324098853   time:  1.4964823722839355
e:  12   train_loss:  1018.6602452377587   time:  1.4966886043548584
e:  13   train_loss:  1021.4773717964285   time:  1.492638349533081
e:  14   train_loss:  992.831818426214   time:  1.495516300201416
e:  15   train_loss:  988.113512865948   time:  1.4935634136199951
e:  15   train_loss:  988.113512865948   val_loss:  560.3467760080464   time:  1.5968899726867676
e:  16   train_loss:  982.6994301572403   time:  1.6310765743255615
e:  17   train_loss:  968.3518112916021   time:  1.4964056015014648
e:  18   train_loss:  951.2596694302924   time:  1.4959092140197754
e:  19   train_loss:  942.6821538654981   time:  1.4941749572753906
e:  20   train_loss:  941.3448414132838   time:  1.4760072231292725
e:  20   train_loss:  941.3448414132838   val_loss:  539.3985509177838   time:  1.5789029598236084
e:  21   train_loss:  949.1584175876352   time:  1.452418565750122
e:  22   train_loss:  940.151050001664   time:  1.4927411079406738
e:  23   train_loss:  920.0221475236007   time:  1.6051125526428223
e:  24   train_loss:  923.4224087896279   time:  1.4945807456970215
e:  25   train_loss:  918.0309988188463   time:  1.496095895767212
e:  25   train_loss:  918.0309988188463   val_loss:  539.8779503289533   time:  1.5990760326385498
e:  26   train_loss:  894.9749229990038   time:  1.495187759399414
FOLD:  2
Model initialization done
Model training starts
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  0   train_loss:  1090.2357341383367   time:  1.4838097095489502
e:  0   train_loss:  1090.2357341383367   val_loss:  538.2758971513603   time:  1.5909371376037598
e:  1   train_loss:  1086.598323069631   time:  1.4777891635894775
e:  2   train_loss:  1100.0601310546042   time:  1.5902330875396729
e:  3   train_loss:  1085.7152777692431   time:  1.477189302444458
e:  4   train_loss:  1076.6805495943681   time:  1.4778850078582764
e:  5   train_loss:  1066.6313944794617   time:  1.475792407989502
e:  5   train_loss:  1066.6313944794617   val_loss:  527.165921872691   time:  1.5819835662841797
e:  6   train_loss:  1075.8314681902157   time:  1.4772915840148926
e:  7   train_loss:  1071.9571528269375   time:  1.4770867824554443
e:  8   train_loss:  1042.6785907486073   time:  1.4761574268341064
e:  9   train_loss:  1017.6733156375254   time:  1.4740986824035645
e:  10   train_loss:  1008.8347644436762   time:  1.6146697998046875
e:  10   train_loss:  1008.8347644436762   val_loss:  508.12131005237933   time:  1.7140562534332275
e:  11   train_loss:  1040.642061586963   time:  1.4776339530944824
e:  12   train_loss:  1059.026167205003   time:  1.4726958274841309
e:  13   train_loss:  986.9526649800978   time:  1.4483058452606201
e:  14   train_loss:  996.2510928401906   time:  1.458282709121704
e:  15   train_loss:  961.1896474922687   time:  1.4782578945159912
e:  15   train_loss:  961.1896474922687   val_loss:  485.0714999808754   time:  1.5851500034332275
e:  16   train_loss:  941.7854063526247   time:  1.4729557037353516
e:  17   train_loss:  1038.4846230603196   time:  1.4782655239105225
e:  18   train_loss:  920.0995950813704   time:  1.611203670501709
e:  19   train_loss:  983.0877292310447   time:  1.477689504623413
e:  20   train_loss:  953.3808373107432   time:  1.4711003303527832
e:  20   train_loss:  953.3808373107432   val_loss:  477.1395193314729   time:  1.5774569511413574
e:  21   train_loss:  908.1422268862594   time:  1.4776647090911865
e:  22   train_loss:  941.4518905372261   time:  1.4755961894989014
e:  23   train_loss:  954.2898726054196   time:  1.4772181510925293
e:  24   train_loss:  886.9147689179817   time:  1.474801778793335
e:  25   train_loss:  930.3092516989847   time:  1.478773832321167
e:  25   train_loss:  930.3092516989847   val_loss:  485.5986829696995   time:  1.712892770767212
e:  26   train_loss:  938.7064862090311   time:  1.4761497974395752
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  996.9831202168182   time:  1.3511993885040283
e:  0   train_loss:  996.9831202168182   val_loss:  915.6571843860945   time:  1.461937665939331
e:  1   train_loss:  995.4895915782259   time:  1.3711168766021729
e:  2   train_loss:  993.4799360351396   time:  1.3847379684448242
e:  3   train_loss:  992.6547493442116   time:  1.374742031097412
e:  4   train_loss:  986.9993920617193   time:  1.509324550628662
e:  5   train_loss:  986.2896166947303   time:  1.3833129405975342
e:  5   train_loss:  986.2896166947303   val_loss:  900.8387089905733   time:  1.495436191558838
e:  6   train_loss:  979.3752251927717   time:  1.3364474773406982
e:  7   train_loss:  978.7152134409864   time:  1.468334436416626
e:  8   train_loss:  975.5345937204966   time:  1.3748195171356201
e:  9   train_loss:  965.4986686093234   time:  1.3705134391784668
e:  10   train_loss:  965.0468915495014   time:  1.3669307231903076
e:  10   train_loss:  965.0468915495014   val_loss:  875.836311509919   time:  1.4778480529785156
e:  11   train_loss:  961.1675295273392   time:  1.3738055229187012
e:  12   train_loss:  951.659037042433   time:  1.3747456073760986
e:  13   train_loss:  943.5880793336207   time:  1.3656532764434814
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  14   train_loss:  935.1408427722488   time:  1.3886620998382568
e:  15   train_loss:  930.5944939176917   time:  1.3749072551727295
e:  15   train_loss:  930.5944939176917   val_loss:  837.8871146752456   time:  1.4858076572418213
e:  16   train_loss:  922.4779311557339   time:  1.3708651065826416
e:  17   train_loss:  912.1284377805963   time:  1.3740124702453613
e:  18   train_loss:  905.1779024806146   time:  1.4981253147125244
e:  19   train_loss:  897.8561182707731   time:  1.3586630821228027
e:  20   train_loss:  888.6300662824608   time:  1.3746893405914307
e:  20   train_loss:  888.6300662824608   val_loss:  794.7955120329717   time:  1.4860997200012207
e:  21   train_loss:  880.3456144960564   time:  1.377838134765625
e:  22   train_loss:  874.3289482467936   time:  1.3745448589324951
e:  23   train_loss:  869.1497193648541   time:  1.3709416389465332
e:  24   train_loss:  866.2625241336149   time:  1.3727121353149414
e:  25   train_loss:  856.2950039895811   time:  1.3757004737854004
e:  25   train_loss:  856.2950039895811   val_loss:  763.2994412452431   time:  1.4872477054595947
e:  26   train_loss:  854.1519032525256   time:  1.3714179992675781
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1070.217597417114   time:  1.485896110534668
e:  0   train_loss:  1070.217597417114   val_loss:  688.8890509829092   time:  1.5912656784057617
e:  1   train_loss:  1055.3220528346671   time:  1.488600254058838
e:  2   train_loss:  1085.1087217001532   time:  1.6333122253417969
e:  3   train_loss:  1081.0350790242617   time:  1.498429775238037
e:  4   train_loss:  1050.7239706380885   time:  1.4991726875305176
e:  5   train_loss:  1078.0266143444205   time:  1.4968342781066895
e:  5   train_loss:  1078.0266143444205   val_loss:  673.3982024257095   time:  1.6020700931549072
e:  6   train_loss:  1050.9788811194815   time:  1.4953010082244873
e:  7   train_loss:  1041.0258122352361   time:  1.489995002746582
e:  8   train_loss:  1062.3420441222254   time:  1.6223008632659912
e:  9   train_loss:  1029.174581550882   time:  1.493687629699707
e:  10   train_loss:  1028.4228116612132   time:  1.4946317672729492
e:  10   train_loss:  1028.4228116612132   val_loss:  646.242398258587   time:  1.5994133949279785
e:  11   train_loss:  1023.9362202350765   time:  1.4962856769561768
e:  12   train_loss:  1018.0143892535507   time:  1.4914665222167969
e:  13   train_loss:  994.3854309907163   time:  1.498507022857666
e:  14   train_loss:  982.1470589469823   time:  1.6253578662872314
e:  15   train_loss:  970.2385846631712   time:  1.496279001235962
e:  15   train_loss:  970.2385846631712   val_loss:  606.8756504344026   time:  1.6017863750457764
e:  16   train_loss:  986.4709721106808   time:  1.4954512119293213
e:  17   train_loss:  951.947896573985   time:  1.494136095046997
e:  18   train_loss:  940.2664420489481   time:  1.49937105178833
e:  19   train_loss:  964.7053327249318   time:  1.4962103366851807
e:  20   train_loss:  938.9154538273209   time:  1.5667104721069336
e:  20   train_loss:  938.9154538273209   val_loss:  572.8516387555853   time:  1.6708428859710693
e:  21   train_loss:  940.125917701304   time:  1.479870319366455
e:  22   train_loss:  917.2714593075133   time:  1.4906806945800781
e:  23   train_loss:  922.8265186895096   time:  1.4971566200256348
e:  24   train_loss:  899.063302157387   time:  1.4982457160949707
e:  25   train_loss:  917.218825293048   time:  1.496788740158081
e:  25   train_loss:  917.218825293048   val_loss:  558.9476105067682   time:  1.6010735034942627
e:  26   train_loss:  919.4706722281624   time:  1.4992449283599854
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 23), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 23) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 23) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 23) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 23)
kwargs: {'config': {'batch_norm': False, 'ff_0': 153, 'ff_num_layers': 2, 'gnn_0': 119, 'gnn_dropout': 0.14301754056973098, 'gnn_num_layers': 2, 'hid_0': 745, 'hid_dropout_rate': 0.23559505514761803, 'in_dropout_rate': 0.44029043103421833, 'lr': 4.787768678407055e-05, 'num_hid_layers': 1, 'optimizer': 'SGD', 'ff_1': 895, 'gnn_1': 306, 'sgd_momentum': 0.19216701227464988}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 767.6528292553313, 'n_epochs': 27.0, 'info': {'validation loss': 767.6528292553313}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 23) started
DEBUG:hpbandster:job_callback for (0, 0, 23) got condition
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 23) finished
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 24) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 24) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 24)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 24) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 24) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 24)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 287, 'ff_num_layers': 1, 'gnn_0': 178, 'gnn_dropout': 0.10704706071413361, 'gnn_num_layers': 1, 'hid_0': 1142, 'hid_dropout_rate': 0.3060214993818148, 'in_dropout_rate': 0.13307502032779367, 'lr': 5.888489735715271e-05, 'num_hid_layers': 3, 'optimizer': 'SGD', 'hid_1': 100, 'hid_2': 195, 'sgd_momentum': 0.6225275032723123}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  0   train_loss:  704.8418094379948   time:  1.5908381938934326
e:  0   train_loss:  704.8418094379948   val_loss:  1673.4446347791734   time:  1.7018048763275146
e:  1   train_loss:  704.3201818684562   time:  1.4989936351776123
e:  2   train_loss:  703.3464086614731   time:  1.4906225204467773
e:  3   train_loss:  702.8548161749131   time:  1.4963254928588867
e:  4   train_loss:  700.7608116662933   time:  1.4699058532714844
e:  5   train_loss:  699.7472538993177   time:  1.497753381729126
e:  5   train_loss:  699.7472538993177   val_loss:  1664.649405914937   time:  1.6093130111694336
e:  6   train_loss:  699.457173437909   time:  1.4953911304473877
e:  7   train_loss:  697.7432271836215   time:  1.487684965133667
e:  8   train_loss:  696.3397049842347   time:  1.4972290992736816
e:  9   train_loss:  694.6551426610638   time:  1.4712786674499512
e:  10   train_loss:  694.1720835234358   time:  1.7244782447814941
e:  10   train_loss:  694.1720835234358   val_loss:  1654.0852303953536   time:  1.8271145820617676
e:  11   train_loss:  694.1378754406765   time:  1.498028039932251
e:  12   train_loss:  692.2997218803916   time:  1.4799268245697021
e:  13   train_loss:  690.4390899287083   time:  1.4310033321380615
e:  14   train_loss:  688.9777791974351   time:  1.486619472503662
e:  15   train_loss:  686.3114887593428   time:  1.4857416152954102
e:  15   train_loss:  686.3114887593428   val_loss:  1638.7923813275834   time:  1.597327470779419
e:  16   train_loss:  684.8113444886056   time:  1.4299771785736084
e:  17   train_loss:  680.9160227086744   time:  1.4310250282287598
e:  18   train_loss:  678.584964862207   time:  1.4361193180084229
e:  19   train_loss:  674.1559322610653   time:  1.4345927238464355
e:  20   train_loss:  668.8067290461804   time:  1.4323828220367432
e:  20   train_loss:  668.8067290461804   val_loss:  1603.630608404464   time:  1.5430376529693604
e:  21   train_loss:  661.3845809137255   time:  1.5712625980377197
e:  22   train_loss:  652.7539410317521   time:  1.421015977859497
e:  23   train_loss:  641.4753039739793   time:  1.429295301437378
e:  24   train_loss:  626.5275031247126   time:  1.4347949028015137
e:  25   train_loss:  610.1286515485453   time:  1.4340286254882812
e:  25   train_loss:  610.1286515485453   val_loss:  1480.6034905377226   time:  1.5455901622772217
e:  26   train_loss:  594.5809117434402   time:  1.437903642654419
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1085.6370258097481   time:  1.5560989379882812
e:  0   train_loss:  1085.6370258097481   val_loss:  628.8341778001286   time:  1.6604127883911133
e:  1   train_loss:  1077.778635295337   time:  1.6407945156097412
e:  2   train_loss:  1076.3126335961606   time:  1.976043462753296
e:  3   train_loss:  1072.369047719349   time:  1.7114121913909912
e:  4   train_loss:  1079.4814812817062   time:  1.64091157913208
e:  5   train_loss:  1088.4073782562414   time:  1.503091812133789
e:  5   train_loss:  1088.4073782562414   val_loss:  622.5079499824986   time:  1.605888843536377
e:  6   train_loss:  1068.6703209551195   time:  1.5483121871948242
e:  7   train_loss:  1073.3433234018348   time:  1.55914306640625
e:  8   train_loss:  1067.8380875576067   time:  1.5537097454071045
e:  9   train_loss:  1073.4996722432722   time:  1.7086098194122314
e:  10   train_loss:  1057.2899450308162   time:  1.559412956237793
e:  10   train_loss:  1057.2899450308162   val_loss:  614.2211945751013   time:  1.663745403289795
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  11   train_loss:  1074.4794046636778   time:  1.5640108585357666
e:  12   train_loss:  1065.7127715352938   time:  1.558171033859253
e:  13   train_loss:  1048.357470192087   time:  1.5570003986358643
e:  14   train_loss:  1054.5204024103398   time:  1.5551385879516602
e:  15   train_loss:  1025.6902151340537   time:  1.6903259754180908
e:  15   train_loss:  1025.6902151340537   val_loss:  594.6815807001545   time:  1.7946374416351318
e:  16   train_loss:  1032.6600089018361   time:  1.5527145862579346
e:  17   train_loss:  1004.4723190031159   time:  1.5567936897277832
e:  18   train_loss:  973.77480442872   time:  1.5576913356781006
e:  19   train_loss:  887.8713948234931   time:  1.558892011642456
e:  20   train_loss:  815.4970085475082   time:  1.5555312633514404
e:  20   train_loss:  815.4970085475082   val_loss:  545.2333172552917   time:  1.6592726707458496
e:  21   train_loss:  752.16480151108   time:  1.5556435585021973
e:  22   train_loss:  729.8585975180977   time:  1.6834352016448975
e:  23   train_loss:  705.010668079087   time:  1.5363762378692627
e:  24   train_loss:  693.3907662408693   time:  1.498232364654541
e:  25   train_loss:  681.4385848199431   time:  1.5513951778411865
e:  25   train_loss:  681.4385848199431   val_loss:  567.5345848131686   time:  1.6557574272155762
e:  26   train_loss:  672.456612650069   time:  1.557509422302246
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1100.755791113849   time:  1.5260915756225586
e:  0   train_loss:  1100.755791113849   val_loss:  539.2969398418064   time:  1.632615327835083
e:  1   train_loss:  1099.8921342207238   time:  1.5482678413391113
e:  2   train_loss:  1066.314445086468   time:  1.6661653518676758
e:  3   train_loss:  1136.1489101125023   time:  1.5338141918182373
e:  4   train_loss:  1083.5815251815293   time:  1.5362944602966309
e:  5   train_loss:  1107.6962130246777   time:  1.5388994216918945
e:  5   train_loss:  1107.6962130246777   val_loss:  533.6051431186011   time:  1.644925594329834
e:  6   train_loss:  1091.5117664816887   time:  1.532207727432251
e:  7   train_loss:  1081.6899880586652   time:  1.5320844650268555
e:  8   train_loss:  1086.5682055980428   time:  1.6560163497924805
e:  9   train_loss:  1046.0753309298561   time:  1.5351192951202393
e:  10   train_loss:  1053.793751324779   time:  1.5338406562805176
e:  10   train_loss:  1053.793751324779   val_loss:  526.4736186316013   time:  1.6414074897766113
e:  11   train_loss:  1093.3980425618436   time:  1.5307807922363281
e:  12   train_loss:  1078.1400457427653   time:  1.5336766242980957
e:  13   train_loss:  1040.9072516283156   time:  1.5349371433258057
e:  14   train_loss:  1026.301677152364   time:  1.5322918891906738
e:  15   train_loss:  1035.9213523089504   time:  1.5165228843688965
e:  15   train_loss:  1035.9213523089504   val_loss:  511.8627876061477   time:  1.6221897602081299
e:  16   train_loss:  1002.4888048937667   time:  1.6316466331481934
e:  17   train_loss:  1052.416886210426   time:  1.5372426509857178
e:  18   train_loss:  991.3794473512771   time:  1.5372624397277832
e:  19   train_loss:  962.8929894080079   time:  1.5360441207885742
e:  20   train_loss:  845.781812770047   time:  1.5315053462982178
e:  20   train_loss:  845.781812770047   val_loss:  483.8288630958719   time:  1.638056755065918
e:  21   train_loss:  785.6346954438409   time:  1.531881332397461
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  22   train_loss:  786.6865365530184   time:  1.5419225692749023
e:  23   train_loss:  738.5922693618401   time:  1.533886432647705
e:  24   train_loss:  705.8749619465897   time:  1.6707494258880615
e:  25   train_loss:  704.4821052844771   time:  1.535231113433838
e:  25   train_loss:  704.4821052844771   val_loss:  524.3919690783954   time:  1.642181634902954
e:  26   train_loss:  674.9173569214404   time:  1.534672737121582
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  997.9162460118058   time:  1.4162867069244385
e:  0   train_loss:  997.9162460118058   val_loss:  917.4328419500708   time:  1.528787612915039
e:  1   train_loss:  1000.5354166238602   time:  1.4288835525512695
e:  2   train_loss:  997.6454427246322   time:  1.425421953201294
e:  3   train_loss:  998.4648509701098   time:  1.4307448863983154
e:  4   train_loss:  993.2711849584844   time:  1.4271364212036133
e:  5   train_loss:  989.6787261129467   time:  1.4293205738067627
e:  5   train_loss:  989.6787261129467   val_loss:  910.7483609954477   time:  1.5418729782104492
e:  6   train_loss:  991.0364461404714   time:  1.433117151260376
e:  7   train_loss:  988.4629041604148   time:  1.547715663909912
e:  8   train_loss:  990.0566147442809   time:  1.3818094730377197
e:  9   train_loss:  986.5544303441552   time:  1.400618076324463
e:  10   train_loss:  984.8017384337223   time:  1.430659532546997
e:  10   train_loss:  984.8017384337223   val_loss:  903.8318105504158   time:  1.5436646938323975
e:  11   train_loss:  983.4288872489091   time:  1.4264261722564697
e:  12   train_loss:  985.4420409799222   time:  1.4262712001800537
e:  13   train_loss:  985.0158871792688   time:  1.4291467666625977
e:  14   train_loss:  979.6088585592674   time:  1.428128719329834
e:  15   train_loss:  979.6795759504378   time:  1.4290125370025635
e:  15   train_loss:  979.6795759504378   val_loss:  895.5913266292438   time:  1.5415775775909424
e:  16   train_loss:  978.2666483182984   time:  1.429971694946289
e:  17   train_loss:  976.8626460833591   time:  1.5490357875823975
e:  18   train_loss:  971.1669914788921   time:  1.4262301921844482
e:  19   train_loss:  969.1049039973336   time:  1.4285407066345215
e:  20   train_loss:  968.8060665807743   time:  1.426866054534912
e:  20   train_loss:  968.8060665807743   val_loss:  882.1374664244336   time:  1.5387213230133057
e:  21   train_loss:  960.8326841107338   time:  1.4315001964569092
e:  22   train_loss:  955.5941007679838   time:  1.4245293140411377
e:  23   train_loss:  949.1007518861842   time:  1.4280474185943604
e:  24   train_loss:  940.8783673747295   time:  1.4290132522583008
e:  25   train_loss:  926.8960224421126   time:  1.429260015487671
e:  25   train_loss:  926.8960224421126   val_loss:  838.2235076814194   time:  1.5413539409637451
e:  26   train_loss:  904.7820498205267   time:  1.4289579391479492
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1062.0496180311065   time:  1.7007436752319336
e:  0   train_loss:  1062.0496180311065   val_loss:  690.0753903171508   time:  1.8068089485168457
e:  1   train_loss:  1080.2309925926684   time:  1.5356006622314453
e:  2   train_loss:  1057.3376278240653   time:  1.5167062282562256
e:  3   train_loss:  1061.9720862850602   time:  1.554741382598877
e:  4   train_loss:  1071.8492016771363   time:  1.5557096004486084
e:  5   train_loss:  1066.571341127067   time:  1.5520262718200684
e:  5   train_loss:  1066.571341127067   val_loss:  682.7113482141842   time:  1.6580891609191895
e:  6   train_loss:  1077.6399339240545   time:  1.6747782230377197
e:  7   train_loss:  1062.0329142696028   time:  1.5514979362487793
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  8   train_loss:  1062.4049181346884   time:  1.5497000217437744
e:  9   train_loss:  1057.2586262299908   time:  1.553055763244629
e:  10   train_loss:  1056.6058700691601   time:  1.5536699295043945
e:  10   train_loss:  1056.6058700691601   val_loss:  671.9568947452453   time:  1.6583659648895264
e:  11   train_loss:  1048.1466540548308   time:  1.550934076309204
e:  12   train_loss:  1049.1379390273578   time:  1.7005624771118164
e:  13   train_loss:  1047.2783828254805   time:  1.549842119216919
e:  14   train_loss:  1020.2721519259828   time:  1.5530669689178467
e:  15   train_loss:  992.2184921025878   time:  1.5529534816741943
e:  15   train_loss:  992.2184921025878   val_loss:  640.3942028886374   time:  1.6582093238830566
e:  16   train_loss:  1014.1468436543081   time:  1.5473878383636475
e:  17   train_loss:  963.9453718198615   time:  1.5433955192565918
e:  18   train_loss:  888.8147040780191   time:  1.7018215656280518
e:  19   train_loss:  806.5713716882929   time:  1.552182912826538
e:  20   train_loss:  744.6761893718925   time:  1.5209205150604248
e:  20   train_loss:  744.6761893718925   val_loss:  562.4585757688251   time:  1.6255919933319092
e:  21   train_loss:  722.9214614297998   time:  1.522153377532959
e:  22   train_loss:  697.3656151458343   time:  1.5494818687438965
e:  23   train_loss:  696.4140713788806   time:  1.552870750427246
e:  24   train_loss:  689.0953716957624   time:  1.697206735610962
e:  25   train_loss:  686.7401868673787   time:  1.550004005432129
e:  25   train_loss:  686.7401868673787   val_loss:  572.3278341053881   time:  1.654423475265503
e:  26   train_loss:  670.56899317202   time:  1.552973985671997
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 24), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 24) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 24) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 24) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 24)
kwargs: {'config': {'batch_norm': True, 'ff_0': 287, 'ff_num_layers': 1, 'gnn_0': 178, 'gnn_dropout': 0.10704706071413361, 'gnn_num_layers': 1, 'hid_0': 1142, 'hid_dropout_rate': 0.3060214993818148, 'in_dropout_rate': 0.13307502032779367, 'lr': 5.888489735715271e-05, 'num_hid_layers': 3, 'optimizer': 'SGD', 'hid_1': 100, 'hid_2': 195, 'sgd_momentum': 0.6225275032723123}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 782.0695508678261, 'n_epochs': 27.0, 'info': {'validation loss': 782.0695508678261}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 24) started
DEBUG:hpbandster:job_callback for (0, 0, 24) got condition
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 24) finished
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 25) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 25) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 25)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 25) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 25) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 25)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 21, 'ff_num_layers': 3, 'gnn_0': 958, 'gnn_dropout': 0.21542627652451324, 'gnn_num_layers': 2, 'hid_0': 1601, 'hid_dropout_rate': 0.4271126297116419, 'in_dropout_rate': 0.3095603548680177, 'lr': 0.00029072047003001915, 'num_hid_layers': 2, 'optimizer': 'Adam', 'ff_1': 1739, 'ff_2': 662, 'gnn_1': 120, 'hid_1': 1877}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  659.4565896345833   time:  1.8120708465576172
e:  0   train_loss:  659.4565896345833   val_loss:  1334.605308956864   time:  1.9283506870269775
e:  1   train_loss:  601.7198943325809   time:  1.8153936862945557
e:  2   train_loss:  594.424191980482   time:  1.793386459350586
e:  3   train_loss:  588.0973692728397   time:  1.754673957824707
e:  4   train_loss:  581.2643484010242   time:  1.7376039028167725
e:  5   train_loss:  573.165309725297   time:  1.9366788864135742
e:  5   train_loss:  573.165309725297   val_loss:  1387.0499233142332   time:  2.0500223636627197
e:  6   train_loss:  561.6654587356494   time:  1.773000717163086
e:  7   train_loss:  545.0395429406462   time:  1.8734652996063232
e:  8   train_loss:  526.1689470868273   time:  1.815077304840088
e:  9   train_loss:  505.8627673061469   time:  1.8024392127990723
e:  10   train_loss:  484.9530316695028   time:  1.7014153003692627
e:  10   train_loss:  484.9530316695028   val_loss:  1369.9081227847873   time:  1.8186407089233398
e:  11   train_loss:  466.52425401306346   time:  1.6819682121276855
e:  12   train_loss:  449.1631288492482   time:  1.7957262992858887
e:  13   train_loss:  440.02185561834153   time:  1.7533612251281738
e:  14   train_loss:  430.8898038343484   time:  1.8464269638061523
e:  15   train_loss:  427.6283140479386   time:  1.699256181716919
e:  15   train_loss:  427.6283140479386   val_loss:  1436.24928868968   time:  1.81247878074646
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  16   train_loss:  421.69735000146534   time:  1.8565881252288818
e:  17   train_loss:  419.4088266070179   time:  1.7683918476104736
e:  18   train_loss:  415.851389101648   time:  1.8174684047698975
e:  19   train_loss:  412.81174240881785   time:  1.8027565479278564
e:  20   train_loss:  409.7245763797035   time:  1.8247160911560059
e:  20   train_loss:  409.7245763797035   val_loss:  1421.996570687836   time:  1.9468128681182861
e:  21   train_loss:  409.7786892389425   time:  1.8109471797943115
e:  22   train_loss:  407.774397775904   time:  1.7964229583740234
e:  23   train_loss:  406.8007521063685   time:  1.7842912673950195
e:  24   train_loss:  405.32963686020366   time:  1.9820048809051514
e:  25   train_loss:  403.7364098675602   time:  1.7473905086517334
e:  25   train_loss:  403.7364098675602   val_loss:  1410.9227354239745   time:  1.8672208786010742
e:  26   train_loss:  399.396936273263   time:  1.7833468914031982
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1005.4590104124992   time:  1.8952100276947021
e:  0   train_loss:  1005.4590104124992   val_loss:  633.5103278849851   time:  2.008472442626953
e:  1   train_loss:  914.8809175207948   time:  1.9314548969268799
e:  2   train_loss:  884.3084785836377   time:  1.9265921115875244
e:  3   train_loss:  884.7471245912581   time:  1.9457218647003174
e:  4   train_loss:  857.7845847925644   time:  1.9011192321777344
e:  5   train_loss:  841.1087010820298   time:  1.9452531337738037
e:  5   train_loss:  841.1087010820298   val_loss:  562.5597302874684   time:  2.2486112117767334
e:  6   train_loss:  739.1442608036814   time:  1.9309120178222656
e:  7   train_loss:  686.6589260547961   time:  1.9529078006744385
e:  8   train_loss:  656.7677903776572   time:  1.8568947315216064
e:  9   train_loss:  643.7902277413301   time:  1.9286282062530518
e:  10   train_loss:  618.938982736818   time:  1.9442970752716064
e:  10   train_loss:  618.938982736818   val_loss:  673.6424383001053   time:  2.0569005012512207
e:  11   train_loss:  607.8962103578248   time:  1.9261853694915771
e:  12   train_loss:  595.6825839397897   time:  2.1162784099578857
e:  13   train_loss:  585.0743981467996   time:  1.9508349895477295
e:  14   train_loss:  570.2724675715721   time:  1.935523509979248
e:  15   train_loss:  566.3640077529104   time:  1.8201231956481934
e:  15   train_loss:  566.3640077529104   val_loss:  673.4061896980048   time:  1.9331629276275635
e:  16   train_loss:  566.9527638912173   time:  1.928318738937378
e:  17   train_loss:  554.2658066972003   time:  1.9528324604034424
e:  18   train_loss:  568.859703687075   time:  2.1877851486206055
e:  19   train_loss:  545.2841705686683   time:  1.9361042976379395
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  20   train_loss:  558.3739861398785   time:  1.9255998134613037
e:  20   train_loss:  558.3739861398785   val_loss:  717.1343087518035   time:  2.0370123386383057
e:  21   train_loss:  554.259116727671   time:  1.931565284729004
e:  22   train_loss:  559.058463725787   time:  1.9164190292358398
e:  23   train_loss:  549.5263032221796   time:  1.9414620399475098
e:  24   train_loss:  543.5878495062739   time:  1.956327199935913
e:  25   train_loss:  542.7657357874392   time:  2.1566355228424072
e:  25   train_loss:  542.7657357874392   val_loss:  664.314677244547   time:  2.268190622329712
e:  26   train_loss:  532.9188553925065   time:  1.9566233158111572
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1017.7999629272654   time:  1.9260802268981934
e:  0   train_loss:  1017.7999629272654   val_loss:  603.5873919042865   time:  2.0415685176849365
e:  1   train_loss:  956.1659442205707   time:  1.882540225982666
e:  2   train_loss:  894.3104455817526   time:  1.9106624126434326
e:  3   train_loss:  880.621815943222   time:  1.819904088973999
e:  4   train_loss:  871.7767750451111   time:  1.9075872898101807
e:  5   train_loss:  877.9813683513644   time:  2.1499533653259277
e:  5   train_loss:  877.9813683513644   val_loss:  488.212784226965   time:  2.2653136253356934
e:  6   train_loss:  783.705940622048   time:  1.8783643245697021
e:  7   train_loss:  723.095522424181   time:  1.935910940170288
e:  8   train_loss:  695.0719363651765   time:  1.9012141227722168
e:  9   train_loss:  670.6768172968655   time:  1.913123369216919
e:  10   train_loss:  659.241806125976   time:  1.8835086822509766
e:  10   train_loss:  659.241806125976   val_loss:  508.86559367480424   time:  1.9993433952331543
e:  11   train_loss:  655.7562429177938   time:  2.1649346351623535
e:  12   train_loss:  625.6932828378885   time:  1.9235832691192627
e:  13   train_loss:  627.4424160863357   time:  1.8634922504425049
e:  14   train_loss:  597.1247761743195   time:  1.864412784576416
e:  15   train_loss:  592.0934176528552   time:  1.9015512466430664
e:  15   train_loss:  592.0934176528552   val_loss:  493.63792864755663   time:  2.0185165405273438
e:  16   train_loss:  597.209417368171   time:  1.891535758972168
e:  17   train_loss:  594.8356950870524   time:  1.9010214805603027
e:  18   train_loss:  589.6510505075985   time:  1.8655428886413574
e:  19   train_loss:  576.7377873023229   time:  2.052276372909546
e:  20   train_loss:  591.0195474151163   time:  1.917529821395874
e:  20   train_loss:  591.0195474151163   val_loss:  494.2111675893619   time:  2.0343949794769287
e:  21   train_loss:  591.456082044076   time:  1.8850781917572021
e:  22   train_loss:  573.9255643991961   time:  1.8712384700775146
e:  23   train_loss:  558.5326188249772   time:  1.917802095413208
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  24   train_loss:  617.299320989368   time:  1.9033093452453613
e:  25   train_loss:  567.9800932157119   time:  1.910456895828247
e:  25   train_loss:  567.9800932157119   val_loss:  528.2483748774647   time:  2.025646448135376
e:  26   train_loss:  560.4786507894885   time:  1.922436237335205
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  935.539381677086   time:  1.8521203994750977
e:  0   train_loss:  935.539381677086   val_loss:  755.6336925210755   time:  1.97373628616333
e:  1   train_loss:  848.3407006382561   time:  1.7824580669403076
e:  2   train_loss:  833.0756964194549   time:  1.7920830249786377
e:  3   train_loss:  821.5342631532774   time:  1.8015286922454834
e:  4   train_loss:  809.0767959335412   time:  1.7836933135986328
e:  5   train_loss:  784.4391919855971   time:  1.8139867782592773
e:  5   train_loss:  784.4391919855971   val_loss:  723.2812998881818   time:  1.937941551208496
e:  6   train_loss:  736.553676371525   time:  1.8108997344970703
e:  7   train_loss:  690.4589053215728   time:  1.7133979797363281
e:  8   train_loss:  654.8936066129877   time:  1.7746214866638184
e:  9   train_loss:  634.4953235210942   time:  1.8112239837646484
e:  10   train_loss:  618.6804686966277   time:  1.7910163402557373
e:  10   train_loss:  618.6804686966277   val_loss:  707.3149319174091   time:  1.9127624034881592
e:  11   train_loss:  601.8604154432137   time:  2.0066606998443604
e:  12   train_loss:  591.5527548237377   time:  1.752974033355713
e:  13   train_loss:  579.5655874319621   time:  1.7716758251190186
e:  14   train_loss:  570.4844731160914   time:  1.7894988059997559
e:  15   train_loss:  559.37463716499   time:  1.7855994701385498
e:  15   train_loss:  559.37463716499   val_loss:  698.01570349269   time:  1.9062161445617676
e:  16   train_loss:  563.393600863835   time:  1.809999704360962
e:  17   train_loss:  545.3865898679219   time:  1.7951257228851318
e:  18   train_loss:  541.8539048632484   time:  1.783811092376709
e:  19   train_loss:  544.6855159266072   time:  1.78438138961792
e:  20   train_loss:  535.8470776129983   time:  1.7780537605285645
e:  20   train_loss:  535.8470776129983   val_loss:  721.2759322076731   time:  1.90159273147583
e:  21   train_loss:  532.5563869142745   time:  1.7886455059051514
e:  22   train_loss:  531.4946189194961   time:  1.8001537322998047
e:  23   train_loss:  530.1855818234271   time:  1.973503589630127
e:  24   train_loss:  525.9026585125316   time:  1.7284250259399414
e:  25   train_loss:  524.9173906541639   time:  1.7359428405761719
e:  25   train_loss:  524.9173906541639   val_loss:  713.978220289812   time:  1.8592989444732666
e:  26   train_loss:  525.5860884385125   time:  1.8091871738433838
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  991.8878764471683   time:  2.0180234909057617
e:  0   train_loss:  991.8878764471683   val_loss:  617.4319156191965   time:  2.132948875427246
e:  1   train_loss:  907.0847001583471   time:  1.9306221008300781
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  2   train_loss:  885.2378088286696   time:  1.8975121974945068
e:  3   train_loss:  880.4211295379158   time:  2.072296380996704
e:  4   train_loss:  863.3377369112781   time:  2.035430908203125
e:  5   train_loss:  789.3799409946804   time:  1.8524413108825684
e:  5   train_loss:  789.3799409946804   val_loss:  569.3356640741835   time:  1.9640569686889648
e:  6   train_loss:  737.0400883662355   time:  1.843719482421875
e:  7   train_loss:  680.3226256083765   time:  1.8927857875823975
e:  8   train_loss:  680.1291150887555   time:  1.8896703720092773
e:  9   train_loss:  646.3546667157563   time:  1.8880531787872314
e:  10   train_loss:  632.6974124883756   time:  2.0580267906188965
e:  10   train_loss:  632.6974124883756   val_loss:  585.6071615918095   time:  2.1703062057495117
e:  11   train_loss:  620.2223813397688   time:  1.874480962753296
e:  12   train_loss:  610.8358528462142   time:  1.7880465984344482
e:  13   train_loss:  610.226042794582   time:  1.8512613773345947
e:  14   train_loss:  611.7401591451503   time:  1.8495941162109375
e:  15   train_loss:  593.2977520132679   time:  1.8305246829986572
e:  15   train_loss:  593.2977520132679   val_loss:  587.6437311533665   time:  1.9411187171936035
e:  16   train_loss:  579.2283573969656   time:  1.817047119140625
e:  17   train_loss:  581.4525384149465   time:  2.063288688659668
e:  18   train_loss:  571.4583332509632   time:  1.8953871726989746
e:  19   train_loss:  573.0555336824482   time:  1.889991044998169
e:  20   train_loss:  578.3481312800822   time:  1.8904364109039307
e:  20   train_loss:  578.3481312800822   val_loss:  575.3982152629251   time:  2.002471685409546
e:  21   train_loss:  580.1603774725912   time:  1.8496661186218262
e:  22   train_loss:  577.3332862235188   time:  1.8799717426300049
e:  23   train_loss:  568.1917933718039   time:  1.8837614059448242
e:  24   train_loss:  565.0861344714665   time:  2.057302951812744
e:  25   train_loss:  564.8442072565244   time:  1.8792293071746826
e:  25   train_loss:  564.8442072565244   val_loss:  589.0059314676546   time:  1.990954875946045
e:  26   train_loss:  581.97827831133   time:  1.9014701843261719
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 25), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 25) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 25) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 25) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 25)
kwargs: {'config': {'batch_norm': False, 'ff_0': 21, 'ff_num_layers': 3, 'gnn_0': 958, 'gnn_dropout': 0.21542627652451324, 'gnn_num_layers': 2, 'hid_0': 1601, 'hid_dropout_rate': 0.4271126297116419, 'in_dropout_rate': 0.3095603548680177, 'lr': 0.00029072047003001915, 'num_hid_layers': 2, 'optimizer': 'Adam', 'ff_1': 1739, 'ff_2': 662, 'gnn_1': 120, 'hid_1': 1877}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 730.5458382076342, 'n_epochs': 27.0, 'info': {'validation loss': 730.5458382076342}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 25) started
DEBUG:hpbandster:job_callback for (0, 0, 25) got condition
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 25) finished
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 26) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 26) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 26)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 26) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 26) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 26)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 876, 'ff_num_layers': 2, 'gnn_0': 227, 'gnn_dropout': 0.49213520925025633, 'gnn_num_layers': 1, 'hid_0': 1532, 'hid_dropout_rate': 0.15679639657463124, 'in_dropout_rate': 0.39029146685469257, 'lr': 0.0025714843620315395, 'num_hid_layers': 1, 'optimizer': 'Adam', 'ff_1': 28}, 'budget': 27.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  615.0590054175277   time:  1.511502981185913
e:  0   train_loss:  615.0590054175277   val_loss:  1424.4298136468815   time:  1.6219456195831299
e:  1   train_loss:  539.4891776549708   time:  1.527554988861084
e:  2   train_loss:  496.88407464555803   time:  1.6584227085113525
e:  3   train_loss:  479.20228646226656   time:  1.643470287322998
e:  4   train_loss:  472.84642695852546   time:  1.6656455993652344
e:  5   train_loss:  457.2354788001946   time:  1.9083268642425537
e:  5   train_loss:  457.2354788001946   val_loss:  1435.9053973973607   time:  2.014061212539673
e:  6   train_loss:  453.4256981977747   time:  1.6628751754760742
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  7   train_loss:  444.4145897995995   time:  1.6189379692077637
e:  8   train_loss:  440.4064853195086   time:  1.5134174823760986
e:  9   train_loss:  435.1237851616983   time:  1.3422255516052246
e:  10   train_loss:  437.1849029808724   time:  1.5276849269866943
e:  10   train_loss:  437.1849029808724   val_loss:  1344.2051856718083   time:  1.6407482624053955
e:  11   train_loss:  429.07188256193064   time:  1.592500925064087
e:  12   train_loss:  425.58474034159906   time:  1.6203677654266357
e:  13   train_loss:  423.055047500528   time:  1.5724472999572754
e:  14   train_loss:  422.4664701381033   time:  1.5651566982269287
e:  15   train_loss:  416.7001902456411   time:  1.7394263744354248
e:  15   train_loss:  416.7001902456411   val_loss:  1319.055261497215   time:  1.8444476127624512
e:  16   train_loss:  418.37027485564556   time:  1.6012496948242188
e:  17   train_loss:  414.4371820741923   time:  1.608752727508545
e:  18   train_loss:  413.7339031165516   time:  1.6024863719940186
e:  19   train_loss:  410.9470324356149   time:  1.5544147491455078
e:  20   train_loss:  410.9499128559905   time:  1.779353141784668
e:  20   train_loss:  410.9499128559905   val_loss:  1319.0758159727409   time:  1.8847928047180176
e:  21   train_loss:  410.1774783397768   time:  1.6038143634796143
e:  22   train_loss:  407.66969030518266   time:  1.5970699787139893
e:  23   train_loss:  404.72722889791874   time:  1.573164701461792
e:  24   train_loss:  399.95534756087466   time:  1.8650932312011719
e:  25   train_loss:  394.1811297906526   time:  1.5570883750915527
e:  25   train_loss:  394.1811297906526   val_loss:  1306.2699451103194   time:  1.6696925163269043
e:  26   train_loss:  390.1783088462411   time:  1.604506492614746
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  919.840374935105   time:  1.7474942207336426
e:  0   train_loss:  919.840374935105   val_loss:  553.8296441100747   time:  1.8526279926300049
e:  1   train_loss:  715.7938034134557   time:  1.7613277435302734
e:  2   train_loss:  651.6523504496316   time:  1.731903314590454
e:  3   train_loss:  653.1869026789207   time:  1.700977087020874
e:  4   train_loss:  635.2108581403022   time:  1.764376163482666
e:  5   train_loss:  627.7127587427377   time:  1.6374483108520508
e:  5   train_loss:  627.7127587427377   val_loss:  567.8684815744017   time:  1.7438182830810547
e:  6   train_loss:  611.097973457979   time:  1.6404869556427002
e:  7   train_loss:  615.9338641078126   time:  1.644545078277588
e:  8   train_loss:  590.6888732002548   time:  1.718445062637329
e:  9   train_loss:  573.79221263861   time:  1.6286084651947021
e:  10   train_loss:  579.6989543945964   time:  1.5695641040802002
e:  10   train_loss:  579.6989543945964   val_loss:  686.8002323350653   time:  1.803553819656372
e:  11   train_loss:  574.471506363559   time:  1.6399321556091309
e:  12   train_loss:  581.6815311857262   time:  1.6960530281066895
e:  13   train_loss:  558.514699633591   time:  1.6547608375549316
e:  14   train_loss:  572.9103669839116   time:  1.6396822929382324
e:  15   train_loss:  564.4397011225033   time:  1.641479253768921
e:  15   train_loss:  564.4397011225033   val_loss:  675.0430157080041   time:  1.7472057342529297
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  16   train_loss:  553.8003945345724   time:  1.637712001800537
e:  17   train_loss:  559.076024462337   time:  1.6430573463439941
e:  18   train_loss:  551.6422939374766   time:  1.6397812366485596
e:  19   train_loss:  546.1540463216967   time:  1.770733118057251
e:  20   train_loss:  558.430502383228   time:  1.6341922283172607
e:  20   train_loss:  558.430502383228   val_loss:  898.8503773682761   time:  1.739121913909912
e:  21   train_loss:  539.269959456378   time:  1.6078262329101562
e:  22   train_loss:  542.7250618888288   time:  1.6388654708862305
e:  23   train_loss:  542.9790341826296   time:  1.642099380493164
e:  24   train_loss:  542.7125466609829   time:  1.6427223682403564
e:  25   train_loss:  551.3403438354495   time:  1.7925989627838135
e:  25   train_loss:  551.3403438354495   val_loss:  884.7900359258789   time:  1.8993165493011475
e:  26   train_loss:  531.6932720685068   time:  1.6401820182800293
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  929.7194078300131   time:  1.5914640426635742
e:  0   train_loss:  929.7194078300131   val_loss:  490.45608204943267   time:  1.6996800899505615
e:  1   train_loss:  734.3093885139053   time:  1.563002109527588
e:  2   train_loss:  690.7539099594459   time:  1.6188395023345947
e:  3   train_loss:  648.9983492379846   time:  1.7726337909698486
e:  4   train_loss:  652.8496520349838   time:  1.6186401844024658
e:  5   train_loss:  654.4834909247988   time:  1.619795322418213
e:  5   train_loss:  654.4834909247988   val_loss:  480.5847888345977   time:  1.7286720275878906
e:  6   train_loss:  613.380051366125   time:  1.6171817779541016
e:  7   train_loss:  616.5803392384084   time:  1.6195194721221924
e:  8   train_loss:  601.5569179356594   time:  1.6205990314483643
e:  9   train_loss:  589.5035231613882   time:  1.6232149600982666
e:  10   train_loss:  599.3760151568025   time:  1.621204137802124
e:  10   train_loss:  599.3760151568025   val_loss:  618.825643987008   time:  1.7306022644042969
e:  11   train_loss:  607.974375709791   time:  1.7540004253387451
e:  12   train_loss:  605.2057615666807   time:  1.6165175437927246
e:  13   train_loss:  612.3628412280547   time:  1.6229217052459717
e:  14   train_loss:  615.4678644966637   time:  1.6229772567749023
e:  15   train_loss:  596.2953613025418   time:  1.6274042129516602
e:  15   train_loss:  596.2953613025418   val_loss:  475.26272462782833   time:  1.7370975017547607
e:  16   train_loss:  600.856989503329   time:  1.6215672492980957
e:  17   train_loss:  603.5807520530793   time:  1.6246075630187988
e:  18   train_loss:  598.5582636313297   time:  1.593747615814209
e:  19   train_loss:  579.471546330989   time:  1.6944873332977295
e:  20   train_loss:  621.0436422940629   time:  1.623915433883667
e:  20   train_loss:  621.0436422940629   val_loss:  534.5872518991097   time:  1.7331020832061768
e:  21   train_loss:  587.7038991138456   time:  1.6211824417114258
e:  22   train_loss:  601.112729123653   time:  1.622436285018921
e:  23   train_loss:  589.2124368352231   time:  1.6217386722564697
e:  24   train_loss:  579.3621950390009   time:  1.6182959079742432
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  25   train_loss:  578.6588485395843   time:  1.6220276355743408
e:  25   train_loss:  578.6588485395843   val_loss:  665.2672665881495   time:  1.8528220653533936
e:  26   train_loss:  598.317941006729   time:  1.6238000392913818
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  873.9736052026991   time:  1.4936575889587402
e:  0   train_loss:  873.9736052026991   val_loss:  738.7121105088398   time:  1.6087510585784912
e:  1   train_loss:  737.0990275760427   time:  1.511490821838379
e:  2   train_loss:  652.2593438513259   time:  1.5112824440002441
e:  3   train_loss:  614.1399443705715   time:  1.5088796615600586
e:  4   train_loss:  614.3810288972637   time:  1.5081532001495361
e:  5   train_loss:  586.6686574421562   time:  1.5128233432769775
e:  5   train_loss:  586.6686574421562   val_loss:  710.1639095298891   time:  1.6285719871520996
e:  6   train_loss:  576.1360504930796   time:  1.5101239681243896
e:  7   train_loss:  569.6272432652797   time:  1.5117273330688477
e:  8   train_loss:  565.6362203639953   time:  1.5083303451538086
e:  9   train_loss:  552.4312255128506   time:  1.631413221359253
e:  10   train_loss:  551.5873601473772   time:  1.4425318241119385
e:  10   train_loss:  551.5873601473772   val_loss:  760.2930085239049   time:  1.5560932159423828
e:  11   train_loss:  560.9523567988821   time:  1.4819328784942627
e:  12   train_loss:  552.8040011353476   time:  1.5106875896453857
e:  13   train_loss:  542.1011632554079   time:  1.5087995529174805
e:  14   train_loss:  543.6152396486482   time:  1.5097897052764893
e:  15   train_loss:  539.9902160029803   time:  1.5092394351959229
e:  15   train_loss:  539.9902160029803   val_loss:  717.1651346258791   time:  1.6233506202697754
e:  16   train_loss:  544.1330014951147   time:  1.5097606182098389
e:  17   train_loss:  532.3234100622917   time:  1.5086705684661865
e:  18   train_loss:  534.853595817274   time:  1.506812572479248
e:  19   train_loss:  535.056353854802   time:  1.5092263221740723
e:  20   train_loss:  540.686785986753   time:  1.5050742626190186
e:  20   train_loss:  540.686785986753   val_loss:  714.5636085080702   time:  1.6198170185089111
e:  21   train_loss:  536.3004516746231   time:  1.5072665214538574
e:  22   train_loss:  532.8476757122186   time:  1.5084989070892334
e:  23   train_loss:  526.3800241626207   time:  1.6227984428405762
e:  24   train_loss:  521.3681459665875   time:  1.5090875625610352
e:  25   train_loss:  530.8559658659491   time:  1.5059468746185303
e:  25   train_loss:  530.8559658659491   val_loss:  705.464570990079   time:  1.6206719875335693
e:  26   train_loss:  523.84817654929   time:  1.509321928024292
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  915.2765315056365   time:  1.6442937850952148
e:  0   train_loss:  915.2765315056365   val_loss:  554.6202314267096   time:  1.752089262008667
e:  1   train_loss:  751.2395963271852   time:  1.6403021812438965
e:  2   train_loss:  672.8063767260991   time:  1.5973014831542969
e:  3   train_loss:  658.1073756578666   time:  1.7383675575256348
e:  4   train_loss:  653.1147050202195   time:  1.6430723667144775
e:  5   train_loss:  629.6805285428452   time:  1.6411182880401611
e:  5   train_loss:  629.6805285428452   val_loss:  583.6561404475988   time:  1.748579740524292
e:  6   train_loss:  604.0499133272875   time:  1.6406571865081787
e:  7   train_loss:  605.8049054775113   time:  1.6408352851867676
e:  8   train_loss:  610.3359405136591   time:  1.6428828239440918
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  9   train_loss:  594.1377638936816   time:  1.645526647567749
e:  10   train_loss:  596.8220481937691   time:  1.7735884189605713
e:  10   train_loss:  596.8220481937691   val_loss:  670.8961431366441   time:  1.8810722827911377
e:  11   train_loss:  589.8933132291919   time:  1.6374754905700684
e:  12   train_loss:  601.9047376236456   time:  1.6410048007965088
e:  13   train_loss:  605.2639167274627   time:  1.6407911777496338
e:  14   train_loss:  578.7269280569122   time:  1.6464838981628418
e:  15   train_loss:  585.3671998814293   time:  1.646251916885376
e:  15   train_loss:  585.3671998814293   val_loss:  615.6806288059618   time:  1.7546460628509521
e:  16   train_loss:  585.4995361605847   time:  1.670175552368164
e:  17   train_loss:  575.8429610687595   time:  1.7841508388519287
e:  18   train_loss:  579.1374817750016   time:  1.6464831829071045
e:  19   train_loss:  586.0325409141988   time:  1.6443004608154297
e:  20   train_loss:  579.776174385393   time:  1.5926010608673096
e:  20   train_loss:  579.776174385393   val_loss:  660.6849315090197   time:  1.6993794441223145
e:  21   train_loss:  571.2683992034849   time:  1.6132521629333496
e:  22   train_loss:  578.6330716784786   time:  1.6458244323730469
e:  23   train_loss:  571.4170240967064   time:  1.766946792602539
e:  24   train_loss:  563.8248219932653   time:  1.640143632888794
e:  25   train_loss:  559.7447377817886   time:  1.6138005256652832
e:  25   train_loss:  559.7447377817886   val_loss:  672.2973476612501   time:  1.7214696407318115
e:  26   train_loss:  555.9136949047453   time:  1.6405768394470215
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 26), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 26) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 26) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 26) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 26)
kwargs: {'config': {'batch_norm': True, 'ff_0': 876, 'ff_num_layers': 2, 'gnn_0': 227, 'gnn_dropout': 0.49213520925025633, 'gnn_num_layers': 1, 'hid_0': 1532, 'hid_dropout_rate': 0.15679639657463124, 'in_dropout_rate': 0.39029146685469257, 'lr': 0.0025714843620315395, 'num_hid_layers': 1, 'optimizer': 'Adam', 'ff_1': 28}, 'budget': 27.0, 'working_directory': '.'}
result: {'loss': 719.0894232530021, 'n_epochs': 27.0, 'info': {'validation loss': 719.0894232530021}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 26) started
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:job_callback for (0, 0, 26) got condition
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 26) finished
DEBUG:hpbandster:ITERATION: Advancing config (0, 0, 2) to next budget 81.000000
DEBUG:hpbandster:ITERATION: Advancing config (0, 0, 10) to next budget 81.000000
DEBUG:hpbandster:ITERATION: Advancing config (0, 0, 14) to next budget 81.000000
DEBUG:hpbandster:ITERATION: Advancing config (0, 0, 15) to next budget 81.000000
DEBUG:hpbandster:ITERATION: Advancing config (0, 0, 16) to next budget 81.000000
DEBUG:hpbandster:ITERATION: Advancing config (0, 0, 21) to next budget 81.000000
DEBUG:hpbandster:ITERATION: Advancing config (0, 0, 22) to next budget 81.000000
DEBUG:hpbandster:ITERATION: Advancing config (0, 0, 25) to next budget 81.000000
DEBUG:hpbandster:ITERATION: Advancing config (0, 0, 26) to next budget 81.000000
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 2) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 2) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 2)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 2) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 2) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 2)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 334, 'ff_num_layers': 1, 'gnn_0': 115, 'gnn_dropout': 0.36093280378861975, 'gnn_num_layers': 3, 'hid_0': 287, 'hid_dropout_rate': 0.4106022389610257, 'in_dropout_rate': 0.159431981485876, 'lr': 0.0027433667469244786, 'num_hid_layers': 1, 'optimizer': 'Adam', 'gnn_1': 223, 'gnn_2': 306}, 'budget': 81.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  632.53178383055   time:  1.328587293624878
e:  0   train_loss:  632.53178383055   val_loss:  1436.614605865116   time:  1.438173770904541
e:  1   train_loss:  593.7582197404317   time:  1.3437070846557617
e:  2   train_loss:  585.4978158323231   time:  1.5363688468933105
e:  3   train_loss:  575.8386343061318   time:  1.323063850402832
e:  4   train_loss:  564.180329324281   time:  1.3330743312835693
e:  5   train_loss:  550.7136995051108   time:  1.3343572616577148
e:  5   train_loss:  550.7136995051108   val_loss:  1385.9396965066815   time:  1.4436025619506836
e:  6   train_loss:  532.1901538218804   time:  1.332529067993164
e:  7   train_loss:  515.0752559821508   time:  1.3396549224853516
e:  8   train_loss:  498.82919146555867   time:  1.3357489109039307
e:  9   train_loss:  485.4803713921408   time:  1.3277018070220947
e:  10   train_loss:  469.77002991461273   time:  1.3400640487670898
e:  10   train_loss:  469.77002991461273   val_loss:  1401.3169606658514   time:  1.4491767883300781
e:  11   train_loss:  455.12293669238215   time:  1.3362386226654053
e:  12   train_loss:  445.82213400898456   time:  1.3404130935668945
e:  13   train_loss:  442.15584526955274   time:  1.516538381576538
e:  14   train_loss:  431.3129861086786   time:  1.3226039409637451
e:  15   train_loss:  426.4596949804615   time:  1.3359098434448242
e:  15   train_loss:  426.4596949804615   val_loss:  1411.5950383648644   time:  1.4445006847381592
e:  16   train_loss:  422.3713037320201   time:  1.3390247821807861
e:  17   train_loss:  419.5862722480269   time:  1.3377387523651123
e:  18   train_loss:  417.2620538281679   time:  1.3321762084960938
e:  19   train_loss:  416.5743537607186   time:  1.3380157947540283
e:  20   train_loss:  414.50830659278455   time:  1.3351349830627441
e:  20   train_loss:  414.50830659278455   val_loss:  1424.8228894712247   time:  1.4445068836212158
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  21   train_loss:  412.26880826565423   time:  1.3416476249694824
e:  22   train_loss:  414.5008916292899   time:  1.4957818984985352
e:  23   train_loss:  410.64760760165893   time:  1.2496998310089111
e:  24   train_loss:  410.7903957825159   time:  1.3194875717163086
e:  25   train_loss:  411.1807175861502   time:  1.2646751403808594
e:  25   train_loss:  411.1807175861502   val_loss:  1426.8773521841808   time:  1.3749585151672363
e:  26   train_loss:  411.81520068482047   time:  1.2754080295562744
e:  27   train_loss:  409.36868606745935   time:  1.2766199111938477
e:  28   train_loss:  407.26401251581336   time:  1.2653601169586182
e:  29   train_loss:  406.81856320295515   time:  1.2733652591705322
e:  30   train_loss:  405.3647910199502   time:  1.3767857551574707
e:  30   train_loss:  405.3647910199502   val_loss:  1430.09354598617   time:  1.486159086227417
e:  31   train_loss:  405.4297112075086   time:  1.3422977924346924
e:  32   train_loss:  404.8539748586388   time:  1.3486473560333252
e:  33   train_loss:  403.7981106267265   time:  1.5132527351379395
e:  34   train_loss:  403.0360458448978   time:  1.2658185958862305
e:  35   train_loss:  401.8371867021683   time:  1.361835241317749
e:  35   train_loss:  401.8371867021683   val_loss:  1421.3268170196613   time:  1.4699687957763672
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  940.3472467642054   time:  1.413447618484497
e:  0   train_loss:  940.3472467642054   val_loss:  542.8859224306931   time:  1.520294189453125
e:  1   train_loss:  873.9591246103215   time:  1.493828296661377
e:  2   train_loss:  795.8780435279314   time:  1.5011637210845947
e:  3   train_loss:  726.4085153007547   time:  1.4505338668823242
e:  4   train_loss:  721.9590263410236   time:  1.4547498226165771
e:  5   train_loss:  708.6065127109173   time:  1.4462735652923584
e:  5   train_loss:  708.6065127109173   val_loss:  810.6186719038795   time:  1.720440149307251
e:  6   train_loss:  684.4051128283983   time:  1.4644615650177002
e:  7   train_loss:  662.3080943180325   time:  1.456700325012207
e:  8   train_loss:  638.4808402724019   time:  1.4555790424346924
e:  9   train_loss:  623.120277935156   time:  1.446146011352539
e:  10   train_loss:  609.3068605889696   time:  1.3925423622131348
e:  10   train_loss:  609.3068605889696   val_loss:  655.8863732529115   time:  1.4951081275939941
e:  11   train_loss:  595.1845422778115   time:  1.3890984058380127
e:  12   train_loss:  587.8739218879736   time:  1.5362398624420166
e:  13   train_loss:  580.7723579040066   time:  1.3953087329864502
e:  14   train_loss:  584.992830454747   time:  1.3958752155303955
e:  15   train_loss:  575.1710498787144   time:  1.3944611549377441
e:  15   train_loss:  575.1710498787144   val_loss:  678.459059019762   time:  1.498490333557129
e:  16   train_loss:  570.8641477038072   time:  1.3913841247558594
e:  17   train_loss:  559.2103000954298   time:  1.3962585926055908
e:  18   train_loss:  555.5647910413735   time:  1.5302140712738037
e:  19   train_loss:  560.816506522598   time:  1.3936748504638672
e:  20   train_loss:  549.6912613225556   time:  1.362217664718628
e:  20   train_loss:  549.6912613225556   val_loss:  661.8882674870778   time:  1.4653007984161377
e:  21   train_loss:  554.8871876114886   time:  1.4198615550994873
e:  22   train_loss:  557.8925578451626   time:  1.4086627960205078
e:  23   train_loss:  549.2611764461824   time:  1.433220386505127
e:  24   train_loss:  543.4356006064091   time:  1.4303059577941895
e:  25   train_loss:  557.38782071727   time:  1.6030011177062988
e:  25   train_loss:  557.38782071727   val_loss:  679.1768001999313   time:  1.7052152156829834
e:  26   train_loss:  549.3487955616007   time:  1.4255764484405518
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  27   train_loss:  542.4208285555247   time:  1.4702889919281006
e:  28   train_loss:  544.736050102658   time:  1.419846773147583
e:  29   train_loss:  548.4466083977968   time:  1.511345386505127
e:  30   train_loss:  549.903186016324   time:  1.3921701908111572
e:  30   train_loss:  549.903186016324   val_loss:  687.689222175314   time:  1.495837926864624
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  956.3451597240435   time:  1.5093376636505127
e:  0   train_loss:  956.3451597240435   val_loss:  476.83550534178414   time:  1.6151719093322754
e:  1   train_loss:  913.9862846982022   time:  1.374746322631836
e:  2   train_loss:  833.2237740811418   time:  1.373363733291626
e:  3   train_loss:  785.3301762202515   time:  1.3753588199615479
e:  4   train_loss:  759.9005699992583   time:  1.372847557067871
e:  5   train_loss:  731.0131297341544   time:  1.3742892742156982
e:  5   train_loss:  731.0131297341544   val_loss:  492.2932175083248   time:  1.4794921875
e:  6   train_loss:  736.3769307497224   time:  1.3748455047607422
e:  7   train_loss:  718.1700680006634   time:  1.4942209720611572
e:  8   train_loss:  689.970210093156   time:  1.373398780822754
e:  9   train_loss:  681.807912856741   time:  1.3652679920196533
e:  10   train_loss:  653.3184784705974   time:  1.3562932014465332
e:  10   train_loss:  653.3184784705974   val_loss:  473.36911854762167   time:  1.4628384113311768
e:  11   train_loss:  674.2421591129194   time:  1.3752000331878662
e:  12   train_loss:  677.9650057152583   time:  1.3633346557617188
e:  13   train_loss:  656.1982375019294   time:  1.3654475212097168
e:  14   train_loss:  620.8969194712539   time:  1.3721816539764404
e:  15   train_loss:  596.168291025838   time:  1.5109052658081055
e:  15   train_loss:  596.168291025838   val_loss:  469.6762172692239   time:  1.6172447204589844
e:  16   train_loss:  653.55780921622   time:  1.3725550174713135
e:  17   train_loss:  603.2595448447232   time:  1.3769302368164062
e:  18   train_loss:  614.7948130886757   time:  1.3764827251434326
e:  19   train_loss:  593.6864548393297   time:  1.373805284500122
e:  20   train_loss:  579.4306958453465   time:  1.3722777366638184
e:  20   train_loss:  579.4306958453465   val_loss:  469.25122264762535   time:  1.4777698516845703
e:  21   train_loss:  584.8348635233034   time:  1.5087988376617432
e:  22   train_loss:  579.2022588600768   time:  1.362372875213623
e:  23   train_loss:  588.6973003154006   time:  1.3727085590362549
e:  24   train_loss:  580.6480958051701   time:  1.3749454021453857
e:  25   train_loss:  579.4488428592005   time:  1.3760120868682861
e:  25   train_loss:  579.4488428592005   val_loss:  510.0329393923031   time:  1.4820966720581055
e:  26   train_loss:  588.2036872402862   time:  1.377509355545044
e:  27   train_loss:  574.7262828502978   time:  1.3716557025909424
e:  28   train_loss:  582.7580188458458   time:  1.3634076118469238
e:  29   train_loss:  562.8316482847314   time:  1.4868557453155518
e:  30   train_loss:  570.6180176958876   time:  1.3712191581726074
e:  30   train_loss:  570.6180176958876   val_loss:  530.4306196712403   time:  1.4767439365386963
e:  31   train_loss:  597.1876377567195   time:  1.3548293113708496
e:  32   train_loss:  578.7597407908752   time:  1.3636789321899414
e:  33   train_loss:  579.3686256158342   time:  1.371722936630249
e:  34   train_loss:  581.1740755495971   time:  1.3760225772857666
e:  35   train_loss:  575.3558254456852   time:  1.3723363876342773
e:  35   train_loss:  575.3558254456852   val_loss:  542.1792816347671   time:  1.4782452583312988
e:  36   train_loss:  589.3212620370787   time:  1.3728361129760742
e:  37   train_loss:  564.8282342432225   time:  1.507533311843872
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  38   train_loss:  563.5188570798364   time:  1.3690659999847412
e:  39   train_loss:  570.9362862849465   time:  1.3701858520507812
e:  40   train_loss:  575.1663547229323   time:  1.3752460479736328
e:  40   train_loss:  575.1663547229323   val_loss:  513.2779251506214   time:  1.4803683757781982
e:  41   train_loss:  585.2874055760567   time:  1.383770227432251
e:  42   train_loss:  566.8780786574354   time:  1.3651573657989502
e:  43   train_loss:  605.907552770473   time:  1.373070478439331
e:  44   train_loss:  575.1325946195841   time:  1.507605791091919
e:  45   train_loss:  607.3500325762275   time:  1.3792579174041748
e:  45   train_loss:  607.3500325762275   val_loss:  577.9625621082031   time:  1.4850995540618896
e:  46   train_loss:  574.7621634227157   time:  1.3764288425445557
e:  47   train_loss:  563.5460352555658   time:  1.3700499534606934
e:  48   train_loss:  594.6642565589076   time:  1.3699121475219727
e:  49   train_loss:  576.7656258639179   time:  1.3720521926879883
e:  50   train_loss:  570.9326480546382   time:  1.3625473976135254
e:  50   train_loss:  570.9326480546382   val_loss:  513.6625568013557   time:  1.4681832790374756
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  888.0563165811619   time:  1.2548880577087402
e:  0   train_loss:  888.0563165811619   val_loss:  746.1307456507957   time:  1.489574670791626
e:  1   train_loss:  825.3680671549961   time:  1.2469589710235596
e:  2   train_loss:  779.4225236548858   time:  1.2557110786437988
e:  3   train_loss:  722.6988724696539   time:  1.2721428871154785
e:  4   train_loss:  679.1443029721219   time:  1.2662549018859863
e:  5   train_loss:  663.6811751623325   time:  1.2643218040466309
e:  5   train_loss:  663.6811751623325   val_loss:  732.8060860720287   time:  1.3751747608184814
e:  6   train_loss:  662.37065625672   time:  1.2677514553070068
e:  7   train_loss:  641.265937462364   time:  1.2677762508392334
e:  8   train_loss:  620.9200750909047   time:  1.2593262195587158
e:  9   train_loss:  612.0443459450325   time:  1.3870105743408203
e:  10   train_loss:  600.1798152248015   time:  1.267817497253418
e:  10   train_loss:  600.1798152248015   val_loss:  722.1932905594159   time:  1.3780238628387451
e:  11   train_loss:  593.2722294455307   time:  1.2681326866149902
e:  12   train_loss:  580.7435456824265   time:  1.2682137489318848
e:  13   train_loss:  569.5173614164937   time:  1.2579214572906494
e:  14   train_loss:  563.0919899819895   time:  1.269428014755249
e:  15   train_loss:  561.5531945101242   time:  1.2640013694763184
e:  15   train_loss:  561.5531945101242   val_loss:  714.0343363248924   time:  1.3737413883209229
e:  16   train_loss:  554.1638903551392   time:  1.2676467895507812
e:  17   train_loss:  561.5652630385914   time:  1.2602839469909668
e:  18   train_loss:  545.5945187342242   time:  1.3881216049194336
e:  19   train_loss:  539.7892744455837   time:  1.2657256126403809
e:  20   train_loss:  540.0292747212884   time:  1.2644412517547607
e:  20   train_loss:  540.0292747212884   val_loss:  711.0859840797389   time:  1.3745574951171875
e:  21   train_loss:  534.3168096319304   time:  1.2608225345611572
e:  22   train_loss:  534.117739094557   time:  1.2814080715179443
e:  23   train_loss:  529.747586690366   time:  1.2576851844787598
e:  24   train_loss:  537.0339556182153   time:  1.248150110244751
e:  25   train_loss:  531.2540028567083   time:  1.2593591213226318
e:  25   train_loss:  531.2540028567083   val_loss:  723.6739076985704   time:  1.3696978092193604
e:  26   train_loss:  532.9598286417206   time:  1.265622854232788
e:  27   train_loss:  535.2387735570343   time:  1.2685904502868652
e:  28   train_loss:  527.7837699585414   time:  1.2692501544952393
e:  29   train_loss:  530.8191334470181   time:  1.2680199146270752
e:  30   train_loss:  529.2694234495489   time:  1.2664835453033447
e:  30   train_loss:  529.2694234495489   val_loss:  720.0427718749961   time:  1.5027074813842773
e:  31   train_loss:  532.7387412703158   time:  1.2679152488708496
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  32   train_loss:  529.6180799632214   time:  1.2697956562042236
e:  33   train_loss:  527.7870577788775   time:  1.266113519668579
e:  34   train_loss:  526.1973182954309   time:  1.2643182277679443
e:  35   train_loss:  531.4003617773756   time:  1.2645747661590576
e:  35   train_loss:  531.4003617773756   val_loss:  711.208702138825   time:  1.3750479221343994
e:  36   train_loss:  530.1854488078122   time:  1.2684910297393799
e:  37   train_loss:  527.4647027876217   time:  1.2674250602722168
e:  38   train_loss:  527.4397520064401   time:  1.2670528888702393
e:  39   train_loss:  524.2734173757934   time:  1.3900468349456787
e:  40   train_loss:  524.53149387121   time:  1.2530715465545654
e:  40   train_loss:  524.53149387121   val_loss:  731.9390773506375   time:  1.3547494411468506
e:  41   train_loss:  523.0297818774769   time:  1.2678875923156738
e:  42   train_loss:  523.1828515574961   time:  1.266786813735962
e:  43   train_loss:  527.4379418889298   time:  1.2649173736572266
e:  44   train_loss:  525.5108184190539   time:  1.2657887935638428
e:  45   train_loss:  520.3703679319411   time:  1.2663533687591553
e:  45   train_loss:  520.3703679319411   val_loss:  722.0894580479321   time:  1.3760299682617188
e:  46   train_loss:  520.4526354851454   time:  1.2711834907531738
e:  47   train_loss:  518.8254362769345   time:  1.2409234046936035
e:  48   train_loss:  516.1131495972775   time:  1.250891923904419
e:  49   train_loss:  517.9796340231205   time:  1.2577428817749023
e:  50   train_loss:  515.0763821614149   time:  1.3892486095428467
e:  50   train_loss:  515.0763821614149   val_loss:  724.9533716700455   time:  1.4994792938232422
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  937.4409073899408   time:  1.3874866962432861
e:  0   train_loss:  937.4409073899408   val_loss:  554.6646263936872   time:  1.492116928100586
e:  1   train_loss:  869.5678723203886   time:  1.3882312774658203
e:  2   train_loss:  813.9607161967322   time:  1.387742042541504
e:  3   train_loss:  742.438639150861   time:  1.382098913192749
e:  4   train_loss:  708.5795360008407   time:  1.3868141174316406
e:  5   train_loss:  701.0889592683504   time:  1.5177443027496338
e:  5   train_loss:  701.0889592683504   val_loss:  561.9160801701028   time:  1.6215436458587646
e:  6   train_loss:  666.9113638914721   time:  1.4016337394714355
e:  7   train_loss:  659.1758627266504   time:  1.3835527896881104
e:  8   train_loss:  648.4436440728351   time:  1.3741354942321777
e:  9   train_loss:  630.5943074960066   time:  1.3844115734100342
e:  10   train_loss:  615.9898974703111   time:  1.3845715522766113
e:  10   train_loss:  615.9898974703111   val_loss:  560.0978329695756   time:  1.4885272979736328
e:  11   train_loss:  614.0274021534625   time:  1.3962960243225098
e:  12   train_loss:  628.2742936508788   time:  1.519859790802002
e:  13   train_loss:  633.1268690295316   time:  1.3854947090148926
e:  14   train_loss:  616.4767899918368   time:  1.3824963569641113
e:  15   train_loss:  607.6728732361902   time:  1.3822224140167236
e:  15   train_loss:  607.6728732361902   val_loss:  562.6976752913315   time:  1.4860782623291016
e:  16   train_loss:  584.0426132509118   time:  1.380476474761963
e:  17   train_loss:  586.3850316092407   time:  1.3610825538635254
e:  18   train_loss:  584.6588224429149   time:  1.3564982414245605
e:  19   train_loss:  590.5461268558139   time:  1.512981653213501
e:  20   train_loss:  581.1502657106881   time:  1.3735311031341553
e:  20   train_loss:  581.1502657106881   val_loss:  568.131354507048   time:  1.476776361465454
e:  21   train_loss:  580.7641825271452   time:  1.3850605487823486
e:  22   train_loss:  579.735108890466   time:  1.3825502395629883
e:  23   train_loss:  582.0570702113085   time:  1.377310037612915
e:  24   train_loss:  586.2600969609634   time:  1.3723559379577637
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  25   train_loss:  575.7797739019102   time:  1.428271770477295
e:  25   train_loss:  575.7797739019102   val_loss:  583.0925121304089   time:  1.5343530178070068
e:  26   train_loss:  571.4053967635388   time:  1.6230220794677734
e:  27   train_loss:  578.8151930058126   time:  1.3847732543945312
e:  28   train_loss:  566.4518122112422   time:  1.386934518814087
e:  29   train_loss:  575.6572354014083   time:  1.3876912593841553
e:  30   train_loss:  574.6034002462558   time:  1.3849916458129883
e:  30   train_loss:  574.6034002462558   val_loss:  562.8159511658033   time:  1.4893736839294434
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 2), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 2) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 2) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 2) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 2)
kwargs: {'config': {'batch_norm': False, 'ff_0': 334, 'ff_num_layers': 1, 'gnn_0': 115, 'gnn_dropout': 0.36093280378861975, 'gnn_num_layers': 3, 'hid_0': 287, 'hid_dropout_rate': 0.4106022389610257, 'in_dropout_rate': 0.159431981485876, 'lr': 0.0027433667469244786, 'num_hid_layers': 1, 'optimizer': 'Adam', 'gnn_1': 223, 'gnn_2': 306}, 'budget': 81.0, 'working_directory': '.'}
result: {'loss': 732.7654904116852, 'n_epochs': 39.0, 'info': {'validation loss': 732.7654904116852}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 2) started
DEBUG:hpbandster:job_callback for (0, 0, 2) got condition
DEBUG:hpbandster:Only 1 run(s) for budget 81.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 2) finished
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 10) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 10) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 10)
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 10) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 10) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 10)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 39, 'ff_num_layers': 2, 'gnn_0': 71, 'gnn_dropout': 0.4680205928046692, 'gnn_num_layers': 2, 'hid_0': 253, 'hid_dropout_rate': 0.33231583631114886, 'in_dropout_rate': 0.4318697065068356, 'lr': 0.00790707314326263, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 235, 'gnn_1': 488, 'hid_1': 215, 'hid_2': 1034}, 'budget': 81.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  942.8750672404428   time:  1.3233718872070312
e:  0   train_loss:  942.8750672404428   val_loss:  1669.4306994065328   time:  1.4321815967559814
e:  1   train_loss:  686.1119110132446   time:  1.3351531028747559
e:  2   train_loss:  641.6447077833922   time:  1.5924468040466309
e:  3   train_loss:  605.1279487204147   time:  1.3338253498077393
e:  4   train_loss:  569.1540226219345   time:  1.3807647228240967
e:  5   train_loss:  549.6823869108915   time:  1.3398280143737793
e:  5   train_loss:  549.6823869108915   val_loss:  1492.6403710867296   time:  1.4508388042449951
e:  6   train_loss:  542.4676190623845   time:  1.337261438369751
e:  7   train_loss:  534.9694117898413   time:  1.329988718032837
e:  8   train_loss:  522.4665723602762   time:  1.3592007160186768
e:  9   train_loss:  517.7815933155647   time:  1.3728222846984863
e:  10   train_loss:  508.992406056232   time:  1.348656415939331
e:  10   train_loss:  508.992406056232   val_loss:  1414.8635931384506   time:  1.4586663246154785
e:  11   train_loss:  506.5391309707825   time:  1.3731181621551514
e:  12   train_loss:  492.70107490720403   time:  1.3795530796051025
e:  13   train_loss:  494.8955214562312   time:  1.5928316116333008
e:  14   train_loss:  482.11950795095237   time:  1.3214240074157715
e:  15   train_loss:  475.4588938480177   time:  1.3324389457702637
e:  15   train_loss:  475.4588938480177   val_loss:  1463.1587653120203   time:  1.4406602382659912
e:  16   train_loss:  464.2364029757758   time:  1.3386883735656738
e:  17   train_loss:  467.1980411475435   time:  1.3775837421417236
e:  18   train_loss:  457.63648479921   time:  1.3303627967834473
e:  19   train_loss:  455.2294008549828   time:  1.3665215969085693
e:  20   train_loss:  453.2054565031092   time:  1.3333230018615723
e:  20   train_loss:  453.2054565031092   val_loss:  1484.963940191198   time:  1.442885398864746
e:  21   train_loss:  444.7891482442187   time:  1.3704757690429688
e:  22   train_loss:  439.74473754033033   time:  1.3775184154510498
e:  23   train_loss:  439.5521526382444   time:  1.3324365615844727
e:  24   train_loss:  434.40183477973187   time:  1.5396857261657715
e:  25   train_loss:  430.08676117153004   time:  1.377171277999878
e:  25   train_loss:  430.08676117153004   val_loss:  1463.5759049044048   time:  1.4878802299499512
e:  26   train_loss:  422.97572744168326   time:  1.3508992195129395
e:  27   train_loss:  421.28125334924914   time:  1.3728108406066895
e:  28   train_loss:  422.61636407814524   time:  1.3274142742156982
e:  29   train_loss:  413.1096776505512   time:  1.3219058513641357
e:  30   train_loss:  405.77071169503176   time:  1.352139949798584
e:  30   train_loss:  405.77071169503176   val_loss:  1324.5290856385302   time:  1.4646966457366943
e:  31   train_loss:  395.7911403411738   time:  1.3383684158325195
e:  32   train_loss:  388.62064422872993   time:  1.5401556491851807
e:  33   train_loss:  374.9018737674447   time:  1.3309557437896729
e:  34   train_loss:  367.80289933079956   time:  1.3854482173919678
e:  35   train_loss:  356.5766498594109   time:  1.3079631328582764
e:  35   train_loss:  356.5766498594109   val_loss:  1275.9068440459532   time:  1.4163858890533447
e:  36   train_loss:  352.3440190282587   time:  1.3338773250579834
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  37   train_loss:  344.6300620199873   time:  1.3263428211212158
e:  38   train_loss:  341.75769743186606   time:  1.3406083583831787
e:  39   train_loss:  333.5073728722135   time:  1.3402037620544434
e:  40   train_loss:  325.63172068431464   time:  1.3320534229278564
e:  40   train_loss:  325.63172068431464   val_loss:  1387.4777753856245   time:  1.4404244422912598
e:  41   train_loss:  323.31343967149616   time:  1.326066493988037
e:  42   train_loss:  317.67710938820176   time:  1.3260035514831543
e:  43   train_loss:  311.42716160871726   time:  1.5398664474487305
e:  44   train_loss:  304.22625601910227   time:  1.3745219707489014
e:  45   train_loss:  302.7019599577132   time:  1.3425798416137695
e:  45   train_loss:  302.7019599577132   val_loss:  1355.2039427030984   time:  1.4512429237365723
e:  46   train_loss:  298.19296223441654   time:  1.335768461227417
e:  47   train_loss:  296.75248140915346   time:  1.3719367980957031
e:  48   train_loss:  290.1405743788632   time:  1.3734583854675293
e:  49   train_loss:  287.28530908351235   time:  1.3725345134735107
e:  50   train_loss:  283.414822413343   time:  1.326507329940796
e:  50   train_loss:  283.414822413343   val_loss:  1392.1731686026021   time:  1.4364662170410156
e:  51   train_loss:  277.4227756139598   time:  1.2856013774871826
e:  52   train_loss:  277.590786040622   time:  1.5636022090911865
e:  53   train_loss:  271.9641277874176   time:  1.3617208003997803
e:  54   train_loss:  273.04953171621423   time:  1.3704509735107422
e:  55   train_loss:  266.77316108462264   time:  1.3744449615478516
e:  55   train_loss:  266.77316108462264   val_loss:  1401.108512579467   time:  1.4830775260925293
e:  56   train_loss:  265.09453737770605   time:  1.3789572715759277
e:  57   train_loss:  260.58800262575005   time:  1.3700776100158691
e:  58   train_loss:  258.4262382530711   time:  1.3752682209014893
e:  59   train_loss:  257.55754002176343   time:  1.3695909976959229
e:  60   train_loss:  253.9787623806216   time:  1.335665225982666
e:  60   train_loss:  253.9787623806216   val_loss:  1370.9737463637505   time:  1.4437153339385986
e:  61   train_loss:  254.40544458669297   time:  1.347489356994629
e:  62   train_loss:  249.95446959095585   time:  1.3200407028198242
e:  63   train_loss:  247.86293824665412   time:  1.507727861404419
e:  64   train_loss:  246.05492010834706   time:  1.3242762088775635
e:  65   train_loss:  244.826911132119   time:  1.3266088962554932
e:  65   train_loss:  244.826911132119   val_loss:  1386.914404790053   time:  1.4362635612487793
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1283.4521910743415   time:  1.4808199405670166
e:  0   train_loss:  1283.4521910743415   val_loss:  625.8025180416173   time:  1.5837898254394531
e:  1   train_loss:  970.6819778882323   time:  1.4997987747192383
e:  2   train_loss:  904.9719690833033   time:  1.4941110610961914
e:  3   train_loss:  843.0346484413003   time:  1.6782987117767334
e:  4   train_loss:  797.7470218943943   time:  1.496769905090332
e:  5   train_loss:  813.6561573123165   time:  1.4408307075500488
e:  5   train_loss:  813.6561573123165   val_loss:  577.7042922203369   time:  1.5434057712554932
e:  6   train_loss:  743.0227082574683   time:  1.4851164817810059
e:  7   train_loss:  768.058501028139   time:  1.464109182357788
e:  8   train_loss:  714.5419583103558   time:  1.4868357181549072
e:  9   train_loss:  696.3188203536997   time:  1.4565093517303467
e:  10   train_loss:  675.0060162438509   time:  1.6938917636871338
e:  10   train_loss:  675.0060162438509   val_loss:  690.6697918316271   time:  1.7958154678344727
e:  11   train_loss:  652.3260245062295   time:  1.4902839660644531
e:  12   train_loss:  650.8333574026985   time:  1.4957921504974365
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  13   train_loss:  637.9485063288384   time:  1.4920377731323242
e:  14   train_loss:  634.878650563662   time:  1.4937896728515625
e:  15   train_loss:  614.1957011423664   time:  1.4959561824798584
e:  15   train_loss:  614.1957011423664   val_loss:  1220.240144325875   time:  1.6003210544586182
e:  16   train_loss:  618.260542998637   time:  1.7476887702941895
e:  17   train_loss:  638.379707685626   time:  1.4592442512512207
e:  18   train_loss:  626.7324491872454   time:  1.4599213600158691
e:  19   train_loss:  629.5748388300306   time:  1.4532592296600342
e:  20   train_loss:  603.3235630338243   time:  1.491502046585083
e:  20   train_loss:  603.3235630338243   val_loss:  911.1003476098351   time:  1.5937683582305908
e:  21   train_loss:  590.1906995646747   time:  1.4421541690826416
e:  22   train_loss:  594.2385967966534   time:  1.4554283618927002
e:  23   train_loss:  573.8243555236589   time:  1.6225903034210205
e:  24   train_loss:  600.0194895795414   time:  1.4556665420532227
e:  25   train_loss:  610.946285288357   time:  1.4798786640167236
e:  25   train_loss:  610.946285288357   val_loss:  725.4718618196521   time:  1.581089735031128
e:  26   train_loss:  614.6597409946094   time:  1.4779040813446045
e:  27   train_loss:  578.4174585784226   time:  1.4867777824401855
e:  28   train_loss:  553.0344795219199   time:  1.4866728782653809
e:  29   train_loss:  551.810886004801   time:  1.494361162185669
e:  30   train_loss:  528.6727391477806   time:  1.646644115447998
e:  30   train_loss:  528.6727391477806   val_loss:  2334.2982537836924   time:  1.7491042613983154
e:  31   train_loss:  534.070167932252   time:  1.4596576690673828
e:  32   train_loss:  526.4130543429852   time:  1.4563288688659668
e:  33   train_loss:  530.8809663373235   time:  1.44000244140625
e:  34   train_loss:  500.95602857580786   time:  1.449714183807373
e:  35   train_loss:  504.88630284557985   time:  1.5025603771209717
e:  35   train_loss:  504.88630284557985   val_loss:  864.9129747686986   time:  1.787872076034546
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1323.5999419945267   time:  1.4079785346984863
e:  0   train_loss:  1323.5999419945267   val_loss:  538.4190895490788   time:  1.5126674175262451
e:  1   train_loss:  1038.6751713882409   time:  1.404317855834961
e:  2   train_loss:  1006.7227626298466   time:  1.4203193187713623
e:  3   train_loss:  930.7415705461922   time:  1.4117424488067627
e:  4   train_loss:  820.2976757010733   time:  1.4132089614868164
e:  5   train_loss:  768.0335389149022   time:  1.4011814594268799
e:  5   train_loss:  768.0335389149022   val_loss:  603.2980382916019   time:  1.506030559539795
e:  6   train_loss:  809.8498953352271   time:  1.4377665519714355
e:  7   train_loss:  775.7192459373827   time:  1.5616114139556885
e:  8   train_loss:  748.148787284328   time:  1.4163267612457275
e:  9   train_loss:  821.9687019071605   time:  1.3927674293518066
e:  10   train_loss:  740.6804224515813   time:  1.3940401077270508
e:  10   train_loss:  740.6804224515813   val_loss:  729.149889702585   time:  1.4982059001922607
e:  11   train_loss:  773.2611017649821   time:  1.4116542339324951
e:  12   train_loss:  723.4620945324968   time:  1.4081180095672607
e:  13   train_loss:  703.97741247148   time:  1.413100242614746
e:  14   train_loss:  719.1749183506902   time:  1.434438705444336
e:  15   train_loss:  748.3176049655859   time:  1.6034090518951416
e:  15   train_loss:  748.3176049655859   val_loss:  469.8364492765393   time:  1.7073099613189697
e:  16   train_loss:  695.9394365105029   time:  1.421550989151001
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  17   train_loss:  686.5710244458238   time:  1.4103999137878418
e:  18   train_loss:  697.413434959012   time:  1.4146695137023926
e:  19   train_loss:  680.1362316222909   time:  1.3958745002746582
e:  20   train_loss:  669.7054992898338   time:  1.4024670124053955
e:  20   train_loss:  669.7054992898338   val_loss:  476.15428785354186   time:  1.508056640625
e:  21   train_loss:  647.65795662529   time:  1.5535836219787598
e:  22   train_loss:  679.3711962954477   time:  1.4129374027252197
e:  23   train_loss:  648.9343701591415   time:  1.4145383834838867
e:  24   train_loss:  627.720077294005   time:  1.4197659492492676
e:  25   train_loss:  648.8006291419501   time:  1.4131691455841064
e:  25   train_loss:  648.8006291419501   val_loss:  462.8565610357727   time:  1.5176348686218262
e:  26   train_loss:  638.4776948267936   time:  1.412283182144165
e:  27   train_loss:  639.3981637848419   time:  1.4148387908935547
e:  28   train_loss:  629.8196844943355   time:  1.4104318618774414
e:  29   train_loss:  639.4349967684788   time:  1.4167163372039795
e:  30   train_loss:  620.5271490543636   time:  1.56453537940979
e:  30   train_loss:  620.5271490543636   val_loss:  461.97499414313575   time:  1.6681029796600342
e:  31   train_loss:  619.680962851621   time:  1.3973331451416016
e:  32   train_loss:  622.3202268727052   time:  1.4223010540008545
e:  33   train_loss:  637.1926582222991   time:  1.4149603843688965
e:  34   train_loss:  621.0491375679763   time:  1.413022518157959
e:  35   train_loss:  658.6271873133174   time:  1.4145221710205078
e:  35   train_loss:  658.6271873133174   val_loss:  463.625301738378   time:  1.5193440914154053
e:  36   train_loss:  631.1586705756235   time:  1.4135513305664062
e:  37   train_loss:  607.3991393668836   time:  1.5908405780792236
e:  38   train_loss:  610.5446924327223   time:  1.4129080772399902
e:  39   train_loss:  598.329052341725   time:  1.4021000862121582
e:  40   train_loss:  597.0578760659821   time:  1.411360740661621
e:  40   train_loss:  597.0578760659821   val_loss:  465.6873035244634   time:  1.5161144733428955
e:  41   train_loss:  599.0993377566042   time:  1.4226548671722412
e:  42   train_loss:  593.8976809555079   time:  1.4131057262420654
e:  43   train_loss:  585.222527614936   time:  1.4091360569000244
e:  44   train_loss:  581.7861923854473   time:  1.4136929512023926
e:  45   train_loss:  605.8026331074477   time:  1.5941319465637207
e:  45   train_loss:  605.8026331074477   val_loss:  542.9865655202344   time:  1.6987323760986328
e:  46   train_loss:  619.7029836560506   time:  1.4146881103515625
e:  47   train_loss:  594.4317236148285   time:  1.4250152111053467
e:  48   train_loss:  643.1153489953573   time:  1.4118587970733643
e:  49   train_loss:  595.1536688816498   time:  1.4174866676330566
e:  50   train_loss:  575.7158646592867   time:  1.4007575511932373
e:  50   train_loss:  575.7158646592867   val_loss:  572.6850511218516   time:  1.5040044784545898
e:  51   train_loss:  577.7881331029806   time:  1.3985061645507812
e:  52   train_loss:  583.8757672543603   time:  1.5831427574157715
e:  53   train_loss:  539.0261995781734   time:  1.4136621952056885
e:  54   train_loss:  577.5253438854164   time:  1.4170076847076416
e:  55   train_loss:  559.0287790658257   time:  1.4145424365997314
e:  55   train_loss:  559.0287790658257   val_loss:  586.4302237225613   time:  1.5198919773101807
e:  56   train_loss:  615.4895841280098   time:  1.4176359176635742
e:  57   train_loss:  544.770061721213   time:  1.4222304821014404
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  58   train_loss:  539.0655683632831   time:  1.4137840270996094
e:  59   train_loss:  555.5701104113426   time:  1.4185278415679932
e:  60   train_loss:  509.8460469721244   time:  1.5779542922973633
e:  60   train_loss:  509.8460469721244   val_loss:  878.1091240944756   time:  1.6828010082244873
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  1293.864113814702   time:  1.3688123226165771
e:  0   train_loss:  1293.864113814702   val_loss:  915.1219211617853   time:  1.4785346984863281
e:  1   train_loss:  972.6664545126522   time:  1.3542909622192383
e:  2   train_loss:  896.2065769995612   time:  1.33555006980896
e:  3   train_loss:  800.6948541630977   time:  1.3336372375488281
e:  4   train_loss:  752.9725623788662   time:  1.330547571182251
e:  5   train_loss:  753.3930147722368   time:  1.324258804321289
e:  5   train_loss:  753.3930147722368   val_loss:  739.2292113785631   time:  1.4351224899291992
e:  6   train_loss:  724.0253732131707   time:  1.315000057220459
e:  7   train_loss:  724.4509033279705   time:  1.3402557373046875
e:  8   train_loss:  750.2397558912498   time:  1.33693528175354
e:  9   train_loss:  698.3368349746677   time:  1.5841255187988281
e:  10   train_loss:  687.7415362078513   time:  1.355703592300415
e:  10   train_loss:  687.7415362078513   val_loss:  781.1873891682621   time:  1.4636809825897217
e:  11   train_loss:  678.166699598658   time:  1.352226972579956
e:  12   train_loss:  659.2125964786777   time:  1.3307647705078125
e:  13   train_loss:  656.1941649141618   time:  1.3359956741333008
e:  14   train_loss:  663.6980333223469   time:  1.365957498550415
e:  15   train_loss:  626.47233331299   time:  1.3352901935577393
e:  15   train_loss:  626.47233331299   val_loss:  744.6211436363958   time:  1.443861484527588
e:  16   train_loss:  614.3818010524074   time:  1.328334093093872
e:  17   train_loss:  640.5225755447054   time:  1.3297381401062012
e:  18   train_loss:  614.0792515462251   time:  1.3797285556793213
e:  19   train_loss:  608.1223104428251   time:  1.370861530303955
e:  20   train_loss:  596.1297097984395   time:  1.542121410369873
e:  20   train_loss:  596.1297097984395   val_loss:  729.1483319207229   time:  1.6531002521514893
e:  21   train_loss:  598.7418210300701   time:  1.3221256732940674
e:  22   train_loss:  592.2129901703028   time:  1.3752496242523193
e:  23   train_loss:  588.1750880011615   time:  1.3716576099395752
e:  24   train_loss:  576.230241593899   time:  1.3629848957061768
e:  25   train_loss:  577.9920453422758   time:  1.3339838981628418
e:  25   train_loss:  577.9920453422758   val_loss:  760.8307550178688   time:  1.4436519145965576
e:  26   train_loss:  601.8447294942703   time:  1.3306128978729248
e:  27   train_loss:  566.6852233138274   time:  1.3741865158081055
e:  28   train_loss:  578.6534844364103   time:  1.3362278938293457
e:  29   train_loss:  597.1521271408891   time:  1.59096097946167
e:  30   train_loss:  593.3347183107325   time:  1.3240065574645996
e:  30   train_loss:  593.3347183107325   val_loss:  759.6327511056007   time:  1.435547113418579
e:  31   train_loss:  582.0340974675955   time:  1.3457293510437012
e:  32   train_loss:  609.7400455353622   time:  1.2481775283813477
e:  33   train_loss:  581.547827144384   time:  1.2468578815460205
e:  34   train_loss:  558.1744083359397   time:  1.2664775848388672
e:  35   train_loss:  562.3068768205572   time:  1.2594883441925049
e:  35   train_loss:  562.3068768205572   val_loss:  754.3276377521563   time:  1.3680107593536377
e:  36   train_loss:  554.4157887434848   time:  1.263293743133545
e:  37   train_loss:  551.6508154609546   time:  1.2539880275726318
e:  38   train_loss:  557.3678577344335   time:  1.3829565048217773
e:  39   train_loss:  544.6326361759334   time:  1.2634389400482178
e:  40   train_loss:  537.987604573869   time:  1.2648711204528809
e:  40   train_loss:  537.987604573869   val_loss:  748.5387485162499   time:  1.373924970626831
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  41   train_loss:  547.5938314346796   time:  1.268772840499878
e:  42   train_loss:  577.3577399013576   time:  1.2619397640228271
e:  43   train_loss:  552.5480697403051   time:  1.2571640014648438
e:  44   train_loss:  537.8733010747918   time:  1.3227040767669678
e:  45   train_loss:  538.0052015940043   time:  1.2630252838134766
e:  45   train_loss:  538.0052015940043   val_loss:  746.5478017417034   time:  1.372361660003662
e:  46   train_loss:  535.4713107829878   time:  1.2605323791503906
e:  47   train_loss:  533.4428439255956   time:  1.2646641731262207
e:  48   train_loss:  525.4126604335944   time:  1.2651071548461914
e:  49   train_loss:  537.0494388672078   time:  1.2639663219451904
e:  50   train_loss:  510.9250325247258   time:  1.2615904808044434
e:  50   train_loss:  510.9250325247258   val_loss:  728.6310676789578   time:  1.4942426681518555
e:  51   train_loss:  542.6065993934213   time:  1.2632825374603271
e:  52   train_loss:  522.4048665875982   time:  1.261843204498291
e:  53   train_loss:  526.5717033462306   time:  1.2626707553863525
e:  54   train_loss:  506.9891136373041   time:  1.2592697143554688
e:  55   train_loss:  500.8301532890162   time:  1.353724479675293
e:  55   train_loss:  500.8301532890162   val_loss:  732.2474301929063   time:  1.462820053100586
e:  56   train_loss:  489.9168628446441   time:  1.257094383239746
e:  57   train_loss:  487.4094835971415   time:  1.2688465118408203
e:  58   train_loss:  479.2073319409106   time:  1.266502857208252
e:  59   train_loss:  477.52935859011535   time:  1.3891041278839111
e:  60   train_loss:  486.43202143601684   time:  1.4060373306274414
e:  60   train_loss:  486.43202143601684   val_loss:  744.4374929645883   time:  1.5057528018951416
e:  61   train_loss:  477.56850958104826   time:  1.365138292312622
e:  62   train_loss:  486.0047595792465   time:  1.3319735527038574
e:  63   train_loss:  481.48901633996326   time:  1.3373444080352783
e:  64   train_loss:  469.5970604919164   time:  1.3250689506530762
e:  65   train_loss:  454.87447235067793   time:  1.3210375308990479
e:  65   train_loss:  454.87447235067793   val_loss:  722.5022530245396   time:  1.4294090270996094
e:  66   train_loss:  454.30921852575545   time:  1.3742265701293945
e:  67   train_loss:  455.95214194626095   time:  1.379148244857788
e:  68   train_loss:  451.6376126114163   time:  1.342325210571289
e:  69   train_loss:  448.64507754279435   time:  1.3685321807861328
e:  70   train_loss:  452.8063746777739   time:  1.5196306705474854
e:  70   train_loss:  452.8063746777739   val_loss:  728.4582314854822   time:  1.631286382675171
e:  71   train_loss:  437.631076522063   time:  1.375812292098999
e:  72   train_loss:  434.73798933654456   time:  1.3496131896972656
e:  73   train_loss:  440.63632640196283   time:  1.3889799118041992
e:  74   train_loss:  441.2092835017154   time:  1.3701808452606201
e:  75   train_loss:  427.5205102640638   time:  1.377777099609375
e:  75   train_loss:  427.5205102640638   val_loss:  724.9290007040729   time:  1.4881224632263184
e:  76   train_loss:  427.38930403376594   time:  1.311331033706665
e:  77   train_loss:  429.93949829368324   time:  1.3607656955718994
e:  78   train_loss:  435.24737503322257   time:  1.3786189556121826
e:  79   train_loss:  424.3784046869733   time:  1.56172513961792
e:  80   train_loss:  416.2234480606532   time:  1.3531737327575684
e:  80   train_loss:  416.2234480606532   val_loss:  731.8592849244044   time:  1.4623103141784668
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1002.3102777523555   time:  1.4562859535217285
e:  0   train_loss:  1002.3102777523555   val_loss:  592.3579170203477   time:  1.5594794750213623
e:  1   train_loss:  823.8236082852541   time:  1.5003950595855713
e:  2   train_loss:  779.8546192408726   time:  1.4952614307403564
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  3   train_loss:  758.8589319464716   time:  1.4947848320007324
e:  4   train_loss:  753.0112839283955   time:  1.6858417987823486
e:  5   train_loss:  711.3865598687257   time:  1.4966621398925781
e:  5   train_loss:  711.3865598687257   val_loss:  603.6868106360886   time:  1.601440191268921
e:  6   train_loss:  698.8398810712579   time:  1.454319953918457
e:  7   train_loss:  713.2274689697774   time:  1.4515857696533203
e:  8   train_loss:  694.272624088584   time:  1.5021693706512451
e:  9   train_loss:  655.8700207599073   time:  1.4974753856658936
e:  10   train_loss:  669.1315619092692   time:  1.4959511756896973
e:  10   train_loss:  669.1315619092692   val_loss:  655.8147031767614   time:  1.8136324882507324
e:  11   train_loss:  658.1620719088426   time:  1.4619758129119873
e:  12   train_loss:  661.9549375394349   time:  1.4380836486816406
e:  13   train_loss:  629.8660568129391   time:  1.491927146911621
e:  14   train_loss:  611.0818195964481   time:  1.4508423805236816
e:  15   train_loss:  616.3708002230252   time:  1.4502167701721191
e:  15   train_loss:  616.3708002230252   val_loss:  591.8920089858323   time:  1.5530271530151367
e:  16   train_loss:  635.0848297848538   time:  1.67610502243042
e:  17   train_loss:  638.2639068980227   time:  1.498060703277588
e:  18   train_loss:  620.5954236689857   time:  1.456512451171875
e:  19   train_loss:  603.3732027346745   time:  1.4458301067352295
e:  20   train_loss:  603.7623422577913   time:  1.452057123184204
e:  20   train_loss:  603.7623422577913   val_loss:  609.5231756928541   time:  1.5562422275543213
e:  21   train_loss:  606.2841998316295   time:  1.4526855945587158
e:  22   train_loss:  609.0155473229717   time:  1.5564780235290527
e:  23   train_loss:  616.1424098440231   time:  1.6355881690979004
e:  24   train_loss:  632.3938333153444   time:  1.3869926929473877
e:  25   train_loss:  640.0296922594912   time:  1.392620325088501
e:  25   train_loss:  640.0296922594912   val_loss:  587.4458783846071   time:  1.4956800937652588
e:  26   train_loss:  600.0079782609243   time:  1.3900744915008545
e:  27   train_loss:  583.996589769326   time:  1.3898289203643799
e:  28   train_loss:  580.1784808232801   time:  1.3871667385101318
e:  29   train_loss:  563.7469333751085   time:  1.3760335445404053
e:  30   train_loss:  553.0023602725377   time:  1.518110990524292
e:  30   train_loss:  553.0023602725377   val_loss:  576.3039074707842   time:  1.621260404586792
e:  31   train_loss:  542.4076167008275   time:  1.3860893249511719
e:  32   train_loss:  551.7316334122229   time:  1.3872900009155273
e:  33   train_loss:  591.5659993641002   time:  1.3825523853302002
e:  34   train_loss:  566.0212861400619   time:  1.3850743770599365
e:  35   train_loss:  583.8784504875835   time:  1.386094331741333
e:  35   train_loss:  583.8784504875835   val_loss:  552.4212886478606   time:  1.489694595336914
e:  36   train_loss:  586.7884426385384   time:  1.5035858154296875
e:  37   train_loss:  586.2236437464651   time:  1.3749561309814453
e:  38   train_loss:  534.5978420649712   time:  1.3835372924804688
e:  39   train_loss:  556.544211945495   time:  1.3861618041992188
e:  40   train_loss:  536.6280225014976   time:  1.3801555633544922
e:  40   train_loss:  536.6280225014976   val_loss:  597.0747815248286   time:  1.4838688373565674
e:  41   train_loss:  584.8831059633301   time:  1.3869359493255615
e:  42   train_loss:  549.66379062408   time:  1.3851988315582275
e:  43   train_loss:  577.2889094188067   time:  1.4964306354522705
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  44   train_loss:  535.3386276526536   time:  1.389284372329712
e:  45   train_loss:  524.2613337671102   time:  1.38606858253479
e:  45   train_loss:  524.2613337671102   val_loss:  602.9104731473045   time:  1.4893455505371094
e:  46   train_loss:  492.09793453069244   time:  1.3832283020019531
e:  47   train_loss:  496.16910049389986   time:  1.3846495151519775
e:  48   train_loss:  504.12385748383684   time:  1.3754618167877197
e:  49   train_loss:  481.7821983927292   time:  1.3828115463256836
e:  50   train_loss:  478.9657054141079   time:  1.517951488494873
e:  50   train_loss:  478.9657054141079   val_loss:  661.67006231438   time:  1.6338627338409424
e:  51   train_loss:  460.93342838315505   time:  1.5547223091125488
e:  52   train_loss:  452.76828532142764   time:  1.4496746063232422
e:  53   train_loss:  437.96711611826225   time:  1.4452486038208008
e:  54   train_loss:  450.1081565030512   time:  1.4453060626983643
e:  55   train_loss:  435.29368459736384   time:  1.459653377532959
e:  55   train_loss:  435.29368459736384   val_loss:  726.4816646135445   time:  1.7625038623809814
e:  56   train_loss:  418.0585908523298   time:  1.445157527923584
e:  57   train_loss:  422.99509085635333   time:  1.4168133735656738
e:  58   train_loss:  432.41688594458503   time:  1.4509611129760742
e:  59   train_loss:  407.3298040588377   time:  1.4482505321502686
e:  60   train_loss:  412.9463551117212   time:  1.3658020496368408
e:  60   train_loss:  412.9463551117212   val_loss:  635.8731146036681   time:  1.4678809642791748
e:  61   train_loss:  433.27147927630983   time:  1.5115501880645752
e:  62   train_loss:  421.68813221273683   time:  1.3786089420318604
e:  63   train_loss:  432.51507060939946   time:  1.3867406845092773
e:  64   train_loss:  408.921377529516   time:  1.381363868713379
e:  65   train_loss:  381.9567589997467   time:  1.3859360218048096
e:  65   train_loss:  381.9567589997467   val_loss:  641.8008918035955   time:  1.4893593788146973
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 10), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 10) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 10) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 10) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 10)
kwargs: {'config': {'batch_norm': True, 'ff_0': 39, 'ff_num_layers': 2, 'gnn_0': 71, 'gnn_dropout': 0.4680205928046692, 'gnn_num_layers': 2, 'hid_0': 253, 'hid_dropout_rate': 0.33231583631114886, 'in_dropout_rate': 0.4318697065068356, 'lr': 0.00790707314326263, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 235, 'gnn_1': 488, 'hid_1': 215, 'hid_2': 1034}, 'budget': 81.0, 'working_directory': '.'}
result: {'loss': 718.1019344163653, 'n_epochs': 61.2, 'info': {'validation loss': 718.1019344163653}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 10) started
DEBUG:hpbandster:job_callback for (0, 0, 10) got condition
DEBUG:hpbandster:Only 2 run(s) for budget 81.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 10) finished
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 14) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 14) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 14)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 14) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 14) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 14)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 214, 'ff_num_layers': 1, 'gnn_0': 1421, 'gnn_dropout': 0.48575232412252367, 'gnn_num_layers': 1, 'hid_0': 366, 'hid_dropout_rate': 0.16943484925922442, 'in_dropout_rate': 0.16962245313039404, 'lr': 0.000645480083493207, 'num_hid_layers': 2, 'optimizer': 'Adam', 'hid_1': 244}, 'budget': 81.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  682.0958588281916   time:  1.2095463275909424
e:  0   train_loss:  682.0958588281916   val_loss:  1511.3636041953412   time:  1.2930710315704346
e:  1   train_loss:  610.4185693988314   time:  1.286747932434082
e:  2   train_loss:  597.1329364305865   time:  1.6043176651000977
e:  3   train_loss:  592.8985989739291   time:  1.395125150680542
e:  4   train_loss:  588.7380655040237   time:  1.4031002521514893
e:  5   train_loss:  583.8011377648954   time:  1.4061639308929443
e:  5   train_loss:  583.8011377648954   val_loss:  1379.5721541691487   time:  1.5166223049163818
e:  6   train_loss:  580.2218372095053   time:  1.417499303817749
e:  7   train_loss:  574.1993323716163   time:  1.2933623790740967
e:  8   train_loss:  567.3052087773801   time:  1.3044230937957764
e:  9   train_loss:  556.5265356459454   time:  1.290931224822998
e:  10   train_loss:  545.5463399540984   time:  1.298642873764038
e:  10   train_loss:  545.5463399540984   val_loss:  1389.2413486646662   time:  1.4085826873779297
e:  11   train_loss:  532.6819307307608   time:  1.2948906421661377
e:  12   train_loss:  517.5606012778455   time:  1.4480538368225098
e:  13   train_loss:  501.47558995735983   time:  1.466531753540039
e:  14   train_loss:  486.9073841090335   time:  1.4402496814727783
e:  15   train_loss:  471.2905014822567   time:  1.4136264324188232
e:  15   train_loss:  471.2905014822567   val_loss:  1351.2184412308716   time:  1.5230889320373535
e:  16   train_loss:  459.6849144791304   time:  1.398833990097046
e:  17   train_loss:  449.3125778756281   time:  1.300036907196045
e:  18   train_loss:  441.592035688824   time:  1.2897911071777344
e:  19   train_loss:  433.1293502781336   time:  1.3845796585083008
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  20   train_loss:  427.6654003920712   time:  1.2998135089874268
e:  20   train_loss:  427.6654003920712   val_loss:  1386.3501316652298   time:  1.4102020263671875
e:  21   train_loss:  425.62711764835524   time:  1.2989544868469238
e:  22   train_loss:  422.9943310288123   time:  1.4216785430908203
e:  23   train_loss:  420.598672702002   time:  1.2808706760406494
e:  24   train_loss:  416.93131168537064   time:  1.2898759841918945
e:  25   train_loss:  415.2388049855635   time:  1.2932496070861816
e:  25   train_loss:  415.2388049855635   val_loss:  1415.036368991915   time:  1.4039356708526611
e:  26   train_loss:  413.4904291909932   time:  1.2946627140045166
e:  27   train_loss:  412.3668891945456   time:  1.2965495586395264
e:  28   train_loss:  412.09300330897076   time:  1.28946852684021
e:  29   train_loss:  410.9366839712143   time:  1.2877485752105713
e:  30   train_loss:  409.35965252360387   time:  1.2962534427642822
e:  30   train_loss:  409.35965252360387   val_loss:  1428.0799643130447   time:  1.406364917755127
e:  31   train_loss:  409.6777863221558   time:  1.290604591369629
e:  32   train_loss:  411.4344826616534   time:  1.5066945552825928
e:  33   train_loss:  409.942908308913   time:  1.4240949153900146
e:  34   train_loss:  406.99543193989615   time:  1.2546288967132568
e:  35   train_loss:  407.29153756110003   time:  1.2714731693267822
e:  35   train_loss:  407.29153756110003   val_loss:  1440.1621932881421   time:  1.3815948963165283
e:  36   train_loss:  404.66296034777946   time:  1.2982816696166992
e:  37   train_loss:  404.9739153945914   time:  1.3702032566070557
e:  38   train_loss:  403.9102965592506   time:  1.291635513305664
e:  39   train_loss:  401.6895178173588   time:  1.2882554531097412
e:  40   train_loss:  401.43346057825204   time:  1.2972867488861084
e:  40   train_loss:  401.43346057825204   val_loss:  1432.5279686784806   time:  1.4068820476531982
e:  41   train_loss:  399.2981148961366   time:  1.2976610660552979
e:  42   train_loss:  396.64749111867235   time:  1.2975800037384033
e:  43   train_loss:  394.691978310101   time:  1.2958307266235352
e:  44   train_loss:  394.06473263303377   time:  1.2974762916564941
e:  45   train_loss:  392.4818945925871   time:  1.4148707389831543
e:  45   train_loss:  392.4818945925871   val_loss:  1434.068664877897   time:  1.5169811248779297
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1055.4041434307344   time:  1.4200248718261719
e:  0   train_loss:  1055.4041434307344   val_loss:  541.684752466616   time:  1.5242369174957275
e:  1   train_loss:  912.350353009694   time:  1.4185292720794678
e:  2   train_loss:  903.9888050636393   time:  1.4181523323059082
e:  3   train_loss:  886.661160466816   time:  1.4169659614562988
e:  4   train_loss:  875.7069831821846   time:  1.4162876605987549
e:  5   train_loss:  884.572371785413   time:  1.546107530593872
e:  5   train_loss:  884.572371785413   val_loss:  562.3328348445564   time:  1.650001049041748
e:  6   train_loss:  861.0362329150953   time:  1.4325180053710938
e:  7   train_loss:  821.1378219687273   time:  1.418524980545044
e:  8   train_loss:  762.5014327410738   time:  1.4251823425292969
e:  9   train_loss:  709.2614307358933   time:  1.5344409942626953
e:  10   train_loss:  686.1857155205239   time:  1.3901126384735107
e:  10   train_loss:  686.1857155205239   val_loss:  931.6079725367157   time:  1.4931213855743408
e:  11   train_loss:  657.7818055216383   time:  1.4124858379364014
e:  12   train_loss:  640.1912521403395   time:  1.5390491485595703
e:  13   train_loss:  637.8190254595014   time:  1.4058210849761963
e:  14   train_loss:  619.4298377207216   time:  1.4146006107330322
e:  15   train_loss:  615.800838185856   time:  1.4106121063232422
e:  15   train_loss:  615.800838185856   val_loss:  887.2793760535383   time:  1.5147373676300049
e:  16   train_loss:  598.5768227665391   time:  1.416717290878296
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  17   train_loss:  592.9978029420593   time:  1.4853599071502686
e:  18   train_loss:  579.8343149921863   time:  1.7455317974090576
e:  19   train_loss:  572.0888087302496   time:  1.5341966152191162
e:  20   train_loss:  568.6744804455961   time:  1.4776182174682617
e:  20   train_loss:  568.6744804455961   val_loss:  991.8534296836348   time:  1.583467960357666
e:  21   train_loss:  566.0880673984243   time:  1.5484328269958496
e:  22   train_loss:  568.9808630124832   time:  1.4131999015808105
e:  23   train_loss:  563.5044448747581   time:  1.4145543575286865
e:  24   train_loss:  557.9296620036994   time:  1.4171109199523926
e:  25   train_loss:  553.9173301244068   time:  1.5577917098999023
e:  25   train_loss:  553.9173301244068   val_loss:  1133.6205858568267   time:  1.661027193069458
e:  26   train_loss:  567.0644529107469   time:  1.4910364151000977
e:  27   train_loss:  540.9661525403576   time:  1.4129188060760498
e:  28   train_loss:  546.5248717000388   time:  1.4156358242034912
e:  29   train_loss:  553.851658800838   time:  1.4052822589874268
e:  30   train_loss:  554.927596519677   time:  1.3864595890045166
e:  30   train_loss:  554.927596519677   val_loss:  967.2706480793346   time:  1.4899842739105225
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1029.224223775992   time:  1.3999409675598145
e:  0   train_loss:  1029.224223775992   val_loss:  473.3740347183192   time:  1.5064151287078857
e:  1   train_loss:  894.4976357462607   time:  1.5319392681121826
e:  2   train_loss:  907.6958350923037   time:  1.402651071548462
e:  3   train_loss:  884.0874888397603   time:  1.3975412845611572
e:  4   train_loss:  861.7153192922619   time:  1.3933696746826172
e:  5   train_loss:  838.4063949164885   time:  1.400374174118042
e:  5   train_loss:  838.4063949164885   val_loss:  506.6806198723868   time:  1.506368637084961
e:  6   train_loss:  842.3942609916196   time:  1.4013209342956543
e:  7   train_loss:  810.198838140639   time:  1.4006900787353516
e:  8   train_loss:  768.0479744225787   time:  1.4139738082885742
e:  9   train_loss:  737.198354534541   time:  1.6950585842132568
e:  10   train_loss:  708.9620154615195   time:  1.468310832977295
e:  10   train_loss:  708.9620154615195   val_loss:  508.9822216432828   time:  1.5725491046905518
e:  11   train_loss:  664.3559393829805   time:  1.4733843803405762
e:  12   train_loss:  659.1937644280465   time:  1.4716198444366455
e:  13   train_loss:  652.4111730598092   time:  1.4814457893371582
e:  14   train_loss:  640.5330345526677   time:  1.4870378971099854
e:  15   train_loss:  615.7833667604538   time:  1.484661340713501
e:  15   train_loss:  615.7833667604538   val_loss:  479.7766328715457   time:  1.5909364223480225
e:  16   train_loss:  638.5406442486724   time:  1.6865484714508057
e:  17   train_loss:  635.2238793884999   time:  1.4764695167541504
e:  18   train_loss:  616.8906036504728   time:  1.4725842475891113
e:  19   train_loss:  608.1842457820823   time:  1.2556700706481934
e:  20   train_loss:  581.3751973189711   time:  1.4904470443725586
e:  20   train_loss:  581.3751973189711   val_loss:  480.98765600786356   time:  1.5957579612731934
e:  21   train_loss:  597.9299033795613   time:  1.4730045795440674
e:  22   train_loss:  584.6409369168517   time:  1.4811599254608154
e:  23   train_loss:  595.9970177983628   time:  1.6712145805358887
e:  24   train_loss:  612.865896516726   time:  1.5077674388885498
e:  25   train_loss:  588.5421748767131   time:  1.4288716316223145
e:  25   train_loss:  588.5421748767131   val_loss:  569.507819922335   time:  1.5345559120178223
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  26   train_loss:  593.4033062556215   time:  1.5567786693572998
e:  27   train_loss:  570.4983092054994   time:  1.4134540557861328
e:  28   train_loss:  595.0869230446158   time:  1.4010608196258545
e:  29   train_loss:  570.2352090809495   time:  1.4038171768188477
e:  30   train_loss:  579.1341926233213   time:  1.4024617671966553
e:  30   train_loss:  579.1341926233213   val_loss:  532.7464700526383   time:  1.5089478492736816
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  968.3355619470802   time:  1.2753629684448242
e:  0   train_loss:  968.3355619470802   val_loss:  796.9653116237995   time:  1.385692834854126
e:  1   train_loss:  854.296914390684   time:  1.4217431545257568
e:  2   train_loss:  839.5350263858943   time:  1.2930727005004883
e:  3   train_loss:  830.6180995168057   time:  1.3007400035858154
e:  4   train_loss:  822.1304471079325   time:  1.2848644256591797
e:  5   train_loss:  816.7534094118096   time:  1.2944366931915283
e:  5   train_loss:  816.7534094118096   val_loss:  733.4511051196539   time:  1.4051432609558105
e:  6   train_loss:  806.1522290367087   time:  1.2985804080963135
e:  7   train_loss:  789.2254071616526   time:  1.2881546020507812
e:  8   train_loss:  769.6255503971665   time:  1.2907390594482422
e:  9   train_loss:  731.8250006582088   time:  1.2652721405029297
e:  10   train_loss:  704.0919039069847   time:  1.2895383834838867
e:  10   train_loss:  704.0919039069847   val_loss:  710.3871279675948   time:  1.400719404220581
e:  11   train_loss:  667.0404326925686   time:  1.2937602996826172
e:  12   train_loss:  640.2260353610108   time:  1.2968604564666748
e:  13   train_loss:  614.1788304553958   time:  1.4155569076538086
e:  14   train_loss:  600.3459565749135   time:  1.293391227722168
e:  15   train_loss:  595.4927484654488   time:  1.295555830001831
e:  15   train_loss:  595.4927484654488   val_loss:  711.9683780736414   time:  1.4071686267852783
e:  16   train_loss:  584.4659560995323   time:  1.2951476573944092
e:  17   train_loss:  574.981096609644   time:  1.2886435985565186
e:  18   train_loss:  567.3884064908351   time:  1.2936806678771973
e:  19   train_loss:  563.0064156987992   time:  1.2970380783081055
e:  20   train_loss:  552.8901739211173   time:  1.297290325164795
e:  20   train_loss:  552.8901739211173   val_loss:  697.2647801498738   time:  1.4080538749694824
e:  21   train_loss:  549.9373901326463   time:  1.2976000308990479
e:  22   train_loss:  546.1275190670633   time:  1.2982542514801025
e:  23   train_loss:  542.1998373913358   time:  1.2953944206237793
e:  24   train_loss:  539.9244406460522   time:  1.2953379154205322
e:  25   train_loss:  540.1760496095055   time:  1.2860541343688965
e:  25   train_loss:  540.1760496095055   val_loss:  717.2352651484708   time:  1.5117051601409912
e:  26   train_loss:  535.1452447791012   time:  1.3602066040039062
e:  27   train_loss:  533.0608207471337   time:  1.293018102645874
e:  28   train_loss:  533.6635874154856   time:  1.2930834293365479
e:  29   train_loss:  531.8677441668849   time:  1.2937984466552734
e:  30   train_loss:  527.565312143625   time:  1.2937901020050049
e:  30   train_loss:  527.565312143625   val_loss:  699.6486300871021   time:  1.404205322265625
e:  31   train_loss:  534.2176998534403   time:  1.2834234237670898
e:  32   train_loss:  529.6668631158834   time:  1.2756309509277344
e:  33   train_loss:  527.0723836031966   time:  1.2962477207183838
e:  34   train_loss:  527.6369315959939   time:  1.2886381149291992
e:  35   train_loss:  525.3884125720896   time:  1.4139790534973145
e:  35   train_loss:  525.3884125720896   val_loss:  710.1997696822995   time:  1.525141954421997
e:  36   train_loss:  528.5297500864905   time:  1.2910640239715576
e:  37   train_loss:  523.6952237213046   time:  1.2964751720428467
e:  38   train_loss:  523.9082263728669   time:  1.2966976165771484
e:  39   train_loss:  521.6581523681149   time:  1.2863328456878662
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  40   train_loss:  519.4125501989771   time:  1.3010499477386475
e:  40   train_loss:  519.4125501989771   val_loss:  717.3144855939171   time:  1.412416696548462
e:  41   train_loss:  524.8184339443052   time:  1.2927320003509521
e:  42   train_loss:  519.5069401282026   time:  1.299605369567871
e:  43   train_loss:  519.8296853760386   time:  1.296973466873169
e:  44   train_loss:  513.26021695928   time:  1.4171006679534912
e:  45   train_loss:  513.5828144371249   time:  1.2802245616912842
e:  45   train_loss:  513.5828144371249   val_loss:  726.6215836735986   time:  1.3905458450317383
e:  46   train_loss:  511.7847449475374   time:  1.2947089672088623
e:  47   train_loss:  513.2978971240015   time:  1.2951462268829346
e:  48   train_loss:  512.277634263848   time:  1.2864511013031006
e:  49   train_loss:  509.40600568950987   time:  1.295790672302246
e:  50   train_loss:  507.9080087420056   time:  1.2912483215332031
e:  50   train_loss:  507.9080087420056   val_loss:  754.8726900484957   time:  1.4013886451721191
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1039.863400325715   time:  1.4194567203521729
e:  0   train_loss:  1039.863400325715   val_loss:  573.17033591367   time:  1.524573802947998
e:  1   train_loss:  907.2632930898965   time:  1.5421257019042969
e:  2   train_loss:  898.2269847113162   time:  1.406625509262085
e:  3   train_loss:  893.6316099114858   time:  1.3805911540985107
e:  4   train_loss:  871.2132091256426   time:  1.4126908779144287
e:  5   train_loss:  874.7150077737265   time:  1.417374849319458
e:  5   train_loss:  874.7150077737265   val_loss:  553.7213940185256   time:  1.5215811729431152
e:  6   train_loss:  824.0529993022506   time:  1.4172101020812988
e:  7   train_loss:  786.7531534060387   time:  1.4073638916015625
e:  8   train_loss:  745.8743383788599   time:  1.549046277999878
e:  9   train_loss:  701.1169593444142   time:  1.416649580001831
e:  10   train_loss:  676.8424973760589   time:  1.4173195362091064
e:  10   train_loss:  676.8424973760589   val_loss:  584.4407181487902   time:  1.5223734378814697
e:  11   train_loss:  644.4659598510732   time:  1.4204421043395996
e:  12   train_loss:  628.6768495880251   time:  1.4191093444824219
e:  13   train_loss:  628.1468478019195   time:  1.4158799648284912
e:  14   train_loss:  620.3594838073955   time:  1.4185099601745605
e:  15   train_loss:  607.6529854214166   time:  1.5427634716033936
e:  15   train_loss:  607.6529854214166   val_loss:  580.7660621580181   time:  1.6420512199401855
e:  16   train_loss:  601.9509643669626   time:  1.4093809127807617
e:  17   train_loss:  599.9035878718602   time:  1.418623447418213
e:  18   train_loss:  580.7436086892321   time:  1.418360710144043
e:  19   train_loss:  582.2096182722794   time:  1.4162952899932861
e:  20   train_loss:  587.1173926540391   time:  1.4176926612854004
e:  20   train_loss:  587.1173926540391   val_loss:  586.3109216756933   time:  1.5218892097473145
e:  21   train_loss:  579.6578334268133   time:  1.4200429916381836
e:  22   train_loss:  575.1376048539797   time:  1.558037519454956
e:  23   train_loss:  594.9418494658762   time:  1.3720173835754395
e:  24   train_loss:  571.8664204633928   time:  1.4972081184387207
e:  25   train_loss:  583.1825730864093   time:  1.4374864101409912
e:  25   train_loss:  583.1825730864093   val_loss:  585.5318624047851   time:  1.5421702861785889
e:  26   train_loss:  571.0404209986295   time:  1.411353588104248
e:  27   train_loss:  577.1293194116338   time:  1.407724380493164
e:  28   train_loss:  568.5181355533534   time:  1.5545306205749512
e:  29   train_loss:  574.0039072764013   time:  1.4151723384857178
e:  30   train_loss:  570.2797410412463   time:  1.4138247966766357
e:  30   train_loss:  570.2797410412463   val_loss:  603.3546530752444   time:  1.5192320346832275
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  31   train_loss:  569.0883395293736   time:  1.413278341293335
e:  32   train_loss:  572.3040450660227   time:  1.4084396362304688
e:  33   train_loss:  564.9336265362323   time:  1.414228916168213
e:  34   train_loss:  565.220769573744   time:  1.5794289112091064
e:  35   train_loss:  572.8194501699788   time:  1.5073199272155762
e:  35   train_loss:  572.8194501699788   val_loss:  595.0730584232718   time:  1.6113977432250977
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 14), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 14) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 14) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 14) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 14)
kwargs: {'config': {'batch_norm': False, 'ff_0': 214, 'ff_num_layers': 1, 'gnn_0': 1421, 'gnn_dropout': 0.48575232412252367, 'gnn_num_layers': 1, 'hid_0': 366, 'hid_dropout_rate': 0.16943484925922442, 'in_dropout_rate': 0.16962245313039404, 'lr': 0.000645480083493207, 'num_hid_layers': 2, 'optimizer': 'Adam', 'hid_1': 244}, 'budget': 81.0, 'working_directory': '.'}
result: {'loss': 723.4526805168413, 'n_epochs': 38.0, 'info': {'validation loss': 723.4526805168413}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 14) started
DEBUG:hpbandster:job_callback for (0, 0, 14) got condition
DEBUG:hpbandster:Only 3 run(s) for budget 81.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 14) finished
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 15) to dispatcher
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 15) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 15)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 15) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 15) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 15)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 30, 'ff_num_layers': 1, 'gnn_0': 1724, 'gnn_dropout': 0.16203243204750928, 'gnn_num_layers': 3, 'hid_0': 1259, 'hid_dropout_rate': 0.4895906060940636, 'in_dropout_rate': 0.17717454867023485, 'lr': 0.001508840596256224, 'num_hid_layers': 3, 'optimizer': 'SGD', 'gnn_1': 1662, 'gnn_2': 71, 'hid_1': 1500, 'hid_2': 256, 'sgd_momentum': 0.6568930593605463}, 'budget': 81.0, 'working_directory': '.'}
FOLD:  0
DEBUG:hpbandster:DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
Model initialization done
Model training starts
e:  0   train_loss:  702.5206306586283   time:  1.7870936393737793
e:  0   train_loss:  702.5206306586283   val_loss:  1645.3995336412331   time:  1.9117810726165771
e:  1   train_loss:  656.2595348332276   time:  1.806875467300415
e:  2   train_loss:  582.4677551712759   time:  1.8007597923278809
e:  3   train_loss:  555.025016486257   time:  1.881688117980957
e:  4   train_loss:  546.2341953397342   time:  1.6327793598175049
e:  5   train_loss:  521.9900651963228   time:  1.685591459274292
e:  5   train_loss:  521.9900651963228   val_loss:  1510.3790101438542   time:  1.8116357326507568
e:  6   train_loss:  508.59864415398386   time:  1.6084907054901123
e:  7   train_loss:  518.6237675626621   time:  2.0437819957733154
e:  8   train_loss:  478.49048221635434   time:  1.7207224369049072
e:  9   train_loss:  468.4949168280083   time:  1.6915299892425537
e:  10   train_loss:  531.4426880975891   time:  1.7424399852752686
e:  10   train_loss:  531.4426880975891   val_loss:  1375.3564085560351   time:  1.8671534061431885
e:  11   train_loss:  484.8292362419221   time:  1.705033779144287
e:  12   train_loss:  451.15239951235964   time:  1.7024321556091309
e:  13   train_loss:  446.54688125555856   time:  1.7020864486694336
e:  14   train_loss:  472.19047655771675   time:  1.698103666305542
e:  15   train_loss:  432.83419594995974   time:  1.7039375305175781
e:  15   train_loss:  432.83419594995974   val_loss:  1433.7093566658746   time:  1.8289556503295898
e:  16   train_loss:  497.83438994915554   time:  1.6990923881530762
e:  17   train_loss:  474.4198565074382   time:  1.698941707611084
e:  18   train_loss:  436.0492919926911   time:  1.9280483722686768
e:  19   train_loss:  420.90659062713416   time:  1.714540719985962
e:  20   train_loss:  416.10583952868416   time:  1.7685546875
e:  20   train_loss:  416.10583952868416   val_loss:  1600.729040283937   time:  1.8918161392211914
e:  21   train_loss:  399.2360313401558   time:  1.7700984477996826
e:  22   train_loss:  446.7297743594464   time:  1.7869198322296143
e:  23   train_loss:  470.8340546008457   time:  1.62457275390625
e:  24   train_loss:  419.2137239254228   time:  1.669050931930542
e:  25   train_loss:  404.6670184865711   time:  1.6873486042022705
e:  25   train_loss:  404.6670184865711   val_loss:  1541.6383202413176   time:  1.8126862049102783
e:  26   train_loss:  389.8694985769922   time:  1.8088316917419434
e:  27   train_loss:  424.46896031779056   time:  1.6972665786743164
e:  28   train_loss:  460.2694635176773   time:  1.695789098739624
e:  29   train_loss:  414.6466893384898   time:  1.7026891708374023
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  30   train_loss:  410.5130138516399   time:  1.7330739498138428
e:  30   train_loss:  410.5130138516399   val_loss:  1387.404779964276   time:  1.8755488395690918
e:  31   train_loss:  389.356867327781   time:  1.6744446754455566
e:  32   train_loss:  409.94163085200876   time:  1.69502854347229
e:  33   train_loss:  432.9937178800976   time:  1.7059226036071777
e:  34   train_loss:  409.29646835618473   time:  1.695713996887207
e:  35   train_loss:  376.8084815404365   time:  1.7068588733673096
e:  35   train_loss:  376.8084815404365   val_loss:  1557.7214104702907   time:  1.9579432010650635
e:  36   train_loss:  407.57331847816323   time:  1.6868000030517578
e:  37   train_loss:  389.8442582395042   time:  1.705245018005371
e:  38   train_loss:  465.8773612551568   time:  1.6396923065185547
e:  39   train_loss:  456.81502568946985   time:  1.689965009689331
e:  40   train_loss:  399.52217620669245   time:  1.6490249633789062
e:  40   train_loss:  399.52217620669245   val_loss:  1532.314285019285   time:  1.7714731693267822
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1060.3790858167201   time:  1.8308720588684082
e:  0   train_loss:  1060.3790858167201   val_loss:  595.0434987472679   time:  1.9492557048797607
e:  1   train_loss:  908.8641434261003   time:  1.8629117012023926
e:  2   train_loss:  779.1089926496908   time:  1.8588805198669434
e:  3   train_loss:  804.2626575511321   time:  1.9487783908843994
e:  4   train_loss:  735.7029050639608   time:  1.8593308925628662
e:  5   train_loss:  722.7463675793844   time:  1.8027405738830566
e:  5   train_loss:  722.7463675793844   val_loss:  1376.8456145524235   time:  1.91917085647583
e:  6   train_loss:  793.245890879632   time:  1.8568158149719238
e:  7   train_loss:  742.1225102863887   time:  1.8593499660491943
e:  8   train_loss:  665.858765111801   time:  1.8534975051879883
e:  9   train_loss:  657.8422233397245   time:  1.8908350467681885
e:  10   train_loss:  780.2004223759847   time:  1.9391369819641113
e:  10   train_loss:  780.2004223759847   val_loss:  1356.273132820724   time:  2.0642051696777344
e:  11   train_loss:  697.1325403985107   time:  1.8959336280822754
e:  12   train_loss:  728.4552700201357   time:  1.841914176940918
e:  13   train_loss:  673.3801140433083   time:  1.859933614730835
e:  14   train_loss:  687.7441468706797   time:  1.8563787937164307
e:  15   train_loss:  700.1245417847671   time:  1.773080587387085
e:  15   train_loss:  700.1245417847671   val_loss:  888.11091371904   time:  2.0124948024749756
e:  16   train_loss:  691.1855350531013   time:  1.8320443630218506
e:  17   train_loss:  646.8880205923764   time:  1.8222193717956543
e:  18   train_loss:  665.8106448110295   time:  1.7618391513824463
e:  19   train_loss:  716.7987395182487   time:  2.0293197631835938
e:  20   train_loss:  685.5644084136733   time:  2.0048320293426514
e:  20   train_loss:  685.5644084136733   val_loss:  4435.375358338755   time:  2.1214048862457275
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  21   train_loss:  611.3799227272611   time:  1.9020042419433594
e:  22   train_loss:  608.4697486462163   time:  1.9086103439331055
e:  23   train_loss:  685.9966523399538   time:  1.9093759059906006
e:  24   train_loss:  620.0642232601983   time:  2.1252694129943848
e:  25   train_loss:  697.8878964608983   time:  2.0093891620635986
e:  25   train_loss:  697.8878964608983   val_loss:  638.277477504815   time:  2.119227409362793
e:  26   train_loss:  967.5997596503169   time:  1.9446585178375244
e:  27   train_loss:  911.2920559857901   time:  1.920036792755127
e:  28   train_loss:  860.6648987767753   time:  1.8836102485656738
e:  29   train_loss:  920.3814779887697   time:  2.0105855464935303
e:  30   train_loss:  931.2877072262504   time:  2.094226837158203
e:  30   train_loss:  931.2877072262504   val_loss:  558.2939371612841   time:  2.2089810371398926
e:  31   train_loss:  906.9199809235264   time:  1.8475935459136963
e:  32   train_loss:  922.8507061952597   time:  1.8407599925994873
e:  33   train_loss:  879.9410513789376   time:  1.8755199909210205
e:  34   train_loss:  924.9363338277903   time:  1.857480525970459
e:  35   train_loss:  897.3898734043808   time:  1.8968660831451416
e:  35   train_loss:  897.3898734043808   val_loss:  534.4138218860227   time:  2.189582347869873
e:  36   train_loss:  872.3460801768852   time:  1.914353609085083
e:  37   train_loss:  946.9352229445635   time:  1.9256255626678467
e:  38   train_loss:  906.1588897440996   time:  1.9094822406768799
e:  39   train_loss:  898.496843558492   time:  1.9166967868804932
e:  40   train_loss:  873.935744919864   time:  1.880126714706421
e:  40   train_loss:  873.935744919864   val_loss:  652.8126073168818   time:  1.9948837757110596
e:  41   train_loss:  849.4213679901715   time:  1.9500317573547363
e:  42   train_loss:  835.3052951308941   time:  2.158181667327881
e:  43   train_loss:  727.2601030910599   time:  1.861387014389038
e:  44   train_loss:  708.1288702024701   time:  1.7777185440063477
e:  45   train_loss:  680.3120104119521   time:  1.8323242664337158
e:  45   train_loss:  680.3120104119521   val_loss:  545.9183034092051   time:  1.9477441310882568
e:  46   train_loss:  650.7085900418951   time:  1.763639211654663
e:  47   train_loss:  772.0765856098327   time:  1.9287405014038086
e:  48   train_loss:  832.0144372506422   time:  2.173970937728882
e:  49   train_loss:  710.6568328660383   time:  1.949207067489624
e:  50   train_loss:  679.8220673239949   time:  2.0108261108398438
e:  50   train_loss:  679.8220673239949   val_loss:  564.8739308363777   time:  2.148547887802124
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  51   train_loss:  711.0581132425091   time:  2.0048627853393555
e:  52   train_loss:  851.3418252470744   time:  1.8601434230804443
e:  53   train_loss:  670.9254259214321   time:  1.8659217357635498
e:  54   train_loss:  665.4656648412843   time:  1.86152982711792
e:  55   train_loss:  627.5669465826641   time:  1.991567611694336
e:  55   train_loss:  627.5669465826641   val_loss:  664.9419227659303   time:  2.1089043617248535
e:  56   train_loss:  606.2965277145315   time:  1.8544907569885254
e:  57   train_loss:  626.7287776390066   time:  1.8616037368774414
e:  58   train_loss:  593.7624589509226   time:  1.8463165760040283
e:  59   train_loss:  557.7826225306261   time:  1.7838847637176514
e:  60   train_loss:  619.1522328983406   time:  1.847485065460205
e:  60   train_loss:  619.1522328983406   val_loss:  555.7423411597468   time:  1.963047742843628
e:  61   train_loss:  591.4109275680398   time:  1.790788173675537
e:  62   train_loss:  543.089554350032   time:  1.9135124683380127
e:  63   train_loss:  623.9094874668247   time:  1.7702655792236328
e:  64   train_loss:  596.2135913050435   time:  1.8232958316802979
e:  65   train_loss:  599.5657605655484   time:  1.9361815452575684
e:  65   train_loss:  599.5657605655484   val_loss:  813.5494880891521   time:  2.0527472496032715
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1152.8291772081413   time:  1.8790993690490723
e:  0   train_loss:  1152.8291772081413   val_loss:  515.8823219962751   time:  1.9976792335510254
e:  1   train_loss:  919.9820762418349   time:  2.1311092376708984
e:  2   train_loss:  798.7836295116018   time:  1.880561113357544
e:  3   train_loss:  796.7767363135414   time:  1.7889976501464844
e:  4   train_loss:  749.0894727087422   time:  1.7862224578857422
e:  5   train_loss:  826.0383265379223   time:  1.860671043395996
e:  5   train_loss:  826.0383265379223   val_loss:  932.7918091161202   time:  1.9782752990722656
e:  6   train_loss:  753.4019603595225   time:  1.8333327770233154
e:  7   train_loss:  766.1965669980995   time:  1.903334617614746
e:  8   train_loss:  834.3329616495896   time:  1.899280309677124
e:  9   train_loss:  1105.1161120280071   time:  1.8964428901672363
e:  10   train_loss:  997.6505601279122   time:  2.035205125808716
e:  10   train_loss:  997.6505601279122   val_loss:  468.93282368938253   time:  2.1545441150665283
e:  11   train_loss:  885.3268356105195   time:  1.821047067642212
e:  12   train_loss:  788.9395176244984   time:  1.8083326816558838
e:  13   train_loss:  729.7659928888982   time:  1.8026096820831299
e:  14   train_loss:  763.7319200432029   time:  1.8820977210998535
e:  15   train_loss:  981.9721946442666   time:  1.8946208953857422
e:  15   train_loss:  981.9721946442666   val_loss:  470.0113643232117   time:  2.0144083499908447
e:  16   train_loss:  863.6257468108402   time:  1.899512529373169
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  17   train_loss:  760.5678313745108   time:  2.2564828395843506
e:  18   train_loss:  815.1566805376763   time:  1.9034440517425537
e:  19   train_loss:  786.6504559339055   time:  1.9105517864227295
e:  20   train_loss:  743.9295183768284   time:  1.8606457710266113
e:  20   train_loss:  743.9295183768284   val_loss:  554.663711126343   time:  1.97886061668396
e:  21   train_loss:  701.8983246368937   time:  1.8118727207183838
e:  22   train_loss:  745.6675847949318   time:  1.881120204925537
e:  23   train_loss:  862.1213912475574   time:  1.7763311862945557
e:  24   train_loss:  887.3125716321646   time:  1.8631420135498047
e:  25   train_loss:  860.7998289954919   time:  2.0615315437316895
e:  25   train_loss:  860.7998289954919   val_loss:  468.1895341317721   time:  2.1813063621520996
e:  26   train_loss:  954.7920587033623   time:  1.8464531898498535
e:  27   train_loss:  900.2965324975843   time:  1.883396863937378
e:  28   train_loss:  891.408613579531   time:  1.9900388717651367
e:  29   train_loss:  914.0907411568774   time:  1.9514307975769043
e:  30   train_loss:  838.2213665185361   time:  1.9711079597473145
e:  30   train_loss:  838.2213665185361   val_loss:  473.00895802285106   time:  2.0938777923583984
e:  31   train_loss:  828.953742630301   time:  1.8822216987609863
e:  32   train_loss:  770.2344114482304   time:  2.050724744796753
e:  33   train_loss:  730.7154141086638   time:  1.850879430770874
e:  34   train_loss:  676.5130711938183   time:  1.8749544620513916
e:  35   train_loss:  694.1022652189646   time:  1.8841450214385986
e:  35   train_loss:  694.1022652189646   val_loss:  566.7817238806476   time:  2.0050227642059326
e:  36   train_loss:  750.8294324126842   time:  1.7733657360076904
e:  37   train_loss:  743.3002021337356   time:  1.848322868347168
e:  38   train_loss:  762.8371566162909   time:  2.026376247406006
e:  39   train_loss:  683.5889951098197   time:  1.896822452545166
e:  40   train_loss:  671.2443492561596   time:  1.9545257091522217
e:  40   train_loss:  671.2443492561596   val_loss:  460.1562633160736   time:  2.075512647628784
e:  41   train_loss:  739.7103807426888   time:  1.8362345695495605
e:  42   train_loss:  713.2265514914575   time:  1.7592017650604248
e:  43   train_loss:  671.6022304452157   time:  1.78147554397583
e:  44   train_loss:  706.3436738709021   time:  1.8041670322418213
e:  45   train_loss:  655.2641542034562   time:  1.7710165977478027
e:  45   train_loss:  655.2641542034562   val_loss:  488.9172159890908   time:  1.8872201442718506
e:  46   train_loss:  647.2628540106147   time:  1.9317331314086914
e:  47   train_loss:  723.968397824719   time:  1.791294813156128
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  48   train_loss:  693.395697542273   time:  1.76212477684021
e:  49   train_loss:  619.3276904908272   time:  2.0095436573028564
e:  50   train_loss:  606.9228949766762   time:  2.0301835536956787
e:  50   train_loss:  606.9228949766762   val_loss:  562.9104636185067   time:  2.1749627590179443
e:  51   train_loss:  599.1731289358269   time:  2.0364696979522705
e:  52   train_loss:  778.9826663128259   time:  1.9432451725006104
e:  53   train_loss:  703.5917132585259   time:  1.9252231121063232
e:  54   train_loss:  717.9294139397124   time:  2.1043968200683594
e:  55   train_loss:  877.182235705751   time:  1.9458322525024414
e:  55   train_loss:  877.182235705751   val_loss:  460.79174718237425   time:  2.0666346549987793
e:  56   train_loss:  765.2078897219637   time:  1.876906156539917
e:  57   train_loss:  776.3421330724345   time:  1.825547695159912
e:  58   train_loss:  744.4420704725677   time:  1.8470699787139893
e:  59   train_loss:  736.0777755912428   time:  1.955049753189087
e:  60   train_loss:  668.2369775661869   time:  1.8177971839904785
e:  60   train_loss:  668.2369775661869   val_loss:  515.7421171380238   time:  1.9353361129760742
e:  61   train_loss:  656.9648874856159   time:  1.842907428741455
e:  62   train_loss:  635.4534518966657   time:  2.1316208839416504
e:  63   train_loss:  599.139909894337   time:  1.92490553855896
e:  64   train_loss:  561.6726459114892   time:  1.8643653392791748
e:  65   train_loss:  580.9564424853305   time:  1.9132275581359863
e:  65   train_loss:  580.9564424853305   val_loss:  468.1079026747305   time:  2.034351110458374
e:  66   train_loss:  559.0701242404105   time:  1.950927734375
e:  67   train_loss:  543.7807509792698   time:  1.8716402053833008
e:  68   train_loss:  534.2347308383602   time:  1.939345359802246
e:  69   train_loss:  523.54932603653   time:  2.071258068084717
e:  70   train_loss:  539.0758352581976   time:  1.9232170581817627
e:  70   train_loss:  539.0758352581976   val_loss:  511.59027865010336   time:  2.0458381175994873
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  990.9928282909216   time:  1.8073983192443848
e:  0   train_loss:  990.9928282909216   val_loss:  890.2442530406413   time:  1.9357690811157227
e:  1   train_loss:  903.5022795818286   time:  1.8156142234802246
e:  2   train_loss:  761.8049481776469   time:  1.740675687789917
e:  3   train_loss:  711.5931758981268   time:  1.784576654434204
e:  4   train_loss:  804.7491680713773   time:  1.7672991752624512
e:  5   train_loss:  917.9291345208975   time:  1.7863800525665283
e:  5   train_loss:  917.9291345208975   val_loss:  745.472468245624   time:  1.9141368865966797
e:  6   train_loss:  756.8584026980083   time:  2.0147624015808105
e:  7   train_loss:  694.7198165581106   time:  1.7524487972259521
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  8   train_loss:  698.6600157166137   time:  1.8172085285186768
e:  9   train_loss:  700.8662000550163   time:  1.8107011318206787
e:  10   train_loss:  663.8886391555977   time:  1.8081457614898682
e:  10   train_loss:  663.8886391555977   val_loss:  716.4216656004336   time:  1.9344630241394043
e:  11   train_loss:  656.7210403824398   time:  1.8119840621948242
e:  12   train_loss:  648.8932691879696   time:  1.8238112926483154
e:  13   train_loss:  668.8152469071846   time:  1.775383472442627
e:  14   train_loss:  637.8364058608165   time:  1.7907211780548096
e:  15   train_loss:  660.1663549866942   time:  1.8141794204711914
e:  15   train_loss:  660.1663549866942   val_loss:  759.4874366936568   time:  1.9431307315826416
e:  16   train_loss:  719.2751581515479   time:  1.8121271133422852
e:  17   train_loss:  676.973014448775   time:  1.8035695552825928
e:  18   train_loss:  625.8240015325562   time:  1.9502489566802979
e:  19   train_loss:  621.0685028606134   time:  1.7112305164337158
e:  20   train_loss:  612.2999776413851   time:  1.7402803897857666
e:  20   train_loss:  612.2999776413851   val_loss:  809.2698318329492   time:  1.8690965175628662
e:  21   train_loss:  646.3084295620463   time:  1.7873494625091553
e:  22   train_loss:  608.6791843555558   time:  1.7756316661834717
e:  23   train_loss:  619.202839414018   time:  1.803065299987793
e:  24   train_loss:  635.7373154766731   time:  1.7896931171417236
e:  25   train_loss:  648.516293341732   time:  1.7932655811309814
e:  25   train_loss:  648.516293341732   val_loss:  726.7231897937211   time:  1.9199118614196777
e:  26   train_loss:  612.4684801939218   time:  1.7570981979370117
e:  27   train_loss:  595.2307972823935   time:  1.7417962551116943
e:  28   train_loss:  611.2035977494984   time:  1.7426416873931885
e:  29   train_loss:  643.0287352560838   time:  1.756403923034668
e:  30   train_loss:  590.3475696293864   time:  1.7921457290649414
e:  30   train_loss:  590.3475696293864   val_loss:  699.6968448699964   time:  1.916900634765625
e:  31   train_loss:  568.7111189042168   time:  1.948641061782837
e:  32   train_loss:  577.9912601792787   time:  1.750413417816162
e:  33   train_loss:  573.6925714066726   time:  1.7595553398132324
e:  34   train_loss:  565.9466087835177   time:  1.7062106132507324
e:  35   train_loss:  643.9277709665158   time:  1.6171398162841797
e:  35   train_loss:  643.9277709665158   val_loss:  692.647238126838   time:  1.7394006252288818
e:  36   train_loss:  646.6232164355715   time:  1.6646435260772705
e:  37   train_loss:  590.0277606866953   time:  1.7050449848175049
e:  38   train_loss:  575.1434304356691   time:  1.6972935199737549
e:  39   train_loss:  561.2570086298775   time:  1.69746994972229
e:  40   train_loss:  536.9925762864382   time:  1.7002854347229004
e:  40   train_loss:  536.9925762864382   val_loss:  668.7451642684376   time:  1.8260772228240967
e:  41   train_loss:  545.3488116581815   time:  1.7189052104949951
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  42   train_loss:  657.9735031807785   time:  1.6999409198760986
e:  43   train_loss:  968.2448370127056   time:  1.829216480255127
e:  44   train_loss:  922.8508061952076   time:  1.6885278224945068
e:  45   train_loss:  851.7532374693858   time:  1.6399264335632324
e:  45   train_loss:  851.7532374693858   val_loss:  751.8195984289347   time:  1.7643046379089355
e:  46   train_loss:  843.0381603498828   time:  1.6821815967559814
e:  47   train_loss:  842.8527646736059   time:  1.6970245838165283
e:  48   train_loss:  849.8527533026563   time:  1.698129653930664
e:  49   train_loss:  830.2678875548687   time:  1.7029967308044434
e:  50   train_loss:  823.4846042756786   time:  1.702606201171875
e:  50   train_loss:  823.4846042756786   val_loss:  748.8903416398979   time:  1.8292853832244873
e:  51   train_loss:  797.879758281275   time:  1.7026965618133545
e:  52   train_loss:  881.5656560823937   time:  1.6607773303985596
e:  53   train_loss:  906.2639303874378   time:  1.6359844207763672
e:  54   train_loss:  868.951419214871   time:  1.7022643089294434
e:  55   train_loss:  845.4889212799178   time:  1.7065603733062744
e:  55   train_loss:  845.4889212799178   val_loss:  744.7463607231874   time:  1.8319628238677979
e:  56   train_loss:  842.3230313982802   time:  1.8231525421142578
e:  57   train_loss:  836.4124946504841   time:  1.701526165008545
e:  58   train_loss:  829.1855770724358   time:  1.7016139030456543
e:  59   train_loss:  783.3827183707286   time:  1.6949729919433594
e:  60   train_loss:  773.1381314534115   time:  1.6999163627624512
e:  60   train_loss:  773.1381314534115   val_loss:  751.1376595873521   time:  1.8252589702606201
e:  61   train_loss:  720.639220368576   time:  1.6974108219146729
e:  62   train_loss:  720.1993204020622   time:  1.7062718868255615
e:  63   train_loss:  725.6409070950007   time:  1.6988716125488281
e:  64   train_loss:  686.5086415198747   time:  1.6947214603424072
e:  65   train_loss:  716.7020833497884   time:  1.7050395011901855
e:  65   train_loss:  716.7020833497884   val_loss:  781.0542188381119   time:  1.8311669826507568
e:  66   train_loss:  754.7189191758289   time:  1.699958086013794
e:  67   train_loss:  678.2680415023705   time:  1.7011277675628662
e:  68   train_loss:  656.2613963692049   time:  1.829784870147705
e:  69   train_loss:  672.7918516428886   time:  1.7038545608520508
e:  70   train_loss:  728.8544150265091   time:  1.6447746753692627
e:  70   train_loss:  728.8544150265091   val_loss:  1429.8556360096552   time:  1.7684893608093262
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1050.5631918504373   time:  1.956108808517456
e:  0   train_loss:  1050.5631918504373   val_loss:  658.0139328419624   time:  2.0685956478118896
e:  1   train_loss:  933.9463633008428   time:  1.9116063117980957
e:  2   train_loss:  752.4804662169004   time:  1.8572986125946045
e:  3   train_loss:  944.5710348108983   time:  1.7785146236419678
e:  4   train_loss:  878.1833407473882   time:  1.9495511054992676
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  5   train_loss:  803.2140224749669   time:  1.8675627708435059
e:  5   train_loss:  803.2140224749669   val_loss:  1046.450581892709   time:  1.984931230545044
e:  6   train_loss:  831.5671076721173   time:  1.7875208854675293
e:  7   train_loss:  987.1597564806686   time:  1.8568108081817627
e:  8   train_loss:  773.3306231374487   time:  1.861903190612793
e:  9   train_loss:  728.2333884044167   time:  1.857255220413208
e:  10   train_loss:  758.2508723179407   time:  1.9451484680175781
e:  10   train_loss:  758.2508723179407   val_loss:  3233780057.7123084   time:  2.0653369426727295
e:  11   train_loss:  774.0598397984573   time:  1.86238694190979
e:  12   train_loss:  751.3976070151006   time:  1.8339526653289795
e:  13   train_loss:  706.9813394421553   time:  1.856916904449463
e:  14   train_loss:  892.9762754201079   time:  1.7661395072937012
e:  15   train_loss:  712.9766237440595   time:  1.7648329734802246
e:  15   train_loss:  712.9766237440595   val_loss:  548.5806559285016   time:  2.0071141719818115
e:  16   train_loss:  711.2541011340104   time:  1.8581790924072266
e:  17   train_loss:  872.9350736671661   time:  1.772496223449707
e:  18   train_loss:  752.5199499214395   time:  1.8271138668060303
e:  19   train_loss:  718.1849914925651   time:  1.8524892330169678
e:  20   train_loss:  856.6115964271735   time:  1.788658857345581
e:  20   train_loss:  856.6115964271735   val_loss:  560.3715909876656   time:  1.9051566123962402
e:  21   train_loss:  796.737915255634   time:  1.7668836116790771
e:  22   train_loss:  763.2990218301863   time:  1.959233283996582
e:  23   train_loss:  699.6211737410172   time:  1.786238431930542
e:  24   train_loss:  700.6918169193552   time:  1.7606356143951416
e:  25   train_loss:  714.0636886327925   time:  1.8212776184082031
e:  25   train_loss:  714.0636886327925   val_loss:  556.6678528120397   time:  1.9412689208984375
e:  26   train_loss:  724.8667043702018   time:  1.858640432357788
e:  27   train_loss:  710.1525179355253   time:  1.8638725280761719
e:  28   train_loss:  660.8931583124627   time:  1.9958786964416504
e:  29   train_loss:  705.4121738704172   time:  1.8587610721588135
e:  30   train_loss:  709.5469761637944   time:  1.77097749710083
e:  30   train_loss:  709.5469761637944   val_loss:  572.0593779887081   time:  1.887885332107544
e:  31   train_loss:  761.5683059025209   time:  1.7722930908203125
e:  32   train_loss:  739.0604090437149   time:  1.8511090278625488
e:  33   train_loss:  682.8799948310566   time:  1.8622913360595703
e:  34   train_loss:  637.505792134364   time:  1.8641741275787354
e:  35   train_loss:  768.6555314769955   time:  1.9194011688232422
e:  35   train_loss:  768.6555314769955   val_loss:  561.793475179028   time:  2.0374481678009033
e:  36   train_loss:  694.5875926186245   time:  1.8525099754333496
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  37   train_loss:  672.408685371289   time:  1.8634099960327148
e:  38   train_loss:  700.7098813476156   time:  1.8457152843475342
e:  39   train_loss:  649.846120773087   time:  1.8231236934661865
e:  40   train_loss:  600.4934796187428   time:  1.8569397926330566
e:  40   train_loss:  600.4934796187428   val_loss:  554.5599546203135   time:  1.9744703769683838
e:  41   train_loss:  609.81793478115   time:  1.8154182434082031
e:  42   train_loss:  668.9356834033929   time:  1.9940860271453857
e:  43   train_loss:  714.4662384908081   time:  1.8635034561157227
e:  44   train_loss:  658.7434446634592   time:  1.8591375350952148
e:  45   train_loss:  764.6137363885749   time:  1.7899866104125977
e:  45   train_loss:  764.6137363885749   val_loss:  561.8696863807123   time:  1.90632963180542
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 15), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 15) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 15) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 15) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 15)
kwargs: {'config': {'batch_norm': True, 'ff_0': 30, 'ff_num_layers': 1, 'gnn_0': 1724, 'gnn_dropout': 0.16203243204750928, 'gnn_num_layers': 3, 'hid_0': 1259, 'hid_dropout_rate': 0.4895906060940636, 'in_dropout_rate': 0.17717454867023485, 'lr': 0.001508840596256224, 'num_hid_layers': 3, 'optimizer': 'SGD', 'gnn_1': 1662, 'gnn_2': 71, 'hid_1': 1500, 'hid_2': 256, 'sgd_momentum': 0.6568930593605463}, 'budget': 81.0, 'working_directory': '.'}
result: {'loss': 717.450462791014, 'n_epochs': 58.0, 'info': {'validation loss': 717.450462791014}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 15) started
DEBUG:hpbandster:job_callback for (0, 0, 15) got condition
DEBUG:hpbandster:Only 4 run(s) for budget 81.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 15) finished
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 16) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 16) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 16)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 16) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 16) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 16)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 455, 'ff_num_layers': 2, 'gnn_0': 1251, 'gnn_dropout': 0.20395971160240467, 'gnn_num_layers': 3, 'hid_0': 650, 'hid_dropout_rate': 0.13942129792862107, 'in_dropout_rate': 0.1608907178961747, 'lr': 0.0009490287408787803, 'num_hid_layers': 1, 'optimizer': 'SGD', 'ff_1': 47, 'gnn_1': 254, 'gnn_2': 178, 'sgd_momentum': 0.5692253051349879}, 'budget': 81.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  682.7492905909835   time:  1.4135065078735352
e:  0   train_loss:  682.7492905909835   val_loss:  1512.2651770992836   time:  1.5270726680755615
e:  1   train_loss:  602.0699490976477   time:  1.410140037536621
e:  2   train_loss:  594.7437407956079   time:  1.6227879524230957
e:  3   train_loss:  591.4322044842626   time:  1.4700675010681152
e:  4   train_loss:  588.6632745484782   time:  1.441981315612793
e:  5   train_loss:  585.7362289465285   time:  1.4442827701568604
e:  5   train_loss:  585.7362289465285   val_loss:  1392.813799483337   time:  1.5590662956237793
e:  6   train_loss:  582.2100161545311   time:  1.4568991661071777
e:  7   train_loss:  578.9080045893947   time:  1.4616870880126953
e:  8   train_loss:  573.6032558402732   time:  1.4335150718688965
e:  9   train_loss:  568.4367754294907   time:  1.3912644386291504
e:  10   train_loss:  563.8632190504071   time:  1.3922209739685059
e:  10   train_loss:  563.8632190504071   val_loss:  1390.5085993751052   time:  1.5058345794677734
e:  11   train_loss:  559.303711316792   time:  1.3904907703399658
e:  12   train_loss:  554.8143381471959   time:  1.389868974685669
e:  13   train_loss:  549.8448051445886   time:  1.5206990242004395
e:  14   train_loss:  545.7131077671202   time:  1.3762941360473633
e:  15   train_loss:  541.3570839701941   time:  1.385591983795166
e:  15   train_loss:  541.3570839701941   val_loss:  1383.2895020991846   time:  1.4998748302459717
e:  16   train_loss:  537.4584452271955   time:  1.3930132389068604
e:  17   train_loss:  533.9405442635434   time:  1.388965368270874
e:  18   train_loss:  530.2118318351413   time:  1.389838457107544
e:  19   train_loss:  526.4143234759026   time:  1.5080580711364746
e:  20   train_loss:  523.2499985795091   time:  1.4560048580169678
e:  20   train_loss:  523.2499985795091   val_loss:  1377.8345648491966   time:  1.5699214935302734
e:  21   train_loss:  520.2077881268531   time:  1.483161449432373
e:  22   train_loss:  516.9008283227553   time:  1.3575832843780518
e:  23   train_loss:  513.8262354080186   time:  1.3893721103668213
e:  24   train_loss:  510.5283372455764   time:  1.392880916595459
e:  25   train_loss:  507.5978596234768   time:  1.3876922130584717
e:  25   train_loss:  507.5978596234768   val_loss:  1381.8214610401353   time:  1.5021586418151855
e:  26   train_loss:  503.9894987584748   time:  1.392425775527954
e:  27   train_loss:  502.85896589404376   time:  1.390990972518921
e:  28   train_loss:  499.32520835723966   time:  1.3925132751464844
e:  29   train_loss:  496.0977576432665   time:  1.3883473873138428
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  30   train_loss:  493.7138118033998   time:  1.3949854373931885
e:  30   train_loss:  493.7138118033998   val_loss:  1384.6231050347724   time:  1.6380054950714111
e:  31   train_loss:  492.03052548017524   time:  1.377000093460083
e:  32   train_loss:  490.3414093580419   time:  1.387852430343628
e:  33   train_loss:  486.43272136595   time:  1.3868331909179688
e:  34   train_loss:  484.1857089922053   time:  1.3912694454193115
e:  35   train_loss:  482.446360961683   time:  1.390575885772705
e:  35   train_loss:  482.446360961683   val_loss:  1416.4823929779623   time:  1.504373550415039
e:  36   train_loss:  480.3210812107037   time:  1.394460916519165
e:  37   train_loss:  478.1388354529895   time:  1.3945555686950684
e:  38   train_loss:  477.02250801702786   time:  1.3929903507232666
e:  39   train_loss:  474.1305541573334   time:  1.3971364498138428
e:  40   train_loss:  474.60775191795864   time:  1.3878765106201172
e:  40   train_loss:  474.60775191795864   val_loss:  1415.3577671711985   time:  1.5013926029205322
e:  41   train_loss:  471.0614082937629   time:  1.5227885246276855
e:  42   train_loss:  468.9303459445578   time:  1.3604793548583984
e:  43   train_loss:  467.63492931030237   time:  1.3617875576019287
e:  44   train_loss:  465.42348863872104   time:  1.3928680419921875
e:  45   train_loss:  463.9035100003538   time:  1.3875012397766113
e:  45   train_loss:  463.9035100003538   val_loss:  1427.0862608198536   time:  1.5013930797576904
e:  46   train_loss:  463.39622307493244   time:  1.387343168258667
e:  47   train_loss:  461.00940818985663   time:  1.3948259353637695
e:  48   train_loss:  459.3493217305142   time:  1.3946995735168457
e:  49   train_loss:  458.44487607189143   time:  1.3855137825012207
e:  50   train_loss:  457.7035902685843   time:  1.3865320682525635
e:  50   train_loss:  457.7035902685843   val_loss:  1431.7076927294427   time:  1.626023530960083
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1042.6892242700674   time:  1.518571376800537
e:  0   train_loss:  1042.6892242700674   val_loss:  542.8318897773711   time:  1.6251301765441895
e:  1   train_loss:  908.72992002422   time:  1.5174038410186768
e:  2   train_loss:  895.0941228448397   time:  1.5173726081848145
e:  3   train_loss:  901.973960507203   time:  1.5189332962036133
e:  4   train_loss:  871.821294938831   time:  1.5118050575256348
e:  5   train_loss:  869.2387397456273   time:  1.5169990062713623
e:  5   train_loss:  869.2387397456273   val_loss:  545.7386801532826   time:  1.6241631507873535
e:  6   train_loss:  846.478722305117   time:  1.6548457145690918
e:  7   train_loss:  834.9709194478564   time:  1.5159614086151123
e:  8   train_loss:  833.6160369421123   time:  1.5166857242584229
e:  9   train_loss:  801.4382028097084   time:  1.5147583484649658
e:  10   train_loss:  778.5955677706573   time:  1.510148286819458
e:  10   train_loss:  778.5955677706573   val_loss:  552.2587321937705   time:  1.6161575317382812
e:  11   train_loss:  744.9031613942269   time:  1.7723357677459717
e:  12   train_loss:  740.0680026306804   time:  1.5112321376800537
e:  13   train_loss:  717.1574349959719   time:  1.6225440502166748
e:  14   train_loss:  710.2371187219106   time:  1.5162878036499023
e:  15   train_loss:  693.2147819838889   time:  1.5182271003723145
e:  15   train_loss:  693.2147819838889   val_loss:  575.9297081120144   time:  1.6249396800994873
e:  16   train_loss:  679.0700019946884   time:  1.5181641578674316
e:  17   train_loss:  667.8150462531412   time:  1.519218921661377
e:  18   train_loss:  659.619519279776   time:  1.5173535346984863
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  19   train_loss:  646.8271923642044   time:  1.512434959411621
e:  20   train_loss:  646.520960072942   time:  1.6831128597259521
e:  20   train_loss:  646.520960072942   val_loss:  577.6432875837676   time:  1.7895691394805908
e:  21   train_loss:  630.4457456667078   time:  1.5880725383758545
e:  22   train_loss:  634.3404731509468   time:  1.5447356700897217
e:  23   train_loss:  628.6706991887811   time:  1.5095539093017578
e:  24   train_loss:  615.8849528462306   time:  1.5152323246002197
e:  25   train_loss:  615.5732728315173   time:  1.8205180168151855
e:  25   train_loss:  615.5732728315173   val_loss:  570.5192451205485   time:  1.9275100231170654
e:  26   train_loss:  604.2056108879575   time:  1.5720701217651367
e:  27   train_loss:  616.4533472819622   time:  1.6515426635742188
e:  28   train_loss:  605.8798089987235   time:  1.5167698860168457
e:  29   train_loss:  597.3902848237713   time:  1.5148801803588867
e:  30   train_loss:  595.6798920436173   time:  1.4846470355987549
e:  30   train_loss:  595.6798920436173   val_loss:  574.115976118547   time:  1.5907328128814697
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1054.1744366020798   time:  1.4863107204437256
e:  0   train_loss:  1054.1744366020798   val_loss:  498.25563284894685   time:  1.5965042114257812
e:  1   train_loss:  893.1253282800334   time:  1.6127817630767822
e:  2   train_loss:  899.8663547912282   time:  1.4990451335906982
e:  3   train_loss:  917.9641036365408   time:  1.5001306533813477
e:  4   train_loss:  870.8309103592103   time:  1.752647876739502
e:  5   train_loss:  879.4243383716897   time:  1.4932286739349365
e:  5   train_loss:  879.4243383716897   val_loss:  488.0710996210677   time:  1.6021604537963867
e:  6   train_loss:  844.2334976773748   time:  1.4994587898254395
e:  7   train_loss:  910.3224339377643   time:  1.493788719177246
e:  8   train_loss:  822.76241130364   time:  1.4972457885742188
e:  9   train_loss:  840.1257209276695   time:  1.5012459754943848
e:  10   train_loss:  783.1235746616081   time:  1.6294634342193604
e:  10   train_loss:  783.1235746616081   val_loss:  504.68095008176357   time:  1.7389047145843506
e:  11   train_loss:  752.1398534877103   time:  1.4954192638397217
e:  12   train_loss:  747.494751881326   time:  1.4963202476501465
e:  13   train_loss:  756.738770245786   time:  1.503702163696289
e:  14   train_loss:  736.2418857144598   time:  1.5019359588623047
e:  15   train_loss:  740.4261861466539   time:  1.5026719570159912
e:  15   train_loss:  740.4261861466539   val_loss:  544.509647384259   time:  1.6122958660125732
e:  16   train_loss:  698.6055212013393   time:  1.5851399898529053
e:  17   train_loss:  703.0794480051082   time:  1.6330549716949463
e:  18   train_loss:  681.0496676670704   time:  1.619339942932129
e:  19   train_loss:  677.3795814258691   time:  1.5897531509399414
e:  20   train_loss:  666.5061065695849   time:  1.4975910186767578
e:  20   train_loss:  666.5061065695849   val_loss:  520.8528072797083   time:  1.60750412940979
e:  21   train_loss:  691.5521763754352   time:  1.4977400302886963
e:  22   train_loss:  655.4788671675466   time:  1.4980828762054443
e:  23   train_loss:  671.8463619708477   time:  1.4955880641937256
e:  24   train_loss:  663.3689434750772   time:  1.4996294975280762
e:  25   train_loss:  637.2197749858383   time:  1.6359529495239258
e:  25   train_loss:  637.2197749858383   val_loss:  499.4637881684005   time:  1.75111985206604
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  26   train_loss:  647.7982139496281   time:  1.5943803787231445
e:  27   train_loss:  644.0771274020638   time:  1.5690562725067139
e:  28   train_loss:  635.8163567300504   time:  1.62835693359375
e:  29   train_loss:  653.3447416743525   time:  1.562671184539795
e:  30   train_loss:  634.8313970541682   time:  1.5711863040924072
e:  30   train_loss:  634.8313970541682   val_loss:  495.6707458425961   time:  1.680586576461792
e:  31   train_loss:  657.3992847426657   time:  1.5759491920471191
e:  32   train_loss:  624.5002889354258   time:  1.7965123653411865
e:  33   train_loss:  639.7049105971951   time:  1.5943067073822021
e:  34   train_loss:  637.9633581908372   time:  1.5094504356384277
e:  35   train_loss:  642.3968877619623   time:  1.5123894214630127
e:  35   train_loss:  642.3968877619623   val_loss:  518.3159685593159   time:  1.6232564449310303
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  960.1876627087732   time:  1.3800902366638184
e:  0   train_loss:  960.1876627087732   val_loss:  771.1725529316822   time:  1.4956963062286377
e:  1   train_loss:  844.5720445485733   time:  1.355191946029663
e:  2   train_loss:  835.8407419850969   time:  1.4573962688446045
e:  3   train_loss:  828.6557502752956   time:  1.3970069885253906
e:  4   train_loss:  825.2877349560893   time:  1.5110230445861816
e:  5   train_loss:  819.7225489851982   time:  1.387897253036499
e:  5   train_loss:  819.7225489851982   val_loss:  730.840885557909   time:  1.5023152828216553
e:  6   train_loss:  811.6505822178822   time:  1.3888871669769287
e:  7   train_loss:  803.6365222093591   time:  1.3860359191894531
e:  8   train_loss:  792.9941145577164   time:  1.3925354480743408
e:  9   train_loss:  781.9206051179656   time:  1.3873841762542725
e:  10   train_loss:  772.1254815389279   time:  1.3942697048187256
e:  10   train_loss:  772.1254815389279   val_loss:  710.0536627493861   time:  1.5533149242401123
e:  11   train_loss:  756.5689789392468   time:  1.579681634902954
e:  12   train_loss:  743.5740682120626   time:  1.4857144355773926
e:  13   train_loss:  732.271114868162   time:  1.3908722400665283
e:  14   train_loss:  720.0374441870753   time:  1.390516757965088
e:  15   train_loss:  709.6126007492054   time:  1.3895411491394043
e:  15   train_loss:  709.6126007492054   val_loss:  703.7496662720521   time:  1.5040168762207031
e:  16   train_loss:  700.5473261951263   time:  1.388880968093872
e:  17   train_loss:  691.7609725414503   time:  1.3889615535736084
e:  18   train_loss:  680.685480327835   time:  1.5308012962341309
e:  19   train_loss:  672.0673689388263   time:  1.450514793395996
e:  20   train_loss:  663.6895714290233   time:  1.3812532424926758
e:  20   train_loss:  663.6895714290233   val_loss:  704.4868978341574   time:  1.496129035949707
e:  21   train_loss:  655.7796489530936   time:  1.378187656402588
e:  22   train_loss:  649.0736156590691   time:  1.346116304397583
e:  23   train_loss:  642.2359504293   time:  1.3806464672088623
e:  24   train_loss:  635.8953390347847   time:  1.391462802886963
e:  25   train_loss:  632.1843618029841   time:  1.3909621238708496
e:  25   train_loss:  632.1843618029841   val_loss:  709.5590298503757   time:  1.5062329769134521
e:  26   train_loss:  624.5208884520274   time:  1.3907175064086914
e:  27   train_loss:  618.7973950368107   time:  1.384711503982544
e:  28   train_loss:  616.3811791406673   time:  1.391350507736206
e:  29   train_loss:  611.260626478822   time:  1.3925209045410156
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  30   train_loss:  608.4784155780575   time:  1.39150071144104
e:  30   train_loss:  608.4784155780575   val_loss:  706.9990073758768   time:  1.5065717697143555
e:  31   train_loss:  604.2239731925547   time:  1.5229833126068115
e:  32   train_loss:  602.6699231483911   time:  1.3934614658355713
e:  33   train_loss:  601.1700667930943   time:  1.3923909664154053
e:  34   train_loss:  599.7479994752551   time:  1.3926856517791748
e:  35   train_loss:  596.7606922421277   time:  1.392259120941162
e:  35   train_loss:  596.7606922421277   val_loss:  706.3960205729348   time:  1.5067343711853027
e:  36   train_loss:  591.0108407190855   time:  1.3937029838562012
e:  37   train_loss:  591.5415557469532   time:  1.3857800960540771
e:  38   train_loss:  586.0371266305037   time:  1.3925824165344238
e:  39   train_loss:  589.709694378687   time:  1.3910539150238037
e:  40   train_loss:  585.5309274503522   time:  1.3909320831298828
e:  40   train_loss:  585.5309274503522   val_loss:  701.6125854123579   time:  1.5056159496307373
e:  41   train_loss:  581.5157794436894   time:  1.3895676136016846
e:  42   train_loss:  580.6368656314994   time:  1.388181447982788
e:  43   train_loss:  577.3586486515371   time:  1.5073308944702148
e:  44   train_loss:  575.2940391882285   time:  1.359485149383545
e:  45   train_loss:  576.5123171251751   time:  1.3903956413269043
e:  45   train_loss:  576.5123171251751   val_loss:  696.92958828794   time:  1.5056536197662354
e:  46   train_loss:  575.6162261972743   time:  1.3922488689422607
e:  47   train_loss:  573.6117367085047   time:  1.3898513317108154
e:  48   train_loss:  570.335796963399   time:  1.3910062313079834
e:  49   train_loss:  570.5806672931913   time:  1.3929851055145264
e:  50   train_loss:  569.4213754586758   time:  1.3934252262115479
e:  50   train_loss:  569.4213754586758   val_loss:  695.4184270942201   time:  1.5090947151184082
e:  51   train_loss:  563.1554631878676   time:  1.3935186862945557
e:  52   train_loss:  566.6211042865659   time:  1.4367265701293945
e:  53   train_loss:  581.7529010931875   time:  1.3924505710601807
e:  54   train_loss:  578.8356478936129   time:  1.3949503898620605
e:  55   train_loss:  562.7071557714071   time:  1.387911319732666
e:  55   train_loss:  562.7071557714071   val_loss:  691.3051356098698   time:  1.502786636352539
e:  56   train_loss:  556.8377550538244   time:  1.523895502090454
e:  57   train_loss:  555.7060405782503   time:  1.391003131866455
e:  58   train_loss:  552.1238112961626   time:  1.3942084312438965
e:  59   train_loss:  553.144066966429   time:  1.3922746181488037
e:  60   train_loss:  551.01246774316   time:  1.3912091255187988
e:  60   train_loss:  551.01246774316   val_loss:  689.4333587479657   time:  1.5055551528930664
e:  61   train_loss:  549.4833281959901   time:  1.5306813716888428
e:  62   train_loss:  552.6124810513681   time:  1.3803431987762451
e:  63   train_loss:  558.3735527122809   time:  1.3834123611450195
e:  64   train_loss:  549.1189215032987   time:  1.3496742248535156
e:  65   train_loss:  551.2681940011345   time:  1.3800530433654785
e:  65   train_loss:  551.2681940011345   val_loss:  685.4439855943868   time:  1.4946939945220947
e:  66   train_loss:  543.2334368164147   time:  1.3889141082763672
e:  67   train_loss:  544.2259528717357   time:  1.3890814781188965
e:  68   train_loss:  540.2774124736595   time:  1.5204613208770752
e:  69   train_loss:  545.720227802393   time:  1.3839058876037598
e:  70   train_loss:  568.7420728514915   time:  1.4155349731445312
e:  70   train_loss:  568.7420728514915   val_loss:  713.7740685597454   time:  1.540605068206787
e:  71   train_loss:  552.1686742829247   time:  1.5178797245025635
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  72   train_loss:  540.5160698744928   time:  1.4525353908538818
e:  73   train_loss:  539.5275280313737   time:  1.4352478981018066
e:  74   train_loss:  546.8040164625223   time:  1.4689180850982666
e:  75   train_loss:  541.4187102202243   time:  1.437117099761963
e:  75   train_loss:  541.4187102202243   val_loss:  700.7911022843781   time:  1.5530409812927246
e:  76   train_loss:  557.7149955091529   time:  1.441847801208496
e:  77   train_loss:  592.2746159013257   time:  1.4865899085998535
e:  78   train_loss:  549.3006354138889   time:  1.458622932434082
e:  79   train_loss:  545.4132622059896   time:  1.4088566303253174
e:  80   train_loss:  542.3350186710501   time:  1.4316790103912354
e:  80   train_loss:  542.3350186710501   val_loss:  679.1289524304398   time:  1.548018217086792
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1036.0331216960303   time:  1.732165813446045
e:  0   train_loss:  1036.0331216960303   val_loss:  556.9880294154765   time:  1.840911865234375
e:  1   train_loss:  905.8186195915118   time:  1.6212475299835205
e:  2   train_loss:  903.814678016793   time:  1.5745980739593506
e:  3   train_loss:  884.4520678688867   time:  1.5436816215515137
e:  4   train_loss:  868.5219809118641   time:  1.5942132472991943
e:  5   train_loss:  871.539915710419   time:  1.5755996704101562
e:  5   train_loss:  871.539915710419   val_loss:  553.6771767539209   time:  1.855245590209961
e:  6   train_loss:  841.2277718370848   time:  1.5686075687408447
e:  7   train_loss:  829.9149831934225   time:  1.5720348358154297
e:  8   train_loss:  841.3361708864682   time:  1.5696744918823242
e:  9   train_loss:  791.4500786238482   time:  1.5754413604736328
e:  10   train_loss:  773.9749819679619   time:  1.578963279724121
e:  10   train_loss:  773.9749819679619   val_loss:  574.6380518554599   time:  1.6882877349853516
e:  11   train_loss:  768.6671584221216   time:  1.7312726974487305
e:  12   train_loss:  742.9371629307077   time:  1.5588366985321045
e:  13   train_loss:  734.440382511681   time:  1.5818796157836914
e:  14   train_loss:  715.8441878790564   time:  1.56528902053833
e:  15   train_loss:  705.0744428539856   time:  1.5241341590881348
e:  15   train_loss:  705.0744428539856   val_loss:  572.2899992053816   time:  1.6061031818389893
e:  16   train_loss:  693.1859603803607   time:  1.4988341331481934
e:  17   train_loss:  694.1915667926619   time:  1.5876562595367432
e:  18   train_loss:  668.5416760205344   time:  1.7540481090545654
e:  19   train_loss:  666.9341976293375   time:  1.5637798309326172
e:  20   train_loss:  662.0889740672787   time:  1.5645058155059814
e:  20   train_loss:  662.0889740672787   val_loss:  570.6699876380239   time:  1.6735846996307373
e:  21   train_loss:  657.2798043303249   time:  1.5319910049438477
e:  22   train_loss:  654.0626886071053   time:  1.5283794403076172
e:  23   train_loss:  653.0323996545575   time:  1.5822288990020752
e:  24   train_loss:  640.6699692814019   time:  1.5617494583129883
e:  25   train_loss:  634.433003655327   time:  1.732243299484253
e:  25   train_loss:  634.433003655327   val_loss:  565.0065135232769   time:  1.8353469371795654
e:  26   train_loss:  642.1205358067762   time:  1.5897469520568848
e:  27   train_loss:  634.1879692710726   time:  1.619187355041504
e:  28   train_loss:  625.0004447301199   time:  1.5350861549377441
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  29   train_loss:  626.3201073224838   time:  1.5610220432281494
e:  30   train_loss:  621.9005545096362   time:  1.5896327495574951
e:  30   train_loss:  621.9005545096362   val_loss:  560.1360335694096   time:  1.7001347541809082
e:  31   train_loss:  610.1003321462897   time:  1.7453570365905762
e:  32   train_loss:  617.6409659515333   time:  1.5200960636138916
e:  33   train_loss:  610.4456894766671   time:  1.566514492034912
e:  34   train_loss:  611.860162498574   time:  1.5871219635009766
e:  35   train_loss:  611.4400809224894   time:  1.526707410812378
e:  35   train_loss:  611.4400809224894   val_loss:  558.708503777261   time:  1.6356217861175537
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 16), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 16) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 16) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 16) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 16)
kwargs: {'config': {'batch_norm': False, 'ff_0': 455, 'ff_num_layers': 2, 'gnn_0': 1251, 'gnn_dropout': 0.20395971160240467, 'gnn_num_layers': 3, 'hid_0': 650, 'hid_dropout_rate': 0.13942129792862107, 'in_dropout_rate': 0.1608907178961747, 'lr': 0.0009490287408787803, 'num_hid_layers': 1, 'optimizer': 'SGD', 'ff_1': 47, 'gnn_1': 254, 'gnn_2': 178, 'sgd_momentum': 0.5692253051349879}, 'budget': 81.0, 'working_directory': '.'}
result: {'loss': 728.3087366863991, 'n_epochs': 46.2, 'info': {'validation loss': 728.3087366863991}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 16) started
DEBUG:hpbandster:job_callback for (0, 0, 16) got condition
DEBUG:hpbandster:Only 5 run(s) for budget 81.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 16) finished
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 21) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 21) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 21)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 21) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 21) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 21)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 136, 'ff_num_layers': 3, 'gnn_0': 104, 'gnn_dropout': 0.09105864397368119, 'gnn_num_layers': 1, 'hid_0': 1098, 'hid_dropout_rate': 0.2950418713601814, 'in_dropout_rate': 0.4290437273961989, 'lr': 0.0008127555244333852, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 72, 'ff_2': 877, 'hid_1': 1783, 'hid_2': 73}, 'budget': 81.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  645.4305928879129   time:  1.5686314105987549
e:  0   train_loss:  645.4305928879129   val_loss:  1439.3255066039176   time:  1.7042467594146729
e:  1   train_loss:  600.5065501807899   time:  1.6628057956695557
e:  2   train_loss:  588.4198644295261   time:  1.8276381492614746
e:  3   train_loss:  571.9543430371403   time:  1.5173430442810059
e:  4   train_loss:  549.0633931113124   time:  1.4654107093811035
e:  5   train_loss:  516.2162488757273   time:  1.527273416519165
e:  5   train_loss:  516.2162488757273   val_loss:  1388.9153198071162   time:  1.641561508178711
e:  6   train_loss:  479.7997914349591   time:  1.537576675415039
e:  7   train_loss:  454.0546374786002   time:  1.5387277603149414
e:  8   train_loss:  434.3176940295654   time:  1.5407319068908691
e:  9   train_loss:  423.58669432044064   time:  1.53263521194458
e:  10   train_loss:  421.44053527701186   time:  1.5296759605407715
e:  10   train_loss:  421.44053527701186   val_loss:  1398.298706814964   time:  1.6431641578674316
e:  11   train_loss:  415.62765141007975   time:  1.536156415939331
e:  12   train_loss:  419.18175270315237   time:  1.5420234203338623
e:  13   train_loss:  409.26416904215654   time:  1.6621723175048828
e:  14   train_loss:  405.1230101254292   time:  1.5379352569580078
e:  15   train_loss:  400.05790850797047   time:  1.5058016777038574
e:  15   train_loss:  400.05790850797047   val_loss:  1413.5711946854565   time:  1.5913302898406982
e:  16   train_loss:  396.8722898694715   time:  1.481285810470581
e:  17   train_loss:  389.48767914355165   time:  1.5359971523284912
e:  18   train_loss:  383.70879572229205   time:  1.5335752964019775
e:  19   train_loss:  377.3789314770493   time:  1.5380804538726807
e:  20   train_loss:  368.3426280918392   time:  1.5381510257720947
e:  20   train_loss:  368.3426280918392   val_loss:  1437.396345880528   time:  1.6524748802185059
e:  21   train_loss:  360.21711077934435   time:  1.5382602214813232
e:  22   train_loss:  351.7639532295889   time:  1.671663522720337
e:  23   train_loss:  347.9309822280011   time:  1.4668302536010742
e:  24   train_loss:  339.5140382963403   time:  1.5145254135131836
e:  25   train_loss:  331.07598094040986   time:  1.5336668491363525
e:  25   train_loss:  331.07598094040986   val_loss:  1406.568783400465   time:  1.6481974124908447
e:  26   train_loss:  321.2908189666716   time:  1.5368854999542236
e:  27   train_loss:  316.4244662156197   time:  1.540952205657959
e:  28   train_loss:  318.5552757598861   time:  1.5371124744415283
e:  29   train_loss:  305.1793332867488   time:  1.5174345970153809
e:  30   train_loss:  294.31194552513574   time:  1.5169286727905273
e:  30   train_loss:  294.31194552513574   val_loss:  1428.6844117570383   time:  1.6348824501037598
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  31   train_loss:  282.4305011197473   time:  1.6104698181152344
e:  32   train_loss:  273.8877253918414   time:  1.7430450916290283
e:  33   train_loss:  267.0188890371006   time:  1.8538463115692139
e:  34   train_loss:  264.47291696458103   time:  1.5750699043273926
e:  35   train_loss:  254.81116175039762   time:  1.5395135879516602
e:  35   train_loss:  254.81116175039762   val_loss:  1507.6821636693055   time:  1.6536355018615723
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  991.5242207301981   time:  1.677248477935791
e:  0   train_loss:  991.5242207301981   val_loss:  542.5235673450899   time:  1.782942771911621
e:  1   train_loss:  911.3048492159903   time:  1.6715590953826904
e:  2   train_loss:  879.4750951438477   time:  1.670525312423706
e:  3   train_loss:  847.756247216113   time:  1.6686477661132812
e:  4   train_loss:  792.8917714626474   time:  1.6781816482543945
e:  5   train_loss:  688.3156870814372   time:  1.8723220825195312
e:  5   train_loss:  688.3156870814372   val_loss:  592.6969933372579   time:  1.9775428771972656
e:  6   train_loss:  614.1050328834607   time:  1.6372826099395752
e:  7   train_loss:  599.2799913872909   time:  1.6749358177185059
e:  8   train_loss:  568.2074294929215   time:  1.6700034141540527
e:  9   train_loss:  570.6589353545033   time:  1.713947057723999
e:  10   train_loss:  551.2551494368747   time:  1.7909538745880127
e:  10   train_loss:  551.2551494368747   val_loss:  573.9781587865502   time:  1.912482500076294
e:  11   train_loss:  548.7535186343632   time:  1.8423042297363281
e:  12   train_loss:  540.8549177724374   time:  1.6766581535339355
e:  13   train_loss:  537.6655669701844   time:  1.671142339706421
e:  14   train_loss:  532.922197353415   time:  1.675011157989502
e:  15   train_loss:  530.4204566190967   time:  1.6730868816375732
e:  15   train_loss:  530.4204566190967   val_loss:  608.8245282470922   time:  1.7799735069274902
e:  16   train_loss:  516.9279949173389   time:  1.6758952140808105
e:  17   train_loss:  519.2150249718466   time:  1.6743977069854736
e:  18   train_loss:  521.9583202476038   time:  1.8001065254211426
e:  19   train_loss:  504.12860728925466   time:  1.672950029373169
e:  20   train_loss:  502.404540222248   time:  1.6733579635620117
e:  20   train_loss:  502.404540222248   val_loss:  586.1660565587167   time:  1.7791593074798584
e:  21   train_loss:  490.8215217858167   time:  1.7952275276184082
e:  22   train_loss:  489.0972275217351   time:  1.7260003089904785
e:  23   train_loss:  470.9847311122873   time:  1.7815520763397217
e:  24   train_loss:  462.1650707662609   time:  1.9012718200683594
e:  25   train_loss:  454.9350477095505   time:  1.9004719257354736
e:  25   train_loss:  454.9350477095505   val_loss:  581.5585121090609   time:  2.005911111831665
e:  26   train_loss:  448.70078373935917   time:  1.7068097591400146
e:  27   train_loss:  434.8542193261046   time:  1.7095167636871338
e:  28   train_loss:  416.30071244263183   time:  1.7064862251281738
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  29   train_loss:  403.8739410768278   time:  1.7095468044281006
e:  30   train_loss:  389.56469145307074   time:  1.7169380187988281
e:  30   train_loss:  389.56469145307074   val_loss:  603.083759749011   time:  2.0120177268981934
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1035.4954896546426   time:  1.7982416152954102
e:  0   train_loss:  1035.4954896546426   val_loss:  482.1712069721036   time:  1.9077060222625732
e:  1   train_loss:  912.7218554343394   time:  1.7159326076507568
e:  2   train_loss:  908.834487563814   time:  1.632153034210205
e:  3   train_loss:  862.344091833712   time:  1.6348257064819336
e:  4   train_loss:  812.9906978254744   time:  1.6332604885101318
e:  5   train_loss:  735.6931893221368   time:  1.634044885635376
e:  5   train_loss:  735.6931893221368   val_loss:  511.2679393878453   time:  1.7435972690582275
e:  6   train_loss:  690.5370316521032   time:  1.7794699668884277
e:  7   train_loss:  632.3821282813333   time:  1.6227576732635498
e:  8   train_loss:  606.984873023604   time:  1.604485273361206
e:  9   train_loss:  647.311967689022   time:  1.5758066177368164
e:  10   train_loss:  608.56839100452   time:  1.6281678676605225
e:  10   train_loss:  608.56839100452   val_loss:  502.4788899585541   time:  1.73677396774292
e:  11   train_loss:  580.642859677235   time:  1.6162962913513184
e:  12   train_loss:  580.6936514451575   time:  1.631497859954834
e:  13   train_loss:  571.2203170251357   time:  1.628436803817749
e:  14   train_loss:  573.279449954834   time:  1.6319739818572998
e:  15   train_loss:  562.1234949932938   time:  1.755012035369873
e:  15   train_loss:  562.1234949932938   val_loss:  588.4815204388136   time:  1.8635458946228027
e:  16   train_loss:  569.8378718368816   time:  1.6299257278442383
e:  17   train_loss:  567.0257234329297   time:  1.627835988998413
e:  18   train_loss:  555.4101764898223   time:  1.631547212600708
e:  19   train_loss:  566.2826851992145   time:  1.6174883842468262
e:  20   train_loss:  548.2605886221364   time:  1.6216814517974854
e:  20   train_loss:  548.2605886221364   val_loss:  515.7816860084574   time:  1.730344533920288
e:  21   train_loss:  532.6820991182582   time:  1.6311671733856201
e:  22   train_loss:  536.0935618998518   time:  1.7604637145996094
e:  23   train_loss:  537.7917402241537   time:  1.6303651332855225
e:  24   train_loss:  516.6443706379607   time:  1.6272165775299072
e:  25   train_loss:  516.0664392852962   time:  1.625326156616211
e:  25   train_loss:  516.0664392852962   val_loss:  529.7411675593969   time:  1.7342913150787354
e:  26   train_loss:  510.025598747013   time:  1.612891674041748
e:  27   train_loss:  508.17241350783854   time:  1.5671608448028564
e:  28   train_loss:  496.3939817886675   time:  1.625220537185669
e:  29   train_loss:  480.14759394557564   time:  1.6292979717254639
e:  30   train_loss:  469.01393438349845   time:  1.7582054138183594
e:  30   train_loss:  469.01393438349845   val_loss:  518.5429719898164   time:  1.866631269454956
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  924.1485735326312   time:  1.5061635971069336
e:  0   train_loss:  924.1485735326312   val_loss:  744.015893011877   time:  1.6212592124938965
e:  1   train_loss:  844.8103402138339   time:  1.517009973526001
e:  2   train_loss:  826.3940629832821   time:  1.520265817642212
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  3   train_loss:  809.2557081441531   time:  1.5210809707641602
e:  4   train_loss:  770.5337685889232   time:  1.5195093154907227
e:  5   train_loss:  691.3559350609211   time:  1.5203022956848145
e:  5   train_loss:  691.3559350609211   val_loss:  714.5188214029511   time:  1.6350312232971191
e:  6   train_loss:  614.9948530541891   time:  1.5192832946777344
e:  7   train_loss:  589.0726206525917   time:  1.5205588340759277
e:  8   train_loss:  565.6522562108405   time:  1.5178790092468262
e:  9   train_loss:  556.1581430852168   time:  1.6256790161132812
e:  10   train_loss:  544.4343143671031   time:  1.5046031475067139
e:  10   train_loss:  544.4343143671031   val_loss:  737.5176020856852   time:  1.6174249649047852
e:  11   train_loss:  534.7409095573344   time:  1.57151198387146
e:  12   train_loss:  529.6316445530815   time:  1.7115328311920166
e:  13   train_loss:  529.6959292176953   time:  1.5959436893463135
e:  14   train_loss:  527.6807397309016   time:  1.5217909812927246
e:  15   train_loss:  527.4915495320034   time:  1.5127246379852295
e:  15   train_loss:  527.4915495320034   val_loss:  766.4315091367126   time:  1.6259183883666992
e:  16   train_loss:  523.8251347334003   time:  1.5478477478027344
e:  17   train_loss:  519.9000133810018   time:  1.5781354904174805
e:  18   train_loss:  513.5346549448627   time:  1.566274642944336
e:  19   train_loss:  508.78188219684745   time:  1.5630996227264404
e:  20   train_loss:  507.0881040634194   time:  1.698946237564087
e:  20   train_loss:  507.0881040634194   val_loss:  747.4617531487119   time:  1.8125832080841064
e:  21   train_loss:  501.5347793302158   time:  1.559370517730713
e:  22   train_loss:  492.61411433603575   time:  1.546349287033081
e:  23   train_loss:  486.0916776564509   time:  1.5777463912963867
e:  24   train_loss:  479.1311711210098   time:  1.5599284172058105
e:  25   train_loss:  471.1599834049325   time:  1.5626964569091797
e:  25   train_loss:  471.1599834049325   val_loss:  751.9509800064446   time:  1.6763637065887451
e:  26   train_loss:  460.77473560988346   time:  1.5647082328796387
e:  27   train_loss:  451.10975177325736   time:  1.5576183795928955
e:  28   train_loss:  444.62326780195525   time:  1.5722553730010986
e:  29   train_loss:  451.2789135508195   time:  1.7315211296081543
e:  30   train_loss:  439.9617537739735   time:  1.5525999069213867
e:  30   train_loss:  439.9617537739735   val_loss:  773.5873679971309   time:  1.6663320064544678
e:  31   train_loss:  425.7376865622501   time:  1.5669481754302979
e:  32   train_loss:  409.1818932258119   time:  1.5732848644256592
e:  33   train_loss:  397.4569315031148   time:  1.496142864227295
e:  34   train_loss:  386.2884825242263   time:  1.5431838035583496
e:  35   train_loss:  369.31171794646633   time:  1.5132687091827393
e:  35   train_loss:  369.31171794646633   val_loss:  779.9323407613493   time:  1.6273667812347412
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  977.433075432878   time:  1.746614694595337
e:  0   train_loss:  977.433075432878   val_loss:  555.7114207023809   time:  1.8553733825683594
e:  1   train_loss:  911.5655616467769   time:  1.8554472923278809
e:  2   train_loss:  907.8497388551345   time:  1.6914653778076172
e:  3   train_loss:  854.8696190922084   time:  1.6524698734283447
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  4   train_loss:  761.2293696417606   time:  1.651064157485962
e:  5   train_loss:  675.6435159015609   time:  1.6537716388702393
e:  5   train_loss:  675.6435159015609   val_loss:  577.2003857821373   time:  1.7605087757110596
e:  6   train_loss:  624.4914340317529   time:  1.651594638824463
e:  7   train_loss:  608.0519021428031   time:  1.6509499549865723
e:  8   train_loss:  603.0591574368603   time:  1.7871441841125488
e:  9   train_loss:  582.4959885208079   time:  1.648916482925415
e:  10   train_loss:  577.7885355009709   time:  1.6512978076934814
e:  10   train_loss:  577.7885355009709   val_loss:  558.0844786941457   time:  1.7586030960083008
e:  11   train_loss:  561.4131780607484   time:  1.6497218608856201
e:  12   train_loss:  568.6627907480532   time:  1.6502158641815186
e:  13   train_loss:  553.481377068907   time:  1.647587776184082
e:  14   train_loss:  561.0441021078627   time:  1.6420845985412598
e:  15   train_loss:  541.686218127998   time:  1.7047498226165771
e:  15   train_loss:  541.686218127998   val_loss:  558.9921620599141   time:  1.805579423904419
e:  16   train_loss:  540.6118894497499   time:  1.6502890586853027
e:  17   train_loss:  542.5967649046358   time:  1.6521430015563965
e:  18   train_loss:  534.3931694411356   time:  1.6476256847381592
e:  19   train_loss:  515.1387970296513   time:  1.6490521430969238
e:  20   train_loss:  506.9507131310224   time:  1.65283203125
e:  20   train_loss:  506.9507131310224   val_loss:  552.7999390793909   time:  1.7595136165618896
e:  21   train_loss:  495.95513435114873   time:  1.7753159999847412
e:  22   train_loss:  490.39357772192517   time:  1.6522431373596191
e:  23   train_loss:  480.06590498482467   time:  1.649566888809204
e:  24   train_loss:  461.9400060712303   time:  1.6464991569519043
e:  25   train_loss:  458.48786023517357   time:  1.6492207050323486
e:  25   train_loss:  458.48786023517357   val_loss:  568.5589967978158   time:  1.7560465335845947
e:  26   train_loss:  442.9275284950397   time:  1.6501197814941406
e:  27   train_loss:  421.6127069119361   time:  1.6477539539337158
e:  28   train_loss:  399.24363201768676   time:  1.7834022045135498
e:  29   train_loss:  373.7058833286857   time:  1.6482727527618408
e:  30   train_loss:  357.81988657049305   time:  1.6514842510223389
e:  30   train_loss:  357.81988657049305   val_loss:  569.3359169047851   time:  1.7592637538909912
e:  31   train_loss:  339.3673838608595   time:  1.6509575843811035
e:  32   train_loss:  325.80964188464554   time:  1.616826057434082
e:  33   train_loss:  317.6845913071368   time:  1.5901551246643066
e:  34   train_loss:  306.52703026000586   time:  1.673992395401001
e:  35   train_loss:  297.3928742412238   time:  1.7834596633911133
e:  35   train_loss:  297.3928742412238   val_loss:  569.1732206318819   time:  1.889951467514038
e:  36   train_loss:  286.9671403543299   time:  1.6499531269073486
e:  37   train_loss:  284.662183986338   time:  1.6526634693145752
e:  38   train_loss:  276.1611546453808   time:  1.6481058597564697
e:  39   train_loss:  267.85190268556966   time:  1.6495225429534912
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  40   train_loss:  266.2491994798054   time:  1.6517667770385742
e:  40   train_loss:  266.2491994798054   val_loss:  587.6202894319152   time:  1.7586827278137207
e:  41   train_loss:  257.29140421176015   time:  1.7831389904022217
e:  42   train_loss:  252.12837706183987   time:  1.6495890617370605
e:  43   train_loss:  247.21467648809664   time:  1.6499457359313965
e:  44   train_loss:  242.53122500590385   time:  1.6479122638702393
e:  45   train_loss:  238.71286185643305   time:  1.644474983215332
e:  45   train_loss:  238.71286185643305   val_loss:  606.126375556653   time:  1.751910924911499
e:  46   train_loss:  237.8015088557013   time:  1.6496620178222656
e:  47   train_loss:  232.68950084810922   time:  1.6469910144805908
e:  48   train_loss:  234.56553371023742   time:  1.7554395198822021
e:  49   train_loss:  231.00231591945587   time:  1.6484284400939941
e:  50   train_loss:  229.18516637478095   time:  1.6126747131347656
e:  50   train_loss:  229.18516637478095   val_loss:  600.3546223524277   time:  1.7179005146026611
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 21), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 21) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 21) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 21) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 21)
kwargs: {'config': {'batch_norm': False, 'ff_0': 136, 'ff_num_layers': 3, 'gnn_0': 104, 'gnn_dropout': 0.09105864397368119, 'gnn_num_layers': 1, 'hid_0': 1098, 'hid_dropout_rate': 0.2950418713601814, 'in_dropout_rate': 0.4290437273961989, 'lr': 0.0008127555244333852, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 72, 'ff_2': 877, 'hid_1': 1783, 'hid_2': 73}, 'budget': 81.0, 'working_directory': '.'}
result: {'loss': 736.1857709213303, 'n_epochs': 36.0, 'info': {'validation loss': 736.1857709213303}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 21) started
DEBUG:hpbandster:job_callback for (0, 0, 21) got condition
DEBUG:hpbandster:Only 6 run(s) for budget 81.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 21) finished
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 22) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 22) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 22)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 22) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 22) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 22)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 17, 'ff_num_layers': 1, 'gnn_0': 281, 'gnn_dropout': 0.3279737195479306, 'gnn_num_layers': 1, 'hid_0': 593, 'hid_dropout_rate': 0.20414696252923964, 'in_dropout_rate': 0.4386659901915775, 'lr': 0.0015707457967605017, 'num_hid_layers': 3, 'optimizer': 'SGD', 'hid_1': 511, 'hid_2': 271, 'sgd_momentum': 0.6094637896459667}, 'budget': 81.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  699.7946978883035   time:  1.3383829593658447
e:  0   train_loss:  699.7946978883035   val_loss:  1643.4727152783894   time:  1.4462831020355225
e:  1   train_loss:  659.9982869631616   time:  1.3685166835784912
e:  2   train_loss:  596.977986606084   time:  1.3650989532470703
e:  3   train_loss:  588.3340724632681   time:  1.3596835136413574
e:  4   train_loss:  578.0070036177477   time:  1.3441030979156494
e:  5   train_loss:  556.8876249554933   time:  1.3504970073699951
e:  5   train_loss:  556.8876249554933   val_loss:  1386.605295828799   time:  1.459167242050171
e:  6   train_loss:  555.3039222398411   time:  1.5481960773468018
e:  7   train_loss:  529.2386523870728   time:  1.3230922222137451
e:  8   train_loss:  569.2721374202183   time:  1.3418166637420654
e:  9   train_loss:  570.7210704800551   time:  1.3359348773956299
e:  10   train_loss:  529.1730047081185   time:  1.3604707717895508
e:  10   train_loss:  529.1730047081185   val_loss:  1374.9777892565469   time:  1.4684133529663086
e:  11   train_loss:  518.1156390357405   time:  1.3430585861206055
e:  12   train_loss:  552.0895210147125   time:  1.3439743518829346
e:  13   train_loss:  551.6874801823578   time:  1.3358407020568848
e:  14   train_loss:  584.1434368158552   time:  1.3357911109924316
e:  15   train_loss:  593.2773325366567   time:  1.512598991394043
e:  15   train_loss:  593.2773325366567   val_loss:  1375.551479766331   time:  1.6127548217773438
e:  16   train_loss:  545.513850104002   time:  1.3519246578216553
e:  17   train_loss:  564.4877231202643   time:  1.3441433906555176
e:  18   train_loss:  545.2981704689752   time:  1.3458478450775146
e:  19   train_loss:  598.7076198672403   time:  1.3437998294830322
e:  20   train_loss:  560.4442519071845   time:  1.34086275100708
e:  20   train_loss:  560.4442519071845   val_loss:  1425.9831318105928   time:  1.4476828575134277
e:  21   train_loss:  528.8976311157103   time:  1.314227819442749
e:  22   train_loss:  535.8577969403568   time:  1.3397374153137207
e:  23   train_loss:  590.841307203437   time:  1.5020320415496826
e:  24   train_loss:  592.1583220676638   time:  1.3383212089538574
e:  25   train_loss:  573.9952728928832   time:  1.330625295639038
e:  25   train_loss:  573.9952728928832   val_loss:  1401.4958199860384   time:  1.437669038772583
e:  26   train_loss:  569.7893262294   time:  1.3615565299987793
e:  27   train_loss:  600.1753836062979   time:  1.3394267559051514
e:  28   train_loss:  589.3818865196694   time:  1.3411061763763428
e:  29   train_loss:  558.7803947747777   time:  1.3535032272338867
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  30   train_loss:  525.4221280981869   time:  1.3393540382385254
e:  30   train_loss:  525.4221280981869   val_loss:  1357.3973826619772   time:  1.4459216594696045
e:  31   train_loss:  502.75171127155   time:  1.3565514087677002
e:  32   train_loss:  518.7542482986261   time:  1.359015703201294
e:  33   train_loss:  596.0460569250554   time:  1.3449678421020508
e:  34   train_loss:  572.4000522483835   time:  1.3373239040374756
e:  35   train_loss:  593.2494732112393   time:  1.5121097564697266
e:  35   train_loss:  593.2494732112393   val_loss:  1462.288776130649   time:  1.61167573928833
e:  36   train_loss:  572.66997381485   time:  1.3330655097961426
e:  37   train_loss:  520.1212617628408   time:  1.3453197479248047
e:  38   train_loss:  538.7910596617915   time:  1.3352086544036865
e:  39   train_loss:  517.8961671017701   time:  1.3467795848846436
e:  40   train_loss:  507.178495948687   time:  1.3418564796447754
e:  40   train_loss:  507.178495948687   val_loss:  1504.523154498522   time:  1.449615716934204
e:  41   train_loss:  504.7753349835511   time:  1.362781286239624
e:  42   train_loss:  476.4331340468269   time:  1.3345088958740234
e:  43   train_loss:  487.0390100813605   time:  1.3015315532684326
e:  44   train_loss:  583.051650469494   time:  1.3474159240722656
e:  45   train_loss:  509.96126412898695   time:  1.5097806453704834
e:  45   train_loss:  509.96126412898695   val_loss:  1411.9691225040556   time:  1.609666109085083
e:  46   train_loss:  473.88635588244375   time:  1.3246779441833496
e:  47   train_loss:  464.7513232357729   time:  1.3421597480773926
e:  48   train_loss:  513.5860672079466   time:  1.3381586074829102
e:  49   train_loss:  462.1742147137316   time:  1.3528854846954346
e:  50   train_loss:  492.8963711992502   time:  1.166818618774414
e:  50   train_loss:  492.8963711992502   val_loss:  1526.2492953179135   time:  1.2468526363372803
e:  51   train_loss:  586.2352890297408   time:  1.332996129989624
e:  52   train_loss:  498.05432998827064   time:  1.357720136642456
e:  53   train_loss:  466.21047769761003   time:  1.3464720249176025
e:  54   train_loss:  576.1067093936598   time:  1.4905664920806885
e:  55   train_loss:  539.6536348738441   time:  1.3339955806732178
e:  55   train_loss:  539.6536348738441   val_loss:  1364.6424492934602   time:  1.4404044151306152
e:  56   train_loss:  483.7900820228404   time:  1.348160743713379
e:  57   train_loss:  453.460061285563   time:  1.3914239406585693
e:  58   train_loss:  448.29659404894124   time:  1.3901591300964355
e:  59   train_loss:  445.8933234745674   time:  1.3445262908935547
e:  60   train_loss:  474.6863187678434   time:  1.361448049545288
e:  60   train_loss:  474.6863187678434   val_loss:  1390.6243757288194   time:  1.4701769351959229
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1082.5861134994993   time:  1.456791639328003
e:  0   train_loss:  1082.5861134994993   val_loss:  602.7942725269892   time:  1.5591435432434082
e:  1   train_loss:  976.8231620388065   time:  1.4464216232299805
e:  2   train_loss:  890.6112729877351   time:  1.6252739429473877
e:  3   train_loss:  857.9240765073578   time:  1.419783115386963
e:  4   train_loss:  900.9864399695103   time:  1.4445381164550781
e:  5   train_loss:  808.3060905885777   time:  1.4523227214813232
e:  5   train_loss:  808.3060905885777   val_loss:  533.2033074053169   time:  1.5543220043182373
e:  6   train_loss:  885.8198021706934   time:  1.4768872261047363
e:  7   train_loss:  796.2388676737361   time:  1.4553778171539307
e:  8   train_loss:  908.7741508839022   time:  1.6185946464538574
e:  9   train_loss:  890.8257467317624   time:  1.4703238010406494
e:  10   train_loss:  827.0321722360254   time:  1.4707348346710205
e:  10   train_loss:  827.0321722360254   val_loss:  541.1848932263005   time:  1.5725438594818115
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  11   train_loss:  835.3208200463538   time:  1.4781620502471924
e:  12   train_loss:  756.7338578160758   time:  1.4529752731323242
e:  13   train_loss:  768.6606256529013   time:  1.453411340713501
e:  14   train_loss:  768.2536533091214   time:  1.6042895317077637
e:  15   train_loss:  747.8571312674064   time:  1.4463772773742676
e:  15   train_loss:  747.8571312674064   val_loss:  532.5659316765508   time:  1.5466692447662354
e:  16   train_loss:  777.253708570791   time:  1.4688282012939453
e:  17   train_loss:  727.4687516711924   time:  1.451819896697998
e:  18   train_loss:  777.2011320256389   time:  1.4505078792572021
e:  19   train_loss:  783.5608952855657   time:  1.4578804969787598
e:  20   train_loss:  786.488525727612   time:  1.453904151916504
e:  20   train_loss:  786.488525727612   val_loss:  528.3127350980511   time:  1.7469186782836914
e:  21   train_loss:  740.2610313090794   time:  1.4513952732086182
e:  22   train_loss:  704.7937031747432   time:  1.4523837566375732
e:  23   train_loss:  789.2658040545772   time:  1.4177577495574951
e:  24   train_loss:  717.6658953545045   time:  1.447200059890747
e:  25   train_loss:  702.6039330351919   time:  1.4499852657318115
e:  25   train_loss:  702.6039330351919   val_loss:  531.2850106332002   time:  1.5518362522125244
e:  26   train_loss:  698.0013926324932   time:  1.472762107849121
e:  27   train_loss:  761.8042606883251   time:  1.4551339149475098
e:  28   train_loss:  712.6763693809778   time:  1.4553313255310059
e:  29   train_loss:  731.6589253590188   time:  1.6277263164520264
e:  30   train_loss:  703.1912160594003   time:  1.4420783519744873
e:  30   train_loss:  703.1912160594003   val_loss:  529.6993275373279   time:  1.5428214073181152
e:  31   train_loss:  692.561141120211   time:  1.4442193508148193
e:  32   train_loss:  747.8989015490312   time:  1.4528193473815918
e:  33   train_loss:  654.0629168871424   time:  1.456862211227417
e:  34   train_loss:  656.784974063181   time:  1.4485232830047607
e:  35   train_loss:  691.3701193893039   time:  1.6516013145446777
e:  35   train_loss:  691.3701193893039   val_loss:  537.514269185087   time:  1.7541213035583496
e:  36   train_loss:  704.7380892852275   time:  1.4590706825256348
e:  37   train_loss:  661.1240810313533   time:  1.470667839050293
e:  38   train_loss:  613.6536252504767   time:  1.4578354358673096
e:  39   train_loss:  603.4335660790854   time:  1.4591715335845947
e:  40   train_loss:  657.1493665708851   time:  1.6342403888702393
e:  40   train_loss:  657.1493665708851   val_loss:  600.7237371483894   time:  1.7295124530792236
e:  41   train_loss:  997.6422487112998   time:  1.4676048755645752
e:  42   train_loss:  946.3935762231364   time:  1.4528617858886719
e:  43   train_loss:  913.0872157469979   time:  1.4166936874389648
e:  44   train_loss:  902.5846475294665   time:  1.4640965461730957
e:  45   train_loss:  911.9410691189779   time:  1.4416711330413818
e:  45   train_loss:  911.9410691189779   val_loss:  546.8412899481002   time:  1.5424070358276367
e:  46   train_loss:  887.6081087743368   time:  1.4674122333526611
e:  47   train_loss:  802.3938808468707   time:  1.6208374500274658
e:  48   train_loss:  824.0631245200628   time:  1.4479169845581055
e:  49   train_loss:  761.6085278577859   time:  1.4504847526550293
e:  50   train_loss:  811.8387427515759   time:  1.4541730880737305
e:  50   train_loss:  811.8387427515759   val_loss:  526.1955508988414   time:  1.5568552017211914
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  51   train_loss:  716.8065314573214   time:  1.4592809677124023
e:  52   train_loss:  637.1584032865339   time:  1.4565179347991943
e:  53   train_loss:  703.9828471642468   time:  1.6222927570343018
e:  54   train_loss:  651.2415742057187   time:  1.4448518753051758
e:  55   train_loss:  908.067123551548   time:  1.4617063999176025
e:  55   train_loss:  908.067123551548   val_loss:  531.3920010516614   time:  1.5627720355987549
e:  56   train_loss:  834.7551970973041   time:  1.4548723697662354
e:  57   train_loss:  877.4605066144783   time:  1.4498884677886963
e:  58   train_loss:  777.5139598742956   time:  1.4463155269622803
e:  59   train_loss:  732.8520311062338   time:  1.4578466415405273
e:  60   train_loss:  797.6118073435089   time:  1.629807949066162
e:  60   train_loss:  797.6118073435089   val_loss:  537.1497447878838   time:  1.7301185131072998
e:  61   train_loss:  814.0996792809235   time:  1.4506866931915283
e:  62   train_loss:  755.1137817724085   time:  1.4398179054260254
e:  63   train_loss:  769.1629404028748   time:  1.4087326526641846
e:  64   train_loss:  765.5720660708199   time:  1.4460370540618896
e:  65   train_loss:  777.7384866966381   time:  1.4538278579711914
e:  65   train_loss:  777.7384866966381   val_loss:  548.9094253458882   time:  1.5550003051757812
e:  66   train_loss:  629.2188153747162   time:  1.4737634658813477
e:  67   train_loss:  628.5822840067472   time:  1.6478016376495361
e:  68   train_loss:  615.1607466961818   time:  1.4661312103271484
e:  69   train_loss:  573.7344534834621   time:  1.4512615203857422
e:  70   train_loss:  590.3404455251462   time:  1.5046920776367188
e:  70   train_loss:  590.3404455251462   val_loss:  545.8912195284327   time:  1.6325774192810059
e:  71   train_loss:  659.0718459014244   time:  1.5427558422088623
e:  72   train_loss:  589.8669187619805   time:  1.4404640197753906
e:  73   train_loss:  550.8077423653081   time:  1.6439850330352783
e:  74   train_loss:  515.2157013870597   time:  1.460146188735962
e:  75   train_loss:  533.9757906948194   time:  1.4557690620422363
e:  75   train_loss:  533.9757906948194   val_loss:  545.8107941223855   time:  1.5559823513031006
e:  76   train_loss:  512.0287221040498   time:  1.468191385269165
e:  77   train_loss:  512.461318444049   time:  1.451941967010498
e:  78   train_loss:  530.8739821632558   time:  1.457839012145996
e:  79   train_loss:  562.6051344569082   time:  1.645256519317627
e:  80   train_loss:  500.412633062935   time:  1.4523379802703857
e:  80   train_loss:  500.412633062935   val_loss:  556.886055835544   time:  1.5542664527893066
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1128.3843543686764   time:  1.4410088062286377
e:  0   train_loss:  1128.3843543686764   val_loss:  517.3067218449469   time:  1.5466527938842773
e:  1   train_loss:  955.973832517564   time:  1.4278790950775146
e:  2   train_loss:  901.0637100411249   time:  1.4078521728515625
e:  3   train_loss:  856.9909291995981   time:  1.4358439445495605
e:  4   train_loss:  924.6536092116298   time:  1.5916650295257568
e:  5   train_loss:  852.1057912499991   time:  1.4359571933746338
e:  5   train_loss:  852.1057912499991   val_loss:  464.9950347367672   time:  1.5396966934204102
e:  6   train_loss:  884.6912842507933   time:  1.4401886463165283
e:  7   train_loss:  830.5160249321784   time:  1.4405786991119385
e:  8   train_loss:  911.2258810737417   time:  1.4575979709625244
e:  9   train_loss:  947.5671495259307   time:  1.4459526538848877
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  10   train_loss:  893.1214722324708   time:  1.4520289897918701
e:  10   train_loss:  893.1214722324708   val_loss:  523.7969672088021   time:  1.5545599460601807
e:  11   train_loss:  923.6932011925876   time:  1.6227738857269287
e:  12   train_loss:  974.7979667805243   time:  1.4423649311065674
e:  13   train_loss:  889.3323270589217   time:  1.440112829208374
e:  14   train_loss:  905.5766556869019   time:  1.4344613552093506
e:  15   train_loss:  873.4461341836367   time:  1.442152500152588
e:  15   train_loss:  873.4461341836367   val_loss:  467.48702230412914   time:  1.5454449653625488
e:  16   train_loss:  920.8250803511318   time:  1.4352619647979736
e:  17   train_loss:  895.5779227225356   time:  1.4350917339324951
e:  18   train_loss:  886.2141748322169   time:  1.4276745319366455
e:  19   train_loss:  887.4587073612829   time:  1.6189796924591064
e:  20   train_loss:  882.0037108016961   time:  1.43729567527771
e:  20   train_loss:  882.0037108016961   val_loss:  484.06041533620794   time:  1.5408735275268555
e:  21   train_loss:  874.3512583502207   time:  1.4341180324554443
e:  22   train_loss:  917.0288702112385   time:  1.4238765239715576
e:  23   train_loss:  840.8526949252956   time:  1.4294946193695068
e:  24   train_loss:  767.8219615809231   time:  1.4719271659851074
e:  25   train_loss:  757.1796415091392   time:  1.5993993282318115
e:  25   train_loss:  757.1796415091392   val_loss:  933.1258503779536   time:  1.702929973602295
e:  26   train_loss:  1004.6668649451326   time:  1.3588950634002686
e:  27   train_loss:  1011.4710074730353   time:  1.4681396484375
e:  28   train_loss:  937.9998274516394   time:  1.517723560333252
e:  29   train_loss:  933.247061435244   time:  1.4115276336669922
e:  30   train_loss:  878.9013579609841   time:  1.470290184020996
e:  30   train_loss:  878.9013579609841   val_loss:  481.91544401552693   time:  1.5757825374603271
e:  31   train_loss:  892.4323505643904   time:  1.4142701625823975
e:  32   train_loss:  899.1976206568243   time:  1.5379912853240967
e:  33   train_loss:  912.3847449136184   time:  1.4168856143951416
e:  34   train_loss:  889.2004743653839   time:  1.4199903011322021
e:  35   train_loss:  884.6238484867006   time:  1.4197802543640137
e:  35   train_loss:  884.6238484867006   val_loss:  485.53207397697327   time:  1.525402545928955
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  987.8758748943069   time:  1.302210807800293
e:  0   train_loss:  987.8758748943069   val_loss:  890.5839833833909   time:  1.411067247390747
e:  1   train_loss:  922.1527993692381   time:  1.3086175918579102
e:  2   train_loss:  845.6997977318116   time:  1.3064086437225342
e:  3   train_loss:  821.5221390971108   time:  1.4351630210876465
e:  4   train_loss:  787.0036041189966   time:  1.3141765594482422
e:  5   train_loss:  876.6879595548887   time:  1.3143749237060547
e:  5   train_loss:  876.6879595548887   val_loss:  737.2972802257236   time:  1.4242372512817383
e:  6   train_loss:  833.0598443888482   time:  1.3017337322235107
e:  7   train_loss:  793.5493440200971   time:  1.280754566192627
e:  8   train_loss:  800.3677216145775   time:  1.3059041500091553
e:  9   train_loss:  808.0538188112868   time:  1.3115484714508057
e:  10   train_loss:  799.0363315598147   time:  1.3137893676757812
e:  10   train_loss:  799.0363315598147   val_loss:  747.8678765924654   time:  1.423811674118042
e:  11   train_loss:  748.4452297565346   time:  1.3107631206512451
e:  12   train_loss:  707.4881852732361   time:  1.3135557174682617
e:  13   train_loss:  674.5960836369848   time:  1.310861349105835
e:  14   train_loss:  700.8114405773085   time:  1.3090715408325195
e:  15   train_loss:  720.9035129455207   time:  1.3098516464233398
e:  15   train_loss:  720.9035129455207   val_loss:  753.1135472018324   time:  1.5455405712127686
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  16   train_loss:  691.0889020570775   time:  1.3168163299560547
e:  17   train_loss:  659.4064755385834   time:  1.3111135959625244
e:  18   train_loss:  650.5464407440467   time:  1.313307762145996
e:  19   train_loss:  654.1727182249217   time:  1.3107120990753174
e:  20   train_loss:  657.849197570397   time:  1.3115980625152588
e:  20   train_loss:  657.849197570397   val_loss:  727.0210050836577   time:  1.421647071838379
e:  21   train_loss:  629.3456999506219   time:  1.3138318061828613
e:  22   train_loss:  617.1664792822961   time:  1.3140053749084473
e:  23   train_loss:  641.4841435015895   time:  1.3124768733978271
e:  24   train_loss:  606.0782526602741   time:  1.4392287731170654
e:  25   train_loss:  609.7124438627773   time:  1.302302360534668
e:  25   train_loss:  609.7124438627773   val_loss:  756.0983721764213   time:  1.4031753540039062
e:  26   train_loss:  661.5279892406862   time:  1.321605920791626
e:  27   train_loss:  661.1923498642303   time:  1.3044021129608154
e:  28   train_loss:  650.9484116235824   time:  1.3336310386657715
e:  29   train_loss:  590.6136680133754   time:  1.275331735610962
e:  30   train_loss:  579.4173234116116   time:  1.295985460281372
e:  30   train_loss:  579.4173234116116   val_loss:  681.2352281292792   time:  1.4053146839141846
e:  31   train_loss:  581.512735068863   time:  1.3115143775939941
e:  32   train_loss:  591.5989681476627   time:  1.304410457611084
e:  33   train_loss:  553.5078712309673   time:  1.3128817081451416
e:  34   train_loss:  569.752325825087   time:  1.3065576553344727
e:  35   train_loss:  669.2391748494044   time:  1.4348959922790527
e:  35   train_loss:  669.2391748494044   val_loss:  665.0813380026805   time:  1.5446150302886963
e:  36   train_loss:  620.0564639205455   time:  1.3056309223175049
e:  37   train_loss:  605.5268008043122   time:  1.313749074935913
e:  38   train_loss:  554.0046604277841   time:  1.3144035339355469
e:  39   train_loss:  549.8859871000225   time:  1.3068037033081055
e:  40   train_loss:  535.9016325367388   time:  1.3129565715789795
e:  40   train_loss:  535.9016325367388   val_loss:  677.8623804426592   time:  1.4232065677642822
e:  41   train_loss:  563.8496265040189   time:  1.3078007698059082
e:  42   train_loss:  624.7777880905785   time:  1.3142716884613037
e:  43   train_loss:  546.0888444366428   time:  1.3141632080078125
e:  44   train_loss:  550.2176526534784   time:  1.436248779296875
e:  45   train_loss:  548.920675529681   time:  1.3006458282470703
e:  45   train_loss:  548.920675529681   val_loss:  673.9214603950924   time:  1.4102356433868408
e:  46   train_loss:  527.9544051919314   time:  1.3154854774475098
e:  47   train_loss:  520.5755714274605   time:  1.3140223026275635
e:  48   train_loss:  613.0349388787406   time:  1.3060815334320068
e:  49   train_loss:  547.6206026963823   time:  1.3134336471557617
e:  50   train_loss:  637.9911217023041   time:  1.3112232685089111
e:  50   train_loss:  637.9911217023041   val_loss:  801.2755176044594   time:  1.4205286502838135
e:  51   train_loss:  660.2033585253076   time:  1.2871699333190918
e:  52   train_loss:  544.8060359170883   time:  1.283867597579956
e:  53   train_loss:  518.7589211316955   time:  1.434997797012329
e:  54   train_loss:  544.4938304686704   time:  1.3113937377929688
e:  55   train_loss:  533.7716818539128   time:  1.3128447532653809
e:  55   train_loss:  533.7716818539128   val_loss:  672.1093174461031   time:  1.4223687648773193
e:  56   train_loss:  502.2791130969018   time:  1.3150215148925781
e:  57   train_loss:  487.77659527673825   time:  1.3127899169921875
e:  58   train_loss:  503.78764776180526   time:  1.3068852424621582
e:  59   train_loss:  801.3637092023046   time:  1.3106458187103271
e:  60   train_loss:  621.3787888164062   time:  1.3126018047332764
e:  60   train_loss:  621.3787888164062   val_loss:  720.3129558559287   time:  1.422450065612793
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  61   train_loss:  529.7909455485805   time:  1.3240301609039307
e:  62   train_loss:  483.7369921487288   time:  1.310483455657959
e:  63   train_loss:  498.4708425929924   time:  1.3138017654418945
e:  64   train_loss:  512.4725643177211   time:  1.3111052513122559
e:  65   train_loss:  487.663103098158   time:  1.313225507736206
e:  65   train_loss:  487.663103098158   val_loss:  708.5985843693416   time:  1.5482404232025146
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1057.3785134598445   time:  1.4322681427001953
e:  0   train_loss:  1057.3785134598445   val_loss:  655.5463911065749   time:  1.5354199409484863
e:  1   train_loss:  931.0586623251994   time:  1.420820951461792
e:  2   train_loss:  885.1246017364043   time:  1.5496985912322998
e:  3   train_loss:  854.6343613003685   time:  1.5471720695495605
e:  4   train_loss:  892.1333541056362   time:  1.544980764389038
e:  5   train_loss:  813.0321853260047   time:  1.5417847633361816
e:  5   train_loss:  813.0321853260047   val_loss:  591.0070746608947   time:  1.8725099563598633
e:  6   train_loss:  918.2210318820336   time:  1.5106589794158936
e:  7   train_loss:  844.7688308701377   time:  1.514352560043335
e:  8   train_loss:  855.0298526463038   time:  1.519155740737915
e:  9   train_loss:  902.0052852710073   time:  1.426215648651123
e:  10   train_loss:  935.9744124632721   time:  1.5010600090026855
e:  10   train_loss:  935.9744124632721   val_loss:  557.000058068465   time:  1.6030092239379883
e:  11   train_loss:  897.776871272222   time:  1.418595314025879
e:  12   train_loss:  903.7145100458828   time:  1.427842140197754
e:  13   train_loss:  895.7045059242945   time:  1.4268872737884521
e:  14   train_loss:  932.0871265103337   time:  1.5503015518188477
e:  15   train_loss:  939.7640392283837   time:  1.41682767868042
e:  15   train_loss:  939.7640392283837   val_loss:  589.5171605510902   time:  1.5194354057312012
e:  16   train_loss:  897.1643104853022   time:  1.4272253513336182
e:  17   train_loss:  913.9531934760356   time:  1.4266917705535889
e:  18   train_loss:  896.250225178812   time:  1.4266414642333984
e:  19   train_loss:  896.6271942616862   time:  1.4280331134796143
e:  20   train_loss:  906.1164812150405   time:  1.5654408931732178
e:  20   train_loss:  906.1164812150405   val_loss:  575.4038657875692   time:  1.668994426727295
e:  21   train_loss:  903.7120239565788   time:  1.4199912548065186
e:  22   train_loss:  860.4400388938609   time:  1.4234633445739746
e:  23   train_loss:  895.1002641742704   time:  1.426039218902588
e:  24   train_loss:  901.1483816867885   time:  1.4183247089385986
e:  25   train_loss:  896.7817785745175   time:  1.5397744178771973
e:  25   train_loss:  896.7817785745175   val_loss:  561.7990045188493   time:  1.6357133388519287
e:  26   train_loss:  893.3367847651318   time:  1.406595230102539
e:  27   train_loss:  903.1579807719882   time:  1.3938302993774414
e:  28   train_loss:  876.2998599422606   time:  1.419508457183838
e:  29   train_loss:  905.1978973753622   time:  1.4172184467315674
e:  30   train_loss:  902.4762227253874   time:  1.4168336391448975
e:  30   train_loss:  902.4762227253874   val_loss:  578.2191669205114   time:  1.5193958282470703
e:  31   train_loss:  894.9540255298966   time:  1.4190735816955566
e:  32   train_loss:  785.6269300564641   time:  1.555309772491455
e:  33   train_loss:  766.8671196881953   time:  1.4272642135620117
e:  34   train_loss:  727.3220941171692   time:  1.429213523864746
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  35   train_loss:  717.7694113833635   time:  1.4363775253295898
e:  35   train_loss:  717.7694113833635   val_loss:  565.929675598662   time:  1.5393757820129395
e:  36   train_loss:  861.3010871938343   time:  1.5867178440093994
e:  37   train_loss:  758.2253353085988   time:  1.4317593574523926
e:  38   train_loss:  724.0450050725312   time:  1.5558393001556396
e:  39   train_loss:  705.0529921546361   time:  1.4266350269317627
e:  40   train_loss:  688.0054843030031   time:  1.4180421829223633
e:  40   train_loss:  688.0054843030031   val_loss:  544.2801093842893   time:  1.520951509475708
e:  41   train_loss:  650.6067144159301   time:  1.4293770790100098
e:  42   train_loss:  647.1245931434208   time:  1.4234049320220947
e:  43   train_loss:  665.8215683893784   time:  1.4272141456604004
e:  44   train_loss:  623.4858663050472   time:  1.4287042617797852
e:  45   train_loss:  611.4722997133119   time:  1.555152416229248
e:  45   train_loss:  611.4722997133119   val_loss:  561.6759990296844   time:  1.6578426361083984
e:  46   train_loss:  601.3958667359652   time:  1.41837477684021
e:  47   train_loss:  612.7567556732221   time:  1.3963158130645752
e:  48   train_loss:  664.0359514078546   time:  1.4034061431884766
e:  49   train_loss:  660.6807222123213   time:  1.4271843433380127
e:  50   train_loss:  602.5144069151585   time:  1.4276518821716309
e:  50   train_loss:  602.5144069151585   val_loss:  542.2496275358569   time:  1.530996322631836
e:  51   train_loss:  566.752937918062   time:  1.439054250717163
e:  52   train_loss:  618.0148144751564   time:  1.5588562488555908
e:  53   train_loss:  587.2449413811783   time:  1.4266526699066162
e:  54   train_loss:  578.0754062869593   time:  1.4251537322998047
e:  55   train_loss:  615.5768998466331   time:  1.4270234107971191
e:  55   train_loss:  615.5768998466331   val_loss:  545.2748546709119   time:  1.5303699970245361
e:  56   train_loss:  600.2782497763728   time:  1.424445629119873
e:  57   train_loss:  559.3227097640382   time:  1.4194059371948242
e:  58   train_loss:  548.4550508639696   time:  1.5394957065582275
e:  59   train_loss:  553.9983050102363   time:  1.4122192859649658
e:  60   train_loss:  591.159796003058   time:  1.4200022220611572
e:  60   train_loss:  591.159796003058   val_loss:  553.277492665067   time:  1.5222508907318115
e:  61   train_loss:  538.867135509022   time:  1.4845585823059082
e:  62   train_loss:  563.3754378649385   time:  1.474625587463379
e:  63   train_loss:  811.4871933404174   time:  1.4272739887237549
e:  64   train_loss:  768.1930246724356   time:  1.700524091720581
e:  65   train_loss:  620.5111887606193   time:  1.4248270988464355
e:  65   train_loss:  620.5111887606193   val_loss:  548.5762069345107   time:  1.5281429290771484
e:  66   train_loss:  558.4635425286067   time:  1.420515775680542
e:  67   train_loss:  555.2114570852568   time:  1.404921531677246
e:  68   train_loss:  534.7403539469913   time:  1.3987929821014404
e:  69   train_loss:  529.4826568011099   time:  1.4245104789733887
e:  70   train_loss:  529.5008800957517   time:  1.5345427989959717
e:  70   train_loss:  529.5008800957517   val_loss:  535.5413096639531   time:  1.6376063823699951
e:  71   train_loss:  513.1575421548771   time:  1.426330327987671
e:  72   train_loss:  544.2347911324753   time:  1.4200153350830078
e:  73   train_loss:  552.3814437458154   time:  1.4262583255767822
e:  74   train_loss:  501.11096055685056   time:  1.4269628524780273
e:  75   train_loss:  568.0510532743042   time:  1.4264333248138428
e:  75   train_loss:  568.0510532743042   val_loss:  534.0929024879612   time:  1.5288009643554688
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  76   train_loss:  537.1132898635635   time:  1.430633783340454
e:  77   train_loss:  510.7862225629907   time:  1.5666863918304443
e:  78   train_loss:  500.94312288365717   time:  1.5046968460083008
e:  79   train_loss:  510.4579044265968   time:  1.5966331958770752
e:  80   train_loss:  513.7922106819827   time:  1.5293729305267334
e:  80   train_loss:  513.7922106819827   val_loss:  541.6919972974199   time:  1.7221393585205078
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 22), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 22) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 22) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 22) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 22)
kwargs: {'config': {'batch_norm': False, 'ff_0': 17, 'ff_num_layers': 1, 'gnn_0': 281, 'gnn_dropout': 0.3279737195479306, 'gnn_num_layers': 1, 'hid_0': 593, 'hid_dropout_rate': 0.20414696252923964, 'in_dropout_rate': 0.4386659901915775, 'lr': 0.0015707457967605017, 'num_hid_layers': 3, 'optimizer': 'SGD', 'hid_1': 511, 'hid_2': 271, 'sgd_momentum': 0.6094637896459667}, 'budget': 81.0, 'working_directory': '.'}
result: {'loss': 709.5524417576454, 'n_epochs': 64.2, 'info': {'validation loss': 709.5524417576454}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 22) started
DEBUG:hpbandster:job_callback for (0, 0, 22) got condition
DEBUG:hpbandster:Only 7 run(s) for budget 81.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 22) finished
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 25) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 25) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 25)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 25) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 25) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 25)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 21, 'ff_num_layers': 3, 'gnn_0': 958, 'gnn_dropout': 0.21542627652451324, 'gnn_num_layers': 2, 'hid_0': 1601, 'hid_dropout_rate': 0.4271126297116419, 'in_dropout_rate': 0.3095603548680177, 'lr': 0.00029072047003001915, 'num_hid_layers': 2, 'optimizer': 'Adam', 'ff_1': 1739, 'ff_2': 662, 'gnn_1': 120, 'hid_1': 1877}, 'budget': 81.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  656.8881176124123   time:  1.762822151184082
e:  0   train_loss:  656.8881176124123   val_loss:  1331.9431571816526   time:  1.905423879623413
e:  1   train_loss:  602.4815022332493   time:  1.7869045734405518
e:  2   train_loss:  592.7365393128703   time:  1.8298184871673584
e:  3   train_loss:  585.8928724630553   time:  1.7250661849975586
e:  4   train_loss:  579.255758519444   time:  1.7105789184570312
e:  5   train_loss:  569.7855546459919   time:  1.6743578910827637
e:  5   train_loss:  569.7855546459919   val_loss:  1381.5546633340034   time:  1.7904555797576904
e:  6   train_loss:  554.699729009154   time:  1.7313449382781982
e:  7   train_loss:  535.8163706095728   time:  1.6732070446014404
e:  8   train_loss:  513.1309466821226   time:  1.7048530578613281
e:  9   train_loss:  489.5043621110106   time:  1.725182056427002
e:  10   train_loss:  468.4548605275129   time:  1.7168707847595215
e:  10   train_loss:  468.4548605275129   val_loss:  1421.7681215777861   time:  1.8357808589935303
e:  11   train_loss:  455.4991163169273   time:  1.7158448696136475
e:  12   train_loss:  442.31607775684546   time:  1.7373943328857422
e:  13   train_loss:  437.38797149775576   time:  1.8365750312805176
e:  14   train_loss:  428.3443476991282   time:  1.7281537055969238
e:  15   train_loss:  422.47445990997   time:  1.7261402606964111
e:  15   train_loss:  422.47445990997   val_loss:  1415.5104890678808   time:  1.8761012554168701
e:  16   train_loss:  420.0076540014079   time:  1.7664282321929932
e:  17   train_loss:  416.72995905781534   time:  1.718031883239746
e:  18   train_loss:  414.3729842199109   time:  1.7206766605377197
e:  19   train_loss:  411.2930819483421   time:  1.7257146835327148
e:  20   train_loss:  408.3520479247374   time:  1.7240970134735107
e:  20   train_loss:  408.3520479247374   val_loss:  1410.7706878664183   time:  1.9245362281799316
e:  21   train_loss:  405.84732084444215   time:  1.7298896312713623
e:  22   train_loss:  405.7037594741344   time:  1.839212417602539
e:  23   train_loss:  404.8048109646644   time:  1.6613619327545166
e:  24   train_loss:  401.88041917436465   time:  1.774489164352417
e:  25   train_loss:  398.23383141532594   time:  1.7161638736724854
e:  25   train_loss:  398.23383141532594   val_loss:  1395.6340318262774   time:  1.8354532718658447
e:  26   train_loss:  395.121054632005   time:  1.7204444408416748
e:  27   train_loss:  391.9440970598461   time:  1.7099337577819824
e:  28   train_loss:  388.34506015023675   time:  1.7404563426971436
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  29   train_loss:  384.63768808109836   time:  1.6716821193695068
e:  30   train_loss:  380.797384922454   time:  1.6424686908721924
e:  30   train_loss:  380.797384922454   val_loss:  1389.1845263636146   time:  1.7604775428771973
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1006.857496368565   time:  1.831289529800415
e:  0   train_loss:  1006.857496368565   val_loss:  644.5350125880508   time:  2.0618133544921875
e:  1   train_loss:  936.9803217826949   time:  1.8520481586456299
e:  2   train_loss:  899.0250465642504   time:  1.8934807777404785
e:  3   train_loss:  881.4492532964339   time:  1.957411766052246
e:  4   train_loss:  867.3258847918403   time:  2.0417585372924805
e:  5   train_loss:  832.2491973985657   time:  1.7681138515472412
e:  5   train_loss:  832.2491973985657   val_loss:  560.7603064047385   time:  1.8875815868377686
e:  6   train_loss:  737.3363388630571   time:  1.8967602252960205
e:  7   train_loss:  707.5080606781416   time:  1.814417839050293
e:  8   train_loss:  693.6878760518975   time:  1.7697334289550781
e:  9   train_loss:  647.9234608843819   time:  1.7336549758911133
e:  10   train_loss:  631.5618227300033   time:  1.803419589996338
e:  10   train_loss:  631.5618227300033   val_loss:  695.077231445533   time:  1.9139008522033691
e:  11   train_loss:  606.9475515843274   time:  1.8442955017089844
e:  12   train_loss:  601.815456402812   time:  1.873162031173706
e:  13   train_loss:  590.0327973780084   time:  2.047258138656616
e:  14   train_loss:  582.8465133852079   time:  1.8621203899383545
e:  15   train_loss:  573.8222654819771   time:  1.8237171173095703
e:  15   train_loss:  573.8222654819771   val_loss:  710.4153180481854   time:  1.9363672733306885
e:  16   train_loss:  559.5028611698318   time:  1.879652500152588
e:  17   train_loss:  552.8752887194983   time:  1.771467924118042
e:  18   train_loss:  563.0980541815211   time:  1.9647488594055176
e:  19   train_loss:  545.5618500248665   time:  1.9972939491271973
e:  20   train_loss:  547.3980149557433   time:  1.979917049407959
e:  20   train_loss:  547.3980149557433   val_loss:  763.7163519978296   time:  2.0905685424804688
e:  21   train_loss:  546.2021965355265   time:  1.8473498821258545
e:  22   train_loss:  551.0509776400078   time:  1.7697339057922363
e:  23   train_loss:  548.203696894209   time:  1.748854160308838
e:  24   train_loss:  545.7569809513897   time:  1.7771286964416504
e:  25   train_loss:  532.478919333189   time:  1.8475346565246582
e:  25   train_loss:  532.478919333189   val_loss:  761.9758385486855   time:  1.9585800170898438
e:  26   train_loss:  538.8666401544747   time:  1.9826688766479492
e:  27   train_loss:  533.0955461427051   time:  1.7796003818511963
e:  28   train_loss:  534.8960895121207   time:  1.8281629085540771
e:  29   train_loss:  528.3287983220323   time:  1.84578537940979
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  30   train_loss:  524.1654024987236   time:  1.824582576751709
e:  30   train_loss:  524.1654024987236   val_loss:  708.7607192109247   time:  1.9342198371887207
e:  31   train_loss:  526.7394184408354   time:  1.8844578266143799
e:  32   train_loss:  519.6483662466326   time:  1.8454203605651855
e:  33   train_loss:  514.2536541268614   time:  1.9840116500854492
e:  34   train_loss:  507.79730691927904   time:  1.9519813060760498
e:  35   train_loss:  504.60032825063615   time:  1.9966449737548828
e:  35   train_loss:  504.60032825063615   val_loss:  701.7877442325761   time:  2.12430739402771
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1035.6338803844164   time:  1.8257386684417725
e:  0   train_loss:  1035.6338803844164   val_loss:  637.8508548914231   time:  1.9402341842651367
e:  1   train_loss:  943.7373631476502   time:  1.9398088455200195
e:  2   train_loss:  930.186987531261   time:  1.9769749641418457
e:  3   train_loss:  866.1759576535298   time:  1.8491268157958984
e:  4   train_loss:  903.4688365302591   time:  1.9614694118499756
e:  5   train_loss:  877.7069606021827   time:  2.160715103149414
e:  5   train_loss:  877.7069606021827   val_loss:  492.5328654708507   time:  2.2775309085845947
e:  6   train_loss:  800.3873371731593   time:  1.9406557083129883
e:  7   train_loss:  733.3870913306314   time:  1.9260079860687256
e:  8   train_loss:  734.9354196241327   time:  1.9205708503723145
e:  9   train_loss:  688.7247366904661   time:  1.9223036766052246
e:  10   train_loss:  664.1234531808509   time:  1.9334721565246582
e:  10   train_loss:  664.1234531808509   val_loss:  548.3985388032246   time:  2.04868221282959
e:  11   train_loss:  648.7844706904486   time:  2.1629796028137207
e:  12   train_loss:  629.0406924985256   time:  1.940197467803955
e:  13   train_loss:  649.6402365585307   time:  1.9762768745422363
e:  14   train_loss:  624.5838429521244   time:  1.956498622894287
e:  15   train_loss:  598.5541875636941   time:  1.8875725269317627
e:  15   train_loss:  598.5541875636941   val_loss:  525.3033478342664   time:  2.0003530979156494
e:  16   train_loss:  604.7748506366172   time:  1.816248893737793
e:  17   train_loss:  596.7672932427721   time:  1.8369295597076416
e:  18   train_loss:  595.1280655093155   time:  1.8760488033294678
e:  19   train_loss:  583.1657649585557   time:  2.029604911804199
e:  20   train_loss:  572.0119513642101   time:  1.9073364734649658
e:  20   train_loss:  572.0119513642101   val_loss:  516.7199547261938   time:  2.025827407836914
e:  21   train_loss:  568.6477781599826   time:  1.8273043632507324
e:  22   train_loss:  581.7456673363821   time:  1.8036868572235107
e:  23   train_loss:  579.4355038656698   time:  1.7857201099395752
e:  24   train_loss:  571.4867426612088   time:  1.7431981563568115
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  25   train_loss:  569.3894413520987   time:  1.7108008861541748
e:  25   train_loss:  569.3894413520987   val_loss:  549.3741580099752   time:  1.8246257305145264
e:  26   train_loss:  612.2480074476523   time:  1.9536688327789307
e:  27   train_loss:  562.117248104501   time:  1.8226039409637451
e:  28   train_loss:  580.8230631546702   time:  1.8164641857147217
e:  29   train_loss:  567.7866791122252   time:  1.8127048015594482
e:  30   train_loss:  558.0786456151126   time:  1.782146692276001
e:  30   train_loss:  558.0786456151126   val_loss:  533.3088577197154   time:  1.8968238830566406
e:  31   train_loss:  570.4764171510756   time:  1.8198750019073486
e:  32   train_loss:  551.7562489198111   time:  1.7518775463104248
e:  33   train_loss:  565.5855540814046   time:  1.8475468158721924
e:  34   train_loss:  552.126073034936   time:  1.9045021533966064
e:  35   train_loss:  544.3335418826845   time:  1.744431734085083
e:  35   train_loss:  544.3335418826845   val_loss:  529.0060752484518   time:  1.856621265411377
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  936.9955126744446   time:  1.6119742393493652
e:  0   train_loss:  936.9955126744446   val_loss:  756.7287033658234   time:  1.7351083755493164
e:  1   train_loss:  846.0925576956112   time:  1.7048559188842773
e:  2   train_loss:  835.5288927801395   time:  1.6953208446502686
e:  3   train_loss:  827.191712442753   time:  1.7012629508972168
e:  4   train_loss:  816.2693494709866   time:  1.7004053592681885
e:  5   train_loss:  800.7823413070557   time:  1.6956067085266113
e:  5   train_loss:  800.7823413070557   val_loss:  725.6874233373607   time:  1.8163478374481201
e:  6   train_loss:  764.085580739802   time:  1.704787015914917
e:  7   train_loss:  710.1255878271352   time:  1.7043819427490234
e:  8   train_loss:  667.3169546072209   time:  1.6920924186706543
e:  9   train_loss:  628.4037562618802   time:  1.697601079940796
e:  10   train_loss:  621.327020984417   time:  1.8034284114837646
e:  10   train_loss:  621.327020984417   val_loss:  717.1720154907853   time:  1.9244792461395264
e:  11   train_loss:  601.6948569407518   time:  1.6985063552856445
e:  12   train_loss:  588.225224464029   time:  1.6379213333129883
e:  13   train_loss:  578.4394094348713   time:  1.67049241065979
e:  14   train_loss:  565.9430781439506   time:  1.697169303894043
e:  15   train_loss:  560.9133092374951   time:  1.6769163608551025
e:  15   train_loss:  560.9133092374951   val_loss:  700.8491814166346   time:  1.7956817150115967
e:  16   train_loss:  555.6208640655966   time:  1.6123902797698975
e:  17   train_loss:  561.500250076663   time:  1.6904377937316895
e:  18   train_loss:  547.2793151376957   time:  1.7300143241882324
e:  19   train_loss:  543.9211908651251   time:  1.8137879371643066
e:  20   train_loss:  541.7165089671975   time:  1.7474064826965332
e:  20   train_loss:  541.7165089671975   val_loss:  746.6584394710935   time:  1.8680288791656494
e:  21   train_loss:  533.8725064283545   time:  1.7395679950714111
e:  22   train_loss:  534.1498141683056   time:  1.7452590465545654
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  23   train_loss:  528.5985240987459   time:  1.7410533428192139
e:  24   train_loss:  527.8430549992736   time:  1.7286713123321533
e:  25   train_loss:  523.9375338360168   time:  1.691809892654419
e:  25   train_loss:  523.9375338360168   val_loss:  725.8542774797045   time:  1.8120801448822021
e:  26   train_loss:  522.0723691868033   time:  1.694760799407959
e:  27   train_loss:  521.6359856095992   time:  1.7025642395019531
e:  28   train_loss:  520.467773289817   time:  1.6968944072723389
e:  29   train_loss:  524.6326735038613   time:  1.697495937347412
e:  30   train_loss:  521.0122829517303   time:  1.8008966445922852
e:  30   train_loss:  521.0122829517303   val_loss:  718.5238265213637   time:  1.9218816757202148
e:  31   train_loss:  521.1422660149511   time:  1.678218126296997
e:  32   train_loss:  522.2758867970267   time:  1.6910779476165771
e:  33   train_loss:  518.3467494166348   time:  1.600651741027832
e:  34   train_loss:  517.8115478367527   time:  1.6618616580963135
e:  35   train_loss:  510.2489210173793   time:  1.6903126239776611
e:  35   train_loss:  510.2489210173793   val_loss:  763.6218239704526   time:  1.8124785423278809
e:  36   train_loss:  505.4019578988675   time:  1.6908843517303467
e:  37   train_loss:  503.9881002656274   time:  1.700746774673462
e:  38   train_loss:  498.14456542430355   time:  1.6993565559387207
e:  39   train_loss:  497.9825261776119   time:  1.817467212677002
e:  40   train_loss:  493.4106060222827   time:  1.649585247039795
e:  40   train_loss:  493.4106060222827   val_loss:  753.5247609300457   time:  1.7685158252716064
e:  41   train_loss:  491.13430846055985   time:  1.737764835357666
e:  42   train_loss:  484.88996496894606   time:  1.7286591529846191
e:  43   train_loss:  483.0815269550105   time:  1.700962781906128
e:  44   train_loss:  475.5478657410015   time:  1.7122433185577393
e:  45   train_loss:  474.7686174882865   time:  1.7239973545074463
e:  45   train_loss:  474.7686174882865   val_loss:  756.5179686673754   time:  1.8752121925354004
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  992.4731858847343   time:  1.8974292278289795
e:  0   train_loss:  992.4731858847343   val_loss:  607.5388661023874   time:  2.013247489929199
e:  1   train_loss:  901.398687308852   time:  1.9651448726654053
e:  2   train_loss:  890.6871444733529   time:  2.099216938018799
e:  3   train_loss:  866.763068516567   time:  1.9799306392669678
e:  4   train_loss:  878.6530367052279   time:  1.8908791542053223
e:  5   train_loss:  805.0137385071707   time:  1.9316678047180176
e:  5   train_loss:  805.0137385071707   val_loss:  564.4757802953044   time:  2.042614698410034
e:  6   train_loss:  730.1856876661092   time:  1.8785364627838135
e:  7   train_loss:  688.7163496870603   time:  1.8902192115783691
e:  8   train_loss:  662.8469376108949   time:  1.8079628944396973
e:  9   train_loss:  654.0799143718459   time:  2.0032007694244385
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  10   train_loss:  621.36761296487   time:  1.9053361415863037
e:  10   train_loss:  621.36761296487   val_loss:  572.4848960112329   time:  2.0184621810913086
e:  11   train_loss:  618.4054241206896   time:  2.0419769287109375
e:  12   train_loss:  608.438618902275   time:  2.091611623764038
e:  13   train_loss:  592.6825124708113   time:  2.005324125289917
e:  14   train_loss:  594.194116315415   time:  1.9127721786499023
e:  15   train_loss:  593.0954971080504   time:  2.0008182525634766
e:  15   train_loss:  593.0954971080504   val_loss:  571.5010343959956   time:  2.1139252185821533
e:  16   train_loss:  598.6818670454769   time:  1.9880096912384033
e:  17   train_loss:  580.2321108500886   time:  1.9787328243255615
e:  18   train_loss:  579.1116678148217   time:  1.9943397045135498
e:  19   train_loss:  568.3197483200006   time:  1.8833088874816895
e:  20   train_loss:  571.8090647467664   time:  1.8126113414764404
e:  20   train_loss:  571.8090647467664   val_loss:  573.6470897070869   time:  2.094290256500244
e:  21   train_loss:  563.1617851441156   time:  1.8558871746063232
e:  22   train_loss:  564.9467818539024   time:  1.9017846584320068
e:  23   train_loss:  574.0088452079018   time:  1.8938779830932617
e:  24   train_loss:  572.4266394961434   time:  1.8717985153198242
e:  25   train_loss:  559.6366809991323   time:  1.8593494892120361
e:  25   train_loss:  559.6366809991323   val_loss:  571.8152226863997   time:  2.0485026836395264
e:  26   train_loss:  557.880016362388   time:  1.9262051582336426
e:  27   train_loss:  559.5916531124833   time:  2.0392580032348633
e:  28   train_loss:  555.116467404602   time:  1.8764922618865967
e:  29   train_loss:  564.3330026606529   time:  1.8906655311584473
e:  30   train_loss:  557.0919048514721   time:  1.8389451503753662
e:  30   train_loss:  557.0919048514721   val_loss:  572.7162029172827   time:  1.9496982097625732
e:  31   train_loss:  544.6133535419103   time:  1.873131275177002
e:  32   train_loss:  548.7023482617547   time:  1.8285620212554932
e:  33   train_loss:  542.9837061810919   time:  1.973407506942749
e:  34   train_loss:  533.986941092856   time:  1.810070276260376
e:  35   train_loss:  545.2996748105306   time:  1.7804441452026367
e:  35   train_loss:  545.2996748105306   val_loss:  589.1142534424428   time:  1.8915090560913086
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 25), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 25) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 25) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 25) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 25)
kwargs: {'config': {'batch_norm': False, 'ff_0': 21, 'ff_num_layers': 3, 'gnn_0': 958, 'gnn_dropout': 0.21542627652451324, 'gnn_num_layers': 2, 'hid_0': 1601, 'hid_dropout_rate': 0.4271126297116419, 'in_dropout_rate': 0.3095603548680177, 'lr': 0.00029072047003001915, 'num_hid_layers': 2, 'optimizer': 'Adam', 'ff_1': 1739, 'ff_2': 662, 'gnn_1': 120, 'hid_1': 1877}, 'budget': 81.0, 'working_directory': '.'}
result: {'loss': 730.1122581538361, 'n_epochs': 36.0, 'info': {'validation loss': 730.1122581538361}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 25) started
DEBUG:hpbandster:job_callback for (0, 0, 25) got condition
DEBUG:hpbandster:Only 8 run(s) for budget 81.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 25) finished
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 26) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 26) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 26)
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 26) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 26) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 26)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 876, 'ff_num_layers': 2, 'gnn_0': 227, 'gnn_dropout': 0.49213520925025633, 'gnn_num_layers': 1, 'hid_0': 1532, 'hid_dropout_rate': 0.15679639657463124, 'in_dropout_rate': 0.39029146685469257, 'lr': 0.0025714843620315395, 'num_hid_layers': 1, 'optimizer': 'Adam', 'ff_1': 28}, 'budget': 81.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  619.7093372216964   time:  1.500138759613037
e:  0   train_loss:  619.7093372216964   val_loss:  1420.0844714027578   time:  1.61165189743042
e:  1   train_loss:  550.0499815183248   time:  1.536864995956421
e:  2   train_loss:  509.4545896151336   time:  1.5120940208435059
e:  3   train_loss:  483.6348614254358   time:  1.4947764873504639
e:  4   train_loss:  471.0602841755502   time:  1.5387794971466064
e:  5   train_loss:  455.57267736540757   time:  1.5248363018035889
e:  5   train_loss:  455.57267736540757   val_loss:  1378.255195356778   time:  1.6365296840667725
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  6   train_loss:  449.80582342056783   time:  1.7064268589019775
e:  7   train_loss:  440.07769357181377   time:  1.5191102027893066
e:  8   train_loss:  439.6613420694728   time:  1.5407462120056152
e:  9   train_loss:  432.01473194440837   time:  1.5265262126922607
e:  10   train_loss:  428.9237207553658   time:  1.5482134819030762
e:  10   train_loss:  428.9237207553658   val_loss:  1209.0807894253412   time:  1.660001516342163
e:  11   train_loss:  428.0265653818201   time:  1.594158411026001
e:  12   train_loss:  426.3466055641452   time:  1.5475916862487793
e:  13   train_loss:  421.4105755928088   time:  1.4979209899902344
e:  14   train_loss:  419.58996346597496   time:  1.4984076023101807
e:  15   train_loss:  420.7672888045275   time:  1.49845552444458
e:  15   train_loss:  420.7672888045275   val_loss:  1198.325154896976   time:  1.7365167140960693
e:  16   train_loss:  418.0599302068819   time:  1.4808099269866943
e:  17   train_loss:  415.1494357690787   time:  1.42983078956604
e:  18   train_loss:  413.3676352052232   time:  1.4730238914489746
e:  19   train_loss:  409.71864729034945   time:  1.4956059455871582
e:  20   train_loss:  408.5705664560304   time:  1.5925819873809814
e:  20   train_loss:  408.5705664560304   val_loss:  1179.9394376725602   time:  1.7792456150054932
e:  21   train_loss:  403.61423384753385   time:  1.749753475189209
e:  22   train_loss:  401.056042810413   time:  1.655364990234375
e:  23   train_loss:  397.2235770485014   time:  1.7033259868621826
e:  24   train_loss:  393.32079239163033   time:  1.5790438652038574
e:  25   train_loss:  391.0520224066364   time:  1.5626037120819092
e:  25   train_loss:  391.0520224066364   val_loss:  1208.6360028910167   time:  1.6746392250061035
e:  26   train_loss:  388.10853110049885   time:  1.6193828582763672
e:  27   train_loss:  382.81354796870386   time:  1.5005707740783691
e:  28   train_loss:  379.07302172419656   time:  1.6670901775360107
e:  29   train_loss:  376.58094113436147   time:  1.4953255653381348
e:  30   train_loss:  370.5715840082984   time:  1.4888291358947754
e:  30   train_loss:  370.5715840082984   val_loss:  1266.0476495073676   time:  1.6012346744537354
e:  31   train_loss:  366.2266789406466   time:  1.4924328327178955
e:  32   train_loss:  361.50462222373085   time:  1.4891250133514404
e:  33   train_loss:  357.5068589939886   time:  1.4982097148895264
e:  34   train_loss:  354.1608621262493   time:  1.4989521503448486
e:  35   train_loss:  349.64952187798696   time:  1.4832370281219482
e:  35   train_loss:  349.64952187798696   val_loss:  1358.1657741639676   time:  1.7119026184082031
e:  36   train_loss:  345.6833798906561   time:  1.395226240158081
e:  37   train_loss:  341.79338123467755   time:  1.4710299968719482
e:  38   train_loss:  337.18098925505734   time:  1.4977848529815674
e:  39   train_loss:  332.8639551369346   time:  1.4965558052062988
e:  40   train_loss:  330.98834524083344   time:  1.4954113960266113
e:  40   train_loss:  330.98834524083344   val_loss:  1363.3108509033773   time:  1.6085031032562256
e:  41   train_loss:  325.6513620965107   time:  1.4932053089141846
e:  42   train_loss:  322.8972993406157   time:  1.494446039199829
e:  43   train_loss:  319.3823216344007   time:  1.494727611541748
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  44   train_loss:  317.3600890824272   time:  1.4987223148345947
e:  45   train_loss:  313.8717155704908   time:  1.496523141860962
e:  45   train_loss:  313.8717155704908   val_loss:  1370.5079680611439   time:  1.6090130805969238
e:  46   train_loss:  312.63531954364527   time:  1.6205568313598633
e:  47   train_loss:  308.9820888171288   time:  1.44789719581604
e:  48   train_loss:  304.6060247117073   time:  1.4821393489837646
e:  49   train_loss:  302.9607434368438   time:  1.4887161254882812
e:  50   train_loss:  299.65532647543404   time:  1.4930803775787354
e:  50   train_loss:  299.65532647543404   val_loss:  1339.7541012023223   time:  1.6048028469085693
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  927.4264957354638   time:  1.6276588439941406
e:  0   train_loss:  927.4264957354638   val_loss:  558.2356169626795   time:  1.7333683967590332
e:  1   train_loss:  753.4633673608489   time:  1.6246025562286377
e:  2   train_loss:  656.8774969594926   time:  1.621938943862915
e:  3   train_loss:  649.1713574724184   time:  1.625788688659668
e:  4   train_loss:  628.3211326890429   time:  1.6117968559265137
e:  5   train_loss:  608.8028105584223   time:  1.736363172531128
e:  5   train_loss:  608.8028105584223   val_loss:  550.0562060395679   time:  1.8408362865447998
e:  6   train_loss:  609.8405640765075   time:  1.6250789165496826
e:  7   train_loss:  601.02714840459   time:  1.6274902820587158
e:  8   train_loss:  599.7302562837499   time:  1.6225965023040771
e:  9   train_loss:  588.911030135795   time:  1.7285327911376953
e:  10   train_loss:  600.4685313431751   time:  1.657583236694336
e:  10   train_loss:  600.4685313431751   val_loss:  881.1438878959827   time:  1.7621219158172607
e:  11   train_loss:  583.6613030070816   time:  1.7560036182403564
e:  12   train_loss:  567.2188662241964   time:  1.6243388652801514
e:  13   train_loss:  571.1543949348859   time:  1.6241872310638428
e:  14   train_loss:  580.2236259054466   time:  1.6241445541381836
e:  15   train_loss:  569.7250613736812   time:  1.6206769943237305
e:  15   train_loss:  569.7250613736812   val_loss:  873.1991484862801   time:  1.7262303829193115
e:  16   train_loss:  574.421575567003   time:  1.6266067028045654
e:  17   train_loss:  559.3147097210999   time:  1.6258223056793213
e:  18   train_loss:  556.1613553957955   time:  1.7363803386688232
e:  19   train_loss:  559.1054939566005   time:  1.6255619525909424
e:  20   train_loss:  554.2938554593642   time:  1.6774482727050781
e:  20   train_loss:  554.2938554593642   val_loss:  1050.631176701148   time:  1.7817051410675049
e:  21   train_loss:  542.7364715049605   time:  1.6264817714691162
e:  22   train_loss:  553.6453246226132   time:  1.5757267475128174
e:  23   train_loss:  547.7032480248513   time:  1.6056504249572754
e:  24   train_loss:  541.8587027347062   time:  1.6120948791503906
e:  25   train_loss:  537.6965973109035   time:  1.7466773986816406
e:  25   train_loss:  537.6965973109035   val_loss:  1079.2046441193647   time:  1.8515090942382812
e:  26   train_loss:  527.3342755017123   time:  1.62581467628479
e:  27   train_loss:  545.444728779913   time:  1.625924825668335
e:  28   train_loss:  531.873229959946   time:  1.6224710941314697
e:  29   train_loss:  514.2662801252109   time:  1.6252574920654297
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  30   train_loss:  517.9199699784141   time:  1.6285579204559326
e:  30   train_loss:  517.9199699784141   val_loss:  952.6156519356645   time:  1.7340645790100098
e:  31   train_loss:  503.24955964802444   time:  1.776456356048584
e:  32   train_loss:  505.9914193609015   time:  1.6257140636444092
e:  33   train_loss:  507.29144562312416   time:  1.6230106353759766
e:  34   train_loss:  501.2986479061587   time:  1.6277344226837158
e:  35   train_loss:  498.93089251357316   time:  1.6433830261230469
e:  35   train_loss:  498.93089251357316   val_loss:  761.372168668158   time:  1.7522704601287842
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  934.7608376538343   time:  1.7260382175445557
e:  0   train_loss:  934.7608376538343   val_loss:  488.03626191496556   time:  1.8350234031677246
e:  1   train_loss:  732.3364672431669   time:  1.7264516353607178
e:  2   train_loss:  671.9937191912196   time:  1.9845049381256104
e:  3   train_loss:  659.5373574434689   time:  1.7073590755462646
e:  4   train_loss:  644.9270489370155   time:  1.6671009063720703
e:  5   train_loss:  622.3817843642838   time:  1.7253293991088867
e:  5   train_loss:  622.3817843642838   val_loss:  468.8358697521099   time:  1.835400104522705
e:  6   train_loss:  623.380010837684   time:  1.7257404327392578
e:  7   train_loss:  638.605683580356   time:  1.73870849609375
e:  8   train_loss:  600.3641047778715   time:  1.721771001815796
e:  9   train_loss:  609.6715908191394   time:  1.7383322715759277
e:  10   train_loss:  642.270662694991   time:  1.851416826248169
e:  10   train_loss:  642.270662694991   val_loss:  493.47659088027314   time:  1.9524266719818115
e:  11   train_loss:  609.9120822186385   time:  1.599658489227295
e:  12   train_loss:  613.818937511972   time:  1.603635549545288
e:  13   train_loss:  602.2516102859447   time:  1.6067736148834229
e:  14   train_loss:  603.0680925947872   time:  1.6030890941619873
e:  15   train_loss:  607.3153515946165   time:  1.6062803268432617
e:  15   train_loss:  607.3153515946165   val_loss:  564.2312921994178   time:  1.7144193649291992
e:  16   train_loss:  578.6707918547017   time:  1.6053457260131836
e:  17   train_loss:  591.7208601232045   time:  1.6024892330169678
e:  18   train_loss:  581.5012651699286   time:  1.7338218688964844
e:  19   train_loss:  589.4488932673296   time:  1.6026909351348877
e:  20   train_loss:  587.9514785384193   time:  1.6021504402160645
e:  20   train_loss:  587.9514785384193   val_loss:  466.0387008481005   time:  1.7095057964324951
e:  21   train_loss:  604.1413412784673   time:  1.5630056858062744
e:  22   train_loss:  610.7315085703789   time:  1.551220417022705
e:  23   train_loss:  654.3411810862199   time:  1.6011526584625244
e:  24   train_loss:  606.9850387634998   time:  1.624455451965332
e:  25   train_loss:  602.507721392983   time:  1.6665124893188477
e:  25   train_loss:  602.507721392983   val_loss:  542.9033588193724   time:  1.7750270366668701
e:  26   train_loss:  596.0934588870451   time:  1.6029431819915771
e:  27   train_loss:  589.2787417378391   time:  1.5991275310516357
e:  28   train_loss:  598.8307872933991   time:  1.6024620532989502
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  29   train_loss:  593.4410805121502   time:  1.6071929931640625
e:  30   train_loss:  573.2413461749057   time:  1.6035969257354736
e:  30   train_loss:  573.2413461749057   val_loss:  485.26567319743896   time:  1.7119731903076172
e:  31   train_loss:  582.8182478695029   time:  1.7479939460754395
e:  32   train_loss:  581.7128271901588   time:  1.6035146713256836
e:  33   train_loss:  557.5456335603936   time:  1.6046931743621826
e:  34   train_loss:  566.1315968045334   time:  1.6027510166168213
e:  35   train_loss:  565.4071187944539   time:  1.5987648963928223
e:  35   train_loss:  565.4071187944539   val_loss:  491.70506114077574   time:  1.7063534259796143
e:  36   train_loss:  573.5883629608475   time:  1.5948388576507568
e:  37   train_loss:  562.4797015609342   time:  1.6167712211608887
e:  38   train_loss:  550.3007316928587   time:  1.6058635711669922
e:  39   train_loss:  539.6755024859146   time:  1.7204606533050537
e:  40   train_loss:  556.1135644174558   time:  1.531998634338379
e:  40   train_loss:  556.1135644174558   val_loss:  547.610409228224   time:  1.6401712894439697
e:  41   train_loss:  552.8987627041182   time:  1.6079299449920654
e:  42   train_loss:  534.9709863559042   time:  1.6030213832855225
e:  43   train_loss:  543.2146561520879   time:  1.6042535305023193
e:  44   train_loss:  537.7846321033904   time:  1.605215072631836
e:  45   train_loss:  540.9110989073492   time:  1.601289987564087
e:  45   train_loss:  540.9110989073492   val_loss:  523.9826783984894   time:  1.7097949981689453
e:  46   train_loss:  524.2973593926853   time:  1.734227180480957
e:  47   train_loss:  523.1132305319366   time:  1.603743553161621
e:  48   train_loss:  535.1657017137157   time:  1.5989491939544678
e:  49   train_loss:  527.7892193015988   time:  1.6030986309051514
e:  50   train_loss:  505.17496392564163   time:  1.6028752326965332
e:  50   train_loss:  505.17496392564163   val_loss:  547.8112239183578   time:  1.7107055187225342
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  870.265076294418   time:  1.4779996871948242
e:  0   train_loss:  870.265076294418   val_loss:  738.222582371223   time:  1.5919506549835205
e:  1   train_loss:  728.5583391028691   time:  1.488502025604248
e:  2   train_loss:  630.4190596544672   time:  1.6085567474365234
e:  3   train_loss:  606.3222220514793   time:  1.4898295402526855
e:  4   train_loss:  591.9139012555221   time:  1.4885265827178955
e:  5   train_loss:  571.2850316335765   time:  1.4919400215148926
e:  5   train_loss:  571.2850316335765   val_loss:  748.0703790433478   time:  1.605543613433838
e:  6   train_loss:  563.3779153129847   time:  1.4977965354919434
e:  7   train_loss:  571.7399948466123   time:  1.4592363834381104
e:  8   train_loss:  560.5594565410655   time:  1.437302827835083
e:  9   train_loss:  567.4889123928896   time:  1.490957498550415
e:  10   train_loss:  554.7020380275281   time:  1.492356777191162
e:  10   train_loss:  554.7020380275281   val_loss:  730.1512536382074   time:  1.681706428527832
e:  11   train_loss:  553.8506700569066   time:  1.566755771636963
e:  12   train_loss:  562.6169280232623   time:  1.4944422245025635
e:  13   train_loss:  557.8920256123267   time:  1.6152098178863525
e:  14   train_loss:  558.4188973158857   time:  1.477156639099121
e:  15   train_loss:  539.7092919990351   time:  1.492645502090454
e:  15   train_loss:  539.7092919990351   val_loss:  724.7158538813793   time:  1.6060922145843506
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  16   train_loss:  546.2228116798802   time:  1.4967832565307617
e:  17   train_loss:  552.3528043352559   time:  1.4910883903503418
e:  18   train_loss:  532.7644678359964   time:  1.491684913635254
e:  19   train_loss:  540.0001594895549   time:  1.48728609085083
e:  20   train_loss:  535.8800336749912   time:  1.4909231662750244
e:  20   train_loss:  535.8800336749912   val_loss:  720.8401447489522   time:  1.604647159576416
e:  21   train_loss:  540.0819352103423   time:  1.4887237548828125
e:  22   train_loss:  532.792724698096   time:  1.4927873611450195
e:  23   train_loss:  539.1925283896044   time:  1.4913921356201172
e:  24   train_loss:  529.1100926783616   time:  1.4857640266418457
e:  25   train_loss:  534.5360194533448   time:  1.5112428665161133
e:  25   train_loss:  534.5360194533448   val_loss:  739.9661962438463   time:  1.7412760257720947
e:  26   train_loss:  533.0303404942183   time:  1.4903266429901123
e:  27   train_loss:  531.5338989462808   time:  1.4327013492584229
e:  28   train_loss:  511.5965944020216   time:  1.460059642791748
e:  29   train_loss:  522.4244130919715   time:  1.4891695976257324
e:  30   train_loss:  513.4976580879163   time:  1.4900383949279785
e:  30   train_loss:  513.4976580879163   val_loss:  709.9647552577244   time:  1.6037356853485107
e:  31   train_loss:  510.9095979837196   time:  1.4928808212280273
e:  32   train_loss:  513.7678720864644   time:  1.5672578811645508
e:  33   train_loss:  503.1176093171348   time:  1.593576431274414
e:  34   train_loss:  503.72773558221996   time:  1.6610362529754639
e:  35   train_loss:  501.9011520452324   time:  1.4619331359863281
e:  35   train_loss:  501.9011520452324   val_loss:  718.3400928040387   time:  1.5664496421813965
e:  36   train_loss:  490.16322022570733   time:  1.4837570190429688
e:  37   train_loss:  488.62563177095876   time:  1.668196439743042
e:  38   train_loss:  479.7074450672864   time:  1.6100599765777588
e:  39   train_loss:  476.8144691996061   time:  1.4900214672088623
e:  40   train_loss:  473.19190682174053   time:  1.4899628162384033
e:  40   train_loss:  473.19190682174053   val_loss:  752.4051819814292   time:  1.6033515930175781
e:  41   train_loss:  471.35129961575814   time:  1.4921391010284424
e:  42   train_loss:  467.97434954238435   time:  1.491748571395874
e:  43   train_loss:  464.71105072423285   time:  1.4917089939117432
e:  44   train_loss:  460.8551479378918   time:  1.575767993927002
e:  45   train_loss:  450.817980600919   time:  1.7207086086273193
e:  45   train_loss:  450.817980600919   val_loss:  763.1306411102686   time:  1.8337199687957764
e:  46   train_loss:  451.66733360986086   time:  1.4984409809112549
e:  47   train_loss:  445.59210782839483   time:  1.5114874839782715
e:  48   train_loss:  440.54685295208594   time:  1.5440030097961426
e:  49   train_loss:  432.2161416336107   time:  1.5293118953704834
e:  50   train_loss:  428.16925864238044   time:  1.5376288890838623
e:  50   train_loss:  428.16925864238044   val_loss:  741.7678065853443   time:  1.651029109954834
e:  51   train_loss:  427.13806402444635   time:  1.539402723312378
e:  52   train_loss:  418.76531920476816   time:  1.5483529567718506
e:  53   train_loss:  412.93273598410747   time:  1.533869981765747
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  54   train_loss:  406.90040140750955   time:  1.7233490943908691
e:  55   train_loss:  401.6269350682357   time:  1.5163531303405762
e:  55   train_loss:  401.6269350682357   val_loss:  720.2696071824042   time:  1.628476858139038
e:  56   train_loss:  395.7378087584797   time:  1.5122344493865967
e:  57   train_loss:  392.0646751804301   time:  1.5381603240966797
e:  58   train_loss:  386.6584145694322   time:  1.5142207145690918
e:  59   train_loss:  375.82466328421117   time:  1.531937599182129
e:  60   train_loss:  380.83367952681965   time:  1.5315520763397217
e:  60   train_loss:  380.83367952681965   val_loss:  736.0537768945347   time:  1.6411855220794678
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  924.037089722639   time:  1.6475906372070312
e:  0   train_loss:  924.037089722639   val_loss:  553.4514134223103   time:  1.752657413482666
e:  1   train_loss:  778.0616461192126   time:  1.6531071662902832
e:  2   train_loss:  672.510631335795   time:  1.643867015838623
e:  3   train_loss:  659.8797659485878   time:  1.8269691467285156
e:  4   train_loss:  640.0567787995604   time:  1.595426321029663
e:  5   train_loss:  640.219636487087   time:  1.6296720504760742
e:  5   train_loss:  640.219636487087   val_loss:  589.3732526775851   time:  1.7355523109436035
e:  6   train_loss:  618.3956282453079   time:  1.6656758785247803
e:  7   train_loss:  610.0428444695025   time:  1.6674754619598389
e:  8   train_loss:  608.0128642584557   time:  1.6618914604187012
e:  9   train_loss:  589.5802898233808   time:  1.8368632793426514
e:  10   train_loss:  596.3017865927418   time:  1.640812873840332
e:  10   train_loss:  596.3017865927418   val_loss:  607.5922297205728   time:  1.749272108078003
e:  11   train_loss:  588.4423611701206   time:  1.682455062866211
e:  12   train_loss:  586.3114984708872   time:  1.6478807926177979
e:  13   train_loss:  592.8119847291027   time:  1.659616231918335
e:  14   train_loss:  589.05423055046   time:  1.6489837169647217
e:  15   train_loss:  596.1106726456286   time:  1.6612181663513184
e:  15   train_loss:  596.1106726456286   val_loss:  620.7173861804181   time:  1.9244906902313232
e:  16   train_loss:  581.9105574374167   time:  1.6664068698883057
e:  17   train_loss:  569.3418106422719   time:  1.6675560474395752
e:  18   train_loss:  572.4169420046069   time:  1.6592791080474854
e:  19   train_loss:  580.6504703994784   time:  1.650996208190918
e:  20   train_loss:  574.9782522515916   time:  1.6757800579071045
e:  20   train_loss:  574.9782522515916   val_loss:  634.5786771864373   time:  1.7802658081054688
e:  21   train_loss:  573.436600785347   time:  1.61993408203125
e:  22   train_loss:  563.5378580854715   time:  1.5921876430511475
e:  23   train_loss:  578.950479510108   time:  1.6422779560089111
e:  24   train_loss:  561.1691964511482   time:  1.8472585678100586
e:  25   train_loss:  567.127903974291   time:  1.6486270427703857
e:  25   train_loss:  567.127903974291   val_loss:  628.5736332707403   time:  1.7535374164581299
e:  26   train_loss:  552.818418623418   time:  1.6748840808868408
e:  27   train_loss:  540.0528289549349   time:  1.6706607341766357
e:  28   train_loss:  535.4621952260826   time:  1.6630990505218506
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  29   train_loss:  528.9950619941895   time:  1.6714246273040771
e:  30   train_loss:  530.5962846280644   time:  1.8664934635162354
e:  30   train_loss:  530.5962846280644   val_loss:  618.2322863255241   time:  1.9719326496124268
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 26), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 26) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 26) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 26) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 26)
kwargs: {'config': {'batch_norm': True, 'ff_0': 876, 'ff_num_layers': 2, 'gnn_0': 227, 'gnn_dropout': 0.49213520925025633, 'gnn_num_layers': 1, 'hid_0': 1532, 'hid_dropout_rate': 0.15679639657463124, 'in_dropout_rate': 0.39029146685469257, 'lr': 0.0025714843620315395, 'num_hid_layers': 1, 'optimizer': 'Adam', 'ff_1': 28}, 'budget': 81.0, 'working_directory': '.'}
result: {'loss': 691.8901026480528, 'n_epochs': 45.0, 'info': {'validation loss': 691.8901026480528}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 26) started
DEBUG:hpbandster:job_callback for (0, 0, 26) got condition
DEBUG:hpbandster:Only 9 run(s) for budget 81.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 26) finished
DEBUG:hpbandster:ITERATION: Advancing config (0, 0, 15) to next budget 243.000000
DEBUG:hpbandster:ITERATION: Advancing config (0, 0, 22) to next budget 243.000000
DEBUG:hpbandster:ITERATION: Advancing config (0, 0, 26) to next budget 243.000000
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 15) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 15) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 15)
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 15) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 15) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 15)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 30, 'ff_num_layers': 1, 'gnn_0': 1724, 'gnn_dropout': 0.16203243204750928, 'gnn_num_layers': 3, 'hid_0': 1259, 'hid_dropout_rate': 0.4895906060940636, 'in_dropout_rate': 0.17717454867023485, 'lr': 0.001508840596256224, 'num_hid_layers': 3, 'optimizer': 'SGD', 'gnn_1': 1662, 'gnn_2': 71, 'hid_1': 1500, 'hid_2': 256, 'sgd_momentum': 0.6568930593605463}, 'budget': 243.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  698.7968425786465   time:  1.785377025604248
e:  0   train_loss:  698.7968425786465   val_loss:  1643.7511806231087   time:  1.9099838733673096
e:  1   train_loss:  661.7416699626846   time:  1.7607553005218506
e:  2   train_loss:  587.5194462722388   time:  1.8055362701416016
e:  3   train_loss:  557.7745131919429   time:  1.779872179031372
e:  4   train_loss:  541.3495955743326   time:  1.774000644683838
e:  5   train_loss:  527.114075301113   time:  1.7425470352172852
e:  5   train_loss:  527.114075301113   val_loss:  3599.075809234861   time:  1.866274118423462
e:  6   train_loss:  505.91090135298043   time:  1.7641003131866455
e:  7   train_loss:  528.384555192717   time:  1.7825188636779785
e:  8   train_loss:  507.05922133028974   time:  1.9053056240081787
e:  9   train_loss:  481.2280968562991   time:  1.7280795574188232
e:  10   train_loss:  479.4944162678189   time:  1.7765982151031494
e:  10   train_loss:  479.4944162678189   val_loss:  1555.8799079914436   time:  1.9497060775756836
e:  11   train_loss:  508.8284853799597   time:  1.7586860656738281
e:  12   train_loss:  489.07497857828974   time:  1.8014311790466309
e:  13   train_loss:  482.8249966411852   time:  1.7198681831359863
e:  14   train_loss:  457.63460640087584   time:  1.730238676071167
e:  15   train_loss:  453.4077682119833   time:  1.7500972747802734
e:  15   train_loss:  453.4077682119833   val_loss:  1381.9385700015857   time:  1.8738813400268555
e:  16   train_loss:  429.63555662334636   time:  1.887394905090332
e:  17   train_loss:  454.81302788245915   time:  1.770995855331421
e:  18   train_loss:  430.95740469018125   time:  1.7666869163513184
e:  19   train_loss:  448.58333216241425   time:  1.7974066734313965
e:  20   train_loss:  419.26086580678765   time:  1.8442604541778564
e:  20   train_loss:  419.26086580678765   val_loss:  1389.5804708781272   time:  1.9872033596038818
e:  21   train_loss:  412.0321205317148   time:  1.7104403972625732
e:  22   train_loss:  477.8604942253472   time:  1.7038843631744385
e:  23   train_loss:  446.55664748455393   time:  1.7042267322540283
e:  24   train_loss:  429.15664364645494   time:  1.632242202758789
e:  25   train_loss:  425.84101614862385   time:  1.6225082874298096
e:  25   train_loss:  425.84101614862385   val_loss:  1400.253649068055   time:  1.8722033500671387
e:  26   train_loss:  402.4934164576661   time:  1.6427481174468994
e:  27   train_loss:  488.6808265455263   time:  1.6889927387237549
e:  28   train_loss:  507.9378530878664   time:  1.6967782974243164
e:  29   train_loss:  493.7883176909818   time:  1.700383186340332
e:  30   train_loss:  436.9910824970149   time:  1.698108196258545
e:  30   train_loss:  436.9910824970149   val_loss:  1603.0915254389668   time:  1.8232476711273193
e:  31   train_loss:  410.0905246992986   time:  1.7021849155426025
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  32   train_loss:  409.79304521135776   time:  1.7027091979980469
e:  33   train_loss:  390.8986465521044   time:  1.6975796222686768
e:  34   train_loss:  452.848616394446   time:  1.692702293395996
e:  35   train_loss:  513.9891594805779   time:  1.6836752891540527
e:  35   train_loss:  513.9891594805779   val_loss:  1613.8197079559443   time:  1.8073396682739258
e:  36   train_loss:  470.62758371161783   time:  1.8145813941955566
e:  37   train_loss:  416.53875718279284   time:  1.7080035209655762
e:  38   train_loss:  402.19323716367614   time:  1.7003865242004395
e:  39   train_loss:  427.37675683912784   time:  1.7023756504058838
e:  40   train_loss:  436.5917611811816   time:  1.69419527053833
e:  40   train_loss:  436.5917611811816   val_loss:  1346.1877216397145   time:  1.8190686702728271
e:  41   train_loss:  393.0830570053037   time:  1.6721241474151611
e:  42   train_loss:  385.835606343934   time:  1.6125683784484863
e:  43   train_loss:  372.6520533257644   time:  1.6661851406097412
e:  44   train_loss:  360.54532291102913   time:  1.675459384918213
e:  45   train_loss:  383.24506050516453   time:  1.6635236740112305
e:  45   train_loss:  383.24506050516453   val_loss:  1491.4899369711134   time:  1.8984580039978027
e:  46   train_loss:  364.95232718157195   time:  1.701249599456787
e:  47   train_loss:  414.2029190611366   time:  1.6987876892089844
e:  48   train_loss:  398.1450282681797   time:  1.703643798828125
e:  49   train_loss:  393.31299974254375   time:  1.6888718605041504
e:  50   train_loss:  390.03808963723526   time:  1.648848533630371
e:  50   train_loss:  390.03808963723526   val_loss:  1329.7746098579278   time:  1.7728021144866943
e:  51   train_loss:  363.5872523648   time:  1.6903536319732666
e:  52   train_loss:  359.6398706114008   time:  1.7027158737182617
e:  53   train_loss:  343.34696436657464   time:  1.6998770236968994
e:  54   train_loss:  342.6816740922826   time:  1.7002272605895996
e:  55   train_loss:  341.7600976809081   time:  1.7017104625701904
e:  55   train_loss:  341.7600976809081   val_loss:  1366.7892950072037   time:  1.8264100551605225
e:  56   train_loss:  333.05056007488713   time:  1.7965443134307861
e:  57   train_loss:  350.3883070479749   time:  1.6758286952972412
e:  58   train_loss:  475.33126092051856   time:  1.7071621417999268
e:  59   train_loss:  450.6853219604237   time:  1.6126604080200195
e:  60   train_loss:  375.89580594504383   time:  1.6464827060699463
e:  60   train_loss:  375.89580594504383   val_loss:  2380.3449282640217   time:  1.7704861164093018
e:  61   train_loss:  415.89200399107307   time:  1.7062914371490479
e:  62   train_loss:  388.739267792948   time:  1.6967978477478027
e:  63   train_loss:  380.02123852857414   time:  1.6955509185791016
e:  64   train_loss:  375.53852910571015   time:  1.6947474479675293
e:  65   train_loss:  340.0021585740478   time:  1.6994237899780273
e:  65   train_loss:  340.0021585740478   val_loss:  1442.3803342233805   time:  1.8249585628509521
e:  66   train_loss:  339.09765835197874   time:  1.6961674690246582
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  67   train_loss:  331.9911827401584   time:  1.8100459575653076
e:  68   train_loss:  367.20150767249623   time:  1.7069292068481445
e:  69   train_loss:  343.4520614212716   time:  1.6361799240112305
e:  70   train_loss:  317.91413691359014   time:  1.6659870147705078
e:  70   train_loss:  317.91413691359014   val_loss:  1403.741211926449   time:  1.7911016941070557
e:  71   train_loss:  334.68012288538495   time:  1.7017896175384521
e:  72   train_loss:  320.5224462226186   time:  1.7001984119415283
e:  73   train_loss:  314.9368203839729   time:  1.7015602588653564
e:  74   train_loss:  326.7565521058938   time:  1.6957423686981201
e:  75   train_loss:  329.54962290509815   time:  1.7027342319488525
e:  75   train_loss:  329.54962290509815   val_loss:  1392.519463094698   time:  1.8272552490234375
e:  76   train_loss:  321.6073739716444   time:  1.6226320266723633
e:  77   train_loss:  388.7292825350267   time:  1.6045868396759033
e:  78   train_loss:  496.8877201399116   time:  1.791102409362793
e:  79   train_loss:  382.5028660751343   time:  1.679696798324585
e:  80   train_loss:  367.147079389781   time:  1.6964325904846191
e:  80   train_loss:  367.147079389781   val_loss:  1518.0066206053616   time:  1.820728063583374
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1082.8310649089897   time:  1.8572101593017578
e:  0   train_loss:  1082.8310649089897   val_loss:  600.5877354673692   time:  1.9737968444824219
e:  1   train_loss:  922.0415738579941   time:  1.8344111442565918
e:  2   train_loss:  787.0875739550615   time:  1.8601129055023193
e:  3   train_loss:  741.4970498648594   time:  1.9892492294311523
e:  4   train_loss:  892.6585438712019   time:  1.857682466506958
e:  5   train_loss:  749.7523008604562   time:  1.8502748012542725
e:  5   train_loss:  749.7523008604562   val_loss:  709.499965390496   time:  1.965285301208496
e:  6   train_loss:  757.0088295832511   time:  1.7794554233551025
e:  7   train_loss:  700.4249792913041   time:  1.857374906539917
e:  8   train_loss:  697.8119910355422   time:  1.8617804050445557
e:  9   train_loss:  675.1025034830346   time:  1.856682538986206
e:  10   train_loss:  734.1946407865829   time:  1.9084229469299316
e:  10   train_loss:  734.1946407865829   val_loss:  825.2787861046485   time:  2.0254392623901367
e:  11   train_loss:  675.7229264652764   time:  1.8352110385894775
e:  12   train_loss:  635.2121567713925   time:  1.7649579048156738
e:  13   train_loss:  780.1586917194791   time:  1.7608706951141357
e:  14   train_loss:  935.0636211757246   time:  1.8186259269714355
e:  15   train_loss:  722.5669409532921   time:  1.8532826900482178
e:  15   train_loss:  722.5669409532921   val_loss:  818.0907573874717   time:  1.9686133861541748
e:  16   train_loss:  723.2899270771944   time:  1.8041369915008545
e:  17   train_loss:  708.9535460349651   time:  1.989121913909912
e:  18   train_loss:  708.2354929325247   time:  1.860945224761963
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  19   train_loss:  654.3447796778214   time:  1.8590917587280273
e:  20   train_loss:  630.5435588641287   time:  1.7703464031219482
e:  20   train_loss:  630.5435588641287   val_loss:  1275.667643181041   time:  1.8859682083129883
e:  21   train_loss:  623.380645295547   time:  1.84017014503479
e:  22   train_loss:  602.6963642692205   time:  1.82952880859375
e:  23   train_loss:  595.4057185385616   time:  1.8248884677886963
e:  24   train_loss:  841.1672317904142   time:  1.9919300079345703
e:  25   train_loss:  847.5196206755261   time:  1.8545587062835693
e:  25   train_loss:  847.5196206755261   val_loss:  2337.981305772036   time:  1.9712824821472168
e:  26   train_loss:  749.8280526845564   time:  1.8600471019744873
e:  27   train_loss:  648.328519738313   time:  1.8484044075012207
e:  28   train_loss:  640.0570465997721   time:  1.755509614944458
e:  29   train_loss:  685.3941104404842   time:  1.801694631576538
e:  30   train_loss:  676.5572063769541   time:  1.8279709815979004
e:  30   train_loss:  676.5572063769541   val_loss:  1082.98364222405   time:  2.069260358810425
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1082.7143659093483   time:  1.8324623107910156
e:  0   train_loss:  1082.7143659093483   val_loss:  519.077244845826   time:  1.9524753093719482
e:  1   train_loss:  968.8029223596773   time:  1.8392188549041748
e:  2   train_loss:  762.1705154550762   time:  1.8378551006317139
e:  3   train_loss:  825.7038711143559   time:  1.816329002380371
e:  4   train_loss:  891.0320604694548   time:  1.7880537509918213
e:  5   train_loss:  752.5850641991685   time:  1.8371152877807617
e:  5   train_loss:  752.5850641991685   val_loss:  71729.42832896556   time:  2.0719456672668457
e:  6   train_loss:  867.7337489302513   time:  1.8387389183044434
e:  7   train_loss:  825.2407251701111   time:  1.7336561679840088
e:  8   train_loss:  724.9762158515343   time:  1.800067663192749
e:  9   train_loss:  720.4628481733655   time:  1.8384554386138916
e:  10   train_loss:  742.6471706253859   time:  1.8350167274475098
e:  10   train_loss:  742.6471706253859   val_loss:  469.32388844672533   time:  1.9559595584869385
e:  11   train_loss:  675.0146210571891   time:  1.8381774425506592
e:  12   train_loss:  658.5868143665166   time:  1.8289382457733154
e:  13   train_loss:  809.2440178704825   time:  1.8697233200073242
e:  14   train_loss:  864.0398651695458   time:  1.7363452911376953
e:  15   train_loss:  825.6919968855602   time:  1.7976839542388916
e:  15   train_loss:  825.6919968855602   val_loss:  1604.2320985958986   time:  1.918288230895996
e:  16   train_loss:  901.5184262915147   time:  1.8422892093658447
e:  17   train_loss:  774.1915193809037   time:  1.847111701965332
e:  18   train_loss:  936.6291433927563   time:  1.8334314823150635
e:  19   train_loss:  737.4186339552398   time:  1.8366689682006836
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  20   train_loss:  738.1803402689224   time:  1.9606964588165283
e:  20   train_loss:  738.1803402689224   val_loss:  473.50147418089665   time:  2.0805153846740723
e:  21   train_loss:  771.3438780943451   time:  1.8429744243621826
e:  22   train_loss:  719.7664222695181   time:  1.8347573280334473
e:  23   train_loss:  856.2076695437656   time:  1.8401827812194824
e:  24   train_loss:  799.0628205125979   time:  1.8405346870422363
e:  25   train_loss:  740.232134409815   time:  1.8426942825317383
e:  25   train_loss:  740.232134409815   val_loss:  570.4639109418283   time:  1.9632742404937744
e:  26   train_loss:  689.6043390295888   time:  1.8384509086608887
e:  27   train_loss:  769.3162736127712   time:  1.9655895233154297
e:  28   train_loss:  702.2196593434599   time:  1.8313238620758057
e:  29   train_loss:  692.0925709453448   time:  1.7389335632324219
e:  30   train_loss:  689.7447328220744   time:  1.782463788986206
e:  30   train_loss:  689.7447328220744   val_loss:  502.1736732924658   time:  1.900057077407837
e:  31   train_loss:  653.2392091660757   time:  1.7357571125030518
e:  32   train_loss:  909.6673790205223   time:  1.8211925029754639
e:  33   train_loss:  750.9169965571057   time:  1.8262510299682617
e:  34   train_loss:  698.9325727695045   time:  1.8344929218292236
e:  35   train_loss:  679.7855158787472   time:  1.9612998962402344
e:  35   train_loss:  679.7855158787472   val_loss:  523.1460209251007   time:  2.0812411308288574
e:  36   train_loss:  674.0034125780153   time:  1.83042573928833
e:  37   train_loss:  674.6934744621444   time:  1.7874786853790283
e:  38   train_loss:  667.8585995522592   time:  1.8283190727233887
e:  39   train_loss:  647.6894140319507   time:  1.8208987712860107
e:  40   train_loss:  709.1886454743698   time:  1.7484238147735596
e:  40   train_loss:  709.1886454743698   val_loss:  479.9517431784043   time:  1.8669493198394775
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  990.7449141261068   time:  1.6837573051452637
e:  0   train_loss:  990.7449141261068   val_loss:  885.5809376425846   time:  1.8092811107635498
e:  1   train_loss:  880.1616404119227   time:  1.7020514011383057
e:  2   train_loss:  725.5962839164788   time:  1.6642653942108154
e:  3   train_loss:  713.5683971960206   time:  1.808790683746338
e:  4   train_loss:  745.8143008585062   time:  1.6246323585510254
e:  5   train_loss:  765.9338690359795   time:  1.6266701221466064
e:  5   train_loss:  765.9338690359795   val_loss:  740.6441343455919   time:  1.7520391941070557
e:  6   train_loss:  717.2973014316217   time:  1.6954901218414307
e:  7   train_loss:  691.4711802492156   time:  1.705019474029541
e:  8   train_loss:  654.4350183309743   time:  1.7020199298858643
e:  9   train_loss:  656.8361084417314   time:  1.701761245727539
e:  10   train_loss:  622.6643201751542   time:  1.6978683471679688
e:  10   train_loss:  622.6643201751542   val_loss:  687.7323790369476   time:  1.8239459991455078
e:  11   train_loss:  615.4781270180167   time:  1.696131706237793
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  12   train_loss:  638.3444181116693   time:  1.6990091800689697
e:  13   train_loss:  633.9114455184688   time:  1.7042381763458252
e:  14   train_loss:  798.2508163630793   time:  1.699326515197754
e:  15   train_loss:  718.2131304884743   time:  1.8070838451385498
e:  15   train_loss:  718.2131304884743   val_loss:  1208.3070826184073   time:  1.9335734844207764
e:  16   train_loss:  725.7083382617285   time:  1.7058842182159424
e:  17   train_loss:  642.3761557667422   time:  1.7024638652801514
e:  18   train_loss:  692.9297726924227   time:  1.7090566158294678
e:  19   train_loss:  652.3605145140622   time:  1.7004690170288086
e:  20   train_loss:  672.9928736727393   time:  1.7015388011932373
e:  20   train_loss:  672.9928736727393   val_loss:  838.3539601609857   time:  1.827582836151123
e:  21   train_loss:  739.6406314699757   time:  1.6600360870361328
e:  22   train_loss:  685.734455350552   time:  1.6129498481750488
e:  23   train_loss:  654.0185179982118   time:  1.7031681537628174
e:  24   train_loss:  639.2060200204063   time:  1.8077635765075684
e:  25   train_loss:  614.4970376389558   time:  1.6970477104187012
e:  25   train_loss:  614.4970376389558   val_loss:  685.9973587645873   time:  1.8223276138305664
e:  26   train_loss:  672.3001267218208   time:  1.7028558254241943
e:  27   train_loss:  670.6084895785968   time:  1.7004389762878418
e:  28   train_loss:  726.4499909604425   time:  1.696948528289795
e:  29   train_loss:  681.8912208514682   time:  1.6990995407104492
e:  30   train_loss:  648.7668952191113   time:  1.698131799697876
e:  30   train_loss:  648.7668952191113   val_loss:  756.1112440575645   time:  1.8239262104034424
e:  31   train_loss:  632.3930652468493   time:  1.7002904415130615
e:  32   train_loss:  676.1868353936134   time:  1.7060081958770752
e:  33   train_loss:  609.5964512588763   time:  1.6984920501708984
e:  34   train_loss:  618.6653658077165   time:  1.694516897201538
e:  35   train_loss:  685.6147699803213   time:  1.8027167320251465
e:  35   train_loss:  685.6147699803213   val_loss:  721.917032241449   time:  1.9286160469055176
e:  36   train_loss:  612.339080047266   time:  1.6926994323730469
e:  37   train_loss:  612.225640354464   time:  1.7001793384552002
e:  38   train_loss:  608.4684103432247   time:  1.700148582458496
e:  39   train_loss:  593.2587491992015   time:  1.6094727516174316
e:  40   train_loss:  569.1841769929173   time:  1.652928113937378
e:  40   train_loss:  569.1841769929173   val_loss:  768.0451434227014   time:  1.779078722000122
e:  41   train_loss:  570.2444450756349   time:  1.693744421005249
e:  42   train_loss:  613.7824066134747   time:  1.7007780075073242
e:  43   train_loss:  578.6388431172654   time:  1.7001266479492188
e:  44   train_loss:  538.4141923587415   time:  1.8181979656219482
e:  45   train_loss:  517.3894991312203   time:  1.6827061176300049
e:  45   train_loss:  517.3894991312203   val_loss:  757.389104749382   time:  1.8082053661346436
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  46   train_loss:  547.2200694907564   time:  1.6959524154663086
e:  47   train_loss:  545.5523411048996   time:  1.7015163898468018
e:  48   train_loss:  497.9568352544851   time:  1.6925103664398193
e:  49   train_loss:  525.4157531442152   time:  1.699021339416504
e:  50   train_loss:  525.9468584639218   time:  1.6950645446777344
e:  50   train_loss:  525.9468584639218   val_loss:  688.1854094199402   time:  1.820570468902588
e:  51   train_loss:  504.1452340154577   time:  1.6968903541564941
e:  52   train_loss:  566.9864029643898   time:  1.706970453262329
e:  53   train_loss:  492.56212045989   time:  1.8571574687957764
e:  54   train_loss:  546.4033485835032   time:  1.733349323272705
e:  55   train_loss:  532.0197961199495   time:  1.739384651184082
e:  55   train_loss:  532.0197961199495   val_loss:  662.1652304248051   time:  1.8648102283477783
e:  56   train_loss:  487.1216451757501   time:  1.774719476699829
e:  57   train_loss:  511.3153762168491   time:  1.6906509399414062
e:  58   train_loss:  454.1273619517006   time:  1.7398717403411865
e:  59   train_loss:  469.5844971880232   time:  1.722137212753296
e:  60   train_loss:  489.3874205065026   time:  1.7301862239837646
e:  60   train_loss:  489.3874205065026   val_loss:  769.8810416097198   time:  1.8981146812438965
e:  61   train_loss:  483.3241998845485   time:  1.8436849117279053
e:  62   train_loss:  538.6026870477247   time:  1.708672046661377
e:  63   train_loss:  473.2827114101933   time:  1.8055691719055176
e:  64   train_loss:  497.3707267607832   time:  1.6847898960113525
e:  65   train_loss:  508.74422441559057   time:  1.7335364818572998
e:  65   train_loss:  508.74422441559057   val_loss:  774.1351079602233   time:  1.9650909900665283
e:  66   train_loss:  520.5138878046234   time:  1.7354135513305664
e:  67   train_loss:  488.4797833985871   time:  1.7169573307037354
e:  68   train_loss:  443.29741036288476   time:  1.7520246505737305
e:  69   train_loss:  447.9967560224157   time:  1.716515064239502
e:  70   train_loss:  456.74178222225333   time:  1.7561707496643066
e:  70   train_loss:  456.74178222225333   val_loss:  687.0286367868214   time:  1.87733793258667
e:  71   train_loss:  425.61245892743824   time:  1.7129700183868408
e:  72   train_loss:  427.5720946218976   time:  1.866837978363037
e:  73   train_loss:  415.42389834538926   time:  1.6113946437835693
e:  74   train_loss:  422.30331148107916   time:  1.7487328052520752
e:  75   train_loss:  618.2545751283535   time:  1.713425874710083
e:  75   train_loss:  618.2545751283535   val_loss:  846.8676426257658   time:  1.8309078216552734
e:  76   train_loss:  728.3461362600813   time:  1.687108039855957
e:  77   train_loss:  674.8408531509068   time:  1.6926660537719727
e:  78   train_loss:  627.5813676897384   time:  1.6941068172454834
e:  79   train_loss:  670.5814311610197   time:  1.693401575088501
e:  80   train_loss:  655.8694298051275   time:  1.6951572895050049
e:  80   train_loss:  655.8694298051275   val_loss:  768.5461876670041   time:  1.8208856582641602
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  81   train_loss:  643.2302379137241   time:  1.7006258964538574
e:  82   train_loss:  639.87293762826   time:  1.6694157123565674
e:  83   train_loss:  625.010230035094   time:  1.6530797481536865
e:  84   train_loss:  614.008083855035   time:  1.6620161533355713
e:  85   train_loss:  604.2828046993903   time:  1.8011465072631836
e:  85   train_loss:  604.2828046993903   val_loss:  788.6836312008321   time:  1.9270999431610107
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1058.8100040009315   time:  1.8510024547576904
e:  0   train_loss:  1058.8100040009315   val_loss:  655.9795289486193   time:  1.9695565700531006
e:  1   train_loss:  917.0854648921945   time:  1.9894239902496338
e:  2   train_loss:  877.3232252335106   time:  1.8872528076171875
e:  3   train_loss:  824.3339490380882   time:  1.8527343273162842
e:  4   train_loss:  788.9961513800848   time:  1.7547569274902344
e:  5   train_loss:  739.7995752287995   time:  1.9466526508331299
e:  5   train_loss:  739.7995752287995   val_loss:  1376.0860217812315   time:  2.0647716522216797
e:  6   train_loss:  712.9771246346204   time:  1.8493833541870117
e:  7   train_loss:  811.8189339871976   time:  1.8552956581115723
e:  8   train_loss:  781.7212754726048   time:  1.8529222011566162
e:  9   train_loss:  812.6793326233462   time:  1.7550766468048096
e:  10   train_loss:  777.452599356088   time:  1.7590267658233643
e:  10   train_loss:  777.452599356088   val_loss:  566.9720235469593   time:  1.8767735958099365
e:  11   train_loss:  763.1771402799916   time:  1.8828048706054688
e:  12   train_loss:  763.6754396072687   time:  1.987633228302002
e:  13   train_loss:  797.8691872386712   time:  1.8490726947784424
e:  14   train_loss:  726.751896018915   time:  1.85410737991333
e:  15   train_loss:  697.8738458638039   time:  1.858508586883545
e:  15   train_loss:  697.8738458638039   val_loss:  560.4011747135488   time:  1.975395917892456
e:  16   train_loss:  747.7977790165404   time:  1.7831039428710938
e:  17   train_loss:  742.8081414476869   time:  1.8292460441589355
e:  18   train_loss:  675.9195709843456   time:  1.8337082862854004
e:  19   train_loss:  658.4781839543992   time:  1.985466480255127
e:  20   train_loss:  710.3672746886282   time:  1.7484188079833984
e:  20   train_loss:  710.3672746886282   val_loss:  562.3605332054299   time:  1.8634717464447021
e:  21   train_loss:  719.5371852711505   time:  1.8436720371246338
e:  22   train_loss:  688.878560203218   time:  1.8084416389465332
e:  23   train_loss:  663.9264086674128   time:  1.77901029586792
e:  24   train_loss:  678.6640463603127   time:  1.9151756763458252
e:  25   train_loss:  616.6333625924143   time:  2.0081839561462402
e:  25   train_loss:  616.6333625924143   val_loss:  542.2245963114523   time:  2.2942068576812744
e:  26   train_loss:  591.726473417858   time:  1.8745582103729248
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  27   train_loss:  703.0908545114726   time:  1.7632994651794434
e:  28   train_loss:  600.2129159667373   time:  1.9474782943725586
e:  29   train_loss:  691.1806081442447   time:  2.05244517326355
e:  30   train_loss:  762.5285904482707   time:  1.9410068988800049
e:  30   train_loss:  762.5285904482707   val_loss:  558.0645286096453   time:  2.149015426635742
e:  31   train_loss:  658.3936016847646   time:  2.150157928466797
e:  32   train_loss:  585.8205530571402   time:  1.905334711074829
e:  33   train_loss:  607.132711409731   time:  2.0577809810638428
e:  34   train_loss:  573.599681093747   time:  1.9190754890441895
e:  35   train_loss:  541.8129528845052   time:  1.8989105224609375
e:  35   train_loss:  541.8129528845052   val_loss:  554.2097216328542   time:  2.013814687728882
e:  36   train_loss:  549.3563786878187   time:  1.9213900566101074
e:  37   train_loss:  550.5817332866113   time:  2.2044453620910645
e:  38   train_loss:  518.0908324388472   time:  1.9800665378570557
e:  39   train_loss:  564.4731428725755   time:  1.9791820049285889
e:  40   train_loss:  514.3136561714433   time:  1.9715354442596436
e:  40   train_loss:  514.3136561714433   val_loss:  537.2823556444534   time:  2.0920636653900146
e:  41   train_loss:  569.9429314581198   time:  1.9770920276641846
e:  42   train_loss:  563.2537871171604   time:  1.985980749130249
e:  43   train_loss:  543.0770754858077   time:  2.2458643913269043
e:  44   train_loss:  493.8343305679166   time:  1.972978115081787
e:  45   train_loss:  531.7399146701654   time:  1.967883586883545
e:  45   train_loss:  531.7399146701654   val_loss:  584.2961502844972   time:  2.0884997844696045
e:  46   train_loss:  504.041330156094   time:  1.9610264301300049
e:  47   train_loss:  476.9105275912824   time:  1.9782214164733887
e:  48   train_loss:  475.09964106439395   time:  1.9760234355926514
e:  49   train_loss:  512.2182770007014   time:  2.231384754180908
e:  50   train_loss:  474.82273743142497   time:  1.8712327480316162
e:  50   train_loss:  474.82273743142497   val_loss:  551.4427961646329   time:  1.9891960620880127
e:  51   train_loss:  523.8919320049606   time:  1.9258413314819336
e:  52   train_loss:  652.0458170005317   time:  1.9769039154052734
e:  53   train_loss:  828.0467169704008   time:  1.9771850109100342
e:  54   train_loss:  949.9035453913605   time:  1.9972338676452637
e:  55   train_loss:  933.6828903734666   time:  1.9951355457305908
e:  55   train_loss:  933.6828903734666   val_loss:  593.7468681148744   time:  2.1170804500579834
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  56   train_loss:  927.1950162754991   time:  2.233428955078125
e:  57   train_loss:  899.7837692700034   time:  1.9745361804962158
e:  58   train_loss:  912.8504093472825   time:  1.7855308055877686
e:  59   train_loss:  917.3248095189051   time:  1.8372983932495117
e:  60   train_loss:  929.9500159303051   time:  1.7808187007904053
e:  60   train_loss:  929.9500159303051   val_loss:  560.4001645189957   time:  1.8987045288085938
e:  61   train_loss:  902.7533888603514   time:  1.8565104007720947
e:  62   train_loss:  899.7279229035863   time:  1.854142189025879
e:  63   train_loss:  914.6164054197357   time:  1.9643018245697021
e:  64   train_loss:  898.3290456484964   time:  1.8648219108581543
e:  65   train_loss:  924.6199279971804   time:  1.811311960220337
e:  65   train_loss:  924.6199279971804   val_loss:  620.1812901828821   time:  1.926745891571045
e:  66   train_loss:  933.7148589586754   time:  1.7863905429840088
e:  67   train_loss:  869.509897995749   time:  1.8524081707000732
e:  68   train_loss:  757.2284734085142   time:  1.8557589054107666
e:  69   train_loss:  886.4567220723594   time:  1.821892261505127
e:  70   train_loss:  923.8910997985903   time:  1.9753177165985107
e:  70   train_loss:  923.8910997985903   val_loss:  565.2070070321641   time:  2.0933725833892822
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 15), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 15) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 15) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 15) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 15)
kwargs: {'config': {'batch_norm': True, 'ff_0': 30, 'ff_num_layers': 1, 'gnn_0': 1724, 'gnn_dropout': 0.16203243204750928, 'gnn_num_layers': 3, 'hid_0': 1259, 'hid_dropout_rate': 0.4895906060940636, 'in_dropout_rate': 0.17717454867023485, 'lr': 0.001508840596256224, 'num_hid_layers': 3, 'optimizer': 'SGD', 'gnn_1': 1662, 'gnn_2': 71, 'hid_1': 1500, 'hid_2': 256, 'sgd_momentum': 0.6568930593605463}, 'budget': 243.0, 'working_directory': '.'}
result: {'loss': 719.826763968256, 'n_epochs': 61.0, 'info': {'validation loss': 719.826763968256}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 15) started
DEBUG:hpbandster:job_callback for (0, 0, 15) got condition
DEBUG:hpbandster:Only 1 run(s) for budget 243.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 15) finished
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 22) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 22) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 22)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 22) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 22) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 22)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 17, 'ff_num_layers': 1, 'gnn_0': 281, 'gnn_dropout': 0.3279737195479306, 'gnn_num_layers': 1, 'hid_0': 593, 'hid_dropout_rate': 0.20414696252923964, 'in_dropout_rate': 0.4386659901915775, 'lr': 0.0015707457967605017, 'num_hid_layers': 3, 'optimizer': 'SGD', 'hid_1': 511, 'hid_2': 271, 'sgd_momentum': 0.6094637896459667}, 'budget': 243.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  700.135222915052   time:  1.3515148162841797
e:  0   train_loss:  700.135222915052   val_loss:  1645.5480244946332   time:  1.4590740203857422
e:  1   train_loss:  663.4753110127011   time:  1.359769344329834
e:  2   train_loss:  597.3284538952557   time:  1.359093427658081
e:  3   train_loss:  589.2616763755041   time:  1.3574447631835938
e:  4   train_loss:  578.9319005607362   time:  1.3371710777282715
e:  5   train_loss:  561.0431423762819   time:  1.3428561687469482
e:  5   train_loss:  561.0431423762819   val_loss:  1477.2795175377191   time:  1.4497954845428467
e:  6   train_loss:  601.4841357154149   time:  1.3526806831359863
e:  7   train_loss:  565.8527439833468   time:  1.3491191864013672
e:  8   train_loss:  536.309364127717   time:  1.5024170875549316
e:  9   train_loss:  575.4196381292473   time:  1.3500359058380127
e:  10   train_loss:  566.1836682436807   time:  1.3768126964569092
e:  10   train_loss:  566.1836682436807   val_loss:  1437.222758107413   time:  1.4843049049377441
e:  11   train_loss:  585.3764466303768   time:  1.339055061340332
e:  12   train_loss:  553.3492971198436   time:  1.3378257751464844
e:  13   train_loss:  568.5142559521429   time:  1.3544812202453613
e:  14   train_loss:  552.5914564286533   time:  1.3174009323120117
e:  15   train_loss:  574.0698182045966   time:  1.3460993766784668
e:  15   train_loss:  574.0698182045966   val_loss:  1345.3258510157002   time:  1.514495611190796
e:  16   train_loss:  564.413436865974   time:  1.5150375366210938
e:  17   train_loss:  539.4169774526019   time:  1.3499913215637207
e:  18   train_loss:  540.125220496797   time:  1.3431921005249023
e:  19   train_loss:  517.8887530795828   time:  1.35086989402771
e:  20   train_loss:  505.39050028291325   time:  1.3530731201171875
e:  20   train_loss:  505.39050028291325   val_loss:  1446.573428126242   time:  1.4606256484985352
e:  21   train_loss:  547.6799298325192   time:  1.3485145568847656
e:  22   train_loss:  528.7954979691295   time:  1.3467066287994385
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
e:  23   train_loss:  544.0629613988058   time:  1.3551278114318848
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  24   train_loss:  516.8963182896314   time:  1.3412821292877197
e:  25   train_loss:  492.5050082820745   time:  1.3330976963043213
e:  25   train_loss:  492.5050082820745   val_loss:  1470.4289310458946   time:  1.6053049564361572
e:  26   train_loss:  487.46529933048794   time:  1.3329463005065918
e:  27   train_loss:  528.2786737402128   time:  1.3505809307098389
e:  28   train_loss:  520.9898763288818   time:  1.351982831954956
e:  29   train_loss:  568.5467296899511   time:  1.4223051071166992
e:  30   train_loss:  531.6678921669517   time:  1.3158740997314453
e:  30   train_loss:  531.6678921669517   val_loss:  1491.3677181590435   time:  1.424314022064209
e:  31   train_loss:  553.5981321261706   time:  1.3149726390838623
e:  32   train_loss:  522.3094934884948   time:  1.3152637481689453
e:  33   train_loss:  485.04187765252567   time:  1.4271667003631592
e:  34   train_loss:  488.07259173751214   time:  1.4283819198608398
e:  35   train_loss:  473.3473412085993   time:  1.3976202011108398
e:  35   train_loss:  473.3473412085993   val_loss:  1377.865481708037   time:  1.5067646503448486
e:  36   train_loss:  471.36244547014445   time:  1.5449202060699463
e:  37   train_loss:  521.1828056839239   time:  1.3035383224487305
e:  38   train_loss:  478.646138236835   time:  1.3123986721038818
e:  39   train_loss:  460.5721763326771   time:  1.3176875114440918
e:  40   train_loss:  453.3887996022666   time:  1.3098671436309814
e:  40   train_loss:  453.3887996022666   val_loss:  1367.764660197747   time:  1.4189815521240234
e:  41   train_loss:  449.74170421110614   time:  1.308624267578125
e:  42   train_loss:  440.9828986187584   time:  1.3149328231811523
e:  43   train_loss:  477.6111337375713   time:  1.3149821758270264
e:  44   train_loss:  533.4840372982192   time:  1.3081691265106201
e:  45   train_loss:  507.62445073390654   time:  1.3066420555114746
e:  45   train_loss:  507.62445073390654   val_loss:  1448.4298792672946   time:  1.541576862335205
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1073.7735105459412   time:  1.4305310249328613
e:  0   train_loss:  1073.7735105459412   val_loss:  598.1477282687767   time:  1.5325498580932617
e:  1   train_loss:  951.2010033008187   time:  1.4225034713745117
e:  2   train_loss:  882.5954817190614   time:  1.4312500953674316
e:  3   train_loss:  841.3679693470273   time:  1.431363582611084
e:  4   train_loss:  947.1109199421355   time:  1.4308981895446777
e:  5   train_loss:  906.3289840990642   time:  1.4294044971466064
e:  5   train_loss:  906.3289840990642   val_loss:  554.4613877958401   time:  1.6592955589294434
e:  6   train_loss:  798.7670708385946   time:  1.4325811862945557
e:  7   train_loss:  931.6224767149358   time:  1.4265861511230469
e:  8   train_loss:  793.8635800345521   time:  1.4229283332824707
e:  9   train_loss:  917.6628896591309   time:  1.4305872917175293
e:  10   train_loss:  871.0035442540693   time:  1.415419340133667
e:  10   train_loss:  871.0035442540693   val_loss:  548.4624793023281   time:  1.5160033702850342
e:  11   train_loss:  823.152897198889   time:  1.39170503616333
e:  12   train_loss:  756.9480105061729   time:  1.430009365081787
e:  13   train_loss:  771.7687057576815   time:  1.4271070957183838
e:  14   train_loss:  716.1981023259927   time:  1.5555000305175781
e:  15   train_loss:  781.5903556121935   time:  1.4215302467346191
e:  15   train_loss:  781.5903556121935   val_loss:  568.0406516171278   time:  1.5236585140228271
e:  16   train_loss:  738.2793243936198   time:  1.432832956314087
e:  17   train_loss:  721.3321012729668   time:  1.4308090209960938
e:  18   train_loss:  769.5120226773103   time:  1.431584358215332
e:  19   train_loss:  911.4833723252874   time:  1.4327547550201416
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  20   train_loss:  789.2874240298353   time:  1.5745978355407715
e:  20   train_loss:  789.2874240298353   val_loss:  536.3631551574298   time:  1.677070140838623
e:  21   train_loss:  826.8085161920545   time:  1.4319136142730713
e:  22   train_loss:  752.7950565745639   time:  1.4304871559143066
e:  23   train_loss:  820.1619468727723   time:  1.4250481128692627
e:  24   train_loss:  729.31834380261   time:  1.4238171577453613
e:  25   train_loss:  721.6581214392986   time:  1.4319746494293213
e:  25   train_loss:  721.6581214392986   val_loss:  530.874725793474   time:  1.6619608402252197
e:  26   train_loss:  754.351239404124   time:  1.4303584098815918
e:  27   train_loss:  695.0776873498115   time:  1.4217052459716797
e:  28   train_loss:  671.8707488037932   time:  1.4285731315612793
e:  29   train_loss:  777.7311070373835   time:  1.4230518341064453
e:  30   train_loss:  732.3499714029866   time:  1.4302699565887451
e:  30   train_loss:  732.3499714029866   val_loss:  528.7787294423689   time:  1.5318326950073242
e:  31   train_loss:  680.8401769378717   time:  1.3979332447052002
e:  32   train_loss:  644.3524418748185   time:  1.5650808811187744
e:  33   train_loss:  669.5578364867993   time:  1.4223127365112305
e:  34   train_loss:  728.0398285106997   time:  1.431565284729004
e:  35   train_loss:  658.8423077946666   time:  1.4289343357086182
e:  35   train_loss:  658.8423077946666   val_loss:  541.9972949674718   time:  1.5311105251312256
e:  36   train_loss:  606.4227052004876   time:  1.4245624542236328
e:  37   train_loss:  733.2588918927541   time:  1.423729658126831
e:  38   train_loss:  616.2755066061643   time:  1.5749449729919434
e:  39   train_loss:  718.8604160258911   time:  1.4301931858062744
e:  40   train_loss:  685.251009326173   time:  1.4278099536895752
e:  40   train_loss:  685.251009326173   val_loss:  529.502242519933   time:  1.5304911136627197
e:  41   train_loss:  622.1116853695779   time:  1.423189401626587
e:  42   train_loss:  628.795333534306   time:  1.4215216636657715
e:  43   train_loss:  621.1633488455055   time:  1.4298584461212158
e:  44   train_loss:  558.9516568572433   time:  1.5695745944976807
e:  45   train_loss:  544.5868955951104   time:  1.4277844429016113
e:  45   train_loss:  544.5868955951104   val_loss:  551.2972208582588   time:  1.5291519165039062
e:  46   train_loss:  711.9877856207909   time:  1.4357428550720215
e:  47   train_loss:  561.7182125462499   time:  1.430288314819336
e:  48   train_loss:  565.6344156665044   time:  1.4297499656677246
e:  49   train_loss:  541.3852287134418   time:  1.4219670295715332
e:  50   train_loss:  557.458085548936   time:  1.429492712020874
e:  50   train_loss:  557.458085548936   val_loss:  558.4378276512502   time:  1.5312724113464355
e:  51   train_loss:  628.8352930046312   time:  1.544260025024414
e:  52   train_loss:  563.7304387554739   time:  1.4046869277954102
e:  53   train_loss:  525.497534347091   time:  1.43129301071167
e:  54   train_loss:  580.7961030915945   time:  1.4287145137786865
e:  55   train_loss:  505.4450570390006   time:  1.423494577407837
e:  55   train_loss:  505.4450570390006   val_loss:  647.6250905617304   time:  1.5258216857910156
e:  56   train_loss:  584.2026930012066   time:  1.4314706325531006
e:  57   train_loss:  569.2988773297756   time:  1.4274909496307373
e:  58   train_loss:  539.6459585896341   time:  1.5416624546051025
e:  59   train_loss:  498.00614996772896   time:  1.4315102100372314
e:  60   train_loss:  513.7597155702756   time:  1.4320824146270752
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  60   train_loss:  513.7597155702756   val_loss:  602.3122890057222   time:  1.5370848178863525
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1096.061223648569   time:  1.415144920349121
e:  0   train_loss:  1096.061223648569   val_loss:  512.8931624990373   time:  1.519507646560669
e:  1   train_loss:  948.6888383996613   time:  1.4047045707702637
e:  2   train_loss:  888.423820276769   time:  1.4129846096038818
e:  3   train_loss:  837.6856151813828   time:  1.412543535232544
e:  4   train_loss:  880.5054552871013   time:  1.5473089218139648
e:  5   train_loss:  940.2915434113137   time:  1.4054994583129883
e:  5   train_loss:  940.2915434113137   val_loss:  469.39898435250825   time:  1.5102126598358154
e:  6   train_loss:  838.5741697665425   time:  1.4144790172576904
e:  7   train_loss:  841.4401169483331   time:  1.4088187217712402
e:  8   train_loss:  818.4385514393849   time:  1.6294574737548828
e:  9   train_loss:  1110.256503885625   time:  1.722590446472168
e:  10   train_loss:  930.0938488723875   time:  1.4004490375518799
e:  10   train_loss:  930.0938488723875   val_loss:  490.0038005930205   time:  1.5047926902770996
e:  11   train_loss:  894.7323119237263   time:  1.6642863750457764
e:  12   train_loss:  874.9307035433299   time:  1.414609670639038
e:  13   train_loss:  852.2943324293415   time:  1.4119298458099365
e:  14   train_loss:  944.6934598125556   time:  1.4065349102020264
e:  15   train_loss:  819.8437673917342   time:  1.4128329753875732
e:  15   train_loss:  819.8437673917342   val_loss:  467.89719279530703   time:  1.5173163414001465
e:  16   train_loss:  847.9100358270199   time:  1.4149847030639648
e:  17   train_loss:  785.3343511508278   time:  1.4144415855407715
e:  18   train_loss:  898.312564385741   time:  1.4298880100250244
e:  19   train_loss:  889.7268840600262   time:  1.551161527633667
e:  20   train_loss:  845.0012900832621   time:  1.4149329662322998
e:  20   train_loss:  845.0012900832621   val_loss:  480.14205055914806   time:  1.5189135074615479
e:  21   train_loss:  811.4188934901856   time:  1.415766716003418
e:  22   train_loss:  737.6419500235919   time:  1.4160282611846924
e:  23   train_loss:  724.7379646604184   time:  1.4160804748535156
e:  24   train_loss:  712.9754427436587   time:  1.4161577224731445
e:  25   train_loss:  695.0314099380222   time:  1.414186716079712
e:  25   train_loss:  695.0314099380222   val_loss:  473.7245691990749   time:  1.5197815895080566
e:  26   train_loss:  710.8923108085951   time:  1.5422017574310303
e:  27   train_loss:  1068.7040586597338   time:  1.4156997203826904
e:  28   train_loss:  977.0812548148236   time:  1.4138233661651611
e:  29   train_loss:  893.049278296237   time:  1.4077918529510498
e:  30   train_loss:  976.5374136381358   time:  1.4073460102081299
e:  30   train_loss:  976.5374136381358   val_loss:  530.1611154276757   time:  1.5123634338378906
e:  31   train_loss:  929.3988514209601   time:  1.3900532722473145
e:  32   train_loss:  922.4670914880712   time:  1.3911099433898926
e:  33   train_loss:  915.9502232968413   time:  1.5336570739746094
e:  34   train_loss:  889.0573963633842   time:  1.4108316898345947
e:  35   train_loss:  884.9646802593863   time:  1.414560079574585
e:  35   train_loss:  884.9646802593863   val_loss:  468.95574220420565   time:  1.5189626216888428
e:  36   train_loss:  899.2823897383298   time:  1.4143362045288086
e:  37   train_loss:  878.898225014381   time:  1.412877082824707
e:  38   train_loss:  901.3400275790589   time:  1.411928415298462
e:  39   train_loss:  941.0002280547766   time:  1.4121389389038086
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  40   train_loss:  888.2942508021993   time:  1.416412115097046
e:  40   train_loss:  888.2942508021993   val_loss:  472.8372460779417   time:  1.6497457027435303
e:  41   train_loss:  944.300774008264   time:  1.4121410846710205
e:  42   train_loss:  880.2270252011323   time:  1.4145994186401367
e:  43   train_loss:  908.2443945548619   time:  1.413198709487915
e:  44   train_loss:  889.5998843804042   time:  1.4156136512756348
e:  45   train_loss:  897.6283748241808   time:  1.412013292312622
e:  45   train_loss:  897.6283748241808   val_loss:  480.0287475730699   time:  1.5171833038330078
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  991.7439135000359   time:  1.309502363204956
e:  0   train_loss:  991.7439135000359   val_loss:  892.4514371013261   time:  1.4182794094085693
e:  1   train_loss:  921.78294352558   time:  1.311821460723877
e:  2   train_loss:  835.5533539661938   time:  1.3030052185058594
e:  3   train_loss:  820.6048669282794   time:  1.4341955184936523
e:  4   train_loss:  797.8248151378175   time:  1.295942783355713
e:  5   train_loss:  883.5761166008267   time:  1.308816909790039
e:  5   train_loss:  883.5761166008267   val_loss:  745.090389998534   time:  1.4177236557006836
e:  6   train_loss:  815.2183667352733   time:  1.2742090225219727
e:  7   train_loss:  785.0609101218608   time:  1.2835073471069336
e:  8   train_loss:  748.9581088413846   time:  1.3201842308044434
e:  9   train_loss:  799.1918737381225   time:  1.3101012706756592
e:  10   train_loss:  895.1645044413273   time:  1.3062171936035156
e:  10   train_loss:  895.1645044413273   val_loss:  748.19467385177   time:  1.415621042251587
e:  11   train_loss:  836.1709464564808   time:  1.3036167621612549
e:  12   train_loss:  804.8586735305876   time:  1.3097293376922607
e:  13   train_loss:  787.8768857094159   time:  1.310023546218872
e:  14   train_loss:  738.054276765618   time:  1.306586742401123
e:  15   train_loss:  683.8037868208461   time:  1.4319491386413574
e:  15   train_loss:  683.8037868208461   val_loss:  747.9348993949449   time:  1.5416481494903564
e:  16   train_loss:  667.1300061569162   time:  1.3009004592895508
e:  17   train_loss:  670.7557115364023   time:  1.307748556137085
e:  18   train_loss:  674.7095555358649   time:  1.3077454566955566
e:  19   train_loss:  667.3182673594131   time:  1.3101837635040283
e:  20   train_loss:  655.9055717019179   time:  1.3092713356018066
e:  20   train_loss:  655.9055717019179   val_loss:  695.0325258134545   time:  1.4186122417449951
e:  21   train_loss:  692.6282425245049   time:  1.305722713470459
e:  22   train_loss:  772.292893834117   time:  1.3092730045318604
e:  23   train_loss:  731.1322600238193   time:  1.2994842529296875
e:  24   train_loss:  694.2048275390126   time:  1.4318110942840576
e:  25   train_loss:  708.4732605720628   time:  1.3050057888031006
e:  25   train_loss:  708.4732605720628   val_loss:  736.3997062181861   time:  1.4136104583740234
e:  26   train_loss:  683.8621782253858   time:  1.3093383312225342
e:  27   train_loss:  664.6532946601691   time:  1.3084754943847656
e:  28   train_loss:  664.92371509334   time:  1.2950420379638672
e:  29   train_loss:  660.2331913858372   time:  1.2740569114685059
e:  30   train_loss:  677.9273056152305   time:  1.3079028129577637
e:  30   train_loss:  677.9273056152305   val_loss:  701.9605713759161   time:  1.4166865348815918
e:  31   train_loss:  651.6876052827   time:  1.308499813079834
e:  32   train_loss:  636.7084535665113   time:  1.2998764514923096
e:  33   train_loss:  621.8364701137806   time:  1.3116674423217773
e:  34   train_loss:  588.9212837610725   time:  1.3042747974395752
e:  35   train_loss:  620.7440279731865   time:  1.4324157238006592
e:  35   train_loss:  620.7440279731865   val_loss:  712.7589215923967   time:  1.542051076889038
e:  36   train_loss:  603.6898441712351   time:  1.3067646026611328
e:  37   train_loss:  588.9387824476183   time:  1.3109714984893799
e:  38   train_loss:  651.5748571449386   time:  1.3116097450256348
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  39   train_loss:  583.2682226274369   time:  1.306403636932373
e:  40   train_loss:  556.6287177806767   time:  1.3125147819519043
e:  40   train_loss:  556.6287177806767   val_loss:  677.0044099886551   time:  1.4226207733154297
e:  41   train_loss:  557.7247397725939   time:  1.3083875179290771
e:  42   train_loss:  618.9938315672584   time:  1.3141515254974365
e:  43   train_loss:  603.6270097822863   time:  1.3133111000061035
e:  44   train_loss:  553.7334438663573   time:  1.4353902339935303
e:  45   train_loss:  575.6511103079638   time:  1.2950468063354492
e:  45   train_loss:  575.6511103079638   val_loss:  743.1600117347127   time:  1.4042489528656006
e:  46   train_loss:  573.9920998051603   time:  1.3108704090118408
e:  47   train_loss:  560.7294913342882   time:  1.3111765384674072
e:  48   train_loss:  547.5676814313489   time:  1.3041110038757324
e:  49   train_loss:  543.1287136762999   time:  1.3113696575164795
e:  50   train_loss:  554.1718904793875   time:  1.3070216178894043
e:  50   train_loss:  554.1718904793875   val_loss:  700.5939127408611   time:  1.4151408672332764
e:  51   train_loss:  532.466072993316   time:  1.2778079509735107
e:  52   train_loss:  706.229508500749   time:  1.2956740856170654
e:  53   train_loss:  829.323279151102   time:  1.4325978755950928
e:  54   train_loss:  793.3535973867563   time:  1.3107850551605225
e:  55   train_loss:  721.2420334729219   time:  1.3105430603027344
e:  55   train_loss:  721.2420334729219   val_loss:  760.1247917428157   time:  1.419743299484253
e:  56   train_loss:  621.3016598341019   time:  1.3115019798278809
e:  57   train_loss:  605.8020863963151   time:  1.3119986057281494
e:  58   train_loss:  559.197330410413   time:  1.3033726215362549
e:  59   train_loss:  537.3714877031172   time:  1.3082365989685059
e:  60   train_loss:  536.7950500681125   time:  1.3123817443847656
e:  60   train_loss:  536.7950500681125   val_loss:  707.397964826926   time:  1.4222049713134766
e:  61   train_loss:  513.0717312455018   time:  1.3090620040893555
e:  62   train_loss:  533.5205417432297   time:  1.3123514652252197
e:  63   train_loss:  521.0911018542002   time:  1.313460111618042
e:  64   train_loss:  542.5965186050948   time:  1.3147339820861816
e:  65   train_loss:  510.961887111008   time:  1.3100035190582275
e:  65   train_loss:  510.961887111008   val_loss:  755.9043831244973   time:  1.545581579208374
e:  66   train_loss:  511.783302295779   time:  1.3128583431243896
e:  67   train_loss:  513.5026151155413   time:  1.3102610111236572
e:  68   train_loss:  572.3480171398062   time:  1.309535264968872
e:  69   train_loss:  508.0850630714575   time:  1.310004472732544
e:  70   train_loss:  589.1574040271823   time:  1.3087573051452637
e:  70   train_loss:  589.1574040271823   val_loss:  767.7538282451304   time:  1.4183285236358643
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1053.571901413055   time:  1.4325451850891113
e:  0   train_loss:  1053.571901413055   val_loss:  663.7611492442484   time:  1.5361602306365967
e:  1   train_loss:  981.3535277855829   time:  1.5693080425262451
e:  2   train_loss:  899.1408087100857   time:  1.3950791358947754
e:  3   train_loss:  839.7106719093358   time:  1.4222972393035889
e:  4   train_loss:  929.6326676834033   time:  1.431429147720337
e:  5   train_loss:  865.1946303610177   time:  1.4275691509246826
e:  5   train_loss:  865.1946303610177   val_loss:  594.0089549656324   time:  1.5309875011444092
e:  6   train_loss:  886.6323327187383   time:  1.4328646659851074
e:  7   train_loss:  848.1327959679754   time:  1.4307074546813965
e:  8   train_loss:  859.5677915570045   time:  1.541644811630249
e:  9   train_loss:  764.064164919347   time:  1.4301681518554688
e:  10   train_loss:  842.2882912916791   time:  1.4299731254577637
e:  10   train_loss:  842.2882912916791   val_loss:  589.0463619041865   time:  1.532867431640625
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  11   train_loss:  924.8082840407466   time:  1.4342718124389648
e:  12   train_loss:  850.7529409734294   time:  1.421424388885498
e:  13   train_loss:  766.2586322246194   time:  1.4313368797302246
e:  14   train_loss:  736.1385201842286   time:  1.5571930408477783
e:  15   train_loss:  761.9182386253918   time:  1.4270074367523193
e:  15   train_loss:  761.9182386253918   val_loss:  548.1601880621896   time:  1.5302753448486328
e:  16   train_loss:  728.9803655325385   time:  1.423722743988037
e:  17   train_loss:  711.2365469816747   time:  1.4278564453125
e:  18   train_loss:  717.5980561409033   time:  1.4309449195861816
e:  19   train_loss:  664.3599553756709   time:  1.4276816844940186
e:  20   train_loss:  647.0511093280841   time:  1.5413250923156738
e:  20   train_loss:  647.0511093280841   val_loss:  561.4843825516122   time:  1.6445693969726562
e:  21   train_loss:  683.5936947875285   time:  1.4318127632141113
e:  22   train_loss:  915.2863966714774   time:  1.4038910865783691
e:  23   train_loss:  770.40679321098   time:  1.4078636169433594
e:  24   train_loss:  836.2411354180956   time:  1.4318928718566895
e:  25   train_loss:  826.647431560408   time:  1.4311189651489258
e:  25   train_loss:  826.647431560408   val_loss:  558.5725451608221   time:  1.5339529514312744
e:  26   train_loss:  728.1035372249778   time:  1.4334440231323242
e:  27   train_loss:  688.1665099473959   time:  1.573761224746704
e:  28   train_loss:  780.828128376601   time:  1.4233603477478027
e:  29   train_loss:  728.0882178535398   time:  1.4304959774017334
e:  30   train_loss:  672.0452563556654   time:  1.4286937713623047
e:  30   train_loss:  672.0452563556654   val_loss:  554.251477683673   time:  1.531886339187622
e:  31   train_loss:  658.4651212970928   time:  1.4226579666137695
e:  32   train_loss:  632.3819874354317   time:  1.422696828842163
e:  33   train_loss:  626.965833411313   time:  1.575587511062622
e:  34   train_loss:  606.8237489972936   time:  1.431323766708374
e:  35   train_loss:  648.87626220912   time:  1.4285776615142822
e:  35   train_loss:  648.87626220912   val_loss:  549.4270518554781   time:  1.5323803424835205
e:  36   train_loss:  598.3503950159641   time:  1.4251477718353271
e:  37   train_loss:  609.3042366564633   time:  1.4247970581054688
e:  38   train_loss:  654.2068367779066   time:  1.4302074909210205
e:  39   train_loss:  606.4218373167458   time:  1.5694763660430908
e:  40   train_loss:  622.4352771974753   time:  1.4276604652404785
e:  40   train_loss:  622.4352771974753   val_loss:  548.6037748628486   time:  1.5300588607788086
e:  41   train_loss:  601.4598352546279   time:  1.4307160377502441
e:  42   train_loss:  627.8687055300798   time:  1.4231972694396973
e:  43   train_loss:  611.3305773867759   time:  1.3942835330963135
e:  44   train_loss:  609.9744949871114   time:  1.4129488468170166
e:  45   train_loss:  582.3702228047692   time:  1.4281251430511475
e:  45   train_loss:  582.3702228047692   val_loss:  534.9827938373194   time:  1.531224250793457
e:  46   train_loss:  566.2582482528045   time:  1.5657925605773926
e:  47   train_loss:  574.6819286490419   time:  1.4314706325531006
e:  48   train_loss:  560.3384679847079   time:  1.4305429458618164
e:  49   train_loss:  542.0516434044156   time:  1.4287543296813965
e:  50   train_loss:  558.637909925405   time:  1.4235618114471436
e:  50   train_loss:  558.637909925405   val_loss:  551.4068515848072   time:  1.5269880294799805
e:  51   train_loss:  545.0345404034864   time:  1.4307715892791748
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  52   train_loss:  579.2887930636095   time:  1.4321634769439697
e:  53   train_loss:  559.5610563207005   time:  1.5408027172088623
e:  54   train_loss:  549.7772543830971   time:  1.4310939311981201
e:  55   train_loss:  529.8608145198542   time:  1.4330549240112305
e:  55   train_loss:  529.8608145198542   val_loss:  545.3840580275651   time:  1.5355958938598633
e:  56   train_loss:  536.8990927789916   time:  1.4343559741973877
e:  57   train_loss:  576.5830156684126   time:  1.4322264194488525
e:  58   train_loss:  628.4207078844338   time:  1.431023120880127
e:  59   train_loss:  547.5587165561051   time:  1.423262596130371
e:  60   train_loss:  520.1861832858234   time:  1.567915439605713
e:  60   train_loss:  520.1861832858234   val_loss:  566.4949571780677   time:  1.6709511280059814
e:  61   train_loss:  498.33281142700577   time:  1.432234525680542
e:  62   train_loss:  489.46544277691527   time:  1.4329595565795898
e:  63   train_loss:  605.7008888295209   time:  1.4083178043365479
e:  64   train_loss:  486.15742671610747   time:  1.4119815826416016
e:  65   train_loss:  509.41659222955263   time:  1.4330782890319824
e:  65   train_loss:  509.41659222955263   val_loss:  532.8579660427619   time:  1.5365326404571533
e:  66   train_loss:  524.0476363344404   time:  1.5780096054077148
e:  67   train_loss:  554.120510109901   time:  1.4299323558807373
e:  68   train_loss:  511.92134587685973   time:  1.4267618656158447
e:  69   train_loss:  471.1891942924315   time:  1.431150197982788
e:  70   train_loss:  537.4256758095116   time:  1.4256477355957031
e:  70   train_loss:  537.4256758095116   val_loss:  557.2075203065305   time:  1.5288145542144775
e:  71   train_loss:  527.3188290732924   time:  1.4334490299224854
e:  72   train_loss:  507.79972675095246   time:  1.4292387962341309
e:  73   train_loss:  483.3976497139148   time:  1.5446674823760986
e:  74   train_loss:  492.01536485259646   time:  1.4325685501098633
e:  75   train_loss:  513.214260331974   time:  1.4281699657440186
e:  75   train_loss:  513.214260331974   val_loss:  545.8395535139159   time:  1.5309205055236816
e:  76   train_loss:  461.31755453660594   time:  1.427220106124878
e:  77   train_loss:  472.4579638407149   time:  1.4286394119262695
e:  78   train_loss:  469.4450894506958   time:  1.4221904277801514
e:  79   train_loss:  476.3605313316756   time:  1.5530130863189697
e:  80   train_loss:  464.70969625855355   time:  1.4246206283569336
e:  80   train_loss:  464.70969625855355   val_loss:  591.2968268100103   time:  1.5281007289886475
e:  81   train_loss:  476.15834464730983   time:  1.4290740489959717
e:  82   train_loss:  447.4582849056115   time:  1.4305531978607178
e:  83   train_loss:  470.1974832044503   time:  1.4191584587097168
e:  84   train_loss:  455.9601122332115   time:  1.393265962600708
e:  85   train_loss:  468.5045121151277   time:  1.5649843215942383
e:  85   train_loss:  468.5045121151277   val_loss:  560.8895122808954   time:  1.668565034866333
e:  86   train_loss:  468.3644303609682   time:  1.4253249168395996
e:  87   train_loss:  567.5391262095474   time:  1.4310688972473145
e:  88   train_loss:  525.6811435330429   time:  1.431840181350708
e:  89   train_loss:  481.7217352473095   time:  1.4293854236602783
e:  90   train_loss:  473.8174144012637   time:  1.4314939975738525
e:  90   train_loss:  473.8174144012637   val_loss:  559.5530698595888   time:  1.5340402126312256
e:  91   train_loss:  469.2648452067963   time:  1.4288074970245361
e:  92   train_loss:  460.8034169255725   time:  1.5580129623413086
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  93   train_loss:  488.0832067649701   time:  1.4246108531951904
e:  94   train_loss:  475.3293448563132   time:  1.4297990798950195
e:  95   train_loss:  492.2807112095209   time:  1.42775559425354
e:  95   train_loss:  492.2807112095209   val_loss:  555.4947854479441   time:  1.5315687656402588
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 22), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 22) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 22) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 22) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 22)
kwargs: {'config': {'batch_norm': False, 'ff_0': 17, 'ff_num_layers': 1, 'gnn_0': 281, 'gnn_dropout': 0.3279737195479306, 'gnn_num_layers': 1, 'hid_0': 593, 'hid_dropout_rate': 0.20414696252923964, 'in_dropout_rate': 0.4386659901915775, 'lr': 0.0015707457967605017, 'num_hid_layers': 3, 'optimizer': 'SGD', 'hid_1': 511, 'hid_2': 271, 'sgd_momentum': 0.6094637896459667}, 'budget': 243.0, 'working_directory': '.'}
result: {'loss': 710.3728298569586, 'n_epochs': 63.0, 'info': {'validation loss': 710.3728298569586}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 22) started
DEBUG:hpbandster:job_callback for (0, 0, 22) got condition
DEBUG:hpbandster:Only 2 run(s) for budget 243.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 22) finished
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 26) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 26) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 26)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 26) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 26) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 26)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 876, 'ff_num_layers': 2, 'gnn_0': 227, 'gnn_dropout': 0.49213520925025633, 'gnn_num_layers': 1, 'hid_0': 1532, 'hid_dropout_rate': 0.15679639657463124, 'in_dropout_rate': 0.39029146685469257, 'lr': 0.0025714843620315395, 'num_hid_layers': 1, 'optimizer': 'Adam', 'ff_1': 28}, 'budget': 243.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  617.4066872891825   time:  1.5472853183746338
e:  0   train_loss:  617.4066872891825   val_loss:  1431.7606893410136   time:  1.660224199295044
e:  1   train_loss:  547.3622454480642   time:  1.5603551864624023
e:  2   train_loss:  502.59231673875775   time:  1.710298776626587
e:  3   train_loss:  482.4291551490004   time:  1.5009374618530273
e:  4   train_loss:  475.447291711281   time:  1.498870849609375
e:  5   train_loss:  460.0212842348663   time:  1.499178171157837
e:  5   train_loss:  460.0212842348663   val_loss:  1459.4424420480505   time:  1.6113357543945312
e:  6   train_loss:  454.42304312221916   time:  1.4978883266448975
e:  7   train_loss:  444.33952475355454   time:  1.4658000469207764
e:  8   train_loss:  441.7464124798242   time:  1.4486303329467773
e:  9   train_loss:  433.11514358436426   time:  1.4951260089874268
e:  10   train_loss:  431.0811469789455   time:  1.4989662170410156
e:  10   train_loss:  431.0811469789455   val_loss:  1452.0881518841604   time:  1.610668659210205
e:  11   train_loss:  430.8065850927784   time:  1.4956715106964111
e:  12   train_loss:  428.01129595403887   time:  1.493985652923584
e:  13   train_loss:  426.4460622523143   time:  1.6273071765899658
e:  14   train_loss:  421.62352684215756   time:  1.4526448249816895
e:  15   train_loss:  419.33364971602253   time:  1.478940486907959
e:  15   train_loss:  419.33364971602253   val_loss:  1345.4783887390372   time:  1.5902888774871826
e:  16   train_loss:  418.89179946698977   time:  1.4890809059143066
e:  17   train_loss:  413.67717644131477   time:  1.531601905822754
e:  18   train_loss:  414.46093889502896   time:  1.4918642044067383
e:  19   train_loss:  409.8488566086395   time:  1.49534273147583
e:  20   train_loss:  407.36631440383735   time:  1.4966981410980225
e:  20   train_loss:  407.36631440383735   val_loss:  1262.318627752838   time:  1.608388900756836
e:  21   train_loss:  404.8903835624358   time:  1.614353895187378
e:  22   train_loss:  401.64025043125173   time:  1.4975051879882812
e:  23   train_loss:  399.7898370243747   time:  1.4959547519683838
e:  24   train_loss:  395.6867246918079   time:  1.496856451034546
e:  25   train_loss:  390.28305643557474   time:  1.4960722923278809
e:  25   train_loss:  390.28305643557474   val_loss:  1292.548696687295   time:  1.6084086894989014
e:  26   train_loss:  386.8930327994325   time:  1.4960708618164062
e:  27   train_loss:  385.5684996182675   time:  1.4394900798797607
e:  28   train_loss:  382.5446361397578   time:  1.4804961681365967
e:  29   train_loss:  375.9700775140048   time:  1.4939138889312744
e:  30   train_loss:  369.9743374924934   time:  1.4971771240234375
e:  30   train_loss:  369.9743374924934   val_loss:  1341.7359777860534   time:  1.7409725189208984
e:  31   train_loss:  365.2016195823269   time:  1.4808928966522217
e:  32   train_loss:  360.7761121742647   time:  1.4968342781066895
e:  33   train_loss:  355.047647027979   time:  1.490734338760376
e:  34   train_loss:  351.5590029910595   time:  1.4951274394989014
e:  35   train_loss:  346.8384003901163   time:  1.4924354553222656
e:  35   train_loss:  346.8384003901163   val_loss:  1382.219195072189   time:  1.6036453247070312
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  36   train_loss:  343.7463080146727   time:  1.4970712661743164
e:  37   train_loss:  340.4736707710579   time:  1.495537281036377
e:  38   train_loss:  336.9231150576667   time:  1.4910130500793457
e:  39   train_loss:  335.365781570715   time:  1.5005099773406982
e:  40   train_loss:  330.8512816911297   time:  1.496338129043579
e:  40   train_loss:  330.8512816911297   val_loss:  1546.0580597055512   time:  1.6077229976654053
e:  41   train_loss:  326.4904799265164   time:  1.6282830238342285
e:  42   train_loss:  322.8513885139379   time:  1.4965786933898926
e:  43   train_loss:  319.9093375072766   time:  1.4976449012756348
e:  44   train_loss:  317.85977849240385   time:  1.5003745555877686
e:  45   train_loss:  313.40757168963796   time:  1.4933693408966064
e:  45   train_loss:  313.40757168963796   val_loss:  1394.3479269116724   time:  1.605093240737915
e:  46   train_loss:  310.41998743884386   time:  1.487267255783081
e:  47   train_loss:  306.10257574145584   time:  1.459782361984253
e:  48   train_loss:  303.99675067429183   time:  1.4888505935668945
e:  49   train_loss:  300.3363785107801   time:  1.5022156238555908
e:  50   train_loss:  297.04881210866665   time:  1.685227870941162
e:  50   train_loss:  297.04881210866665   val_loss:  1410.9172878008478   time:  1.9110229015350342
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  947.3087258715817   time:  1.6291224956512451
e:  0   train_loss:  947.3087258715817   val_loss:  551.7784896568261   time:  1.7332396507263184
e:  1   train_loss:  758.6226933172129   time:  1.7879116535186768
e:  2   train_loss:  667.8304907199217   time:  1.6330204010009766
e:  3   train_loss:  650.6284589153934   time:  1.710911512374878
e:  4   train_loss:  628.9569574599536   time:  1.630502700805664
e:  5   train_loss:  602.6557690507454   time:  1.6300787925720215
e:  5   train_loss:  602.6557690507454   val_loss:  570.2819902061345   time:  1.8639209270477295
e:  6   train_loss:  594.0801982786382   time:  1.6333789825439453
e:  7   train_loss:  609.8557782008652   time:  1.6284611225128174
e:  8   train_loss:  596.1985927714161   time:  1.630957841873169
e:  9   train_loss:  590.796634367399   time:  1.635176658630371
e:  10   train_loss:  575.7730857788727   time:  1.6341593265533447
e:  10   train_loss:  575.7730857788727   val_loss:  609.460950338445   time:  1.7387514114379883
e:  11   train_loss:  584.3074822967534   time:  1.628697156906128
e:  12   train_loss:  574.9045676091171   time:  1.632558822631836
e:  13   train_loss:  598.9485051457518   time:  1.6184258460998535
e:  14   train_loss:  570.8887099718619   time:  1.6939587593078613
e:  15   train_loss:  566.017372447337   time:  1.6322779655456543
e:  15   train_loss:  566.017372447337   val_loss:  599.3310685922567   time:  1.7375319004058838
e:  16   train_loss:  558.9225069387064   time:  1.6346771717071533
e:  17   train_loss:  569.5606473863533   time:  1.6335902214050293
e:  18   train_loss:  583.2436932833706   time:  1.633192777633667
e:  19   train_loss:  551.2406076453212   time:  1.6347448825836182
e:  20   train_loss:  549.3922888180141   time:  1.785445213317871
e:  20   train_loss:  549.3922888180141   val_loss:  724.1639583589985   time:  1.891207218170166
e:  21   train_loss:  549.4892297521067   time:  1.6319067478179932
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  22   train_loss:  536.709532683558   time:  1.6286218166351318
e:  23   train_loss:  560.3444062566432   time:  1.630389928817749
e:  24   train_loss:  552.3061576669012   time:  1.6303670406341553
e:  25   train_loss:  537.7137829679989   time:  1.6278407573699951
e:  25   train_loss:  537.7137829679989   val_loss:  764.9604144024717   time:  1.8598945140838623
e:  26   train_loss:  532.156095620242   time:  1.63124418258667
e:  27   train_loss:  538.0887041971893   time:  1.6313002109527588
e:  28   train_loss:  526.8004447275899   time:  1.6299567222595215
e:  29   train_loss:  525.6412470141333   time:  1.6282341480255127
e:  30   train_loss:  525.5442768056066   time:  1.6298019886016846
e:  30   train_loss:  525.5442768056066   val_loss:  740.207819205558   time:  1.7347197532653809
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  912.0363980168838   time:  1.7057409286499023
e:  0   train_loss:  912.0363980168838   val_loss:  488.5466291366855   time:  1.8060474395751953
e:  1   train_loss:  738.2596821200053   time:  1.5576460361480713
e:  2   train_loss:  686.6244856618995   time:  1.6088271141052246
e:  3   train_loss:  681.5034688771004   time:  1.611037254333496
e:  4   train_loss:  667.2481409090498   time:  1.6071257591247559
e:  5   train_loss:  635.5608383978208   time:  1.6106462478637695
e:  5   train_loss:  635.5608383978208   val_loss:  486.3055353466705   time:  1.7185957431793213
e:  6   train_loss:  680.4786260351016   time:  1.6080079078674316
e:  7   train_loss:  649.39652606089   time:  1.6318707466125488
e:  8   train_loss:  639.2442244482606   time:  1.742051601409912
e:  9   train_loss:  602.4142055019524   time:  1.6105799674987793
e:  10   train_loss:  619.738633036465   time:  1.6120822429656982
e:  10   train_loss:  619.738633036465   val_loss:  831.8810276271154   time:  1.7208778858184814
e:  11   train_loss:  593.1050450370776   time:  1.6108717918395996
e:  12   train_loss:  621.6021655613097   time:  1.6083869934082031
e:  13   train_loss:  621.4320763495616   time:  1.6098082065582275
e:  14   train_loss:  584.1937242275352   time:  1.7394886016845703
e:  15   train_loss:  590.6021802526011   time:  1.6169452667236328
e:  15   train_loss:  590.6021802526011   val_loss:  579.8820213746916   time:  1.7258672714233398
e:  16   train_loss:  589.2153437104539   time:  1.6125891208648682
e:  17   train_loss:  582.5972321928776   time:  1.606661081314087
e:  18   train_loss:  586.5155948388896   time:  1.597165822982788
e:  19   train_loss:  602.9519555957592   time:  1.5455176830291748
e:  20   train_loss:  580.9573379086617   time:  1.6094105243682861
e:  20   train_loss:  580.9573379086617   val_loss:  513.2740591241594   time:  1.7178549766540527
e:  21   train_loss:  575.5954871297733   time:  1.6109099388122559
e:  22   train_loss:  580.0346596515802   time:  1.7461421489715576
e:  23   train_loss:  585.6893040833036   time:  1.6109180450439453
e:  24   train_loss:  567.7060892436059   time:  1.6086692810058594
e:  25   train_loss:  577.109596478707   time:  1.6118369102478027
e:  25   train_loss:  577.109596478707   val_loss:  565.1396925562823   time:  1.7196729183197021
e:  26   train_loss:  613.5439761925159   time:  1.6126184463500977
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  27   train_loss:  604.5680225916345   time:  1.5934092998504639
e:  28   train_loss:  586.2782647720045   time:  1.5930848121643066
e:  29   train_loss:  563.9820821976589   time:  1.7462668418884277
e:  30   train_loss:  571.2770976142507   time:  1.6138741970062256
e:  30   train_loss:  571.2770976142507   val_loss:  549.1993783791968   time:  1.7226452827453613
e:  31   train_loss:  556.8758184502237   time:  1.6131319999694824
e:  32   train_loss:  586.7531709443846   time:  1.6146557331085205
e:  33   train_loss:  556.2989124298786   time:  1.614973545074463
e:  34   train_loss:  564.9686996510595   time:  1.6131095886230469
e:  35   train_loss:  548.7830690175847   time:  1.611875057220459
e:  35   train_loss:  548.7830690175847   val_loss:  587.8397708795133   time:  1.7205688953399658
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  864.6306029528033   time:  1.4787862300872803
e:  0   train_loss:  864.6306029528033   val_loss:  739.1463769699883   time:  1.7111585140228271
e:  1   train_loss:  719.2254410940125   time:  1.4339525699615479
e:  2   train_loss:  633.0895106272935   time:  1.4882373809814453
e:  3   train_loss:  615.2478986608518   time:  1.5008084774017334
e:  4   train_loss:  593.9370367214719   time:  1.503553867340088
e:  5   train_loss:  595.1452682489435   time:  1.5034022331237793
e:  5   train_loss:  595.1452682489435   val_loss:  725.0452878256002   time:  1.6176328659057617
e:  6   train_loss:  563.9864392139767   time:  1.5011496543884277
e:  7   train_loss:  567.6300139724323   time:  1.5025169849395752
e:  8   train_loss:  570.8492895148911   time:  1.4964501857757568
e:  9   train_loss:  559.2631752646025   time:  1.5028514862060547
e:  10   train_loss:  564.8252541191943   time:  1.500913143157959
e:  10   train_loss:  564.8252541191943   val_loss:  744.7555506811166   time:  1.6144003868103027
e:  11   train_loss:  565.7131066027815   time:  1.627265214920044
e:  12   train_loss:  562.3071005606433   time:  1.4978480339050293
e:  13   train_loss:  548.4075281717245   time:  1.4844419956207275
e:  14   train_loss:  544.1297547502002   time:  1.4982361793518066
e:  15   train_loss:  548.5438765254294   time:  1.4979948997497559
e:  15   train_loss:  548.5438765254294   val_loss:  724.7467729985043   time:  1.6116034984588623
e:  16   train_loss:  551.7376858618995   time:  1.5009276866912842
e:  17   train_loss:  539.234332504854   time:  1.4954967498779297
e:  18   train_loss:  536.8220956614323   time:  1.502335548400879
e:  19   train_loss:  543.9036429345018   time:  1.4981105327606201
e:  20   train_loss:  537.0179493987769   time:  1.4690351486206055
e:  20   train_loss:  537.0179493987769   val_loss:  742.3243008671666   time:  1.581716775894165
e:  21   train_loss:  532.3757395555444   time:  1.4430696964263916
e:  22   train_loss:  532.9332306684224   time:  1.5010840892791748
e:  23   train_loss:  526.2857694722355   time:  1.6196465492248535
e:  24   train_loss:  527.5244698256415   time:  1.500915765762329
e:  25   train_loss:  526.2077804704152   time:  1.5016820430755615
e:  25   train_loss:  526.2077804704152   val_loss:  742.8555391043916   time:  1.6166996955871582
e:  26   train_loss:  528.4942974895732   time:  1.5020077228546143
e:  27   train_loss:  524.1831912913539   time:  1.5025439262390137
e:  28   train_loss:  525.9622117532273   time:  1.5000274181365967
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  29   train_loss:  517.0728635717137   time:  1.4975035190582275
e:  30   train_loss:  523.947147362665   time:  1.5007586479187012
e:  30   train_loss:  523.947147362665   val_loss:  743.3850247053849   time:  1.6149299144744873
e:  31   train_loss:  524.6711217986785   time:  1.5021412372589111
e:  32   train_loss:  519.8728864293117   time:  1.5030169486999512
e:  33   train_loss:  511.9242951163213   time:  1.5023367404937744
e:  34   train_loss:  505.0709840256715   time:  1.6269428730010986
e:  35   train_loss:  499.67816277985673   time:  1.4982414245605469
e:  35   train_loss:  499.67816277985673   val_loss:  746.3807579619732   time:  1.603666067123413
e:  36   train_loss:  499.6247767636261   time:  1.5015828609466553
e:  37   train_loss:  494.2474451556899   time:  1.5007708072662354
e:  38   train_loss:  493.66786207114137   time:  1.5001356601715088
e:  39   train_loss:  488.7173315340569   time:  1.499974012374878
e:  40   train_loss:  479.957701072678   time:  1.443645715713501
e:  40   train_loss:  479.957701072678   val_loss:  769.8323465575597   time:  1.5557184219360352
e:  41   train_loss:  478.81634406977923   time:  1.4676640033721924
e:  42   train_loss:  475.59036062379585   time:  1.5004472732543945
e:  43   train_loss:  472.84981630185365   time:  1.5015239715576172
e:  44   train_loss:  467.200845449094   time:  1.4975764751434326
e:  45   train_loss:  463.61105974606755   time:  1.6203575134277344
e:  45   train_loss:  463.61105974606755   val_loss:  785.6647715584637   time:  1.7346370220184326
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  920.6514999043377   time:  1.636920690536499
e:  0   train_loss:  920.6514999043377   val_loss:  555.741712115309   time:  1.743776798248291
e:  1   train_loss:  719.9215503076559   time:  1.635143518447876
e:  2   train_loss:  678.3077430371995   time:  1.6342227458953857
e:  3   train_loss:  643.1353493641308   time:  1.634371042251587
e:  4   train_loss:  624.7853906852145   time:  1.633108377456665
e:  5   train_loss:  609.8728538901602   time:  1.7870585918426514
e:  5   train_loss:  609.8728538901602   val_loss:  590.6610745248684   time:  1.894319772720337
e:  6   train_loss:  596.2161074074766   time:  1.6333062648773193
e:  7   train_loss:  602.9137618652866   time:  1.6334240436553955
e:  8   train_loss:  593.5367008574285   time:  1.6273479461669922
e:  9   train_loss:  594.5637579074948   time:  1.6328184604644775
e:  10   train_loss:  601.8774577964095   time:  1.6345300674438477
e:  10   train_loss:  601.8774577964095   val_loss:  636.7045805332365   time:  1.8688149452209473
e:  11   train_loss:  591.4573358086312   time:  1.631042242050171
e:  12   train_loss:  593.0860105305651   time:  1.590174674987793
e:  13   train_loss:  599.7947686946466   time:  1.5895652770996094
e:  14   train_loss:  590.5129211624776   time:  1.6327216625213623
e:  15   train_loss:  579.362957952861   time:  1.6336143016815186
e:  15   train_loss:  579.362957952861   val_loss:  641.9303843964082   time:  1.7402713298797607
e:  16   train_loss:  599.2975851011846   time:  1.6359124183654785
e:  17   train_loss:  585.7583907559805   time:  1.786311149597168
e:  18   train_loss:  578.6915977107715   time:  1.6332905292510986
e:  19   train_loss:  588.6049420239725   time:  1.6338467597961426
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  20   train_loss:  575.5391913399095   time:  1.6329865455627441
e:  20   train_loss:  575.5391913399095   val_loss:  628.678861512766   time:  1.7399184703826904
e:  21   train_loss:  569.0532826751128   time:  1.6324224472045898
e:  22   train_loss:  585.3416390083772   time:  1.6322813034057617
e:  23   train_loss:  582.7904142941433   time:  1.7861573696136475
e:  24   train_loss:  577.0949358355589   time:  1.6338951587677002
e:  25   train_loss:  563.2784746603528   time:  1.6306185722351074
e:  25   train_loss:  563.2784746603528   val_loss:  644.943257229025   time:  1.7382311820983887
e:  26   train_loss:  565.9372308404695   time:  1.6275532245635986
e:  27   train_loss:  555.8670164569752   time:  1.6338331699371338
e:  28   train_loss:  556.6988806134513   time:  1.6357638835906982
e:  29   train_loss:  563.4761576151269   time:  1.7814691066741943
e:  30   train_loss:  563.731564553709   time:  1.5915017127990723
e:  30   train_loss:  563.731564553709   val_loss:  656.6093490351105   time:  1.6966478824615479
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 26), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 26) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 26) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 26) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 26)
kwargs: {'config': {'batch_norm': True, 'ff_0': 876, 'ff_num_layers': 2, 'gnn_0': 227, 'gnn_dropout': 0.49213520925025633, 'gnn_num_layers': 1, 'hid_0': 1532, 'hid_dropout_rate': 0.15679639657463124, 'in_dropout_rate': 0.39029146685469257, 'lr': 0.0025714843620315395, 'num_hid_layers': 1, 'optimizer': 'Adam', 'ff_1': 28}, 'budget': 243.0, 'working_directory': '.'}
result: {'loss': 716.1782275740295, 'n_epochs': 38.0, 'info': {'validation loss': 716.1782275740295}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 26) started
DEBUG:hpbandster:job_callback for (0, 0, 26) got condition
DEBUG:hpbandster:Only 3 run(s) for budget 243.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 26) finished
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:ITERATION: Advancing config (0, 0, 22) to next budget 729.000000
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: trying submitting job (0, 0, 22) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 22) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 22)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 22) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 22) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (0, 0, 22)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 17, 'ff_num_layers': 1, 'gnn_0': 281, 'gnn_dropout': 0.3279737195479306, 'gnn_num_layers': 1, 'hid_0': 593, 'hid_dropout_rate': 0.20414696252923964, 'in_dropout_rate': 0.4386659901915775, 'lr': 0.0015707457967605017, 'num_hid_layers': 3, 'optimizer': 'SGD', 'hid_1': 511, 'hid_2': 271, 'sgd_momentum': 0.6094637896459667}, 'budget': 729.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  700.2870561304996   time:  1.4580659866333008
e:  0   train_loss:  700.2870561304996   val_loss:  1645.9739261546442   time:  1.5672998428344727
e:  1   train_loss:  664.1578016219903   time:  1.3280959129333496
e:  2   train_loss:  596.3673868973257   time:  1.3104383945465088
e:  3   train_loss:  589.2808679160011   time:  1.3089702129364014
e:  4   train_loss:  578.8922135853503   time:  1.3151869773864746
e:  5   train_loss:  556.7401201267924   time:  1.3144383430480957
e:  5   train_loss:  556.7401201267924   val_loss:  1422.0224343801942   time:  1.4227344989776611
e:  6   train_loss:  599.3377122105007   time:  1.4476871490478516
e:  7   train_loss:  584.6126093496135   time:  1.300084114074707
e:  8   train_loss:  553.7787604097847   time:  1.30946946144104
e:  9   train_loss:  550.4877349475099   time:  1.3105370998382568
e:  10   train_loss:  585.6179890746871   time:  1.318713903427124
e:  10   train_loss:  585.6179890746871   val_loss:  1357.9184992835017   time:  1.4272313117980957
e:  11   train_loss:  538.1987686541527   time:  1.3192706108093262
e:  12   train_loss:  525.4595782242293   time:  1.317636489868164
e:  13   train_loss:  566.4296191750705   time:  1.3153495788574219
e:  14   train_loss:  568.2274656771243   time:  1.3204565048217773
e:  15   train_loss:  559.2425175737112   time:  1.3178441524505615
e:  15   train_loss:  559.2425175737112   val_loss:  1395.7639586044913   time:  1.4272480010986328
e:  16   train_loss:  551.9559290233171   time:  1.3089399337768555
e:  17   train_loss:  548.8246818244058   time:  1.4400279521942139
e:  18   train_loss:  518.4223533692602   time:  1.2942349910736084
e:  19   train_loss:  526.3659631113771   time:  1.3119449615478516
e:  20   train_loss:  593.093795698206   time:  1.3186511993408203
e:  20   train_loss:  593.093795698206   val_loss:  1406.6638880058483   time:  1.4272239208221436
e:  21   train_loss:  578.9361500826983   time:  1.2904651165008545
e:  22   train_loss:  540.5010314937331   time:  1.3003168106079102
e:  23   train_loss:  537.7175936766052   time:  1.3179152011871338
e:  24   train_loss:  523.032058991476   time:  1.3083610534667969
e:  25   train_loss:  508.63260454294317   time:  1.3184714317321777
e:  25   train_loss:  508.63260454294317   val_loss:  1398.7618656070722   time:  1.4267024993896484
e:  26   train_loss:  516.380176014685   time:  1.317199945449829
e:  27   train_loss:  550.7536585856625   time:  1.3661854267120361
e:  28   train_loss:  565.1469137632331   time:  1.5370569229125977
e:  29   train_loss:  528.2070743939553   time:  1.4342317581176758
e:  30   train_loss:  513.7168379929229   time:  1.4303829669952393
e:  30   train_loss:  513.7168379929229   val_loss:  1414.3690832294392   time:  1.54099440574646
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  31   train_loss:  504.3939265078881   time:  1.3964834213256836
e:  32   train_loss:  547.6346072998567   time:  1.5064942836761475
e:  33   train_loss:  508.94997688565286   time:  1.3398964405059814
e:  34   train_loss:  554.3988287113532   time:  1.407480239868164
e:  35   train_loss:  596.4572165796217   time:  1.4059820175170898
e:  35   train_loss:  596.4572165796217   val_loss:  1406.5659961887584   time:  1.5176749229431152
e:  36   train_loss:  592.8824960479654   time:  1.3883707523345947
e:  37   train_loss:  590.4858383479414   time:  1.5288467407226562
e:  38   train_loss:  592.5122062687633   time:  1.2983348369598389
e:  39   train_loss:  581.8308261828906   time:  1.3096508979797363
e:  40   train_loss:  614.8897131976037   time:  1.3068020343780518
e:  40   train_loss:  614.8897131976037   val_loss:  1413.7714081033712   time:  1.4155116081237793
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1060.839167019066   time:  1.4308791160583496
e:  0   train_loss:  1060.839167019066   val_loss:  602.8957127860419   time:  1.5327999591827393
e:  1   train_loss:  986.0367639488791   time:  1.4110171794891357
e:  2   train_loss:  891.9545478667325   time:  1.3976633548736572
e:  3   train_loss:  849.317893775945   time:  1.5755884647369385
e:  4   train_loss:  887.051202436388   time:  1.4303617477416992
e:  5   train_loss:  835.9770440434834   time:  1.428349256515503
e:  5   train_loss:  835.9770440434834   val_loss:  531.8781528593287   time:  1.5310072898864746
e:  6   train_loss:  796.4552679302412   time:  1.4232447147369385
e:  7   train_loss:  813.2324107689441   time:  1.4248952865600586
e:  8   train_loss:  821.7167487144432   time:  1.4336895942687988
e:  9   train_loss:  833.0654293938073   time:  1.572920560836792
e:  10   train_loss:  849.9417035592887   time:  1.4301226139068604
e:  10   train_loss:  849.9417035592887   val_loss:  543.2840901683878   time:  1.531587839126587
e:  11   train_loss:  786.5613116541045   time:  1.4338810443878174
e:  12   train_loss:  795.983831955419   time:  1.431675672531128
e:  13   train_loss:  777.5298209810969   time:  1.4327316284179688
e:  14   train_loss:  729.900031549813   time:  1.4243946075439453
e:  15   train_loss:  777.7961625900035   time:  1.4463374614715576
e:  15   train_loss:  777.7961625900035   val_loss:  536.4041645859054   time:  1.548387050628662
e:  16   train_loss:  699.389805180382   time:  1.5836315155029297
e:  17   train_loss:  688.2677021356309   time:  1.43406343460083
e:  18   train_loss:  818.2738011024298   time:  1.4383037090301514
e:  19   train_loss:  821.1874430660159   time:  1.4498350620269775
e:  20   train_loss:  762.7069948415187   time:  1.4285058975219727
e:  20   train_loss:  762.7069948415187   val_loss:  546.0446931060613   time:  1.5311007499694824
e:  21   train_loss:  699.2895937929352   time:  1.4270737171173096
e:  22   train_loss:  666.0223798644458   time:  1.4006638526916504
e:  23   train_loss:  741.3020125760949   time:  1.553347110748291
e:  24   train_loss:  705.8453150188135   time:  1.4298043251037598
e:  25   train_loss:  707.4002525642342   time:  1.430882453918457
e:  25   train_loss:  707.4002525642342   val_loss:  577.1492404504413   time:  1.5320355892181396
e:  26   train_loss:  712.9753825801247   time:  1.4325110912322998
e:  27   train_loss:  736.3670805536293   time:  1.4314818382263184
e:  28   train_loss:  659.6251364326446   time:  1.430542230606079
e:  29   train_loss:  638.4295728677089   time:  1.423783540725708
e:  30   train_loss:  631.270787003997   time:  1.5670173168182373
e:  30   train_loss:  631.270787003997   val_loss:  532.7308483413544   time:  1.6687283515930176
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  31   train_loss:  651.9974724113542   time:  1.435713291168213
e:  32   train_loss:  908.3852706298848   time:  1.4330964088439941
e:  33   train_loss:  852.7034491363934   time:  1.429302453994751
e:  34   train_loss:  843.605388454786   time:  1.432889461517334
e:  35   train_loss:  760.2750363854593   time:  1.4319217205047607
e:  35   train_loss:  760.2750363854593   val_loss:  529.572776887804   time:  1.5340754985809326
e:  36   train_loss:  681.2221197444906   time:  1.5745007991790771
e:  37   train_loss:  627.1691838660697   time:  1.436079978942871
e:  38   train_loss:  598.6511731084786   time:  1.42818284034729
e:  39   train_loss:  686.2795192413776   time:  1.433584213256836
e:  40   train_loss:  603.3513360288275   time:  1.4276442527770996
e:  40   train_loss:  603.3513360288275   val_loss:  657.3901542285353   time:  1.5298144817352295
e:  41   train_loss:  789.5136972639984   time:  1.4324777126312256
e:  42   train_loss:  694.6034051245072   time:  1.3987042903900146
e:  43   train_loss:  628.8886562481771   time:  1.5277471542358398
e:  44   train_loss:  660.6426425420311   time:  1.4305295944213867
e:  45   train_loss:  704.4474230025576   time:  1.43056321144104
e:  45   train_loss:  704.4474230025576   val_loss:  528.7315803217999   time:  1.5323526859283447
e:  46   train_loss:  607.8071680629222   time:  1.429694414138794
e:  47   train_loss:  580.0637129249585   time:  1.4305405616760254
e:  48   train_loss:  616.6427726575862   time:  1.4286918640136719
e:  49   train_loss:  576.6003386643774   time:  1.564955234527588
e:  50   train_loss:  541.5158680482926   time:  1.4304018020629883
e:  50   train_loss:  541.5158680482926   val_loss:  542.0331260246675   time:  1.53230881690979
e:  51   train_loss:  546.6659252287253   time:  1.4314682483673096
e:  52   train_loss:  574.5593799118925   time:  1.4314639568328857
e:  53   train_loss:  524.9200661464471   time:  1.4316694736480713
e:  54   train_loss:  554.932754093307   time:  1.4295589923858643
e:  55   train_loss:  517.4403223635103   time:  1.5634093284606934
e:  55   train_loss:  517.4403223635103   val_loss:  554.13698776408   time:  1.6651897430419922
e:  56   train_loss:  534.2377132960378   time:  1.43214750289917
e:  57   train_loss:  557.2940361696557   time:  1.430950403213501
e:  58   train_loss:  507.35500244805127   time:  1.4314632415771484
e:  59   train_loss:  497.63632083766214   time:  1.4288733005523682
e:  60   train_loss:  529.4759164451838   time:  1.4321131706237793
e:  60   train_loss:  529.4759164451838   val_loss:  536.8020148221584   time:  1.5334415435791016
e:  61   train_loss:  564.9148827461618   time:  1.4294993877410889
e:  62   train_loss:  591.123463366263   time:  1.5427970886230469
e:  63   train_loss:  543.2429505542518   time:  1.3924932479858398
e:  64   train_loss:  495.80511321749964   time:  1.427621603012085
e:  65   train_loss:  503.4858252909572   time:  1.4233639240264893
e:  65   train_loss:  503.4858252909572   val_loss:  556.7021882118597   time:  1.5253238677978516
e:  66   train_loss:  486.280422840114   time:  1.4298272132873535
e:  67   train_loss:  511.1088028321493   time:  1.431262493133545
e:  68   train_loss:  524.7910705391163   time:  1.5704166889190674
e:  69   train_loss:  498.6966367893467   time:  1.4221158027648926
e:  70   train_loss:  492.3595048057211   time:  1.4303109645843506
e:  70   train_loss:  492.3595048057211   val_loss:  595.62510869061   time:  1.5321223735809326
e:  71   train_loss:  482.1976675521521   time:  1.4297211170196533
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  72   train_loss:  466.41364448080793   time:  1.4262115955352783
e:  73   train_loss:  491.3641824356043   time:  1.4266815185546875
e:  74   train_loss:  447.7267252122862   time:  1.429689645767212
e:  75   train_loss:  692.7325601659323   time:  1.5733973979949951
e:  75   train_loss:  692.7325601659323   val_loss:  549.260159611809   time:  1.6745431423187256
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1141.5173094624306   time:  1.4122040271759033
e:  0   train_loss:  1141.5173094624306   val_loss:  514.5252703392408   time:  1.5162463188171387
e:  1   train_loss:  949.7101171185137   time:  1.4124176502227783
e:  2   train_loss:  898.8907722973528   time:  1.4132733345031738
e:  3   train_loss:  878.198868227092   time:  1.4058001041412354
e:  4   train_loss:  880.5670681599507   time:  1.4110009670257568
e:  5   train_loss:  841.7641384712821   time:  1.4238276481628418
e:  5   train_loss:  841.7641384712821   val_loss:  463.5553895751215   time:  1.6489589214324951
e:  6   train_loss:  800.7136822017167   time:  1.4123797416687012
e:  7   train_loss:  1165.460456105638   time:  1.3834760189056396
e:  8   train_loss:  1045.568276127532   time:  1.3956308364868164
e:  9   train_loss:  897.1697147526427   time:  1.414522409439087
e:  10   train_loss:  900.9339311140991   time:  1.4107928276062012
e:  10   train_loss:  900.9339311140991   val_loss:  530.0475697349755   time:  1.5156352519989014
e:  11   train_loss:  853.8449544672796   time:  1.4135935306549072
e:  12   train_loss:  831.3084713742439   time:  1.4136462211608887
e:  13   train_loss:  981.081654966271   time:  1.534766674041748
e:  14   train_loss:  825.5626643424771   time:  1.4121956825256348
e:  15   train_loss:  781.5203166764614   time:  1.4116425514221191
e:  15   train_loss:  781.5203166764614   val_loss:  468.81643191783974   time:  1.5161809921264648
e:  16   train_loss:  830.7667903511697   time:  1.4131567478179932
e:  17   train_loss:  752.6380661357737   time:  1.405656337738037
e:  18   train_loss:  762.755374951627   time:  1.4125828742980957
e:  19   train_loss:  725.47822189282   time:  1.4146370887756348
e:  20   train_loss:  696.396550178458   time:  1.542466163635254
e:  20   train_loss:  696.396550178458   val_loss:  465.96309357327095   time:  1.6466500759124756
e:  21   train_loss:  725.4709156743788   time:  1.4079461097717285
e:  22   train_loss:  838.2498085836837   time:  1.4142382144927979
e:  23   train_loss:  801.9338131107123   time:  1.4157419204711914
e:  24   train_loss:  760.6600594743076   time:  1.4164433479309082
e:  25   train_loss:  713.7514199018098   time:  1.4141950607299805
e:  25   train_loss:  713.7514199018098   val_loss:  470.3182856869862   time:  1.518794059753418
e:  26   train_loss:  708.1916441887246   time:  1.4147744178771973
e:  27   train_loss:  677.3942641216164   time:  1.5489587783813477
e:  28   train_loss:  697.0210739635388   time:  1.3804686069488525
e:  29   train_loss:  987.3985197426477   time:  1.4066596031188965
e:  30   train_loss:  910.7530404068724   time:  1.4088916778564453
e:  30   train_loss:  910.7530404068724   val_loss:  485.1227822110596   time:  1.513577938079834
e:  31   train_loss:  883.167913488445   time:  1.409999132156372
e:  32   train_loss:  880.467704052958   time:  1.410959243774414
e:  33   train_loss:  849.7642717279006   time:  1.4086854457855225
e:  34   train_loss:  780.1784008070357   time:  1.4126965999603271
e:  35   train_loss:  850.1342236838715   time:  1.5451793670654297
e:  35   train_loss:  850.1342236838715   val_loss:  498.49273881764105   time:  1.6495602130889893
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  988.8617099740187   time:  1.294154405593872
e:  0   train_loss:  988.8617099740187   val_loss:  889.1776923711788   time:  1.403627634048462
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  1   train_loss:  907.6404743628771   time:  1.3076019287109375
e:  2   train_loss:  837.9297313464265   time:  1.3003363609313965
e:  3   train_loss:  821.0670804840365   time:  1.3089873790740967
e:  4   train_loss:  772.9990315430929   time:  1.3064203262329102
e:  5   train_loss:  859.8551278337934   time:  1.307837963104248
e:  5   train_loss:  859.8551278337934   val_loss:  740.9658714720545   time:  1.417607069015503
e:  6   train_loss:  818.0536250302924   time:  1.3099091053009033
e:  7   train_loss:  778.0613102090052   time:  1.306858777999878
e:  8   train_loss:  812.6622108285983   time:  1.3055951595306396
e:  9   train_loss:  826.0281281605735   time:  1.423893690109253
e:  10   train_loss:  781.8661391245657   time:  1.3028135299682617
e:  10   train_loss:  781.8661391245657   val_loss:  801.2632377674714   time:  1.4108781814575195
e:  11   train_loss:  845.9122531667746   time:  1.3009047508239746
e:  12   train_loss:  807.8808325649621   time:  1.3011093139648438
e:  13   train_loss:  872.1503879783163   time:  1.287630558013916
e:  14   train_loss:  848.5096434481837   time:  1.2748987674713135
e:  15   train_loss:  838.2717061920898   time:  1.3061614036560059
e:  15   train_loss:  838.2717061920898   val_loss:  802.4270470367331   time:  1.414705514907837
e:  16   train_loss:  839.978568934316   time:  1.3017611503601074
e:  17   train_loss:  810.5916557395054   time:  1.308351993560791
e:  18   train_loss:  838.2140225949975   time:  1.3451042175292969
e:  19   train_loss:  790.0254766306548   time:  1.321807861328125
e:  20   train_loss:  854.60208645025   time:  1.3214607238769531
e:  20   train_loss:  854.60208645025   val_loss:  752.275978765268   time:  1.4316296577453613
e:  21   train_loss:  833.1481905405103   time:  1.4406373500823975
e:  22   train_loss:  833.9898630990159   time:  1.3061504364013672
e:  23   train_loss:  831.0007932632584   time:  1.3043746948242188
e:  24   train_loss:  831.1329084093458   time:  1.3031809329986572
e:  25   train_loss:  828.503990627465   time:  1.3118033409118652
e:  25   train_loss:  828.503990627465   val_loss:  743.6443935613801   time:  1.4216499328613281
e:  26   train_loss:  826.8878676515145   time:  1.3069243431091309
e:  27   train_loss:  827.7018863440327   time:  1.3116810321807861
e:  28   train_loss:  822.8468271064912   time:  1.3058879375457764
e:  29   train_loss:  814.2214130970517   time:  1.310929298400879
e:  30   train_loss:  834.0651164297125   time:  1.311751127243042
e:  30   train_loss:  834.0651164297125   val_loss:  744.7887440167198   time:  1.5465672016143799
e:  31   train_loss:  835.6279210324345   time:  1.304405927658081
e:  32   train_loss:  845.8928017920927   time:  1.3059890270233154
e:  33   train_loss:  848.1165141019183   time:  1.310774564743042
e:  34   train_loss:  840.4105223482518   time:  1.314452886581421
e:  35   train_loss:  834.7623985325303   time:  1.3067498207092285
e:  35   train_loss:  834.7623985325303   val_loss:  744.2528705014364   time:  1.4153172969818115
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1059.4026207808167   time:  1.391289234161377
e:  0   train_loss:  1059.4026207808167   val_loss:  659.5872353203557   time:  1.4950799942016602
e:  1   train_loss:  962.6172572748991   time:  1.4336376190185547
e:  2   train_loss:  877.1512850945877   time:  1.4307200908660889
e:  3   train_loss:  832.1903448287738   time:  1.5417723655700684
e:  4   train_loss:  986.749502946383   time:  1.4322052001953125
e:  5   train_loss:  1024.5794891613173   time:  1.4356606006622314
e:  5   train_loss:  1024.5794891613173   val_loss:  580.7288953165893   time:  1.5383174419403076
e:  6   train_loss:  907.9552619535906   time:  1.4333643913269043
e:  7   train_loss:  910.5533358462443   time:  1.4325222969055176
e:  8   train_loss:  878.3692080066689   time:  1.4311981201171875
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  9   train_loss:  849.0891060468169   time:  1.4247987270355225
e:  10   train_loss:  907.2117375104108   time:  1.5672423839569092
e:  10   train_loss:  907.2117375104108   val_loss:  583.334343480942   time:  1.6702256202697754
e:  11   train_loss:  833.1081659963804   time:  1.429607629776001
e:  12   train_loss:  827.4701651004727   time:  1.4312357902526855
e:  13   train_loss:  790.5544654627432   time:  1.4252982139587402
e:  14   train_loss:  741.4103492700201   time:  1.4296669960021973
e:  15   train_loss:  732.6285345542778   time:  1.4307725429534912
e:  15   train_loss:  732.6285345542778   val_loss:  554.1972082402053   time:  1.5340471267700195
e:  16   train_loss:  740.0784670006626   time:  1.5720295906066895
e:  17   train_loss:  735.0195259849492   time:  1.4290399551391602
e:  18   train_loss:  777.1500963389085   time:  1.4263432025909424
e:  19   train_loss:  734.4270686574057   time:  1.430347204208374
e:  20   train_loss:  692.1193412751595   time:  1.389333963394165
e:  20   train_loss:  692.1193412751595   val_loss:  545.0553533006963   time:  1.4917082786560059
e:  21   train_loss:  684.8797174738329   time:  1.4241695404052734
e:  22   train_loss:  784.825117516832   time:  1.4282631874084473
e:  23   train_loss:  715.4932486785086   time:  1.5435986518859863
e:  24   train_loss:  654.8871777400234   time:  1.4301090240478516
e:  25   train_loss:  718.8552780849332   time:  1.4276325702667236
e:  25   train_loss:  718.8552780849332   val_loss:  559.4761346029532   time:  1.5303955078125
e:  26   train_loss:  678.3523381655391   time:  1.4265751838684082
e:  27   train_loss:  666.482247705291   time:  1.4292619228363037
e:  28   train_loss:  661.0408950720084   time:  1.4234328269958496
e:  29   train_loss:  627.7245816761924   time:  1.5521776676177979
e:  30   train_loss:  607.4944581856612   time:  1.4231023788452148
e:  30   train_loss:  607.4944581856612   val_loss:  549.788997387663   time:  1.5264339447021484
e:  31   train_loss:  577.2643978143702   time:  1.4345076084136963
e:  32   train_loss:  805.6289259520713   time:  1.43131422996521
e:  33   train_loss:  777.3190220860873   time:  1.4310717582702637
e:  34   train_loss:  665.926787815111   time:  1.429417371749878
e:  35   train_loss:  614.9602976031068   time:  1.5658466815948486
e:  35   train_loss:  614.9602976031068   val_loss:  594.3584409161796   time:  1.6691021919250488
e:  36   train_loss:  618.6649117580552   time:  1.4226300716400146
e:  37   train_loss:  638.8284755103372   time:  1.4318134784698486
e:  38   train_loss:  584.5231011523621   time:  1.4326183795928955
e:  39   train_loss:  590.1119200034974   time:  1.4287848472595215
e:  40   train_loss:  599.0163647796026   time:  1.418281078338623
e:  40   train_loss:  599.0163647796026   val_loss:  538.6078240257913   time:  1.5204002857208252
e:  41   train_loss:  576.5168384661612   time:  1.4137508869171143
e:  42   train_loss:  567.7866278379018   time:  1.5599017143249512
e:  43   train_loss:  570.9766221108413   time:  1.423591136932373
e:  44   train_loss:  577.6098846558757   time:  1.426365852355957
e:  45   train_loss:  548.8221388430865   time:  1.4224019050598145
e:  45   train_loss:  548.8221388430865   val_loss:  539.1131564830719   time:  1.5257539749145508
e:  46   train_loss:  548.163263981828   time:  1.4283266067504883
e:  47   train_loss:  545.4170090185339   time:  1.4311351776123047
e:  48   train_loss:  629.2399382491805   time:  1.5698001384735107
e:  49   train_loss:  607.7664447548461   time:  1.4257049560546875
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  50   train_loss:  580.418013370611   time:  1.473327875137329
e:  50   train_loss:  580.418013370611   val_loss:  552.647063077035   time:  1.5790903568267822
e:  51   train_loss:  552.4225918082379   time:  1.5208313465118408
e:  52   train_loss:  548.7699978182291   time:  1.5206036567687988
e:  53   train_loss:  670.7759636234335   time:  1.5275096893310547
e:  54   train_loss:  640.4297122158342   time:  1.5176262855529785
e:  55   train_loss:  594.1750382613249   time:  1.7354040145874023
e:  55   train_loss:  594.1750382613249   val_loss:  589.0393811185534   time:  1.8402824401855469
e:  56   train_loss:  562.063875102211   time:  1.5312340259552002
e:  57   train_loss:  591.5635323599549   time:  1.5186598300933838
e:  58   train_loss:  561.1030487493731   time:  1.5206873416900635
e:  59   train_loss:  541.7908558171971   time:  1.51601243019104
e:  60   train_loss:  557.8630185348369   time:  1.5010995864868164
e:  60   train_loss:  557.8630185348369   val_loss:  549.593961157217   time:  1.6056530475616455
e:  61   train_loss:  534.919559138747   time:  1.5017106533050537
e:  62   train_loss:  526.1917489983417   time:  1.7442755699157715
e:  63   train_loss:  529.4344985486592   time:  1.5298075675964355
e:  64   train_loss:  592.7886867102571   time:  1.514556646347046
e:  65   train_loss:  563.6781243483566   time:  1.5076398849487305
e:  65   train_loss:  563.6781243483566   val_loss:  557.324255836105   time:  1.6140990257263184
e:  66   train_loss:  531.5136868592423   time:  1.5203580856323242
e:  67   train_loss:  502.7975133847833   time:  1.5362780094146729
e:  68   train_loss:  543.0324570843959   time:  1.7345564365386963
e:  69   train_loss:  595.9548480805191   time:  1.5148603916168213
e:  70   train_loss:  530.5157781278558   time:  1.5177850723266602
e:  70   train_loss:  530.5157781278558   val_loss:  541.4095205662105   time:  1.622645616531372
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (0, 0, 22), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (0, 0, 22) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 22) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 22) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (0, 0, 22)
kwargs: {'config': {'batch_norm': False, 'ff_0': 17, 'ff_num_layers': 1, 'gnn_0': 281, 'gnn_dropout': 0.3279737195479306, 'gnn_num_layers': 1, 'hid_0': 593, 'hid_dropout_rate': 0.20414696252923964, 'in_dropout_rate': 0.4386659901915775, 'lr': 0.0015707457967605017, 'num_hid_layers': 3, 'optimizer': 'SGD', 'hid_1': 511, 'hid_2': 271, 'sgd_momentum': 0.6094637896459667}, 'budget': 729.0, 'working_directory': '.'}
result: {'loss': 725.9558329356537, 'n_epochs': 51.0, 'info': {'validation loss': 725.9558329356537}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 22) started
DEBUG:hpbandster:job_callback for (0, 0, 22) got condition
DEBUG:hpbandster:Only 1 run(s) for budget 729.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (0, 0, 22) finished
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: trying submitting job (1, 0, 0) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 0) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 0)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 0) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 0) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (1, 0, 0)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 162, 'ff_num_layers': 2, 'gnn_0': 391, 'gnn_dropout': 0.13982932286408628, 'gnn_num_layers': 2, 'hid_0': 1008, 'hid_dropout_rate': 0.10857706752752738, 'in_dropout_rate': 0.22148979768320165, 'lr': 0.0033913035717204132, 'num_hid_layers': 2, 'optimizer': 'SGD', 'ff_1': 203, 'gnn_1': 1274, 'hid_1': 1125, 'sgd_momentum': 0.9119437450801725}, 'budget': 81.0, 'working_directory': '.'}
FOLD:  0
DEBUG:hpbandster:DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
Model initialization done
Model training starts
e:  0   train_loss:  647.3260063621544   time:  1.584061622619629
e:  0   train_loss:  647.3260063621544   val_loss:  1466.8257301584888   time:  1.7015981674194336
e:  1   train_loss:  566.9663115789456   time:  1.5874881744384766
e:  2   train_loss:  531.1472500104297   time:  1.5710999965667725
e:  3   train_loss:  507.86636524651345   time:  1.5716290473937988
e:  4   train_loss:  506.3761883644266   time:  1.5623829364776611
e:  5   train_loss:  491.48663969761054   time:  1.5619630813598633
e:  5   train_loss:  491.48663969761054   val_loss:  1368.5735782781217   time:  1.6795909404754639
e:  6   train_loss:  482.7897837532357   time:  1.7715909481048584
e:  7   train_loss:  477.97446863808227   time:  1.5568687915802002
e:  8   train_loss:  461.40077020655434   time:  1.514031171798706
e:  9   train_loss:  453.83594500404456   time:  1.5670006275177002
e:  10   train_loss:  455.5525329102399   time:  1.616600751876831
e:  10   train_loss:  455.5525329102399   val_loss:  1423.6578977818735   time:  1.7348861694335938
e:  11   train_loss:  441.61149118354376   time:  1.627821445465088
e:  12   train_loss:  434.3358828673021   time:  1.6188623905181885
e:  13   train_loss:  421.6942197156551   time:  1.6035618782043457
e:  14   train_loss:  409.33498242374895   time:  1.6233444213867188
e:  15   train_loss:  405.1129027279419   time:  1.6147375106811523
e:  15   train_loss:  405.1129027279419   val_loss:  1409.6733299563339   time:  1.9566740989685059
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  16   train_loss:  416.4766911722127   time:  1.608849287033081
e:  17   train_loss:  400.01968871363243   time:  1.597459316253662
e:  18   train_loss:  378.2106646874043   time:  1.5813782215118408
e:  19   train_loss:  369.27906178571936   time:  1.620448350906372
e:  20   train_loss:  359.5955060869869   time:  1.574211835861206
e:  20   train_loss:  359.5955060869869   val_loss:  1432.9232624084752   time:  1.6911711692810059
e:  21   train_loss:  355.7113737740473   time:  1.5154948234558105
e:  22   train_loss:  354.6989091386524   time:  1.5088653564453125
e:  23   train_loss:  347.1224666630223   time:  1.506575345993042
e:  24   train_loss:  338.42077538761686   time:  1.5109729766845703
e:  25   train_loss:  328.2231428954441   time:  1.5069770812988281
e:  25   train_loss:  328.2231428954441   val_loss:  1460.1100574722748   time:  1.6232872009277344
e:  26   train_loss:  324.8612825201519   time:  1.612670660018921
e:  27   train_loss:  320.071469815181   time:  1.460571050643921
e:  28   train_loss:  309.6759142183589   time:  1.5095596313476562
e:  29   train_loss:  300.68042815691365   time:  1.5124201774597168
e:  30   train_loss:  303.8320827343012   time:  1.6089894771575928
e:  30   train_loss:  303.8320827343012   val_loss:  1481.2877515927983   time:  1.7261855602264404
e:  31   train_loss:  314.46639536470474   time:  1.5154225826263428
e:  32   train_loss:  328.9306183042701   time:  1.51228666305542
e:  33   train_loss:  355.3656531721453   time:  1.5134296417236328
e:  34   train_loss:  338.8645896114386   time:  1.511183738708496
e:  35   train_loss:  316.74146567621364   time:  1.5109879970550537
e:  35   train_loss:  316.74146567621364   val_loss:  1486.5988181147657   time:  1.7487595081329346
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1066.9361258432634   time:  1.6755695343017578
e:  0   train_loss:  1066.9361258432634   val_loss:  592.7852739802703   time:  1.7882351875305176
e:  1   train_loss:  963.5263703756724   time:  1.8752615451812744
e:  2   train_loss:  882.0085057111927   time:  1.6424057483673096
e:  3   train_loss:  959.4902301186418   time:  1.709808111190796
e:  4   train_loss:  975.964038787794   time:  1.725296974182129
e:  5   train_loss:  888.7851454179959   time:  1.7298119068145752
e:  5   train_loss:  888.7851454179959   val_loss:  4876705.189070481   time:  2.0356268882751465
e:  6   train_loss:  839.0880800513082   time:  1.665820598602295
e:  7   train_loss:  761.4402730888355   time:  1.643617868423462
e:  8   train_loss:  729.9061579732692   time:  1.6154165267944336
e:  9   train_loss:  687.3657934416902   time:  1.6001183986663818
e:  10   train_loss:  744.6745080801874   time:  1.6431479454040527
e:  10   train_loss:  744.6745080801874   val_loss:  494048.4045726013   time:  1.752816915512085
e:  11   train_loss:  853.6426119899486   time:  1.6456055641174316
e:  12   train_loss:  828.475685149016   time:  1.6447272300720215
e:  13   train_loss:  878.3198707459533   time:  1.800065279006958
e:  14   train_loss:  6850551139788.543   time:  1.646378517150879
e:  15   train_loss:  nan   time:  1.640918493270874
e:  15   train_loss:  nan   val_loss:  nan   time:  1.7498042583465576
e:  16   train_loss:  nan   time:  1.6392557621002197
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  17   train_loss:  nan   time:  1.6381025314331055
e:  18   train_loss:  nan   time:  1.6414721012115479
e:  19   train_loss:  nan   time:  1.7708659172058105
e:  20   train_loss:  nan   time:  1.6388590335845947
e:  20   train_loss:  nan   val_loss:  nan   time:  1.7482974529266357
e:  21   train_loss:  nan   time:  1.6344714164733887
e:  22   train_loss:  nan   time:  1.769967794418335
e:  23   train_loss:  nan   time:  1.652418851852417
e:  24   train_loss:  nan   time:  1.637704610824585
e:  25   train_loss:  nan   time:  1.772219181060791
e:  25   train_loss:  nan   val_loss:  nan   time:  1.8817026615142822
e:  26   train_loss:  nan   time:  1.6425118446350098
e:  27   train_loss:  nan   time:  1.6950976848602295
e:  28   train_loss:  nan   time:  1.6505367755889893
e:  29   train_loss:  nan   time:  1.67903470993042
e:  30   train_loss:  nan   time:  1.7406589984893799
e:  30   train_loss:  nan   val_loss:  nan   time:  1.8513448238372803
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  995.8470622256583   time:  1.6502010822296143
e:  0   train_loss:  995.8470622256583   val_loss:  2272667.1240500696   time:  1.7634005546569824
e:  1   train_loss:  1786.940159716118   time:  1.8062114715576172
e:  2   train_loss:  1.647125378237068e+84   time:  1.7081048488616943
e:  3   train_loss:  nan   time:  1.6438000202178955
e:  4   train_loss:  nan   time:  1.639524221420288
e:  5   train_loss:  nan   time:  1.6277086734771729
e:  5   train_loss:  nan   val_loss:  nan   time:  1.7410492897033691
e:  6   train_loss:  nan   time:  1.6401803493499756
e:  7   train_loss:  nan   time:  1.6352481842041016
e:  8   train_loss:  nan   time:  1.6264228820800781
e:  9   train_loss:  nan   time:  1.7788505554199219
e:  10   train_loss:  nan   time:  1.6963610649108887
e:  10   train_loss:  nan   val_loss:  nan   time:  1.8167307376861572
e:  11   train_loss:  nan   time:  1.629410982131958
e:  12   train_loss:  nan   time:  1.626662015914917
e:  13   train_loss:  nan   time:  1.5730481147766113
e:  14   train_loss:  nan   time:  1.6263294219970703
e:  15   train_loss:  nan   time:  1.7845113277435303
e:  15   train_loss:  nan   val_loss:  nan   time:  1.896618127822876
e:  16   train_loss:  nan   time:  1.623917579650879
e:  17   train_loss:  nan   time:  1.6271841526031494
e:  18   train_loss:  nan   time:  1.7393090724945068
e:  19   train_loss:  nan   time:  1.7316744327545166
e:  20   train_loss:  nan   time:  1.7045154571533203
e:  20   train_loss:  nan   val_loss:  nan   time:  1.8160786628723145
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  21   train_loss:  nan   time:  1.6817526817321777
e:  22   train_loss:  nan   time:  1.746272325515747
e:  23   train_loss:  nan   time:  1.6236340999603271
e:  24   train_loss:  nan   time:  1.6286866664886475
e:  25   train_loss:  nan   time:  1.6235299110412598
e:  25   train_loss:  nan   val_loss:  nan   time:  1.7362101078033447
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (1, 0, 0), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (1, 0, 0) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 0) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 0) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (1, 0, 0)
kwargs: {'config': {'batch_norm': True, 'ff_0': 162, 'ff_num_layers': 2, 'gnn_0': 391, 'gnn_dropout': 0.13982932286408628, 'gnn_num_layers': 2, 'hid_0': 1008, 'hid_dropout_rate': 0.10857706752752738, 'in_dropout_rate': 0.22148979768320165, 'lr': 0.0033913035717204132, 'num_hid_layers': 2, 'optimizer': 'SGD', 'ff_1': 203, 'gnn_1': 1274, 'hid_1': 1125, 'sgd_momentum': 0.9119437450801725}, 'budget': 81.0, 'working_directory': '.'}
result: None
exception: Traceback (most recent call last):
  File "/home/tasnina/.conda/envs/synergy/lib/python3.9/site-packages/hpbandster/core/worker.py", line 206, in start_computation
    result = {'result': self.compute(*args, config_id=id, **kwargs),
  File "/home/tasnina/Projects/SynVerse/code/models/encoder_mlp_worker.py", line 48, in compute
    best_model_state, val_losses[fold],_, req_epochs[fold] = self.runner.train_model(model, optimizer, criterion, train_loader,
  File "/home/tasnina/Projects/SynVerse/code/models/runner.py", line 237, in train_model
    return best_model, min_val_loss, train_loss, req_epochs
UnboundLocalError: local variable 'best_model' referenced before assignment


DEBUG:hpbandster:job_callback for (1, 0, 0) started
DEBUG:hpbandster:job_callback for (1, 0, 0) got condition
WARNING:hpbandster:job (1, 0, 0) failed with exception
Traceback (most recent call last):
  File "/home/tasnina/.conda/envs/synergy/lib/python3.9/site-packages/hpbandster/core/worker.py", line 206, in start_computation
    result = {'result': self.compute(*args, config_id=id, **kwargs),
  File "/home/tasnina/Projects/SynVerse/code/models/encoder_mlp_worker.py", line 48, in compute
    best_model_state, val_losses[fold],_, req_epochs[fold] = self.runner.train_model(model, optimizer, criterion, train_loader,
  File "/home/tasnina/Projects/SynVerse/code/models/runner.py", line 237, in train_model
    return best_model, min_val_loss, train_loss, req_epochs
UnboundLocalError: local variable 'best_model' referenced before assignment

DEBUG:hpbandster:Only 10 run(s) for budget 81.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (1, 0, 0) finished
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: trying submitting job (1, 0, 1) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 1) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 1)
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 1) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 1) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (1, 0, 1)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 26, 'ff_num_layers': 2, 'gnn_0': 230, 'gnn_dropout': 0.2687433749896259, 'gnn_num_layers': 2, 'hid_0': 128, 'hid_dropout_rate': 0.16439702726623406, 'in_dropout_rate': 0.35448831363775246, 'lr': 0.00013516628064470158, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 1057, 'gnn_1': 267, 'hid_1': 99, 'hid_2': 682}, 'budget': 81.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  704.674180343353   time:  1.342233657836914
e:  0   train_loss:  704.674180343353   val_loss:  1671.6876375284176   time:  1.426161289215088
e:  1   train_loss:  702.170900077042   time:  0.9909627437591553
e:  2   train_loss:  693.4668545672292   time:  1.1555070877075195
e:  3   train_loss:  676.467309075253   time:  1.238999605178833
e:  4   train_loss:  642.3819460177957   time:  1.2469663619995117
e:  5   train_loss:  603.4151703030501   time:  1.2471537590026855
e:  5   train_loss:  603.4151703030501   val_loss:  1387.165589503778   time:  1.3569226264953613
e:  6   train_loss:  600.0466480626083   time:  1.2470932006835938
e:  7   train_loss:  596.1076256761253   time:  1.2513642311096191
e:  8   train_loss:  596.134194551568   time:  1.2445659637451172
e:  9   train_loss:  594.5222834152646   time:  1.2434659004211426
e:  10   train_loss:  591.9721353537465   time:  1.2573039531707764
e:  10   train_loss:  591.9721353537465   val_loss:  1404.9877147246475   time:  1.3669791221618652
e:  11   train_loss:  591.2273073913126   time:  1.2450861930847168
e:  12   train_loss:  591.2639409730871   time:  1.256890058517456
e:  13   train_loss:  590.5178622491106   time:  1.3731791973114014
e:  14   train_loss:  589.684933551361   time:  1.2983002662658691
e:  15   train_loss:  589.2041532629188   time:  1.2980215549468994
e:  15   train_loss:  589.2041532629188   val_loss:  1410.513521141076   time:  1.4062151908874512
e:  16   train_loss:  588.8748949949179   time:  1.2895455360412598
e:  17   train_loss:  586.7804788459116   time:  1.3971176147460938
e:  18   train_loss:  585.3257921176428   time:  1.3292226791381836
e:  19   train_loss:  584.8771012374598   time:  1.33542799949646
e:  20   train_loss:  582.7332574923885   time:  1.314321756362915
e:  20   train_loss:  582.7332574923885   val_loss:  1407.4819758752783   time:  1.4572312831878662
e:  21   train_loss:  581.2138519854338   time:  1.4065327644348145
e:  22   train_loss:  579.5339930391372   time:  1.4857828617095947
e:  23   train_loss:  577.2050308099465   time:  1.3143951892852783
e:  24   train_loss:  573.9407391150335   time:  1.527090311050415
e:  25   train_loss:  570.7424829181932   time:  1.4572064876556396
e:  25   train_loss:  570.7424829181932   val_loss:  1398.452008041177   time:  1.5572023391723633
e:  26   train_loss:  565.2590468294553   time:  1.228867530822754
e:  27   train_loss:  559.3276608816574   time:  1.312455654144287
e:  28   train_loss:  553.2284992191877   time:  1.2929768562316895
e:  29   train_loss:  543.6720366506535   time:  1.3681232929229736
e:  30   train_loss:  535.6787213002681   time:  1.2970499992370605
e:  30   train_loss:  535.6787213002681   val_loss:  1411.651114147554   time:  1.4053430557250977
e:  31   train_loss:  527.8363823185879   time:  1.2462446689605713
e:  32   train_loss:  518.9329191099889   time:  1.2332944869995117
e:  33   train_loss:  508.3274580839826   time:  1.2377424240112305
e:  34   train_loss:  499.2771143638322   time:  1.245102882385254
e:  35   train_loss:  491.5164283343125   time:  1.368619441986084
e:  35   train_loss:  491.5164283343125   val_loss:  1400.5260727241418   time:  1.4689295291900635
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1073.9619499940475   time:  1.3597314357757568
e:  0   train_loss:  1073.9619499940475   val_loss:  624.8681642266498   time:  1.4615156650543213
e:  1   train_loss:  1077.2957070124223   time:  1.3563148975372314
e:  2   train_loss:  1062.1322101060105   time:  1.360370397567749
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  3   train_loss:  1015.9238817606133   time:  1.3633294105529785
e:  4   train_loss:  962.7861284766043   time:  1.4397592544555664
e:  5   train_loss:  901.9281146231956   time:  1.7238469123840332
e:  5   train_loss:  901.9281146231956   val_loss:  562.5546502722476   time:  1.8278913497924805
e:  6   train_loss:  927.170421977314   time:  1.4660000801086426
e:  7   train_loss:  917.8625738219447   time:  1.4854285717010498
e:  8   train_loss:  900.7096061396421   time:  1.4851579666137695
e:  9   train_loss:  900.1268549835715   time:  1.4859092235565186
e:  10   train_loss:  897.7857965219121   time:  1.4871959686279297
e:  10   train_loss:  897.7857965219121   val_loss:  536.5750025420765   time:  1.591254472732544
e:  11   train_loss:  903.1035395655365   time:  1.512923002243042
e:  12   train_loss:  895.9297127989634   time:  1.7294025421142578
e:  13   train_loss:  886.6732103225632   time:  1.3887200355529785
e:  14   train_loss:  910.6406511957389   time:  1.3642175197601318
e:  15   train_loss:  881.1960511804695   time:  1.37764310836792
e:  15   train_loss:  881.1960511804695   val_loss:  539.8972835619707   time:  1.481067180633545
e:  16   train_loss:  885.8475714399086   time:  1.3772175312042236
e:  17   train_loss:  878.3858421390323   time:  1.3650047779083252
e:  18   train_loss:  874.2095097799497   time:  1.3782696723937988
e:  19   train_loss:  830.2860324723698   time:  1.528496503829956
e:  20   train_loss:  810.0056978827299   time:  1.3749675750732422
e:  20   train_loss:  810.0056978827299   val_loss:  577.5134197736135   time:  1.4779722690582275
e:  21   train_loss:  788.69570585336   time:  1.3850486278533936
e:  22   train_loss:  757.6459050135486   time:  1.3962552547454834
e:  23   train_loss:  741.8536729591447   time:  1.375453233718872
e:  24   train_loss:  734.4987160414212   time:  1.3651342391967773
e:  25   train_loss:  707.3352022574139   time:  1.3901433944702148
e:  25   train_loss:  707.3352022574139   val_loss:  835.4543485980205   time:  1.629159927368164
e:  26   train_loss:  710.319682206062   time:  1.4606695175170898
e:  27   train_loss:  699.2941188299117   time:  1.3505005836486816
e:  28   train_loss:  679.9799877072368   time:  1.359400987625122
e:  29   train_loss:  674.5548257194632   time:  1.36134672164917
e:  30   train_loss:  682.6558619346965   time:  1.34877610206604
e:  30   train_loss:  682.6558619346965   val_loss:  903.5141053998238   time:  1.4520454406738281
e:  31   train_loss:  677.2003404438361   time:  1.4808056354522705
e:  32   train_loss:  664.367769053929   time:  1.3591291904449463
e:  33   train_loss:  671.9115581823094   time:  1.4123749732971191
e:  34   train_loss:  646.533228361698   time:  1.6174795627593994
e:  35   train_loss:  642.7721750007818   time:  1.481260061264038
e:  35   train_loss:  642.7721750007818   val_loss:  910.6836625997852   time:  1.5828425884246826
e:  36   train_loss:  631.6747178106971   time:  1.4021379947662354
e:  37   train_loss:  637.8677142706197   time:  1.496274709701538
e:  38   train_loss:  632.7259620059242   time:  1.3477940559387207
e:  39   train_loss:  620.5754573772897   time:  1.450047492980957
e:  40   train_loss:  621.5329426942932   time:  1.3631436824798584
e:  40   train_loss:  621.5329426942932   val_loss:  914.0583967879193   time:  1.4651820659637451
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1129.4613003122308   time:  1.3579819202423096
e:  0   train_loss:  1129.4613003122308   val_loss:  536.5967025692619   time:  1.4662504196166992
e:  1   train_loss:  1149.4786327791894   time:  1.3597533702850342
e:  2   train_loss:  1056.8294514204556   time:  1.3749268054962158
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  3   train_loss:  1052.6660671735779   time:  1.6930911540985107
e:  4   train_loss:  949.4862149451245   time:  1.4602670669555664
e:  5   train_loss:  894.1415190909786   time:  1.4562196731567383
e:  5   train_loss:  894.1415190909786   val_loss:  519.5373541145327   time:  1.5622694492340088
e:  6   train_loss:  1004.7906869860029   time:  1.4614989757537842
e:  7   train_loss:  878.9496945552469   time:  1.4597299098968506
e:  8   train_loss:  933.0464792833791   time:  1.4583988189697266
e:  9   train_loss:  902.4260653629111   time:  1.455714464187622
e:  10   train_loss:  869.8363141265106   time:  1.4876627922058105
e:  10   train_loss:  869.8363141265106   val_loss:  485.72986847833766   time:  1.8056049346923828
e:  11   train_loss:  882.9407903603465   time:  1.4434118270874023
e:  12   train_loss:  880.9972971714438   time:  1.4560036659240723
e:  13   train_loss:  872.4987618522214   time:  1.449366807937622
e:  14   train_loss:  878.3457683584434   time:  1.4469208717346191
e:  15   train_loss:  898.2730449480406   time:  1.4570868015289307
e:  15   train_loss:  898.2730449480406   val_loss:  485.8084854823514   time:  1.563687801361084
e:  16   train_loss:  855.918337823951   time:  1.4613242149353027
e:  17   train_loss:  844.5361292604715   time:  1.456047534942627
e:  18   train_loss:  849.6297440792091   time:  1.657015323638916
e:  19   train_loss:  943.7014470454419   time:  1.4598636627197266
e:  20   train_loss:  827.8581931832861   time:  1.4585638046264648
e:  20   train_loss:  827.8581931832861   val_loss:  488.2120613074601   time:  1.5650203227996826
e:  21   train_loss:  819.852642004033   time:  1.461677074432373
e:  22   train_loss:  799.7267067734393   time:  1.4598424434661865
e:  23   train_loss:  795.0232194082532   time:  1.4509515762329102
e:  24   train_loss:  765.4507533299895   time:  1.4583706855773926
e:  25   train_loss:  745.658926639413   time:  1.462099552154541
e:  25   train_loss:  745.658926639413   val_loss:  478.2255546163377   time:  1.5688555240631104
e:  26   train_loss:  724.711783612303   time:  1.6919174194335938
e:  27   train_loss:  706.0447748295416   time:  1.4615719318389893
e:  28   train_loss:  723.655145266086   time:  1.457179307937622
e:  29   train_loss:  693.8389986209521   time:  1.4582412242889404
e:  30   train_loss:  698.2657393041977   time:  1.449411392211914
e:  30   train_loss:  698.2657393041977   val_loss:  480.50974492662135   time:  1.5564818382263184
e:  31   train_loss:  711.0926715586343   time:  1.4551706314086914
e:  32   train_loss:  668.4408995137463   time:  1.459423303604126
e:  33   train_loss:  669.7421488978143   time:  1.6522979736328125
e:  34   train_loss:  680.5306527122551   time:  1.4480211734771729
e:  35   train_loss:  677.5457837222174   time:  1.4538331031799316
e:  35   train_loss:  677.5457837222174   val_loss:  470.64278184956623   time:  1.5603053569793701
e:  36   train_loss:  702.5766886803602   time:  1.459083080291748
e:  37   train_loss:  666.000962137336   time:  1.4571607112884521
e:  38   train_loss:  650.6196225365006   time:  1.459139108657837
e:  39   train_loss:  641.5869240233001   time:  1.4626860618591309
e:  40   train_loss:  639.5714298903519   time:  1.6767005920410156
e:  40   train_loss:  639.5714298903519   val_loss:  471.6083958543213   time:  1.7828562259674072
e:  41   train_loss:  636.153984629487   time:  1.4619998931884766
e:  42   train_loss:  646.5289816637919   time:  1.353137731552124
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  43   train_loss:  627.4063561575381   time:  1.4516427516937256
e:  44   train_loss:  654.464065040358   time:  1.4610726833343506
e:  45   train_loss:  661.544561115157   time:  1.4606876373291016
e:  45   train_loss:  661.544561115157   val_loss:  503.0701537265218   time:  1.5674657821655273
e:  46   train_loss:  639.3155683879132   time:  1.4578816890716553
e:  47   train_loss:  614.1714315707874   time:  1.6856913566589355
e:  48   train_loss:  617.6224679763659   time:  1.4593634605407715
e:  49   train_loss:  627.3119210867729   time:  1.4588747024536133
e:  50   train_loss:  611.1243751333401   time:  1.4570391178131104
e:  50   train_loss:  611.1243751333401   val_loss:  475.6835535716163   time:  1.564030647277832
e:  51   train_loss:  600.8150915059252   time:  1.459406852722168
e:  52   train_loss:  604.2115141105637   time:  1.4581308364868164
e:  53   train_loss:  600.5953077473089   time:  1.4488282203674316
e:  54   train_loss:  654.5004842962112   time:  1.4523932933807373
e:  55   train_loss:  620.9396603095566   time:  1.688147783279419
e:  55   train_loss:  620.9396603095566   val_loss:  499.3193323418477   time:  1.7946531772613525
e:  56   train_loss:  579.9140544651663   time:  1.4591867923736572
e:  57   train_loss:  604.8589894041805   time:  1.457594871520996
e:  58   train_loss:  597.096173366137   time:  1.4609582424163818
e:  59   train_loss:  629.5889244375173   time:  1.4590866565704346
e:  60   train_loss:  596.2733124505343   time:  1.458127737045288
e:  60   train_loss:  596.2733124505343   val_loss:  483.8932457474184   time:  1.5640838146209717
e:  61   train_loss:  599.0487025465901   time:  1.4593405723571777
e:  62   train_loss:  600.6937614830383   time:  1.666203498840332
e:  63   train_loss:  592.638223781531   time:  1.4582045078277588
e:  64   train_loss:  576.4291020355079   time:  1.4604313373565674
e:  65   train_loss:  604.0219107408225   time:  1.4608819484710693
e:  65   train_loss:  604.0219107408225   val_loss:  535.9844094657891   time:  1.5682525634765625
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  1001.4914997758032   time:  1.356619119644165
e:  0   train_loss:  1001.4914997758032   val_loss:  914.3171587139785   time:  1.4679720401763916
e:  1   train_loss:  995.5491303529386   time:  1.2948980331420898
e:  2   train_loss:  985.4575847617737   time:  1.5527610778808594
e:  3   train_loss:  964.6669211359986   time:  1.316823959350586
e:  4   train_loss:  927.7224400007761   time:  1.2917015552520752
e:  5   train_loss:  872.4971111979511   time:  1.3360817432403564
e:  5   train_loss:  872.4971111979511   val_loss:  756.2550727769977   time:  1.4466302394866943
e:  6   train_loss:  839.3850098430197   time:  1.3550212383270264
e:  7   train_loss:  834.1400360296727   time:  1.3529305458068848
e:  8   train_loss:  831.8442608312513   time:  1.33836030960083
e:  9   train_loss:  829.4379660867346   time:  1.3518471717834473
e:  10   train_loss:  829.9675825286929   time:  1.354227066040039
e:  10   train_loss:  829.9675825286929   val_loss:  741.1117804365156   time:  1.4652562141418457
e:  11   train_loss:  831.3688715100221   time:  1.351991891860962
e:  12   train_loss:  828.1906638003798   time:  1.3530473709106445
e:  13   train_loss:  826.9619094639833   time:  1.574615716934204
e:  14   train_loss:  822.9135874102333   time:  1.336249589920044
e:  15   train_loss:  821.5511372376001   time:  1.3614747524261475
e:  15   train_loss:  821.5511372376001   val_loss:  739.9399173199789   time:  1.5015358924865723
e:  16   train_loss:  817.9935920718951   time:  1.4271230697631836
e:  17   train_loss:  812.123732620586   time:  1.2338082790374756
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  18   train_loss:  812.6355799011221   time:  1.2350265979766846
e:  19   train_loss:  801.065576088861   time:  1.2381999492645264
e:  20   train_loss:  797.014381632483   time:  1.240511417388916
e:  20   train_loss:  797.014381632483   val_loss:  733.0602470756444   time:  1.3496909141540527
e:  21   train_loss:  787.6119397911434   time:  1.2378413677215576
e:  22   train_loss:  771.9930860676295   time:  1.2275769710540771
e:  23   train_loss:  758.2636697870847   time:  1.2368402481079102
e:  24   train_loss:  741.5634059360978   time:  1.238055944442749
e:  25   train_loss:  724.1841760427415   time:  1.2260253429412842
e:  25   train_loss:  724.1841760427415   val_loss:  731.0631696405782   time:  1.3345236778259277
e:  26   train_loss:  708.7728019661736   time:  1.368466854095459
e:  27   train_loss:  702.3669264960249   time:  1.237929105758667
e:  28   train_loss:  683.9867770019464   time:  1.2377710342407227
e:  29   train_loss:  671.63868523308   time:  1.2371227741241455
e:  30   train_loss:  666.3262882980523   time:  1.2395014762878418
e:  30   train_loss:  666.3262882980523   val_loss:  733.9758442709593   time:  1.3472702503204346
e:  31   train_loss:  653.6731143128129   time:  1.2257614135742188
e:  32   train_loss:  653.9481846469411   time:  1.223707675933838
e:  33   train_loss:  647.4420748313737   time:  1.237321138381958
e:  34   train_loss:  641.9447619792201   time:  1.2375869750976562
e:  35   train_loss:  633.5790477642969   time:  1.238051414489746
e:  35   train_loss:  633.5790477642969   val_loss:  724.0958863143193   time:  1.3463828563690186
e:  36   train_loss:  639.4377653719921   time:  1.236755609512329
e:  37   train_loss:  628.5026062788069   time:  1.2362897396087646
e:  38   train_loss:  626.3559437222353   time:  1.3669109344482422
e:  39   train_loss:  620.2833305873709   time:  1.212890625
e:  40   train_loss:  616.1077488708311   time:  1.2372498512268066
e:  40   train_loss:  616.1077488708311   val_loss:  714.710731050934   time:  1.3460490703582764
e:  41   train_loss:  609.9914484160171   time:  1.2368216514587402
e:  42   train_loss:  611.2530051649842   time:  1.234370470046997
e:  43   train_loss:  603.9500841818634   time:  1.2370798587799072
e:  44   train_loss:  601.2686711764829   time:  1.2400944232940674
e:  45   train_loss:  597.3367240325342   time:  1.2406866550445557
e:  45   train_loss:  597.3367240325342   val_loss:  710.4613468320862   time:  1.3502206802368164
e:  46   train_loss:  594.8567710153727   time:  1.239781379699707
e:  47   train_loss:  587.8548109365892   time:  1.2299530506134033
e:  48   train_loss:  581.6877080396139   time:  1.2414131164550781
e:  49   train_loss:  583.9075279702267   time:  1.248262643814087
e:  50   train_loss:  579.5013089885196   time:  1.2296483516693115
e:  50   train_loss:  579.5013089885196   val_loss:  708.5987976816559   time:  1.3386270999908447
e:  51   train_loss:  572.310463074505   time:  1.3673996925354004
e:  52   train_loss:  570.4705791184983   time:  1.2386271953582764
e:  53   train_loss:  567.5274466322329   time:  1.2389516830444336
e:  54   train_loss:  568.1741938092639   time:  1.2302844524383545
e:  55   train_loss:  566.4162397457989   time:  1.2278127670288086
e:  55   train_loss:  566.4162397457989   val_loss:  701.9280749639914   time:  1.3363347053527832
e:  56   train_loss:  567.2796563418749   time:  1.2400012016296387
e:  57   train_loss:  557.6848423907871   time:  1.2258093357086182
e:  58   train_loss:  558.7293802793074   time:  1.23759126663208
e:  59   train_loss:  553.2591587560357   time:  1.2397241592407227
e:  60   train_loss:  552.5586785838443   time:  1.23952317237854
e:  60   train_loss:  552.5586785838443   val_loss:  698.0449572268019   time:  1.3479077816009521
e:  61   train_loss:  550.3993218592916   time:  1.236901044845581
e:  62   train_loss:  549.9335130460257   time:  1.238464593887329
e:  63   train_loss:  548.903509483868   time:  1.3672730922698975
e:  64   train_loss:  552.4774601130124   time:  1.212789535522461
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  65   train_loss:  546.9291936986774   time:  1.2396774291992188
e:  65   train_loss:  546.9291936986774   val_loss:  699.4634190697257   time:  1.349086046218872
e:  66   train_loss:  545.1426163694609   time:  1.2387404441833496
e:  67   train_loss:  547.9359673389396   time:  1.23541259765625
e:  68   train_loss:  542.531909136165   time:  1.2358946800231934
e:  69   train_loss:  546.5241273378431   time:  1.2396984100341797
e:  70   train_loss:  542.6366466991451   time:  1.2421839237213135
e:  70   train_loss:  542.6366466991451   val_loss:  701.2707312781832   time:  1.351947546005249
e:  71   train_loss:  540.4126882700175   time:  1.2416059970855713
e:  72   train_loss:  540.2168358511469   time:  1.2291536331176758
e:  73   train_loss:  535.9010181991927   time:  1.2397119998931885
e:  74   train_loss:  539.0157461319636   time:  1.2401342391967773
e:  75   train_loss:  537.4293799994107   time:  1.2291676998138428
e:  75   train_loss:  537.4293799994107   val_loss:  703.9970045217055   time:  1.3376846313476562
e:  76   train_loss:  536.1171131194229   time:  1.3669307231903076
e:  77   train_loss:  533.1699809111462   time:  1.2382495403289795
e:  78   train_loss:  537.8727214270062   time:  1.226304292678833
e:  79   train_loss:  537.6079097938494   time:  1.2358262538909912
e:  80   train_loss:  535.991043566623   time:  1.2390897274017334
e:  80   train_loss:  535.991043566623   val_loss:  704.8438602825807   time:  1.3474388122558594
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1080.0652160918028   time:  1.3570678234100342
e:  0   train_loss:  1080.0652160918028   val_loss:  688.5009596461816   time:  1.4609127044677734
e:  1   train_loss:  1046.830905658438   time:  1.3555994033813477
e:  2   train_loss:  1048.6793580115086   time:  1.348229169845581
e:  3   train_loss:  1015.8317681812475   time:  1.3443045616149902
e:  4   train_loss:  941.5929749711935   time:  1.3652520179748535
e:  5   train_loss:  908.4405009560878   time:  1.4901750087738037
e:  5   train_loss:  908.4405009560878   val_loss:  566.2272168605135   time:  1.5926096439361572
e:  6   train_loss:  896.6156125613351   time:  1.353480577468872
e:  7   train_loss:  893.6083141498257   time:  1.342750072479248
e:  8   train_loss:  880.8827747728038   time:  1.3561303615570068
e:  9   train_loss:  897.8229634461094   time:  1.34419846534729
e:  10   train_loss:  899.9860737709329   time:  1.3534612655639648
e:  10   train_loss:  899.9860737709329   val_loss:  556.6379654485795   time:  1.4561586380004883
e:  11   train_loss:  872.6350153620618   time:  1.4915690422058105
e:  12   train_loss:  877.5627890876067   time:  1.3567025661468506
e:  13   train_loss:  881.4939658965648   time:  1.3554980754852295
e:  14   train_loss:  868.2840422583965   time:  1.3533446788787842
e:  15   train_loss:  875.5882550495456   time:  1.3461904525756836
e:  15   train_loss:  875.5882550495456   val_loss:  555.6998649384126   time:  1.4499006271362305
e:  16   train_loss:  873.7864232402015   time:  1.3616342544555664
e:  17   train_loss:  849.2451188967132   time:  1.3519434928894043
e:  18   train_loss:  837.8815629904037   time:  1.4604313373565674
e:  19   train_loss:  837.5776649500388   time:  1.3403797149658203
e:  20   train_loss:  803.7042738548279   time:  1.3565115928649902
e:  20   train_loss:  803.7042738548279   val_loss:  560.39583399951   time:  1.4590768814086914
e:  21   train_loss:  766.7138965640257   time:  1.3563690185546875
e:  22   train_loss:  750.4680821449349   time:  1.355818510055542
e:  23   train_loss:  736.840864038893   time:  1.3557772636413574
e:  24   train_loss:  717.9669688865613   time:  1.342273473739624
e:  25   train_loss:  702.5077211334276   time:  1.4902892112731934
e:  25   train_loss:  702.5077211334276   val_loss:  576.78434359702   time:  1.5929791927337646
e:  26   train_loss:  695.2459517733761   time:  1.3541948795318604
e:  27   train_loss:  690.0453492092261   time:  1.3562219142913818
e:  28   train_loss:  682.4157600206573   time:  1.351334571838379
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  29   train_loss:  674.4783965882748   time:  1.3558757305145264
e:  30   train_loss:  671.4318738552784   time:  1.356050729751587
e:  30   train_loss:  671.4318738552784   val_loss:  577.1198836250472   time:  1.4594035148620605
e:  31   train_loss:  674.0368793717457   time:  1.4939889907836914
e:  32   train_loss:  669.0241745428241   time:  1.3533430099487305
e:  33   train_loss:  665.4387549147207   time:  1.350606918334961
e:  34   train_loss:  650.1993798297727   time:  1.355954647064209
e:  35   train_loss:  646.4069533256528   time:  1.3476479053497314
e:  35   train_loss:  646.4069533256528   val_loss:  578.0930243282473   time:  1.4508061408996582
e:  36   train_loss:  654.4466895953568   time:  1.355288028717041
e:  37   train_loss:  651.4778920789078   time:  1.3522863388061523
e:  38   train_loss:  640.4742868831901   time:  1.4694619178771973
e:  39   train_loss:  628.7695472019525   time:  1.3501403331756592
e:  40   train_loss:  628.8832979364594   time:  1.348017692565918
e:  40   train_loss:  628.8832979364594   val_loss:  579.9391787164891   time:  1.4524729251861572
e:  41   train_loss:  627.1102367203212   time:  1.3488404750823975
e:  42   train_loss:  619.8210299699998   time:  1.3545632362365723
e:  43   train_loss:  627.3821227390591   time:  1.3438818454742432
e:  44   train_loss:  623.340267181788   time:  1.3515164852142334
e:  45   train_loss:  608.949655284655   time:  1.4912631511688232
e:  45   train_loss:  608.949655284655   val_loss:  589.4759453530335   time:  1.5947768688201904
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (1, 0, 1), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (1, 0, 1) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 1) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 1) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (1, 0, 1)
kwargs: {'config': {'batch_norm': False, 'ff_0': 26, 'ff_num_layers': 2, 'gnn_0': 230, 'gnn_dropout': 0.2687433749896259, 'gnn_num_layers': 2, 'hid_0': 128, 'hid_dropout_rate': 0.16439702726623406, 'in_dropout_rate': 0.35448831363775246, 'lr': 0.00013516628064470158, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 1057, 'gnn_1': 267, 'hid_1': 99, 'hid_2': 682}, 'budget': 81.0, 'working_directory': '.'}
result: {'loss': 729.625639212127, 'n_epochs': 53.2, 'info': {'validation loss': 729.625639212127}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 1) started
DEBUG:hpbandster:job_callback for (1, 0, 1) got condition
DEBUG:hpbandster:Only 11 run(s) for budget 81.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (1, 0, 1) finished
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: trying submitting job (1, 0, 2) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 2) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 2)
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 2) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 2) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (1, 0, 2)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 534, 'ff_num_layers': 2, 'gnn_0': 88, 'gnn_dropout': 0.3869701579061263, 'gnn_num_layers': 1, 'hid_0': 251, 'hid_dropout_rate': 0.004944144219669322, 'in_dropout_rate': 0.016557116620530277, 'lr': 1.348922129808559e-05, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 94, 'hid_1': 211, 'hid_2': 147}, 'budget': 81.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  704.9304887178772   time:  1.3461945056915283
e:  0   train_loss:  704.9304887178772   val_loss:  1672.774577613107   time:  1.4556691646575928
e:  1   train_loss:  704.2957145306407   time:  1.3222031593322754
e:  2   train_loss:  703.9832903457864   time:  1.3588511943817139
e:  3   train_loss:  703.4764632012616   time:  1.225057601928711
e:  4   train_loss:  703.3275452052251   time:  1.2368531227111816
e:  5   train_loss:  703.2143023620894   time:  1.2366843223571777
e:  5   train_loss:  703.2143023620894   val_loss:  1671.088964209159   time:  1.3435137271881104
e:  6   train_loss:  704.1228282674263   time:  1.3618402481079102
e:  7   train_loss:  703.8054503844785   time:  1.23323655128479
e:  8   train_loss:  702.7955279321116   time:  1.3267993927001953
e:  9   train_loss:  702.1260146986518   time:  1.2920842170715332
e:  10   train_loss:  701.8844849451112   time:  1.3300881385803223
e:  10   train_loss:  701.8844849451112   val_loss:  1668.0037524147358   time:  1.4396371841430664
e:  11   train_loss:  702.2504871152578   time:  1.2843503952026367
e:  12   train_loss:  700.9428608928308   time:  1.2842659950256348
e:  13   train_loss:  700.0805468010593   time:  1.2808845043182373
e:  14   train_loss:  699.9999543415856   time:  1.309309959411621
e:  15   train_loss:  699.7277253882706   time:  1.3029310703277588
e:  15   train_loss:  699.7277253882706   val_loss:  1662.3200057244858   time:  1.4096786975860596
e:  16   train_loss:  697.4913070752424   time:  1.2726836204528809
e:  17   train_loss:  696.2128080801788   time:  1.2892937660217285
e:  18   train_loss:  694.32601124923   time:  1.2358300685882568
e:  19   train_loss:  693.4552835304119   time:  1.35683012008667
e:  20   train_loss:  691.8407766608029   time:  1.239534854888916
e:  20   train_loss:  691.8407766608029   val_loss:  1651.7722723747236   time:  1.3459739685058594
e:  21   train_loss:  690.5181069585719   time:  1.229917287826538
e:  22   train_loss:  688.0618921998885   time:  1.2391178607940674
e:  23   train_loss:  685.6801005730423   time:  1.2379446029663086
e:  24   train_loss:  683.432474358295   time:  1.2428479194641113
e:  25   train_loss:  680.0461074693093   time:  1.2290599346160889
e:  25   train_loss:  680.0461074693093   val_loss:  1634.7105149833662   time:  1.3365628719329834
e:  26   train_loss:  678.6527350561727   time:  1.2355029582977295
e:  27   train_loss:  673.6561615743956   time:  1.2425239086151123
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  28   train_loss:  670.3563855106026   time:  1.246260643005371
e:  29   train_loss:  665.6078567528507   time:  1.3565077781677246
e:  30   train_loss:  662.3152419992188   time:  1.2402687072753906
e:  30   train_loss:  662.3152419992188   val_loss:  1609.6693030626682   time:  1.3477587699890137
e:  31   train_loss:  658.292503587785   time:  1.2405555248260498
e:  32   train_loss:  653.4749956800063   time:  1.2367677688598633
e:  33   train_loss:  648.0650808434858   time:  1.2275521755218506
e:  34   train_loss:  643.5668180531516   time:  1.2401914596557617
e:  35   train_loss:  636.0048548948349   time:  1.2288308143615723
e:  35   train_loss:  636.0048548948349   val_loss:  1575.1484985106283   time:  1.3354973793029785
e:  36   train_loss:  632.1304545039941   time:  1.2412116527557373
e:  37   train_loss:  624.6173070983268   time:  1.2280652523040771
e:  38   train_loss:  618.6110247519575   time:  1.3672726154327393
e:  39   train_loss:  613.6257063715758   time:  1.225050926208496
e:  40   train_loss:  606.047775236959   time:  1.221444845199585
e:  40   train_loss:  606.047775236959   val_loss:  1534.8822372650236   time:  1.3274767398834229
e:  41   train_loss:  599.0958220823583   time:  1.2198741436004639
e:  42   train_loss:  594.0031709041106   time:  1.2283358573913574
e:  43   train_loss:  587.893230946766   time:  1.2398035526275635
e:  44   train_loss:  583.1325639164486   time:  1.2267072200775146
e:  45   train_loss:  574.6405828579832   time:  1.2364108562469482
e:  45   train_loss:  574.6405828579832   val_loss:  1495.4513834823554   time:  1.343398094177246
e:  46   train_loss:  569.9404469199361   time:  1.3525631427764893
e:  47   train_loss:  564.3595257212153   time:  1.235283374786377
e:  48   train_loss:  561.952684256494   time:  1.23325514793396
e:  49   train_loss:  558.0654452757375   time:  1.239546775817871
e:  50   train_loss:  554.3764712148773   time:  1.2281856536865234
e:  50   train_loss:  554.3764712148773   val_loss:  1466.8829781305199   time:  1.3357439041137695
e:  51   train_loss:  551.4929350778225   time:  1.238295555114746
e:  52   train_loss:  548.157838408055   time:  1.238921880722046
e:  53   train_loss:  543.2840910886649   time:  1.240849256515503
e:  54   train_loss:  541.9292956577322   time:  1.2336962223052979
e:  55   train_loss:  538.1634946151433   time:  1.240769386291504
e:  55   train_loss:  538.1634946151433   val_loss:  1452.82034495381   time:  1.4773402214050293
e:  56   train_loss:  536.0508799015093   time:  1.221987009048462
e:  57   train_loss:  533.5660806445895   time:  1.2284018993377686
e:  58   train_loss:  533.115016712304   time:  1.2309417724609375
e:  59   train_loss:  532.0247760189517   time:  1.23885178565979
e:  60   train_loss:  528.963330968375   time:  1.2352581024169922
e:  60   train_loss:  528.963330968375   val_loss:  1450.139819697313   time:  1.342254400253296
e:  61   train_loss:  527.0174317926584   time:  1.2392840385437012
e:  62   train_loss:  524.6765715389338   time:  1.2395589351654053
e:  63   train_loss:  521.617237880853   time:  1.2321460247039795
e:  64   train_loss:  519.9333364405868   time:  1.224031925201416
e:  65   train_loss:  521.6176240728357   time:  1.2229862213134766
e:  65   train_loss:  521.6176240728357   val_loss:  1452.8224545641474   time:  1.3290653228759766
e:  66   train_loss:  517.155414207667   time:  1.3689429759979248
e:  67   train_loss:  513.0971779878635   time:  1.2269728183746338
e:  68   train_loss:  513.5829414543631   time:  1.2369575500488281
e:  69   train_loss:  512.8605739962491   time:  1.2412474155426025
e:  70   train_loss:  512.2969311766296   time:  1.2291994094848633
e:  70   train_loss:  512.2969311766296   val_loss:  1455.5889270305338   time:  1.3359620571136475
e:  71   train_loss:  509.56583602235673   time:  1.2272882461547852
e:  72   train_loss:  506.8304664763282   time:  1.2379512786865234
e:  73   train_loss:  505.35326911491757   time:  1.2372469902038574
e:  74   train_loss:  501.9700792940254   time:  1.2250890731811523
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  75   train_loss:  503.99294218789123   time:  1.2307608127593994
e:  75   train_loss:  503.99294218789123   val_loss:  1457.462409139865   time:  1.4679501056671143
e:  76   train_loss:  501.3993131522756   time:  1.2373573780059814
e:  77   train_loss:  501.80070670737325   time:  1.2369616031646729
e:  78   train_loss:  498.4457381205778   time:  1.2400894165039062
e:  79   train_loss:  499.07601378127845   time:  1.2254164218902588
e:  80   train_loss:  497.81144325450316   time:  1.239131212234497
e:  80   train_loss:  497.81144325450316   val_loss:  1464.0069568983897   time:  1.3457708358764648
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1090.9198386787318   time:  1.3482754230499268
e:  0   train_loss:  1090.9198386787318   val_loss:  627.8398348234529   time:  1.4482066631317139
e:  1   train_loss:  1085.440345026141   time:  1.3567988872528076
e:  2   train_loss:  1084.5135098540586   time:  1.4890508651733398
e:  3   train_loss:  1073.476120491185   time:  1.3549389839172363
e:  4   train_loss:  1085.864404873565   time:  1.3403441905975342
e:  5   train_loss:  1080.596532594092   time:  1.3477354049682617
e:  5   train_loss:  1080.596532594092   val_loss:  626.5846408966611   time:  1.448136806488037
e:  6   train_loss:  1079.3206686236908   time:  1.3403363227844238
e:  7   train_loss:  1090.5060516866322   time:  1.3539071083068848
e:  8   train_loss:  1077.4276022647934   time:  1.353559970855713
e:  9   train_loss:  1077.9780149647975   time:  1.4869587421417236
e:  10   train_loss:  1076.5221162874518   time:  1.352454662322998
e:  10   train_loss:  1076.5221162874518   val_loss:  624.0886733641576   time:  1.4530866146087646
e:  11   train_loss:  1070.4474940404948   time:  1.3533744812011719
e:  12   train_loss:  1080.0836517932703   time:  1.3416898250579834
e:  13   train_loss:  1069.8689348350836   time:  1.3598129749298096
e:  14   train_loss:  1080.6409168485948   time:  1.3534510135650635
e:  15   train_loss:  1080.2758656854537   time:  1.3511669635772705
e:  15   train_loss:  1080.2758656854537   val_loss:  618.8302234622942   time:  1.5756065845489502
e:  16   train_loss:  1064.3406015579947   time:  1.3550751209259033
e:  17   train_loss:  1060.137300714815   time:  1.354416847229004
e:  18   train_loss:  1068.0430644912874   time:  1.3485145568847656
e:  19   train_loss:  1066.297169138902   time:  1.3501691818237305
e:  20   train_loss:  1049.1661781255189   time:  1.3411767482757568
e:  20   train_loss:  1049.1661781255189   val_loss:  609.2779949643955   time:  1.4416875839233398
e:  21   train_loss:  1045.5559588614624   time:  1.4938290119171143
e:  22   train_loss:  1039.4163212429464   time:  1.3589367866516113
e:  23   train_loss:  1049.4193473346518   time:  1.3608744144439697
e:  24   train_loss:  1037.6548999273202   time:  1.3506779670715332
e:  25   train_loss:  1045.7168768169995   time:  1.3427655696868896
e:  25   train_loss:  1045.7168768169995   val_loss:  594.2849771055475   time:  1.4434750080108643
e:  26   train_loss:  1019.8271305739584   time:  1.3543190956115723
e:  27   train_loss:  1020.679837424874   time:  1.3344314098358154
e:  28   train_loss:  994.4703611031675   time:  1.4538524150848389
e:  29   train_loss:  991.7946380234688   time:  1.352759599685669
e:  30   train_loss:  967.4496573989446   time:  1.3553693294525146
e:  30   train_loss:  967.4496573989446   val_loss:  574.4862880646513   time:  1.4556281566619873
e:  31   train_loss:  967.1144499962855   time:  1.3538548946380615
e:  32   train_loss:  951.7416785928859   time:  1.358816146850586
e:  33   train_loss:  930.6952039480578   time:  1.3518741130828857
e:  34   train_loss:  924.1872516127423   time:  1.3392863273620605
e:  35   train_loss:  911.2359097487495   time:  1.4905986785888672
e:  35   train_loss:  911.2359097487495   val_loss:  554.8541758090363   time:  1.5910720825195312
e:  36   train_loss:  903.497899938217   time:  1.3510990142822266
e:  37   train_loss:  890.1330031682496   time:  1.3535923957824707
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  38   train_loss:  868.1580742925693   time:  1.3530466556549072
e:  39   train_loss:  874.5200916296432   time:  1.352281093597412
e:  40   train_loss:  834.2895053491895   time:  1.3535358905792236
e:  40   train_loss:  834.2895053491895   val_loss:  542.2667135922388   time:  1.4545674324035645
e:  41   train_loss:  820.4395475429652   time:  1.493560791015625
e:  42   train_loss:  822.5196600332615   time:  1.3513908386230469
e:  43   train_loss:  805.9595997762749   time:  1.3488175868988037
e:  44   train_loss:  780.6871265274594   time:  1.351905107498169
e:  45   train_loss:  769.1245983266953   time:  1.3456406593322754
e:  45   train_loss:  769.1245983266953   val_loss:  541.3252653068276   time:  1.4462177753448486
e:  46   train_loss:  762.3718222639541   time:  1.3532326221466064
e:  47   train_loss:  749.9172710338067   time:  1.3550443649291992
e:  48   train_loss:  748.1718280216272   time:  1.46347975730896
e:  49   train_loss:  733.1356530590459   time:  1.336946725845337
e:  50   train_loss:  734.399268960726   time:  1.345855474472046
e:  50   train_loss:  734.399268960726   val_loss:  545.8916558582437   time:  1.445908546447754
e:  51   train_loss:  727.5303341130714   time:  1.3468658924102783
e:  52   train_loss:  712.2277987502943   time:  1.351003885269165
e:  53   train_loss:  716.8890775620571   time:  1.3402817249298096
e:  54   train_loss:  711.119342923967   time:  1.3473057746887207
e:  55   train_loss:  709.302519189302   time:  1.4888076782226562
e:  55   train_loss:  709.302519189302   val_loss:  547.4013348136637   time:  1.5895614624023438
e:  56   train_loss:  706.3614385687715   time:  1.3522050380706787
e:  57   train_loss:  691.2580567820578   time:  1.349578857421875
e:  58   train_loss:  700.4181263879464   time:  1.3431177139282227
e:  59   train_loss:  686.5766160743815   time:  1.3390793800354004
e:  60   train_loss:  675.7432926938886   time:  1.3542966842651367
e:  60   train_loss:  675.7432926938886   val_loss:  547.0881308216461   time:  1.5851681232452393
e:  61   train_loss:  687.0381736193946   time:  1.3493695259094238
e:  62   train_loss:  675.8863578488931   time:  1.3390014171600342
e:  63   train_loss:  674.3036215535785   time:  1.347543478012085
e:  64   train_loss:  671.105381280797   time:  1.3557586669921875
e:  65   train_loss:  667.3347520632875   time:  1.3408238887786865
e:  65   train_loss:  667.3347520632875   val_loss:  547.2285412514053   time:  1.4409105777740479
e:  66   train_loss:  668.0250755029092   time:  1.482884168624878
e:  67   train_loss:  672.7569145043003   time:  1.3386380672454834
e:  68   train_loss:  663.2393540288006   time:  1.3525536060333252
e:  69   train_loss:  669.6541687856605   time:  1.3490262031555176
e:  70   train_loss:  666.0722621084253   time:  1.3432157039642334
e:  70   train_loss:  666.0722621084253   val_loss:  547.7062118786932   time:  1.4433777332305908
e:  71   train_loss:  663.3446337680735   time:  1.33024001121521
e:  72   train_loss:  659.3727943592949   time:  1.3483870029449463
e:  73   train_loss:  653.6169061589189   time:  1.4874138832092285
e:  74   train_loss:  657.2343457215535   time:  1.343010663986206
e:  75   train_loss:  653.4616502460669   time:  1.3521311283111572
e:  75   train_loss:  653.4616502460669   val_loss:  548.2939586419224   time:  1.4531264305114746
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1087.6480170634143   time:  1.3381454944610596
e:  0   train_loss:  1087.6480170634143   val_loss:  539.9739319051861   time:  1.4410409927368164
e:  1   train_loss:  1090.4701442686178   time:  1.3234682083129883
e:  2   train_loss:  1096.6230394310269   time:  1.3300869464874268
e:  3   train_loss:  1096.1916365385712   time:  1.47171950340271
e:  4   train_loss:  1084.011324076044   time:  1.3353960514068604
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  5   train_loss:  1058.0937659880376   time:  1.4463884830474854
e:  5   train_loss:  1058.0937659880376   val_loss:  538.9530867649952   time:  1.552255630493164
e:  6   train_loss:  1061.348082897725   time:  1.4509389400482178
e:  7   train_loss:  1110.5375068199655   time:  1.4514353275299072
e:  8   train_loss:  1162.7661436996152   time:  1.4493391513824463
e:  9   train_loss:  1113.1483599931878   time:  1.4521994590759277
e:  10   train_loss:  1083.3383731731915   time:  1.4484200477600098
e:  10   train_loss:  1083.3383731731915   val_loss:  536.9330321634383   time:  1.553548812866211
e:  11   train_loss:  1080.458043683667   time:  1.4496235847473145
e:  12   train_loss:  1078.0427012534046   time:  1.677727222442627
e:  13   train_loss:  1138.5295509260432   time:  1.4464085102081299
e:  14   train_loss:  1096.6054782523775   time:  1.4464635848999023
e:  15   train_loss:  1074.170832454217   time:  1.4394066333770752
e:  15   train_loss:  1074.170832454217   val_loss:  533.1147413278723   time:  1.5435528755187988
e:  16   train_loss:  1064.381425112951   time:  1.3383407592773438
e:  17   train_loss:  1069.0775243351543   time:  1.324721097946167
e:  18   train_loss:  1056.5352240633097   time:  1.334855556488037
e:  19   train_loss:  1074.137260105563   time:  1.474987268447876
e:  20   train_loss:  1079.963119066559   time:  1.3383779525756836
e:  20   train_loss:  1079.963119066559   val_loss:  526.7556363963216   time:  1.4414007663726807
e:  21   train_loss:  1047.5841446182071   time:  1.3396458625793457
e:  22   train_loss:  1028.7823058134816   time:  1.3351051807403564
e:  23   train_loss:  1034.3399913561007   time:  1.3347346782684326
e:  24   train_loss:  1118.0627286163442   time:  1.337517499923706
e:  25   train_loss:  1010.7110211133095   time:  1.3251008987426758
e:  25   train_loss:  1010.7110211133095   val_loss:  517.1371363348437   time:  1.4282562732696533
e:  26   train_loss:  1033.323954683207   time:  1.3485596179962158
e:  27   train_loss:  1002.1311856101306   time:  1.4745845794677734
e:  28   train_loss:  1010.7366706648731   time:  1.335752010345459
e:  29   train_loss:  971.7094364991715   time:  1.3325490951538086
e:  30   train_loss:  986.0213480907782   time:  1.3245735168457031
e:  30   train_loss:  986.0213480907782   val_loss:  505.5333965995319   time:  1.4271759986877441
e:  31   train_loss:  968.224895320945   time:  1.3391728401184082
e:  32   train_loss:  948.0154275068201   time:  1.3374016284942627
e:  33   train_loss:  934.6398978785995   time:  1.28660249710083
e:  34   train_loss:  946.6453234645531   time:  1.3484230041503906
e:  35   train_loss:  923.4035205448511   time:  1.4806950092315674
e:  35   train_loss:  923.4035205448511   val_loss:  494.7781260036598   time:  1.5827860832214355
e:  36   train_loss:  898.8309627386905   time:  1.3300378322601318
e:  37   train_loss:  947.7429396624905   time:  1.3045220375061035
e:  38   train_loss:  892.4100156828835   time:  1.3172674179077148
e:  39   train_loss:  856.1042894581271   time:  1.322709560394287
e:  40   train_loss:  832.5674498225545   time:  1.322096824645996
e:  40   train_loss:  832.5674498225545   val_loss:  489.26204036246054   time:  1.4254605770111084
e:  41   train_loss:  873.5102363729179   time:  1.4472875595092773
e:  42   train_loss:  854.2804084905613   time:  1.3331923484802246
e:  43   train_loss:  801.4922750991059   time:  1.338649034500122
e:  44   train_loss:  794.4135555749679   time:  1.333883285522461
e:  45   train_loss:  792.4714377390959   time:  1.3228199481964111
e:  45   train_loss:  792.4714377390959   val_loss:  490.789936482916   time:  1.4259591102600098
e:  46   train_loss:  784.317689607076   time:  1.3391599655151367
e:  47   train_loss:  768.1901176352358   time:  1.3238677978515625
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  48   train_loss:  795.4523533281944   time:  1.3377881050109863
e:  49   train_loss:  749.6945988482935   time:  1.3375978469848633
e:  50   train_loss:  749.8348769573422   time:  1.4636151790618896
e:  50   train_loss:  749.8348769573422   val_loss:  496.8280010591569   time:  1.5660650730133057
e:  51   train_loss:  748.8489999057024   time:  1.323878526687622
e:  52   train_loss:  788.9874631823807   time:  1.3414199352264404
e:  53   train_loss:  771.0702375832417   time:  1.4280741214752197
e:  54   train_loss:  795.4255389551823   time:  1.4056313037872314
e:  55   train_loss:  740.55294104762   time:  1.4050517082214355
e:  55   train_loss:  740.55294104762   val_loss:  500.78669630573955   time:  1.5091955661773682
e:  56   train_loss:  739.9308966974282   time:  1.3763206005096436
e:  57   train_loss:  721.7106925056848   time:  1.532609224319458
e:  58   train_loss:  714.1389961850361   time:  1.3602006435394287
e:  59   train_loss:  721.9338228830711   time:  1.3484382629394531
e:  60   train_loss:  719.080942555825   time:  1.3912522792816162
e:  60   train_loss:  719.080942555825   val_loss:  502.71973808984575   time:  1.4958629608154297
e:  61   train_loss:  709.9858678389355   time:  1.3541221618652344
e:  62   train_loss:  718.5254957177899   time:  1.3611364364624023
e:  63   train_loss:  734.7639259491729   time:  1.3604717254638672
e:  64   train_loss:  760.9635987490346   time:  1.367044448852539
e:  65   train_loss:  714.4721975751434   time:  1.5348126888275146
e:  65   train_loss:  714.4721975751434   val_loss:  500.8927904381647   time:  1.6387269496917725
e:  66   train_loss:  703.4589080058087   time:  1.3732001781463623
e:  67   train_loss:  722.6423142509086   time:  1.3752171993255615
e:  68   train_loss:  727.5665749597065   time:  1.366196632385254
e:  69   train_loss:  697.6944067637602   time:  1.362982988357544
e:  70   train_loss:  684.4593902588636   time:  1.361342430114746
e:  70   train_loss:  684.4593902588636   val_loss:  500.42360905032103   time:  1.4639723300933838
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  998.9157825213841   time:  1.2808353900909424
e:  0   train_loss:  998.9157825213841   val_loss:  916.99999588423   time:  1.3879063129425049
e:  1   train_loss:  999.6894164627035   time:  1.4439823627471924
e:  2   train_loss:  997.5388210577809   time:  1.2409331798553467
e:  3   train_loss:  997.3674142354998   time:  1.2351055145263672
e:  4   train_loss:  996.6037474309542   time:  1.244163990020752
e:  5   train_loss:  1000.3529288988937   time:  1.2433085441589355
e:  5   train_loss:  1000.3529288988937   val_loss:  915.5269935293343   time:  1.3521790504455566
e:  6   train_loss:  996.566214729525   time:  1.2403359413146973
e:  7   train_loss:  997.2190777362837   time:  1.2635812759399414
e:  8   train_loss:  997.3842367986058   time:  1.2407505512237549
e:  9   train_loss:  995.4382611156732   time:  1.2344927787780762
e:  10   train_loss:  995.06198463715   time:  1.2587969303131104
e:  10   train_loss:  995.06198463715   val_loss:  913.2112831145961   time:  1.5512478351593018
e:  11   train_loss:  997.0146814483672   time:  1.2448170185089111
e:  12   train_loss:  991.3486686688336   time:  1.2519590854644775
e:  13   train_loss:  992.7648546890314   time:  1.2751579284667969
e:  14   train_loss:  992.3913614232083   time:  1.2625064849853516
e:  15   train_loss:  989.3211113687861   time:  1.241581916809082
e:  15   train_loss:  989.3211113687861   val_loss:  908.8373326902988   time:  1.3502051830291748
e:  16   train_loss:  987.5217683625104   time:  1.2326748371124268
e:  17   train_loss:  987.4196489953321   time:  1.2727389335632324
e:  18   train_loss:  986.2340002009134   time:  1.2369487285614014
e:  19   train_loss:  984.9319413228977   time:  1.262547492980957
e:  20   train_loss:  980.1904333914237   time:  1.2512922286987305
e:  20   train_loss:  980.1904333914237   val_loss:  901.4843187795564   time:  1.357863187789917
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  21   train_loss:  981.7193717377306   time:  1.4734766483306885
e:  22   train_loss:  977.9448365384786   time:  1.2423934936523438
e:  23   train_loss:  974.6378232095492   time:  1.2486088275909424
e:  24   train_loss:  970.9432760233898   time:  1.247422695159912
e:  25   train_loss:  968.2711035627839   time:  1.2667946815490723
e:  25   train_loss:  968.2711035627839   val_loss:  889.7968638227985   time:  1.3743727207183838
e:  26   train_loss:  966.7787139566598   time:  1.259946346282959
e:  27   train_loss:  959.1607383714538   time:  1.2614061832427979
e:  28   train_loss:  956.3957956491168   time:  1.2857913970947266
e:  29   train_loss:  950.3279827988378   time:  1.2598748207092285
e:  30   train_loss:  947.2948930738953   time:  1.265831708908081
e:  30   train_loss:  947.2948930738953   val_loss:  872.7015790618952   time:  1.3737130165100098
e:  31   train_loss:  941.1180203624253   time:  1.2656466960906982
e:  32   train_loss:  935.0823334208825   time:  1.243135929107666
e:  33   train_loss:  926.5964139786201   time:  1.4171819686889648
e:  34   train_loss:  922.0736081005456   time:  1.2571325302124023
e:  35   train_loss:  914.9810645253807   time:  1.2777900695800781
e:  35   train_loss:  914.9810645253807   val_loss:  849.6575631244498   time:  1.3862755298614502
e:  36   train_loss:  904.6043568428576   time:  1.2747538089752197
e:  37   train_loss:  897.4610501982899   time:  1.2937426567077637
e:  38   train_loss:  887.4222827347204   time:  1.281656265258789
e:  39   train_loss:  876.3411109577773   time:  1.2620301246643066
e:  40   train_loss:  869.0813844028143   time:  1.2629766464233398
e:  40   train_loss:  869.0813844028143   val_loss:  822.7462759464171   time:  1.3714773654937744
e:  41   train_loss:  860.0490873562594   time:  1.2439861297607422
e:  42   train_loss:  850.7011113614511   time:  1.2626798152923584
e:  43   train_loss:  836.4943306349013   time:  1.2623076438903809
e:  44   train_loss:  829.3091761657245   time:  1.2759552001953125
e:  45   train_loss:  813.3198574863985   time:  1.2708263397216797
e:  45   train_loss:  813.3198574863985   val_loss:  796.3643969564836   time:  1.5294702053070068
e:  46   train_loss:  803.7689222244614   time:  1.2399706840515137
e:  47   train_loss:  802.4250309532085   time:  1.2526328563690186
e:  48   train_loss:  786.0412053398127   time:  1.2849199771881104
e:  49   train_loss:  782.8387529990221   time:  1.2716126441955566
e:  50   train_loss:  765.7253843574906   time:  1.2753844261169434
e:  50   train_loss:  765.7253843574906   val_loss:  774.1537648978247   time:  1.3824481964111328
e:  51   train_loss:  751.2510214489328   time:  1.289893627166748
e:  52   train_loss:  754.8384063908195   time:  1.240649938583374
e:  53   train_loss:  733.8419744807479   time:  1.2726194858551025
e:  54   train_loss:  733.0535232411356   time:  1.2426037788391113
e:  55   train_loss:  725.7662698635698   time:  1.43161940574646
e:  55   train_loss:  725.7662698635698   val_loss:  758.7781769811905   time:  1.5385050773620605
e:  56   train_loss:  708.0864196673907   time:  1.216768741607666
e:  57   train_loss:  706.1320062642004   time:  1.2593424320220947
e:  58   train_loss:  703.2815559925036   time:  1.240607500076294
e:  59   train_loss:  694.3560313559847   time:  1.0820775032043457
e:  60   train_loss:  694.9667931884932   time:  1.0046963691711426
e:  60   train_loss:  694.9667931884932   val_loss:  751.761256367636   time:  1.0880098342895508
e:  61   train_loss:  686.9187926952646   time:  1.1947932243347168
e:  62   train_loss:  681.2849285723388   time:  1.2666385173797607
e:  63   train_loss:  679.2313814285444   time:  1.2674407958984375
e:  64   train_loss:  676.9648542392531   time:  1.4241724014282227
e:  65   train_loss:  666.6804553113525   time:  1.260692834854126
e:  65   train_loss:  666.6804553113525   val_loss:  748.5241523930166   time:  1.3676400184631348
e:  66   train_loss:  666.2778124590661   time:  1.2463068962097168
e:  67   train_loss:  663.59780367432   time:  1.2737421989440918
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  68   train_loss:  660.7878404591709   time:  1.2610995769500732
e:  69   train_loss:  657.503048553832   time:  1.2619800567626953
e:  70   train_loss:  655.3502151702664   time:  1.272230863571167
e:  70   train_loss:  655.3502151702664   val_loss:  746.7809826635107   time:  1.380286693572998
e:  71   train_loss:  655.6503556813587   time:  1.2709178924560547
e:  72   train_loss:  654.8115871821793   time:  1.2383825778961182
e:  73   train_loss:  651.9275410069652   time:  1.4266386032104492
e:  74   train_loss:  648.3432517481982   time:  1.2804157733917236
e:  75   train_loss:  644.6900573914779   time:  1.2700684070587158
e:  75   train_loss:  644.6900573914779   val_loss:  747.5784513512374   time:  1.3782081604003906
e:  76   train_loss:  639.0869446176122   time:  1.2554006576538086
e:  77   train_loss:  639.5088316512254   time:  1.2796685695648193
e:  78   train_loss:  638.0842251945238   time:  1.247755527496338
e:  79   train_loss:  632.3263720944816   time:  1.2640538215637207
e:  80   train_loss:  632.801213437979   time:  1.2575006484985352
e:  80   train_loss:  632.801213437979   val_loss:  748.1545540669982   time:  1.3648591041564941
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1077.875194765584   time:  1.3886432647705078
e:  0   train_loss:  1077.875194765584   val_loss:  692.2728430253467   time:  1.489781141281128
e:  1   train_loss:  1093.5888516511106   time:  1.3889498710632324
e:  2   train_loss:  1087.6287164951634   time:  1.5233144760131836
e:  3   train_loss:  1066.1243737794605   time:  1.3993453979492188
e:  4   train_loss:  1061.763787348283   time:  1.389070749282837
e:  5   train_loss:  1071.207213830079   time:  1.4104950428009033
e:  5   train_loss:  1071.207213830079   val_loss:  690.7701858409704   time:  1.5120656490325928
e:  6   train_loss:  1069.5173201743721   time:  1.3748955726623535
e:  7   train_loss:  1090.4637683027374   time:  1.378962516784668
e:  8   train_loss:  1062.5805777195815   time:  1.5370783805847168
e:  9   train_loss:  1076.7561264691453   time:  1.3649866580963135
e:  10   train_loss:  1063.1521643749975   time:  1.3675074577331543
e:  10   train_loss:  1063.1521643749975   val_loss:  687.938930484394   time:  1.4693477153778076
e:  11   train_loss:  1090.7628470250145   time:  1.3908908367156982
e:  12   train_loss:  1050.6073443035903   time:  1.3912112712860107
e:  13   train_loss:  1070.2544970885265   time:  1.3612496852874756
e:  14   train_loss:  1081.4354174443356   time:  1.3868720531463623
e:  15   train_loss:  1074.142380188939   time:  1.5381832122802734
e:  15   train_loss:  1074.142380188939   val_loss:  682.6796641737175   time:  1.6406810283660889
e:  16   train_loss:  1047.1713240501235   time:  1.3969407081604004
e:  17   train_loss:  1053.2717506858528   time:  1.3793249130249023
e:  18   train_loss:  1073.2331279717619   time:  1.3747658729553223
e:  19   train_loss:  1046.5647130424663   time:  1.4018323421478271
e:  20   train_loss:  1065.403382013069   time:  1.3664569854736328
e:  20   train_loss:  1065.403382013069   val_loss:  673.3385926419388   time:  1.467536211013794
e:  21   train_loss:  1031.8978124347302   time:  1.3952603340148926
e:  22   train_loss:  1061.2837963494505   time:  1.5351033210754395
e:  23   train_loss:  1025.6819704235334   time:  1.3788044452667236
e:  24   train_loss:  1030.4319119972158   time:  1.3714313507080078
e:  25   train_loss:  1001.4382057354728   time:  1.3790104389190674
e:  25   train_loss:  1001.4382057354728   val_loss:  658.8647335359303   time:  1.4802725315093994
e:  26   train_loss:  1014.5583522279578   time:  1.3996448516845703
e:  27   train_loss:  1002.404809430702   time:  1.363828420639038
e:  28   train_loss:  1001.1076525318537   time:  1.3762986660003662
e:  29   train_loss:  978.3429771540092   time:  1.5073418617248535
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  30   train_loss:  983.3080819487459   time:  1.3907749652862549
e:  30   train_loss:  983.3080819487459   val_loss:  638.9222978042081   time:  1.4930250644683838
e:  31   train_loss:  953.0086193263456   time:  1.3814187049865723
e:  32   train_loss:  973.9382126717088   time:  1.3788199424743652
e:  33   train_loss:  954.357918642399   time:  1.423811674118042
e:  34   train_loss:  916.8817151182619   time:  1.352107048034668
e:  35   train_loss:  925.0842181625028   time:  1.398855447769165
e:  35   train_loss:  925.0842181625028   val_loss:  615.1188797788758   time:  1.643522024154663
e:  36   train_loss:  890.0728964468415   time:  1.3843843936920166
e:  37   train_loss:  896.3775708734609   time:  1.3682725429534912
e:  38   train_loss:  867.6713541516955   time:  1.3762309551239014
e:  39   train_loss:  882.8629350941578   time:  1.3641457557678223
e:  40   train_loss:  839.5775206142376   time:  1.3615784645080566
e:  40   train_loss:  839.5775206142376   val_loss:  592.8337885112696   time:  1.4639630317687988
e:  41   train_loss:  840.1223136910276   time:  1.5425207614898682
e:  42   train_loss:  826.8422020278327   time:  1.384101390838623
e:  43   train_loss:  798.6036836355927   time:  1.369596004486084
e:  44   train_loss:  816.5663944842167   time:  1.3977940082550049
e:  45   train_loss:  775.9493649176052   time:  1.3719375133514404
e:  45   train_loss:  775.9493649176052   val_loss:  577.3436878088525   time:  1.4741339683532715
e:  46   train_loss:  778.8139977840156   time:  1.3783044815063477
e:  47   train_loss:  770.4727753749276   time:  1.569411039352417
e:  48   train_loss:  759.8060583098181   time:  1.3576431274414062
e:  49   train_loss:  766.7496088481507   time:  1.391812801361084
e:  50   train_loss:  743.9591971888415   time:  1.381455421447754
e:  50   train_loss:  743.9591971888415   val_loss:  569.7175222958839   time:  1.4841299057006836
e:  51   train_loss:  741.9219864866898   time:  1.365523099899292
e:  52   train_loss:  730.3598728290765   time:  1.383467435836792
e:  53   train_loss:  726.315775336841   time:  1.5555613040924072
e:  54   train_loss:  718.266472537031   time:  1.3870675563812256
e:  55   train_loss:  711.9693656692791   time:  1.3884894847869873
e:  55   train_loss:  711.9693656692791   val_loss:  568.7197625246852   time:  1.4925642013549805
e:  56   train_loss:  712.5972501734109   time:  1.378831148147583
e:  57   train_loss:  721.7301023796886   time:  1.3821067810058594
e:  58   train_loss:  706.9964909170703   time:  1.4322967529296875
e:  59   train_loss:  700.558502918488   time:  1.552427053451538
e:  60   train_loss:  702.9295966693522   time:  1.3829197883605957
e:  60   train_loss:  702.9295966693522   val_loss:  569.5736733606293   time:  1.4838902950286865
e:  61   train_loss:  702.4002824398588   time:  1.3872175216674805
e:  62   train_loss:  701.2907801966114   time:  1.3799817562103271
e:  63   train_loss:  686.4468855529332   time:  1.407801866531372
e:  64   train_loss:  692.7114317337467   time:  1.3727905750274658
e:  65   train_loss:  680.8844923079834   time:  1.391793966293335
e:  65   train_loss:  680.8844923079834   val_loss:  572.5595783018812   time:  1.4941918849945068
e:  66   train_loss:  685.7803148480332   time:  1.5358281135559082
e:  67   train_loss:  687.0403160392616   time:  1.3773272037506104
e:  68   train_loss:  693.0192172329976   time:  1.3816537857055664
e:  69   train_loss:  684.9150046361702   time:  1.3800909519195557
e:  70   train_loss:  672.089522386636   time:  1.3732693195343018
e:  70   train_loss:  672.089522386636   val_loss:  575.288115516347   time:  1.4762673377990723
e:  71   train_loss:  677.4957744011969   time:  1.3855781555175781
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  72   train_loss:  680.9425122036344   time:  1.3586530685424805
e:  73   train_loss:  675.7167200803776   time:  1.5111699104309082
e:  74   train_loss:  682.3103312824238   time:  1.375624656677246
e:  75   train_loss:  673.3244569970836   time:  1.4179980754852295
e:  75   train_loss:  673.3244569970836   val_loss:  579.1362437440763   time:  1.520167350769043
e:  76   train_loss:  677.4959484419462   time:  1.3885178565979004
e:  77   train_loss:  665.5959044774248   time:  1.4010231494903564
e:  78   train_loss:  669.9167043700398   time:  1.3794047832489014
e:  79   train_loss:  659.9893967526109   time:  1.3484930992126465
e:  80   train_loss:  651.2254236645126   time:  1.5499227046966553
e:  80   train_loss:  651.2254236645126   val_loss:  582.8725985059833   time:  1.6523606777191162
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (1, 0, 2), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (1, 0, 2) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 2) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 2) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (1, 0, 2)
kwargs: {'config': {'batch_norm': True, 'ff_0': 534, 'ff_num_layers': 2, 'gnn_0': 88, 'gnn_dropout': 0.3869701579061263, 'gnn_num_layers': 1, 'hid_0': 251, 'hid_dropout_rate': 0.004944144219669322, 'in_dropout_rate': 0.016557116620530277, 'lr': 1.348922129808559e-05, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 94, 'hid_1': 211, 'hid_2': 147}, 'budget': 81.0, 'working_directory': '.'}
result: {'loss': 759.2455741109594, 'n_epochs': 77.6, 'info': {'validation loss': 759.2455741109594}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 2) started
DEBUG:hpbandster:job_callback for (1, 0, 2) got condition
DEBUG:hpbandster:Only 12 run(s) for budget 81.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (1, 0, 2) finished
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: trying submitting job (1, 0, 3) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 3) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 3)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 3) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 3) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (1, 0, 3)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 350, 'ff_num_layers': 1, 'gnn_0': 273, 'gnn_dropout': 0.4926001898319325, 'gnn_num_layers': 2, 'hid_0': 319, 'hid_dropout_rate': 0.20913935875813694, 'in_dropout_rate': 0.39261936678966447, 'lr': 8.092857623382594e-05, 'num_hid_layers': 1, 'optimizer': 'SGD', 'gnn_1': 214, 'sgd_momentum': 0.5041435177631874}, 'budget': 81.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  704.3476924477516   time:  1.3369626998901367
e:  0   train_loss:  704.3476924477516   val_loss:  1669.4252397758546   time:  1.4463958740234375
e:  1   train_loss:  700.2704061842359   time:  1.3318119049072266
e:  2   train_loss:  695.2821133280414   time:  1.3245561122894287
e:  3   train_loss:  688.2370847983983   time:  1.3356008529663086
e:  4   train_loss:  681.4495354980228   time:  1.300868272781372
e:  5   train_loss:  670.8251195614639   time:  1.3183777332305908
e:  5   train_loss:  670.8251195614639   val_loss:  1607.6319123591527   time:  1.4258239269256592
e:  6   train_loss:  660.65401247597   time:  1.3319268226623535
e:  7   train_loss:  645.4860913263882   time:  1.2855288982391357
e:  8   train_loss:  631.4181543852403   time:  1.3047776222229004
e:  9   train_loss:  616.6473405243778   time:  1.4063851833343506
e:  10   train_loss:  603.5579494458517   time:  1.3159427642822266
e:  10   train_loss:  603.5579494458517   val_loss:  1478.6393712376719   time:  1.4245657920837402
e:  11   train_loss:  590.3678439528516   time:  1.2679173946380615
e:  12   train_loss:  578.7068150354789   time:  1.346015453338623
e:  13   train_loss:  570.5109600793282   time:  1.2617993354797363
e:  14   train_loss:  563.5729329230329   time:  1.2780721187591553
e:  15   train_loss:  556.7042128947464   time:  1.2695081233978271
e:  15   train_loss:  556.7042128947464   val_loss:  1402.420389132804   time:  1.3784856796264648
e:  16   train_loss:  547.213427407205   time:  1.288787841796875
e:  17   train_loss:  540.4614076045461   time:  1.2893750667572021
e:  18   train_loss:  534.7938339471714   time:  1.3122000694274902
e:  19   train_loss:  527.1002513888357   time:  1.4187343120574951
e:  20   train_loss:  522.8847502072571   time:  1.2564051151275635
e:  20   train_loss:  522.8847502072571   val_loss:  1398.1050365862343   time:  1.3651409149169922
e:  21   train_loss:  517.7405997174324   time:  1.2547194957733154
e:  22   train_loss:  512.2927525283959   time:  1.252763032913208
e:  23   train_loss:  506.78613487635965   time:  1.2454726696014404
e:  24   train_loss:  500.33401537135796   time:  1.2418951988220215
e:  25   train_loss:  495.8450420388897   time:  1.2345950603485107
e:  25   train_loss:  495.8450420388897   val_loss:  1421.5836336481073   time:  1.343003273010254
e:  26   train_loss:  493.1323958575958   time:  1.2577695846557617
e:  27   train_loss:  492.5164908804547   time:  1.2453217506408691
e:  28   train_loss:  489.6408140247089   time:  1.3844738006591797
e:  29   train_loss:  483.4442937021738   time:  1.2403557300567627
e:  30   train_loss:  480.8621432719186   time:  1.254378318786621
e:  30   train_loss:  480.8621432719186   val_loss:  1441.9917401491944   time:  1.3620779514312744
e:  31   train_loss:  477.36718583568194   time:  1.243248462677002
e:  32   train_loss:  478.47284122325107   time:  1.2453405857086182
e:  33   train_loss:  470.04223680532795   time:  1.2564449310302734
e:  34   train_loss:  469.61309875070486   time:  1.2461953163146973
e:  35   train_loss:  467.89973159178186   time:  1.2562391757965088
e:  35   train_loss:  467.89973159178186   val_loss:  1399.7077864663715   time:  1.3644378185272217
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  36   train_loss:  465.5494246531881   time:  1.4081604480743408
e:  37   train_loss:  462.0567902040582   time:  1.2668960094451904
e:  38   train_loss:  460.25929748251764   time:  1.2877678871154785
e:  39   train_loss:  459.4066868674827   time:  1.2696692943572998
e:  40   train_loss:  460.69353009173085   time:  1.2705624103546143
e:  40   train_loss:  460.69353009173085   val_loss:  1361.2696921464212   time:  1.3797836303710938
e:  41   train_loss:  457.16996516789305   time:  1.319136142730713
e:  42   train_loss:  455.0964793045465   time:  1.3022148609161377
e:  43   train_loss:  452.8270430455371   time:  1.2978935241699219
e:  44   train_loss:  456.1472509183281   time:  1.272411584854126
e:  45   train_loss:  452.4443163732385   time:  1.304689645767212
e:  45   train_loss:  452.4443163732385   val_loss:  1430.593517909824   time:  1.414599895477295
e:  46   train_loss:  450.4059764764606   time:  1.2967722415924072
e:  47   train_loss:  452.4777367384827   time:  1.4382851123809814
e:  48   train_loss:  449.9193140698855   time:  1.2637462615966797
e:  49   train_loss:  450.531828930562   time:  1.3006463050842285
e:  50   train_loss:  446.76195648366274   time:  1.2872188091278076
e:  50   train_loss:  446.76195648366274   val_loss:  1510.1272755127684   time:  1.3952219486236572
e:  51   train_loss:  448.30183104264466   time:  1.3044886589050293
e:  52   train_loss:  446.0214673205678   time:  1.2899229526519775
e:  53   train_loss:  449.0238209661274   time:  1.326770305633545
e:  54   train_loss:  442.41366746807535   time:  1.3355531692504883
e:  55   train_loss:  449.7050162666696   time:  1.2565999031066895
e:  55   train_loss:  449.7050162666696   val_loss:  1461.7001861276829   time:  1.3647489547729492
e:  56   train_loss:  447.70630535090794   time:  1.2567648887634277
e:  57   train_loss:  445.747895708403   time:  1.371589183807373
e:  58   train_loss:  442.3794543552036   time:  1.2421190738677979
e:  59   train_loss:  441.03122101038764   time:  1.2415509223937988
e:  60   train_loss:  440.9828397963605   time:  1.2480626106262207
e:  60   train_loss:  440.9828397963605   val_loss:  1451.0311425227128   time:  1.3609178066253662
e:  61   train_loss:  443.1722514197678   time:  1.2571492195129395
e:  62   train_loss:  441.2482232278384   time:  1.2574591636657715
e:  63   train_loss:  444.02462600599824   time:  1.2462167739868164
e:  64   train_loss:  443.57529103151285   time:  1.262376308441162
e:  65   train_loss:  441.6730383142309   time:  1.2752976417541504
e:  65   train_loss:  441.6730383142309   val_loss:  1405.2735400678498   time:  1.3848376274108887
e:  66   train_loss:  437.0597672208333   time:  1.3835680484771729
e:  67   train_loss:  442.745999995237   time:  1.242178201675415
e:  68   train_loss:  442.45165703984236   time:  1.2575349807739258
e:  69   train_loss:  440.39111161633576   time:  1.2559678554534912
e:  70   train_loss:  442.6956304887083   time:  1.2391138076782227
e:  70   train_loss:  442.6956304887083   val_loss:  1478.9344194146381   time:  1.347027063369751
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1086.3771676230601   time:  1.3708858489990234
e:  0   train_loss:  1086.3771676230601   val_loss:  625.149184287801   time:  1.4732327461242676
e:  1   train_loss:  1095.1813938369723   time:  1.4904742240905762
e:  2   train_loss:  1063.792890167644   time:  1.4968528747558594
e:  3   train_loss:  1029.1507497551454   time:  1.4940202236175537
e:  4   train_loss:  994.5955746902187   time:  1.715364933013916
e:  5   train_loss:  983.9245715691791   time:  1.4802050590515137
e:  5   train_loss:  983.9245715691791   val_loss:  565.0732859935705   time:  1.5849635601043701
e:  6   train_loss:  921.4783716747855   time:  1.3769614696502686
e:  7   train_loss:  847.6262798603971   time:  1.3767035007476807
e:  8   train_loss:  784.1840975918245   time:  1.376436471939087
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  9   train_loss:  750.5391561626774   time:  1.3803603649139404
e:  10   train_loss:  719.7332713804012   time:  1.5147984027862549
e:  10   train_loss:  719.7332713804012   val_loss:  543.456419399943   time:  1.6181244850158691
e:  11   train_loss:  715.2939218268779   time:  1.3671786785125732
e:  12   train_loss:  696.8745966697855   time:  1.372861385345459
e:  13   train_loss:  678.2658894065686   time:  1.3742437362670898
e:  14   train_loss:  670.8542886300204   time:  1.3665218353271484
e:  15   train_loss:  670.0670315273073   time:  1.4974522590637207
e:  15   train_loss:  670.0670315273073   val_loss:  586.1266938447513   time:  1.5937514305114746
e:  16   train_loss:  652.6418634251976   time:  1.368865966796875
e:  17   train_loss:  642.9302714385176   time:  1.3764774799346924
e:  18   train_loss:  636.7418563893829   time:  1.3684239387512207
e:  19   train_loss:  628.23557741668   time:  1.359104871749878
e:  20   train_loss:  619.2929775329134   time:  1.3415005207061768
e:  20   train_loss:  619.2929775329134   val_loss:  646.2068550991262   time:  1.4426968097686768
e:  21   train_loss:  629.7448172099181   time:  1.3652293682098389
e:  22   train_loss:  608.615570798429   time:  1.5077030658721924
e:  23   train_loss:  609.8413067859153   time:  1.3779969215393066
e:  24   train_loss:  605.7937227365161   time:  1.3778398036956787
e:  25   train_loss:  601.1091913435331   time:  1.3757176399230957
e:  25   train_loss:  601.1091913435331   val_loss:  579.6448542777086   time:  1.47890043258667
e:  26   train_loss:  603.9875217331545   time:  1.3808073997497559
e:  27   train_loss:  595.661139124802   time:  1.3790059089660645
e:  28   train_loss:  603.582820066777   time:  1.5098097324371338
e:  29   train_loss:  602.409634653158   time:  1.378249168395996
e:  30   train_loss:  606.0737400776087   time:  1.3670685291290283
e:  30   train_loss:  606.0737400776087   val_loss:  599.9418798003404   time:  1.4702033996582031
e:  31   train_loss:  601.4773829390989   time:  1.3777334690093994
e:  32   train_loss:  605.3648697966736   time:  1.3780877590179443
e:  33   train_loss:  596.8636448608497   time:  1.3790247440338135
e:  34   train_loss:  613.0296393872763   time:  1.3781843185424805
e:  35   train_loss:  602.1673671757794   time:  1.5068979263305664
e:  35   train_loss:  602.1673671757794   val_loss:  615.8144623597216   time:  1.609278917312622
e:  36   train_loss:  591.5353777630148   time:  1.3677103519439697
e:  37   train_loss:  605.3059157380322   time:  1.3799395561218262
e:  38   train_loss:  594.2494174290939   time:  1.3676130771636963
e:  39   train_loss:  600.8313546247637   time:  1.3771634101867676
e:  40   train_loss:  599.4581260700438   time:  1.3789842128753662
e:  40   train_loss:  599.4581260700438   val_loss:  702.7265808551294   time:  1.4820451736450195
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1097.6278731527032   time:  1.4782111644744873
e:  0   train_loss:  1097.6278731527032   val_loss:  535.7076893867652   time:  1.5834839344024658
e:  1   train_loss:  1074.0695689385948   time:  1.35194730758667
e:  2   train_loss:  1065.7578018779645   time:  1.3612699508666992
e:  3   train_loss:  1088.9048132127637   time:  1.3614115715026855
e:  4   train_loss:  1027.077808528569   time:  1.3599250316619873
e:  5   train_loss:  953.856007360774   time:  1.356153964996338
e:  5   train_loss:  953.856007360774   val_loss:  488.5076113039425   time:  1.4609496593475342
e:  6   train_loss:  889.4261417170246   time:  1.4984018802642822
e:  7   train_loss:  823.127253716225   time:  1.3488962650299072
e:  8   train_loss:  809.950812928501   time:  1.358973503112793
e:  9   train_loss:  762.986682618634   time:  1.36063551902771
e:  10   train_loss:  743.8387945372873   time:  1.3591382503509521
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
e:  10   train_loss:  743.8387945372873   val_loss:  488.1375374296829   time:  1.4660229682922363
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  11   train_loss:  698.7300154773685   time:  1.3654932975769043
e:  12   train_loss:  707.3378253717583   time:  1.3570735454559326
e:  13   train_loss:  686.3340366519666   time:  1.3510196208953857
e:  14   train_loss:  695.7164639064354   time:  1.4698553085327148
e:  15   train_loss:  670.5690285707719   time:  1.3581163883209229
e:  15   train_loss:  670.5690285707719   val_loss:  686.3477995192702   time:  1.463942527770996
e:  16   train_loss:  660.8183492420104   time:  1.3585410118103027
e:  17   train_loss:  637.7514803474559   time:  1.348494052886963
e:  18   train_loss:  636.6034994207611   time:  1.3551397323608398
e:  19   train_loss:  631.146004940603   time:  1.3585717678070068
e:  20   train_loss:  634.338404536521   time:  1.3556265830993652
e:  20   train_loss:  634.338404536521   val_loss:  978.8777106640599   time:  1.4609055519104004
e:  21   train_loss:  626.1330454493884   time:  1.3452553749084473
e:  22   train_loss:  619.1097214580705   time:  1.4710745811462402
e:  23   train_loss:  646.7592002241173   time:  1.3546137809753418
e:  24   train_loss:  623.0121864300198   time:  1.3524813652038574
e:  25   train_loss:  635.8042285967354   time:  1.357926368713379
e:  25   train_loss:  635.8042285967354   val_loss:  536.5974900847818   time:  1.4623196125030518
e:  26   train_loss:  639.5455737922732   time:  1.3586063385009766
e:  27   train_loss:  621.669451506575   time:  1.3544011116027832
e:  28   train_loss:  653.5104721662897   time:  1.355445146560669
e:  29   train_loss:  617.7465127337668   time:  1.4921159744262695
e:  30   train_loss:  627.6917650559275   time:  1.3587768077850342
e:  30   train_loss:  627.6917650559275   val_loss:  513.4205588254124   time:  1.464113712310791
e:  31   train_loss:  652.0458642506336   time:  1.3575477600097656
e:  32   train_loss:  621.612356295795   time:  1.3577327728271484
e:  33   train_loss:  612.9847498826459   time:  1.3566570281982422
e:  34   train_loss:  640.119528091825   time:  1.3649539947509766
e:  35   train_loss:  621.3563530780458   time:  1.347856044769287
e:  35   train_loss:  621.3563530780458   val_loss:  1606.8906546894796   time:  1.4533321857452393
e:  36   train_loss:  603.9028754840637   time:  1.3728020191192627
e:  37   train_loss:  628.3958054196029   time:  1.4939944744110107
e:  38   train_loss:  613.8605576057122   time:  1.3599011898040771
e:  39   train_loss:  619.4821997492571   time:  1.3549749851226807
e:  40   train_loss:  610.2884298866642   time:  1.3472685813903809
e:  40   train_loss:  610.2884298866642   val_loss:  638.1813155376059   time:  1.4520151615142822
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  995.9420597107211   time:  1.2554888725280762
e:  0   train_loss:  995.9420597107211   val_loss:  911.7370996450139   time:  1.365544319152832
e:  1   train_loss:  984.4403777468774   time:  1.2460944652557373
e:  2   train_loss:  975.6249574873   time:  1.236584186553955
e:  3   train_loss:  964.1250323665092   time:  1.2491588592529297
e:  4   train_loss:  948.8016961638252   time:  1.2537057399749756
e:  5   train_loss:  928.8135131408839   time:  1.378690242767334
e:  5   train_loss:  928.8135131408839   val_loss:  841.4648141421198   time:  1.4889390468597412
e:  6   train_loss:  898.9696476937693   time:  1.2441680431365967
e:  7   train_loss:  870.3804572897204   time:  1.2553014755249023
e:  8   train_loss:  831.324875043867   time:  1.2557880878448486
e:  9   train_loss:  786.2284507702882   time:  1.255854606628418
e:  10   train_loss:  752.6513311568561   time:  1.2568318843841553
e:  10   train_loss:  752.6513311568561   val_loss:  776.0877489978326   time:  1.3667223453521729
e:  11   train_loss:  713.3539849677067   time:  1.2513060569763184
e:  12   train_loss:  693.9115776649362   time:  1.2533411979675293
e:  13   train_loss:  686.6265782648671   time:  1.2439939975738525
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  14   train_loss:  672.6520472393479   time:  1.3864188194274902
e:  15   train_loss:  666.310508873797   time:  1.2374491691589355
e:  15   train_loss:  666.310508873797   val_loss:  744.9905031858495   time:  1.3466458320617676
e:  16   train_loss:  657.556617163276   time:  1.254591703414917
e:  17   train_loss:  641.7223453301094   time:  1.2560088634490967
e:  18   train_loss:  639.7565006137837   time:  1.2459344863891602
e:  19   train_loss:  631.9235969379163   time:  1.2478632926940918
e:  20   train_loss:  620.7516365766647   time:  1.255518913269043
e:  20   train_loss:  620.7516365766647   val_loss:  754.0526601413213   time:  1.364945650100708
e:  21   train_loss:  610.2155801688916   time:  1.2537157535552979
e:  22   train_loss:  605.2084873354403   time:  1.2568023204803467
e:  23   train_loss:  610.1454325784526   time:  1.2574331760406494
e:  24   train_loss:  592.3356894915491   time:  1.2567708492279053
e:  25   train_loss:  592.1612215298117   time:  1.2431824207305908
e:  25   train_loss:  592.1612215298117   val_loss:  815.4604998656793   time:  1.3524701595306396
e:  26   train_loss:  582.2235938325663   time:  1.2413952350616455
e:  27   train_loss:  587.7479350203886   time:  1.255277156829834
e:  28   train_loss:  582.5115374293306   time:  1.3829693794250488
e:  29   train_loss:  582.8511018784126   time:  1.2320780754089355
e:  30   train_loss:  577.3897737167554   time:  1.2560687065124512
e:  30   train_loss:  577.3897737167554   val_loss:  762.2650032607817   time:  1.3664791584014893
e:  31   train_loss:  583.191508560205   time:  1.2580268383026123
e:  32   train_loss:  577.1712225140316   time:  1.2542998790740967
e:  33   train_loss:  575.4845035260531   time:  1.2541000843048096
e:  34   train_loss:  577.414121300307   time:  1.2615220546722412
e:  35   train_loss:  567.2652402149046   time:  1.2605810165405273
e:  35   train_loss:  567.2652402149046   val_loss:  753.49168129469   time:  1.3713326454162598
e:  36   train_loss:  567.1667205925529   time:  1.2584781646728516
e:  37   train_loss:  568.1951877499239   time:  1.2477319240570068
e:  38   train_loss:  579.4309150386553   time:  1.2564387321472168
e:  39   train_loss:  566.1139389968762   time:  1.2581071853637695
e:  40   train_loss:  574.7359046451841   time:  1.2471158504486084
e:  40   train_loss:  574.7359046451841   val_loss:  805.8226685306469   time:  1.3569064140319824
e:  41   train_loss:  566.0981047358628   time:  1.3824577331542969
e:  42   train_loss:  562.3123706816162   time:  1.2568683624267578
e:  43   train_loss:  564.3490342316594   time:  1.2580163478851318
e:  44   train_loss:  569.8418628944128   time:  1.2586166858673096
e:  45   train_loss:  560.5011245538265   time:  1.2569096088409424
e:  45   train_loss:  560.5011245538265   val_loss:  876.6934144410063   time:  1.3663692474365234
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1076.2044125717025   time:  1.3776936531066895
e:  0   train_loss:  1076.2044125717025   val_loss:  686.0673068390444   time:  1.4822778701782227
e:  1   train_loss:  1067.930231621125   time:  1.3763582706451416
e:  2   train_loss:  1042.784699819419   time:  1.3554115295410156
e:  3   train_loss:  1039.7351164491192   time:  1.352782964706421
e:  4   train_loss:  990.3414554966868   time:  1.3960530757904053
e:  5   train_loss:  963.0739373723076   time:  1.510134220123291
e:  5   train_loss:  963.0739373723076   val_loss:  610.0495275249407   time:  1.6136269569396973
e:  6   train_loss:  909.604472330849   time:  1.375098705291748
e:  7   train_loss:  823.1539345278694   time:  1.3655815124511719
e:  8   train_loss:  749.8218440068716   time:  1.3733925819396973
e:  9   train_loss:  738.528938049491   time:  1.3639452457427979
e:  10   train_loss:  709.5378783557272   time:  1.371429681777954
e:  10   train_loss:  709.5378783557272   val_loss:  561.7705593036574   time:  1.4748468399047852
e:  11   train_loss:  696.652501003591   time:  1.5073237419128418
e:  12   train_loss:  697.1025071347912   time:  1.3744165897369385
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  13   train_loss:  682.2473770442833   time:  1.3799657821655273
e:  14   train_loss:  666.8022668009991   time:  1.3727476596832275
e:  15   train_loss:  675.1925011605878   time:  1.363853931427002
e:  15   train_loss:  675.1925011605878   val_loss:  576.5312809702887   time:  1.468217134475708
e:  16   train_loss:  660.1692235701372   time:  1.374922752380371
e:  17   train_loss:  653.2732693138682   time:  1.3706729412078857
e:  18   train_loss:  647.2432545887766   time:  1.4802885055541992
e:  19   train_loss:  646.1733365743551   time:  1.3733110427856445
e:  20   train_loss:  635.3349489684985   time:  1.374164342880249
e:  20   train_loss:  635.3349489684985   val_loss:  615.3878220075302   time:  1.4773340225219727
e:  21   train_loss:  634.1536400630529   time:  1.3772974014282227
e:  22   train_loss:  629.0734119264426   time:  1.3761820793151855
e:  23   train_loss:  617.378629645088   time:  1.3602170944213867
e:  24   train_loss:  620.6621479297831   time:  1.341235876083374
e:  25   train_loss:  619.4604999684549   time:  1.5071794986724854
e:  25   train_loss:  619.4604999684549   val_loss:  635.1862094651007   time:  1.6107172966003418
e:  26   train_loss:  620.937249535031   time:  1.3739910125732422
e:  27   train_loss:  621.3337950128495   time:  1.3757710456848145
e:  28   train_loss:  624.1393816727261   time:  1.3730030059814453
e:  29   train_loss:  630.0919237003984   time:  1.3738186359405518
e:  30   train_loss:  622.6939707605668   time:  1.3743197917938232
e:  30   train_loss:  622.6939707605668   val_loss:  676.4785698973312   time:  1.4782404899597168
e:  31   train_loss:  608.3543149932949   time:  1.512129783630371
e:  32   train_loss:  626.8554900864602   time:  1.3724074363708496
e:  33   train_loss:  613.2855642789978   time:  1.3693325519561768
e:  34   train_loss:  609.0342635108109   time:  1.3749215602874756
e:  35   train_loss:  604.1647690248373   time:  1.369084358215332
e:  35   train_loss:  604.1647690248373   val_loss:  627.3093047918524   time:  1.4729788303375244
e:  36   train_loss:  610.9118548352806   time:  1.376610517501831
e:  37   train_loss:  608.0574877137898   time:  1.3761515617370605
e:  38   train_loss:  606.7388600907831   time:  1.4864616394042969
e:  39   train_loss:  596.1454392435384   time:  1.3813202381134033
e:  40   train_loss:  592.852151594687   time:  1.3787896633148193
e:  40   train_loss:  592.852151594687   val_loss:  627.1933605832562   time:  1.4823365211486816
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (1, 0, 3), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (1, 0, 3) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 3) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 3) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (1, 0, 3)
kwargs: {'config': {'batch_norm': True, 'ff_0': 350, 'ff_num_layers': 1, 'gnn_0': 273, 'gnn_dropout': 0.4926001898319325, 'gnn_num_layers': 2, 'hid_0': 319, 'hid_dropout_rate': 0.20913935875813694, 'in_dropout_rate': 0.39261936678966447, 'lr': 8.092857623382594e-05, 'num_hid_layers': 1, 'optimizer': 'SGD', 'gnn_1': 214, 'sgd_momentum': 0.5041435177631874}, 'budget': 81.0, 'working_directory': '.'}
result: {'loss': 739.9249422931109, 'n_epochs': 47.0, 'info': {'validation loss': 739.9249422931109}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 3) started
DEBUG:hpbandster:job_callback for (1, 0, 3) got condition
DEBUG:hpbandster:Only 13 run(s) for budget 81.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (1, 0, 3) finished
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: trying submitting job (1, 0, 4) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 4) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 4)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 4) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 4) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (1, 0, 4)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 22, 'ff_num_layers': 3, 'gnn_0': 240, 'gnn_dropout': 0.26905268172807817, 'gnn_num_layers': 1, 'hid_0': 159, 'hid_dropout_rate': 0.025527023061804544, 'in_dropout_rate': 0.05124128827485169, 'lr': 6.405476745348204e-05, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 130, 'ff_2': 591, 'hid_1': 822, 'hid_2': 343}, 'budget': 81.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  705.499957788973   time:  1.3592536449432373
e:  0   train_loss:  705.499957788973   val_loss:  1673.1161231211947   time:  1.469226598739624
e:  1   train_loss:  700.1326129930742   time:  1.3023512363433838
e:  2   train_loss:  694.0106677902273   time:  1.3027682304382324
e:  3   train_loss:  679.0020689448593   time:  1.5908119678497314
e:  4   train_loss:  653.3815490921704   time:  1.3336246013641357
e:  5   train_loss:  616.1185880032723   time:  1.3662548065185547
e:  5   train_loss:  616.1185880032723   val_loss:  1570.5996149201876   time:  1.4757323265075684
e:  6   train_loss:  577.9027127626512   time:  1.3675146102905273
e:  7   train_loss:  550.0097237568856   time:  1.2917630672454834
e:  8   train_loss:  542.0383019378683   time:  1.2347338199615479
e:  9   train_loss:  528.3375535310744   time:  1.2346827983856201
e:  10   train_loss:  527.2826180745066   time:  1.2471444606781006
e:  10   train_loss:  527.2826180745066   val_loss:  1469.5460907402837   time:  1.3678042888641357
e:  11   train_loss:  525.7103153982467   time:  1.2668168544769287
e:  12   train_loss:  525.7013700396774   time:  1.2386863231658936
e:  13   train_loss:  518.0325994138996   time:  1.2384834289550781
e:  14   train_loss:  513.979810887891   time:  1.2520389556884766
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  15   train_loss:  516.7992425956758   time:  1.358008623123169
e:  15   train_loss:  516.7992425956758   val_loss:  1460.3252061663522   time:  1.4565820693969727
e:  16   train_loss:  518.8577548402527   time:  1.2316410541534424
e:  17   train_loss:  516.0210388869474   time:  1.2385001182556152
e:  18   train_loss:  511.990595453676   time:  1.2364656925201416
e:  19   train_loss:  514.203477816264   time:  1.2377040386199951
e:  20   train_loss:  512.5543591318799   time:  1.2392308712005615
e:  20   train_loss:  512.5543591318799   val_loss:  1451.089196841163   time:  1.346421241760254
e:  21   train_loss:  513.0137958636942   time:  1.2385246753692627
e:  22   train_loss:  505.2282836585978   time:  1.2293436527252197
e:  23   train_loss:  500.1257313842069   time:  1.2305033206939697
e:  24   train_loss:  500.3590888485944   time:  1.2399661540985107
e:  25   train_loss:  503.7241777366839   time:  1.3592429161071777
e:  25   train_loss:  503.7241777366839   val_loss:  1453.3909896407492   time:  1.4577484130859375
e:  26   train_loss:  491.4681513005903   time:  1.2295904159545898
e:  27   train_loss:  504.83621310610397   time:  1.2248013019561768
e:  28   train_loss:  492.0375640477326   time:  1.2286126613616943
e:  29   train_loss:  493.3183376410709   time:  1.2295629978179932
e:  30   train_loss:  490.1673177911838   time:  1.2361981868743896
e:  30   train_loss:  490.1673177911838   val_loss:  1459.322447221354   time:  1.3426389694213867
e:  31   train_loss:  488.11135988883007   time:  1.2390575408935547
e:  32   train_loss:  485.7605432314481   time:  1.2317664623260498
e:  33   train_loss:  489.7517792786732   time:  1.2296490669250488
e:  34   train_loss:  481.5215218090284   time:  1.3520891666412354
e:  35   train_loss:  488.40035293350155   time:  1.2223453521728516
e:  35   train_loss:  488.40035293350155   val_loss:  1469.1762819065511   time:  1.328460931777954
e:  36   train_loss:  483.1518046445237   time:  1.231144666671753
e:  37   train_loss:  489.30009932643   time:  1.2380454540252686
e:  38   train_loss:  477.5144363840203   time:  1.2381970882415771
e:  39   train_loss:  480.32063194987825   time:  1.2394120693206787
e:  40   train_loss:  479.3724038246886   time:  1.2284724712371826
e:  40   train_loss:  479.3724038246886   val_loss:  1465.1904557112503   time:  1.3358497619628906
e:  41   train_loss:  481.0749547842041   time:  1.2368836402893066
e:  42   train_loss:  475.71785425829023   time:  1.2375850677490234
e:  43   train_loss:  476.05698750915894   time:  1.2387416362762451
e:  44   train_loss:  474.6875032456161   time:  1.231393575668335
e:  45   train_loss:  474.70502474033685   time:  1.2391817569732666
e:  45   train_loss:  474.70502474033685   val_loss:  1478.3904841621086   time:  1.470712423324585
e:  46   train_loss:  466.95799058344727   time:  1.22444486618042
e:  47   train_loss:  467.3702151493341   time:  1.2280139923095703
e:  48   train_loss:  461.3793550347196   time:  1.228492259979248
e:  49   train_loss:  464.5758376225396   time:  1.2382071018218994
e:  50   train_loss:  461.78530352885275   time:  1.2290902137756348
e:  50   train_loss:  461.78530352885275   val_loss:  1482.0605373560745   time:  1.3353455066680908
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1083.8832286913653   time:  1.331651210784912
e:  0   train_loss:  1083.8832286913653   val_loss:  627.8800820049676   time:  1.4319140911102295
e:  1   train_loss:  1069.5409543850335   time:  1.3553454875946045
e:  2   train_loss:  1057.2626240729223   time:  1.487776756286621
e:  3   train_loss:  1039.3587373868868   time:  1.333801031112671
e:  4   train_loss:  978.7553169826169   time:  1.3474583625793457
e:  5   train_loss:  906.0133633087657   time:  1.3489131927490234
e:  5   train_loss:  906.0133633087657   val_loss:  579.9510442677728   time:  1.4492788314819336
e:  6   train_loss:  783.0817069818703   time:  1.3409366607666016
e:  7   train_loss:  712.3940932931348   time:  1.3457565307617188
e:  8   train_loss:  705.5124540193351   time:  1.4881255626678467
e:  9   train_loss:  710.2122955831786   time:  1.355708122253418
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  10   train_loss:  700.2713306895893   time:  1.4044582843780518
e:  10   train_loss:  700.2713306895893   val_loss:  538.2440177268074   time:  1.50443434715271
e:  11   train_loss:  686.2245568328544   time:  1.5167207717895508
e:  12   train_loss:  683.9601420687586   time:  1.4215011596679688
e:  13   train_loss:  676.968583820591   time:  1.3789637088775635
e:  14   train_loss:  663.1422782611712   time:  1.5116691589355469
e:  15   train_loss:  671.55649352949   time:  1.3746531009674072
e:  15   train_loss:  671.55649352949   val_loss:  540.5305863576953   time:  1.4747381210327148
e:  16   train_loss:  661.6589186699304   time:  1.5097169876098633
e:  17   train_loss:  674.6414471679778   time:  1.4320120811462402
e:  18   train_loss:  662.8947790952947   time:  1.4306299686431885
e:  19   train_loss:  649.4825765865428   time:  1.5156614780426025
e:  20   train_loss:  650.0353408441002   time:  1.5938706398010254
e:  20   train_loss:  650.0353408441002   val_loss:  539.2905174571213   time:  1.6939609050750732
e:  21   train_loss:  659.8910473617038   time:  1.606369972229004
e:  22   train_loss:  649.2464293796752   time:  1.4986042976379395
e:  23   train_loss:  647.5333027148486   time:  1.4350669384002686
e:  24   train_loss:  661.4057795610684   time:  1.3514795303344727
e:  25   train_loss:  635.5629970462815   time:  1.3429152965545654
e:  25   train_loss:  635.5629970462815   val_loss:  542.862954432894   time:  1.443936824798584
e:  26   train_loss:  633.4104511965588   time:  1.3543236255645752
e:  27   train_loss:  641.9512701948503   time:  1.3507604598999023
e:  28   train_loss:  632.6753263638537   time:  1.4613900184631348
e:  29   train_loss:  624.9164868889932   time:  1.3538868427276611
e:  30   train_loss:  630.4226300342459   time:  1.3546924591064453
e:  30   train_loss:  630.4226300342459   val_loss:  545.0256965743685   time:  1.4547781944274902
e:  31   train_loss:  618.5807138637772   time:  1.353156566619873
e:  32   train_loss:  631.5097189113113   time:  1.3548710346221924
e:  33   train_loss:  612.8039992916393   time:  1.3526756763458252
e:  34   train_loss:  623.3974684891015   time:  1.3424835205078125
e:  35   train_loss:  630.7912067181232   time:  1.4857020378112793
e:  35   train_loss:  630.7912067181232   val_loss:  548.4404578676474   time:  1.5867609977722168
e:  36   train_loss:  631.4214167148127   time:  1.3576672077178955
e:  37   train_loss:  618.0298993553685   time:  1.360624074935913
e:  38   train_loss:  624.2267183771493   time:  1.3425250053405762
e:  39   train_loss:  626.813507712546   time:  1.3244853019714355
e:  40   train_loss:  618.7043731536331   time:  1.345641851425171
e:  40   train_loss:  618.7043731536331   val_loss:  550.8751614581715   time:  1.4461901187896729
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1142.9531477858754   time:  1.4688725471496582
e:  0   train_loss:  1142.9531477858754   val_loss:  538.592024447759   time:  1.572399377822876
e:  1   train_loss:  1114.4928024759417   time:  1.31813383102417
e:  2   train_loss:  1057.8753101195914   time:  1.592174768447876
e:  3   train_loss:  1052.5826268101098   time:  1.6085820198059082
e:  4   train_loss:  990.5975995300477   time:  1.4987971782684326
e:  5   train_loss:  944.4965196153191   time:  1.3466699123382568
e:  5   train_loss:  944.4965196153191   val_loss:  496.09797031934977   time:  1.4505336284637451
e:  6   train_loss:  823.3783299134057   time:  1.3443279266357422
e:  7   train_loss:  818.8034698597189   time:  1.357412338256836
e:  8   train_loss:  774.7809037648116   time:  1.477623701095581
e:  9   train_loss:  742.1157093127063   time:  1.3437118530273438
e:  10   train_loss:  712.8113482177808   time:  1.3402955532073975
e:  10   train_loss:  712.8113482177808   val_loss:  482.4624643151164   time:  1.443504810333252
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  11   train_loss:  687.4246103976513   time:  1.3530399799346924
e:  12   train_loss:  691.5569228516081   time:  1.3448636531829834
e:  13   train_loss:  689.369388321325   time:  1.3447754383087158
e:  14   train_loss:  711.9901830178255   time:  1.3460886478424072
e:  15   train_loss:  716.7408860010264   time:  1.4781348705291748
e:  15   train_loss:  716.7408860010264   val_loss:  476.6545753474445   time:  1.5749213695526123
e:  16   train_loss:  710.3729200620967   time:  1.3329291343688965
e:  17   train_loss:  700.9179378442188   time:  1.3321666717529297
e:  18   train_loss:  682.3273777606433   time:  1.3376402854919434
e:  19   train_loss:  677.0944875338931   time:  1.3455772399902344
e:  20   train_loss:  670.9448669507698   time:  1.3413243293762207
e:  20   train_loss:  670.9448669507698   val_loss:  473.4501163033127   time:  1.4447367191314697
e:  21   train_loss:  668.6868255941162   time:  1.333038091659546
e:  22   train_loss:  695.3638629013793   time:  1.466801404953003
e:  23   train_loss:  676.2516022770226   time:  1.3293800354003906
e:  24   train_loss:  663.8775602413427   time:  1.3428006172180176
e:  25   train_loss:  658.9807084399434   time:  1.3434553146362305
e:  25   train_loss:  658.9807084399434   val_loss:  474.7469221759688   time:  1.4464850425720215
e:  26   train_loss:  674.0486585677013   time:  1.343430757522583
e:  27   train_loss:  674.2902214882266   time:  1.3400633335113525
e:  28   train_loss:  654.8517336963293   time:  1.3433868885040283
e:  29   train_loss:  647.2270002298146   time:  1.3431994915008545
e:  30   train_loss:  658.3471102796972   time:  1.480478286743164
e:  30   train_loss:  658.3471102796972   val_loss:  472.24617129967436   time:  1.5832717418670654
e:  31   train_loss:  673.4484078087378   time:  1.342536211013794
e:  32   train_loss:  666.981150109403   time:  1.3399958610534668
e:  33   train_loss:  631.2094778519547   time:  1.341214895248413
e:  34   train_loss:  643.9586304299324   time:  1.3441009521484375
e:  35   train_loss:  661.8599658698784   time:  1.3403143882751465
e:  35   train_loss:  661.8599658698784   val_loss:  474.4778069540722   time:  1.4441795349121094
e:  36   train_loss:  652.7009686136932   time:  1.345360517501831
e:  37   train_loss:  641.2878434600575   time:  1.4399616718292236
e:  38   train_loss:  647.8918598509247   time:  1.4587373733520508
e:  39   train_loss:  653.3631791915566   time:  1.3407394886016846
e:  40   train_loss:  667.751108084954   time:  1.3554797172546387
e:  40   train_loss:  667.751108084954   val_loss:  476.872518241719   time:  1.4588420391082764
e:  41   train_loss:  660.3045091398615   time:  1.3439786434173584
e:  42   train_loss:  629.2555702184186   time:  1.3320066928863525
e:  43   train_loss:  644.8671768872505   time:  1.333648681640625
e:  44   train_loss:  621.0593885984125   time:  1.3278391361236572
e:  45   train_loss:  647.636210472107   time:  1.467437982559204
e:  45   train_loss:  647.636210472107   val_loss:  475.10548089951243   time:  1.5704069137573242
e:  46   train_loss:  627.4228738011784   time:  1.3325564861297607
e:  47   train_loss:  642.2990253068908   time:  1.3399131298065186
e:  48   train_loss:  639.4313924741712   time:  1.3436086177825928
e:  49   train_loss:  630.1430486517152   time:  1.3445918560028076
e:  50   train_loss:  628.9986536988121   time:  1.3438560962677002
e:  50   train_loss:  628.9986536988121   val_loss:  472.59843322706763   time:  1.447664737701416
e:  51   train_loss:  633.1646270081351   time:  1.344071626663208
e:  52   train_loss:  627.5245387311251   time:  1.4733421802520752
e:  53   train_loss:  634.9097549253712   time:  1.33119797706604
e:  54   train_loss:  616.8969898812514   time:  1.3351609706878662
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  55   train_loss:  641.2023880606987   time:  1.3350000381469727
e:  55   train_loss:  641.2023880606987   val_loss:  473.3451607055673   time:  1.4379312992095947
e:  56   train_loss:  624.0109728420649   time:  1.327848196029663
e:  57   train_loss:  632.5895323779224   time:  1.3354933261871338
e:  58   train_loss:  627.0944752264355   time:  1.340829610824585
e:  59   train_loss:  632.0782474808018   time:  1.4541151523590088
e:  60   train_loss:  616.4706500450534   time:  1.3367564678192139
e:  60   train_loss:  616.4706500450534   val_loss:  481.96016458637223   time:  1.4396336078643799
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  999.9906301413791   time:  1.2290470600128174
e:  0   train_loss:  999.9906301413791   val_loss:  917.4282581851892   time:  1.3368823528289795
e:  1   train_loss:  993.627243070872   time:  1.2335293292999268
e:  2   train_loss:  985.6844020992133   time:  1.2380952835083008
e:  3   train_loss:  968.1832994832743   time:  1.2375397682189941
e:  4   train_loss:  946.3246274451393   time:  1.2312114238739014
e:  5   train_loss:  887.0547576694402   time:  1.222726583480835
e:  5   train_loss:  887.0547576694402   val_loss:  849.6226713128787   time:  1.3305039405822754
e:  6   train_loss:  818.8211301475109   time:  1.2269480228424072
e:  7   train_loss:  761.492980094251   time:  1.2784786224365234
e:  8   train_loss:  723.7119664292807   time:  1.2341761589050293
e:  9   train_loss:  695.9301145124202   time:  1.3500001430511475
e:  10   train_loss:  688.7373740410427   time:  1.227802038192749
e:  10   train_loss:  688.7373740410427   val_loss:  762.5972616432889   time:  1.3343725204467773
e:  11   train_loss:  686.114099747763   time:  1.2260346412658691
e:  12   train_loss:  677.6575689690757   time:  1.2290661334991455
e:  13   train_loss:  675.4117914784887   time:  1.2370350360870361
e:  14   train_loss:  668.9006588238947   time:  1.2297585010528564
e:  15   train_loss:  668.1363396808855   time:  1.2319698333740234
e:  15   train_loss:  668.1363396808855   val_loss:  784.790378332843   time:  1.3387303352355957
e:  16   train_loss:  650.7821965878419   time:  1.2305381298065186
e:  17   train_loss:  646.7039201086786   time:  1.2353503704071045
e:  18   train_loss:  653.2105577716108   time:  1.235551357269287
e:  19   train_loss:  633.7323381143664   time:  1.2358529567718506
e:  20   train_loss:  628.4503887590919   time:  1.2496333122253418
e:  20   train_loss:  628.4503887590919   val_loss:  794.8517134064525   time:  1.3570475578308105
e:  21   train_loss:  624.0709108644105   time:  1.234618902206421
e:  22   train_loss:  628.1035182842545   time:  1.2437396049499512
e:  23   train_loss:  619.7376939131948   time:  1.3653013706207275
e:  24   train_loss:  616.4487442334191   time:  1.2128105163574219
e:  25   train_loss:  619.4140926862354   time:  1.2335178852081299
e:  25   train_loss:  619.4140926862354   val_loss:  810.1116911144761   time:  1.3414387702941895
e:  26   train_loss:  609.8833082309357   time:  1.2365236282348633
e:  27   train_loss:  600.7461111140357   time:  1.2307484149932861
e:  28   train_loss:  602.5033416724858   time:  1.2245361804962158
e:  29   train_loss:  607.1345540334   time:  1.221174955368042
e:  30   train_loss:  604.2207696126386   time:  1.2290232181549072
e:  30   train_loss:  604.2207696126386   val_loss:  812.233829692947   time:  1.3367745876312256
e:  31   train_loss:  602.8489204670799   time:  1.2344181537628174
e:  32   train_loss:  607.6823666070934   time:  1.2267992496490479
e:  33   train_loss:  588.9152974255524   time:  1.2368414402008057
e:  34   train_loss:  601.7052921529265   time:  1.2439794540405273
e:  35   train_loss:  589.4895198062592   time:  1.2192022800445557
e:  35   train_loss:  589.4895198062592   val_loss:  817.1197039465571   time:  1.325892686843872
e:  36   train_loss:  588.741412161026   time:  1.4143414497375488
e:  37   train_loss:  589.8725078603329   time:  1.2368683815002441
e:  38   train_loss:  604.6255765635947   time:  1.242527723312378
e:  39   train_loss:  588.7362476586723   time:  1.238048791885376
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  40   train_loss:  587.979237045697   time:  1.2414131164550781
e:  40   train_loss:  587.979237045697   val_loss:  815.4558735950319   time:  1.348586082458496
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1085.2415251454008   time:  1.3564739227294922
e:  0   train_loss:  1085.2415251454008   val_loss:  689.0887330181044   time:  1.4589295387268066
e:  1   train_loss:  1063.472186076598   time:  1.3561701774597168
e:  2   train_loss:  1057.6550690515137   time:  1.3557965755462646
e:  3   train_loss:  1033.0104502997374   time:  1.3586978912353516
e:  4   train_loss:  990.0855038769977   time:  1.498537302017212
e:  5   train_loss:  912.7014318656509   time:  1.3461930751800537
e:  5   train_loss:  912.7014318656509   val_loss:  625.9560208526557   time:  1.4482593536376953
e:  6   train_loss:  800.035913227916   time:  1.3563332557678223
e:  7   train_loss:  722.1673204366149   time:  1.3452777862548828
e:  8   train_loss:  741.6581948092239   time:  1.3516757488250732
e:  9   train_loss:  711.6610508280136   time:  1.3548858165740967
e:  10   train_loss:  693.593129455605   time:  1.4039909839630127
e:  10   train_loss:  693.593129455605   val_loss:  570.5966263721855   time:  1.6642816066741943
e:  11   train_loss:  702.5349886989302   time:  1.4460194110870361
e:  12   train_loss:  688.8697799636045   time:  1.3537940979003906
e:  13   train_loss:  689.0575224979901   time:  1.3439180850982666
e:  14   train_loss:  681.0777472808157   time:  1.3566882610321045
e:  15   train_loss:  693.1953544115514   time:  1.3543024063110352
e:  15   train_loss:  693.1953544115514   val_loss:  573.5976812637833   time:  1.4570631980895996
e:  16   train_loss:  679.4908031539012   time:  1.3620870113372803
e:  17   train_loss:  668.6922232370713   time:  1.3485498428344727
e:  18   train_loss:  673.299382371598   time:  1.5066609382629395
e:  19   train_loss:  658.3353937623361   time:  1.3589162826538086
e:  20   train_loss:  652.3629337587894   time:  1.3523051738739014
e:  20   train_loss:  652.3629337587894   val_loss:  581.9961301388404   time:  1.4536786079406738
e:  21   train_loss:  645.5073344879405   time:  1.3502624034881592
e:  22   train_loss:  664.5734891357445   time:  1.3434534072875977
e:  23   train_loss:  663.232473434151   time:  1.3561413288116455
e:  24   train_loss:  639.3183133302057   time:  1.468658447265625
e:  25   train_loss:  649.3728579396711   time:  1.3507115840911865
e:  25   train_loss:  649.3728579396711   val_loss:  586.6068278914155   time:  1.4531662464141846
e:  26   train_loss:  647.643998251176   time:  1.3465297222137451
e:  27   train_loss:  639.84041969687   time:  1.482131004333496
e:  28   train_loss:  646.2182047681868   time:  1.662964105606079
e:  29   train_loss:  629.1558566996068   time:  1.5263211727142334
e:  30   train_loss:  644.7771922863128   time:  1.508453369140625
e:  30   train_loss:  644.7771922863128   val_loss:  589.984196493455   time:  1.6100518703460693
e:  31   train_loss:  629.8617651155323   time:  1.339010238647461
e:  32   train_loss:  631.7506184185851   time:  1.3437187671661377
e:  33   train_loss:  631.5035342065148   time:  1.3554344177246094
e:  34   train_loss:  626.4492861354579   time:  1.3650712966918945
e:  35   train_loss:  627.7484913248195   time:  1.3524885177612305
e:  35   train_loss:  627.7484913248195   val_loss:  593.7804256662364   time:  1.4539155960083008
e:  36   train_loss:  628.8570134548557   time:  1.3536181449890137
e:  37   train_loss:  622.3711573163965   time:  1.4856574535369873
e:  38   train_loss:  629.102908992779   time:  1.3420453071594238
e:  39   train_loss:  619.4301881917507   time:  1.3516674041748047
e:  40   train_loss:  613.5122834374201   time:  1.351611614227295
e:  40   train_loss:  613.5122834374201   val_loss:  595.4684863384465   time:  1.453758955001831
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (1, 0, 4), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (1, 0, 4) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 4) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 4) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (1, 0, 4)
kwargs: {'config': {'batch_norm': True, 'ff_0': 22, 'ff_num_layers': 3, 'gnn_0': 240, 'gnn_dropout': 0.26905268172807817, 'gnn_num_layers': 1, 'hid_0': 159, 'hid_dropout_rate': 0.025527023061804544, 'in_dropout_rate': 0.05124128827485169, 'lr': 6.405476745348204e-05, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 130, 'ff_2': 591, 'hid_1': 822, 'hid_2': 343}, 'budget': 81.0, 'working_directory': '.'}
result: {'loss': 758.9546547766238, 'n_epochs': 46.0, 'info': {'validation loss': 758.9546547766238}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 4) started
DEBUG:hpbandster:job_callback for (1, 0, 4) got condition
DEBUG:hpbandster:Only 14 run(s) for budget 81.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (1, 0, 4) finished
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: trying submitting job (1, 0, 5) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 5) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 5)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 5) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 5) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (1, 0, 5)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 28, 'ff_num_layers': 1, 'gnn_0': 89, 'gnn_dropout': 0.10641623199340061, 'gnn_num_layers': 1, 'hid_0': 523, 'hid_dropout_rate': 0.013411139819705098, 'in_dropout_rate': 0.3926441083649277, 'lr': 0.00011123578317406136, 'num_hid_layers': 3, 'optimizer': 'Adam', 'hid_1': 149, 'hid_2': 1121}, 'budget': 81.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  705.5944700858034   time:  1.3360316753387451
e:  0   train_loss:  705.5944700858034   val_loss:  1670.8303682513615   time:  1.4436116218566895
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  1   train_loss:  699.7538373534943   time:  1.292922019958496
e:  2   train_loss:  690.1048436365212   time:  1.292118787765503
e:  3   train_loss:  667.6452987989677   time:  1.4077322483062744
e:  4   train_loss:  631.2747234914793   time:  1.2789115905761719
e:  5   train_loss:  596.8995059229966   time:  1.2758378982543945
e:  5   train_loss:  596.8995059229966   val_loss:  1389.5068049349723   time:  1.3836567401885986
e:  6   train_loss:  589.5666677723796   time:  1.290858507156372
e:  7   train_loss:  580.8191126609081   time:  1.4078729152679443
e:  8   train_loss:  574.541667947799   time:  1.421046257019043
e:  9   train_loss:  566.3380149542359   time:  1.4189283847808838
e:  10   train_loss:  558.0192370626273   time:  1.4126639366149902
e:  10   train_loss:  558.0192370626273   val_loss:  1395.8460829713893   time:  1.521958827972412
e:  11   train_loss:  548.307720342247   time:  1.3934109210968018
e:  12   train_loss:  537.2428277905076   time:  1.3971257209777832
e:  13   train_loss:  524.6007341445508   time:  1.3418481349945068
e:  14   train_loss:  512.6186953925036   time:  1.3548216819763184
e:  15   train_loss:  502.83177447823965   time:  1.4741692543029785
e:  15   train_loss:  502.83177447823965   val_loss:  1377.5378990900713   time:  1.5719025135040283
e:  16   train_loss:  493.24495088044995   time:  1.2887697219848633
e:  17   train_loss:  484.53570677388933   time:  1.2790915966033936
e:  18   train_loss:  478.99806481264824   time:  1.291727066040039
e:  19   train_loss:  473.4453503274373   time:  1.2904975414276123
e:  20   train_loss:  466.0467672718931   time:  1.284531593322754
e:  20   train_loss:  466.0467672718931   val_loss:  1404.4804295293482   time:  1.392418384552002
e:  21   train_loss:  460.11722644805633   time:  1.293050765991211
e:  22   train_loss:  456.6592364000682   time:  1.2918686866760254
e:  23   train_loss:  454.2433594438258   time:  1.2829809188842773
e:  24   train_loss:  448.1310758038498   time:  1.3993737697601318
e:  25   train_loss:  442.354017346429   time:  1.2904384136199951
e:  25   train_loss:  442.354017346429   val_loss:  1385.7871129260773   time:  1.3985023498535156
e:  26   train_loss:  436.44891813543944   time:  1.2815978527069092
e:  27   train_loss:  436.6455806607082   time:  1.2911624908447266
e:  28   train_loss:  433.12882022396315   time:  1.2868101596832275
e:  29   train_loss:  429.48049736730087   time:  1.2906324863433838
e:  30   train_loss:  428.639510642855   time:  1.2964212894439697
e:  30   train_loss:  428.639510642855   val_loss:  1378.6636727764476   time:  1.403918981552124
e:  31   train_loss:  424.5491634225016   time:  1.2805202007293701
e:  32   train_loss:  423.7738565971275   time:  1.2893481254577637
e:  33   train_loss:  422.1498698966089   time:  1.4078373908996582
e:  34   train_loss:  419.81647825797563   time:  1.242281198501587
e:  35   train_loss:  419.8113518166207   time:  1.2716729640960693
e:  35   train_loss:  419.8113518166207   val_loss:  1389.5100946002012   time:  1.379148006439209
e:  36   train_loss:  418.57190640314906   time:  1.290755033493042
e:  37   train_loss:  417.58699866403015   time:  1.288320541381836
e:  38   train_loss:  413.3272350026642   time:  1.2856662273406982
e:  39   train_loss:  412.95708009757163   time:  1.2813665866851807
e:  40   train_loss:  412.4102536001168   time:  1.2902801036834717
e:  40   train_loss:  412.4102536001168   val_loss:  1409.3532361181785   time:  1.3968377113342285
e:  41   train_loss:  411.60361536578586   time:  1.2907061576843262
e:  42   train_loss:  408.10173300557517   time:  1.2895293235778809
e:  43   train_loss:  407.19929406851554   time:  1.2878916263580322
e:  44   train_loss:  408.29592040616285   time:  1.2908399105072021
e:  45   train_loss:  405.3628531655439   time:  1.4072160720825195
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  45   train_loss:  405.3628531655439   val_loss:  1406.3953584631408   time:  1.509190559387207
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1089.974077760677   time:  1.4061319828033447
e:  0   train_loss:  1089.974077760677   val_loss:  625.8568632850073   time:  1.5073509216308594
e:  1   train_loss:  1073.5715993844417   time:  1.4065077304840088
e:  2   train_loss:  1064.760159757152   time:  1.4054443836212158
e:  3   train_loss:  1004.0923866328152   time:  1.4083890914916992
e:  4   train_loss:  962.4390028699765   time:  1.403886079788208
e:  5   train_loss:  873.5036943970647   time:  1.534843921661377
e:  5   train_loss:  873.5036943970647   val_loss:  597.7628517694818   time:  1.635695219039917
e:  6   train_loss:  879.1044700610126   time:  1.3965067863464355
e:  7   train_loss:  846.2823916191226   time:  1.4051446914672852
e:  8   train_loss:  815.0338837880446   time:  1.4061613082885742
e:  9   train_loss:  782.7172792727424   time:  1.392442226409912
e:  10   train_loss:  743.8391282439327   time:  1.3750395774841309
e:  10   train_loss:  743.8391282439327   val_loss:  597.0282056033685   time:  1.4751744270324707
e:  11   train_loss:  708.0211324861069   time:  1.4064083099365234
e:  12   train_loss:  688.4430405977336   time:  1.528228998184204
e:  13   train_loss:  672.9921769101142   time:  1.3965122699737549
e:  14   train_loss:  666.4288639859737   time:  1.4044115543365479
e:  15   train_loss:  648.5088225463119   time:  1.4058220386505127
e:  15   train_loss:  648.5088225463119   val_loss:  710.2089202819911   time:  1.5071077346801758
e:  16   train_loss:  638.7823712722177   time:  1.4074983596801758
e:  17   train_loss:  635.1041199706153   time:  1.4084498882293701
e:  18   train_loss:  617.1840399068677   time:  1.5458974838256836
e:  19   train_loss:  618.4915679344954   time:  1.3997085094451904
e:  20   train_loss:  608.4923938648916   time:  1.4077544212341309
e:  20   train_loss:  608.4923938648916   val_loss:  707.7006197620217   time:  1.5088410377502441
e:  21   train_loss:  595.7514576633382   time:  1.4086272716522217
e:  22   train_loss:  597.1169148310232   time:  1.4033780097961426
e:  23   train_loss:  591.0321813276237   time:  1.405526876449585
e:  24   train_loss:  584.4952567349638   time:  1.4072039127349854
e:  25   train_loss:  590.8347040913621   time:  1.546661138534546
e:  25   train_loss:  590.8347040913621   val_loss:  747.3542259422298   time:  1.647324800491333
e:  26   train_loss:  575.0453740313453   time:  1.401045799255371
e:  27   train_loss:  578.3127762418954   time:  1.638657808303833
e:  28   train_loss:  573.2280970864573   time:  1.4475460052490234
e:  29   train_loss:  576.4165228142685   time:  1.4394190311431885
e:  30   train_loss:  566.103359406698   time:  1.428037405014038
e:  30   train_loss:  566.103359406698   val_loss:  828.0114656480329   time:  1.5279436111450195
e:  31   train_loss:  580.6127631804908   time:  1.3856728076934814
e:  32   train_loss:  565.8698399211179   time:  1.546281099319458
e:  33   train_loss:  556.2294791359905   time:  1.4060673713684082
e:  34   train_loss:  563.1369718195335   time:  1.4026858806610107
e:  35   train_loss:  556.800299856209   time:  1.3974440097808838
e:  35   train_loss:  556.800299856209   val_loss:  921.5110307295782   time:  1.4994356632232666
e:  36   train_loss:  558.0363112156188   time:  1.3967134952545166
e:  37   train_loss:  558.3032370230233   time:  1.4066894054412842
e:  38   train_loss:  551.0030924595582   time:  1.5572810173034668
e:  39   train_loss:  552.8840074722116   time:  1.3946478366851807
e:  40   train_loss:  547.2618064720759   time:  1.4160816669464111
e:  40   train_loss:  547.2618064720759   val_loss:  947.4321624449   time:  1.5162928104400635
FOLD:  2
Model initialization done
Model training starts
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  0   train_loss:  1081.7195583380935   time:  1.3983814716339111
e:  0   train_loss:  1081.7195583380935   val_loss:  537.0194433333771   time:  1.5020809173583984
e:  1   train_loss:  1061.1559884679723   time:  1.3904802799224854
e:  2   train_loss:  1082.1342590024296   time:  1.3903827667236328
e:  3   train_loss:  1012.5934410983848   time:  1.389063835144043
e:  4   train_loss:  994.0619896966962   time:  1.402733564376831
e:  5   train_loss:  877.1346225787711   time:  1.5199487209320068
e:  5   train_loss:  877.1346225787711   val_loss:  531.28488877533   time:  1.6227853298187256
e:  6   train_loss:  878.9165864572175   time:  1.4959766864776611
e:  7   train_loss:  847.8418148536225   time:  1.3955867290496826
e:  8   train_loss:  804.9692314927371   time:  1.3823959827423096
e:  9   train_loss:  787.2322315954589   time:  1.3776752948760986
e:  10   train_loss:  758.574077396976   time:  1.353097915649414
e:  10   train_loss:  758.574077396976   val_loss:  495.27006925886434   time:  1.4565558433532715
e:  11   train_loss:  725.894910864657   time:  1.5011699199676514
e:  12   train_loss:  714.6962693010365   time:  1.489734411239624
e:  13   train_loss:  693.5743659493259   time:  1.4944961071014404
e:  14   train_loss:  669.5545306428039   time:  1.3893859386444092
e:  15   train_loss:  669.3397488245969   time:  1.3824093341827393
e:  15   train_loss:  669.3397488245969   val_loss:  524.4794093534881   time:  1.4858577251434326
e:  16   train_loss:  678.7135609997813   time:  1.3914949893951416
e:  17   train_loss:  656.3144316288906   time:  1.3833832740783691
e:  18   train_loss:  646.0202328594052   time:  1.3884451389312744
e:  19   train_loss:  645.4334653873724   time:  1.391822099685669
e:  20   train_loss:  655.5135635395956   time:  1.5155863761901855
e:  20   train_loss:  655.5135635395956   val_loss:  520.0573641682569   time:  1.618973970413208
e:  21   train_loss:  663.866009596866   time:  1.3832435607910156
e:  22   train_loss:  621.7612239431853   time:  1.3879666328430176
e:  23   train_loss:  624.9099008463327   time:  1.391228437423706
e:  24   train_loss:  643.9099032569143   time:  1.3903069496154785
e:  25   train_loss:  616.5905542933571   time:  1.3953568935394287
e:  25   train_loss:  616.5905542933571   val_loss:  538.9129092570997   time:  1.5006380081176758
e:  26   train_loss:  608.2920434867281   time:  1.3960247039794922
e:  27   train_loss:  620.0515658485278   time:  1.5185608863830566
e:  28   train_loss:  616.5588607208616   time:  1.38983154296875
e:  29   train_loss:  610.8923372971235   time:  1.3835785388946533
e:  30   train_loss:  629.614070612508   time:  1.3798894882202148
e:  30   train_loss:  629.614070612508   val_loss:  564.7151879247343   time:  1.4830660820007324
e:  31   train_loss:  583.9956840080652   time:  1.3593559265136719
e:  32   train_loss:  590.2562831934233   time:  1.3896162509918213
e:  33   train_loss:  599.7308802588709   time:  1.3861172199249268
e:  34   train_loss:  582.82435644432   time:  1.3909189701080322
e:  35   train_loss:  594.8862797030034   time:  1.520815134048462
e:  35   train_loss:  594.8862797030034   val_loss:  566.353769861587   time:  1.6244993209838867
e:  36   train_loss:  575.6195190849639   time:  1.6479873657226562
e:  37   train_loss:  594.5966839911467   time:  1.6352717876434326
e:  38   train_loss:  573.4442462360986   time:  1.5900273323059082
e:  39   train_loss:  583.0072523841085   time:  1.519428014755249
e:  40   train_loss:  575.9637438665645   time:  1.517759084701538
e:  40   train_loss:  575.9637438665645   val_loss:  540.4763193026879   time:  1.6227831840515137
FOLD:  3
Model initialization done
Model training starts
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  0   train_loss:  999.0085207354609   time:  1.2797787189483643
e:  0   train_loss:  999.0085207354609   val_loss:  915.484194503396   time:  1.3879280090332031
e:  1   train_loss:  992.3544636219729   time:  1.4102680683135986
e:  2   train_loss:  980.5155651694469   time:  1.2837474346160889
e:  3   train_loss:  957.0430110990314   time:  1.2846076488494873
e:  4   train_loss:  905.9857820503976   time:  1.2822527885437012
e:  5   train_loss:  848.2452193659842   time:  1.292206048965454
e:  5   train_loss:  848.2452193659842   val_loss:  742.9977052169086   time:  1.400822639465332
e:  6   train_loss:  824.3211034173755   time:  1.314887523651123
e:  7   train_loss:  817.7161437326052   time:  1.3408679962158203
e:  8   train_loss:  799.5255234999844   time:  1.2862522602081299
e:  9   train_loss:  783.7104186647388   time:  1.291292428970337
e:  10   train_loss:  761.0839104895256   time:  1.2881519794464111
e:  10   train_loss:  761.0839104895256   val_loss:  739.2508386097763   time:  1.520625352859497
e:  11   train_loss:  733.593147568563   time:  1.2552313804626465
e:  12   train_loss:  700.6308615847664   time:  1.2762715816497803
e:  13   train_loss:  679.2426189515485   time:  1.285538673400879
e:  14   train_loss:  658.620038546445   time:  1.3067331314086914
e:  15   train_loss:  642.1530316422269   time:  1.54537034034729
e:  15   train_loss:  642.1530316422269   val_loss:  728.2823733107839   time:  1.654402494430542
e:  16   train_loss:  632.6848922205661   time:  1.319190502166748
e:  17   train_loss:  623.1275761616986   time:  1.3500137329101562
e:  18   train_loss:  619.5300818519047   time:  1.3284142017364502
e:  19   train_loss:  604.2629033227213   time:  1.340533971786499
e:  20   train_loss:  602.4154686012355   time:  1.3323745727539062
e:  20   train_loss:  602.4154686012355   val_loss:  721.7436514290491   time:  1.439971923828125
e:  21   train_loss:  594.2955370573393   time:  1.4938220977783203
e:  22   train_loss:  584.1370133027299   time:  1.3150899410247803
e:  23   train_loss:  579.9000574204731   time:  1.3132944107055664
e:  24   train_loss:  575.7187036653455   time:  1.318206548690796
e:  25   train_loss:  577.7983579154079   time:  1.3264915943145752
e:  25   train_loss:  577.7983579154079   val_loss:  721.8073380722066   time:  1.4345276355743408
e:  26   train_loss:  572.7896251820059   time:  1.3312606811523438
e:  27   train_loss:  563.073207026661   time:  1.3223693370819092
e:  28   train_loss:  564.7932725868652   time:  1.336855173110962
e:  29   train_loss:  558.1136895354584   time:  1.323591709136963
e:  30   train_loss:  553.0613950995078   time:  1.330955982208252
e:  30   train_loss:  553.0613950995078   val_loss:  710.0085744710808   time:  1.4392378330230713
e:  31   train_loss:  553.2837450394233   time:  1.3287570476531982
e:  32   train_loss:  547.6037931242047   time:  1.3297677040100098
e:  33   train_loss:  548.4027134728999   time:  1.4609503746032715
e:  34   train_loss:  543.1932412001862   time:  1.3234291076660156
e:  35   train_loss:  545.4595650828892   time:  1.3314557075500488
e:  35   train_loss:  545.4595650828892   val_loss:  711.2440526152974   time:  1.4401402473449707
e:  36   train_loss:  540.6100080055197   time:  1.3258171081542969
e:  37   train_loss:  540.0071103855087   time:  1.335963249206543
e:  38   train_loss:  540.2967625192957   time:  1.3240830898284912
e:  39   train_loss:  533.6773823663502   time:  1.3275535106658936
e:  40   train_loss:  532.4790075949959   time:  1.328317403793335
e:  40   train_loss:  532.4790075949959   val_loss:  714.5651044436909   time:  1.4363353252410889
e:  41   train_loss:  536.5185874109854   time:  1.3411121368408203
e:  42   train_loss:  528.674975294734   time:  1.335444688796997
e:  43   train_loss:  532.0738311197339   time:  1.326939582824707
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  44   train_loss:  531.6893770037093   time:  1.3301668167114258
e:  45   train_loss:  527.2686479926332   time:  1.3611862659454346
e:  45   train_loss:  527.2686479926332   val_loss:  717.4670086724353   time:  1.6275076866149902
e:  46   train_loss:  525.0963124123995   time:  1.335791826248169
e:  47   train_loss:  526.4624910575349   time:  1.3280932903289795
e:  48   train_loss:  521.2036012630145   time:  1.3269872665405273
e:  49   train_loss:  521.7090616643836   time:  1.3320577144622803
e:  50   train_loss:  518.6260082408231   time:  1.3260369300842285
e:  50   train_loss:  518.6260082408231   val_loss:  715.2870817556352   time:  1.4341115951538086
e:  51   train_loss:  521.1988554073523   time:  1.3435437679290771
e:  52   train_loss:  525.0090440289295   time:  1.3303380012512207
e:  53   train_loss:  515.48219096175   time:  1.3295156955718994
e:  54   train_loss:  516.5060490758632   time:  1.3192024230957031
e:  55   train_loss:  513.3525114819878   time:  1.4981989860534668
e:  55   train_loss:  513.3525114819878   val_loss:  721.9580797836362   time:  1.6064071655273438
e:  56   train_loss:  513.3755338680282   time:  1.3268036842346191
e:  57   train_loss:  512.5997678046459   time:  1.3687615394592285
e:  58   train_loss:  508.10104818982336   time:  1.3397107124328613
e:  59   train_loss:  507.4156983838483   time:  1.3506290912628174
e:  60   train_loss:  503.89379901106895   time:  1.3296399116516113
e:  60   train_loss:  503.89379901106895   val_loss:  722.3988513666799   time:  1.438354730606079
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1071.0513751526616   time:  1.452024221420288
e:  0   train_loss:  1071.0513751526616   val_loss:  689.1551005683291   time:  1.555159091949463
e:  1   train_loss:  1064.785261829291   time:  1.469620943069458
e:  2   train_loss:  1044.4410503280078   time:  1.5383124351501465
e:  3   train_loss:  1017.9988874469905   time:  1.5020864009857178
e:  4   train_loss:  950.6345133159599   time:  1.4443597793579102
e:  5   train_loss:  886.6975215169953   time:  1.4899609088897705
e:  5   train_loss:  886.6975215169953   val_loss:  555.8187793988836   time:  1.592923641204834
e:  6   train_loss:  883.5556419632226   time:  1.4619262218475342
e:  7   train_loss:  859.5340290138495   time:  1.453124761581421
e:  8   train_loss:  843.7759862580982   time:  1.6448688507080078
e:  9   train_loss:  771.8813303006266   time:  1.4529495239257812
e:  10   train_loss:  737.7729856010708   time:  1.4921553134918213
e:  10   train_loss:  737.7729856010708   val_loss:  563.8342965540235   time:  1.5926415920257568
e:  11   train_loss:  706.6665984637498   time:  1.4859044551849365
e:  12   train_loss:  680.3540404368937   time:  1.4536452293395996
e:  13   train_loss:  681.448443560856   time:  1.4673724174499512
e:  14   train_loss:  659.1135413203651   time:  1.6324541568756104
e:  15   train_loss:  638.9207050173432   time:  1.4601783752441406
e:  15   train_loss:  638.9207050173432   val_loss:  589.5125913719594   time:  1.5615975856781006
e:  16   train_loss:  625.1301040413305   time:  1.4647188186645508
e:  17   train_loss:  623.5667993820498   time:  1.4387199878692627
e:  18   train_loss:  627.214589089648   time:  1.479616403579712
e:  19   train_loss:  615.4395558278643   time:  1.4523890018463135
e:  20   train_loss:  614.2029489665678   time:  1.4771251678466797
e:  20   train_loss:  614.2029489665678   val_loss:  602.3557941988427   time:  1.7501482963562012
e:  21   train_loss:  601.3638543509811   time:  1.4416964054107666
e:  22   train_loss:  619.1045701440049   time:  1.4835114479064941
e:  23   train_loss:  598.7873361952381   time:  1.477367877960205
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  24   train_loss:  603.6215989438239   time:  1.50968599319458
e:  25   train_loss:  593.8941332995314   time:  1.5018951892852783
e:  25   train_loss:  593.8941332995314   val_loss:  592.012300821054   time:  1.6084935665130615
e:  26   train_loss:  599.8464112327114   time:  1.424128532409668
e:  27   train_loss:  588.0172813119289   time:  1.4043824672698975
e:  28   train_loss:  593.586619673812   time:  1.4077231884002686
e:  29   train_loss:  591.359770838116   time:  1.536515474319458
e:  30   train_loss:  587.7124535732831   time:  1.3996174335479736
e:  30   train_loss:  587.7124535732831   val_loss:  598.2629619507004   time:  1.502244234085083
e:  31   train_loss:  576.7382262656122   time:  1.4117786884307861
e:  32   train_loss:  579.5873823350707   time:  1.407945156097412
e:  33   train_loss:  598.6025429974654   time:  1.409515142440796
e:  34   train_loss:  576.2809257303377   time:  1.3839051723480225
e:  35   train_loss:  577.9101406004742   time:  1.5314862728118896
e:  35   train_loss:  577.9101406004742   val_loss:  601.6480720691958   time:  1.6340389251708984
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (1, 0, 5), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (1, 0, 5) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 5) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 5) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (1, 0, 5)
kwargs: {'config': {'batch_norm': True, 'ff_0': 28, 'ff_num_layers': 1, 'gnn_0': 89, 'gnn_dropout': 0.10641623199340061, 'gnn_num_layers': 1, 'hid_0': 523, 'hid_dropout_rate': 0.013411139819705098, 'in_dropout_rate': 0.3926441083649277, 'lr': 0.00011123578317406136, 'num_hid_layers': 3, 'optimizer': 'Adam', 'hid_1': 149, 'hid_2': 1121}, 'budget': 81.0, 'working_directory': '.'}
result: {'loss': 747.1327055644537, 'n_epochs': 44.0, 'info': {'validation loss': 747.1327055644537}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 5) started
DEBUG:hpbandster:job_callback for (1, 0, 5) got condition
DEBUG:hpbandster:Only 15 run(s) for budget 81.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (1, 0, 5) finished
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: trying submitting job (1, 0, 6) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 6) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 6)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 6) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 6) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (1, 0, 6)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 41, 'ff_num_layers': 3, 'gnn_0': 491, 'gnn_dropout': 0.23868205655955999, 'gnn_num_layers': 1, 'hid_0': 167, 'hid_dropout_rate': 0.28531407445078205, 'in_dropout_rate': 0.2139208235378634, 'lr': 0.00016620403527456542, 'num_hid_layers': 3, 'optimizer': 'SGD', 'ff_1': 116, 'ff_2': 149, 'hid_1': 143, 'hid_2': 95, 'sgd_momentum': 0.11676690229995361}, 'budget': 81.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  703.4741529483422   time:  1.264371395111084
e:  0   train_loss:  703.4741529483422   val_loss:  1669.3686555078798   time:  1.370941400527954
e:  1   train_loss:  702.0497672184856   time:  1.2708494663238525
e:  2   train_loss:  701.721470660842   time:  1.2622640132904053
e:  3   train_loss:  700.2818750899228   time:  1.239140272140503
e:  4   train_loss:  698.5595711199078   time:  1.2646570205688477
e:  5   train_loss:  698.670084077624   time:  1.2668533325195312
e:  5   train_loss:  698.670084077624   val_loss:  1660.9747558389859   time:  1.3731417655944824
e:  6   train_loss:  697.0889132701042   time:  1.418222188949585
e:  7   train_loss:  695.8485086486713   time:  1.242241382598877
e:  8   train_loss:  694.6608888394742   time:  1.2883775234222412
e:  9   train_loss:  693.6630906219201   time:  1.2896332740783691
e:  10   train_loss:  692.9005125373254   time:  1.2905299663543701
e:  10   train_loss:  692.9005125373254   val_loss:  1651.0196294014693   time:  1.3995351791381836
e:  11   train_loss:  691.8995762022518   time:  1.2884447574615479
e:  12   train_loss:  690.0988825008219   time:  1.2873730659484863
e:  13   train_loss:  688.0597901589541   time:  1.287996530532837
e:  14   train_loss:  686.7409399230725   time:  1.2857835292816162
e:  15   train_loss:  685.3112043830048   time:  1.2812144756317139
e:  15   train_loss:  685.3112043830048   val_loss:  1636.484448950466   time:  1.3898429870605469
e:  16   train_loss:  682.8074640825313   time:  1.2883501052856445
e:  17   train_loss:  680.0011679305637   time:  1.2875041961669922
e:  18   train_loss:  676.5189659843471   time:  1.282177209854126
e:  19   train_loss:  672.3019609641135   time:  1.450082778930664
e:  20   train_loss:  666.2986071333507   time:  1.2818915843963623
e:  20   train_loss:  666.2986071333507   val_loss:  1598.1552853174405   time:  1.3898119926452637
e:  21   train_loss:  657.237006908133   time:  1.2764666080474854
e:  22   train_loss:  644.4738121244026   time:  1.2833263874053955
e:  23   train_loss:  626.4136916605439   time:  1.2816412448883057
e:  24   train_loss:  606.6789135805808   time:  1.2865393161773682
e:  25   train_loss:  582.8948262123407   time:  1.27498197555542
e:  25   train_loss:  582.8948262123407   val_loss:  1400.3857283812308   time:  1.384263277053833
e:  26   train_loss:  575.8684339832494   time:  1.2725520133972168
e:  27   train_loss:  562.3388701549279   time:  1.284379243850708
e:  28   train_loss:  547.2612229203119   time:  1.2813520431518555
e:  29   train_loss:  529.3434236356052   time:  1.4298396110534668
e:  30   train_loss:  513.7591608471934   time:  1.2859854698181152
e:  30   train_loss:  513.7591608471934   val_loss:  1433.0089207092408   time:  1.394895315170288
e:  31   train_loss:  497.0478035699492   time:  1.2803287506103516
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  32   train_loss:  494.8507844147235   time:  1.2839717864990234
e:  33   train_loss:  494.30787623291025   time:  1.2747211456298828
e:  34   train_loss:  478.5212979936537   time:  1.2949540615081787
e:  35   train_loss:  481.1363470399989   time:  1.2838830947875977
e:  35   train_loss:  481.1363470399989   val_loss:  1369.1518315454957   time:  1.3926010131835938
e:  36   train_loss:  477.942835465356   time:  1.2901909351348877
e:  37   train_loss:  473.8247630071831   time:  1.2689244747161865
e:  38   train_loss:  469.15108734604655   time:  1.45747709274292
e:  39   train_loss:  462.2945823673038   time:  1.268712043762207
e:  40   train_loss:  465.85772561249735   time:  1.2853212356567383
e:  40   train_loss:  465.85772561249735   val_loss:  1356.8302286168725   time:  1.3935999870300293
e:  41   train_loss:  465.86631952950165   time:  1.275538444519043
e:  42   train_loss:  459.8822173067953   time:  1.270611047744751
e:  43   train_loss:  460.79659576205233   time:  1.28305983543396
e:  44   train_loss:  460.23958069215723   time:  1.2585959434509277
e:  45   train_loss:  461.318416332439   time:  1.2823152542114258
e:  45   train_loss:  461.318416332439   val_loss:  1410.5712174498303   time:  1.3911848068237305
e:  46   train_loss:  456.36118244017774   time:  1.4262206554412842
e:  47   train_loss:  459.26169776658594   time:  1.287276029586792
e:  48   train_loss:  455.8973386852682   time:  1.282679796218872
e:  49   train_loss:  455.6551797086301   time:  1.2884094715118408
e:  50   train_loss:  450.2664506926118   time:  1.274461269378662
e:  50   train_loss:  450.2664506926118   val_loss:  1604.2490564159111   time:  1.3838486671447754
e:  51   train_loss:  453.9347669255832   time:  1.2897069454193115
e:  52   train_loss:  454.9224375935978   time:  1.290715217590332
e:  53   train_loss:  452.6758011242228   time:  1.2842133045196533
e:  54   train_loss:  455.8411338276587   time:  1.2821261882781982
e:  55   train_loss:  453.8948231432221   time:  1.2859992980957031
e:  55   train_loss:  453.8948231432221   val_loss:  1454.2992224339685   time:  1.5576937198638916
e:  56   train_loss:  449.826047481367   time:  1.26926589012146
e:  57   train_loss:  449.0418699680949   time:  1.2758371829986572
e:  58   train_loss:  450.65128307064424   time:  1.2803521156311035
e:  59   train_loss:  447.8846084471513   time:  1.2827401161193848
e:  60   train_loss:  451.6088398829801   time:  1.278980016708374
e:  60   train_loss:  451.6088398829801   val_loss:  1432.7404877770418   time:  1.3876416683197021
e:  61   train_loss:  449.51466282264096   time:  1.2800297737121582
e:  62   train_loss:  447.15805330695383   time:  1.2787699699401855
e:  63   train_loss:  449.0142446081318   time:  1.284297227859497
e:  64   train_loss:  446.92790766837675   time:  1.2891955375671387
e:  65   train_loss:  446.12298082800123   time:  1.2680566310882568
e:  65   train_loss:  446.12298082800123   val_loss:  1415.4416424104268   time:  1.3763048648834229
e:  66   train_loss:  445.4548242133693   time:  1.4438095092773438
e:  67   train_loss:  445.4602970951209   time:  1.263092041015625
e:  68   train_loss:  444.79465448744634   time:  1.2783284187316895
e:  69   train_loss:  443.5087188986583   time:  1.2965419292449951
e:  70   train_loss:  445.701915101454   time:  1.2800579071044922
e:  70   train_loss:  445.701915101454   val_loss:  1389.906274967764   time:  1.3888907432556152
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1092.8938461581895   time:  1.3974618911743164
e:  0   train_loss:  1092.8938461581895   val_loss:  627.4196566684234   time:  1.5003466606140137
e:  1   train_loss:  1089.3707089266543   time:  1.4072659015655518
e:  2   train_loss:  1064.5944193558964   time:  1.4018166065216064
e:  3   train_loss:  1071.042794554015   time:  1.5435149669647217
e:  4   train_loss:  1082.0005413905444   time:  1.3952605724334717
e:  5   train_loss:  1083.8134662604023   time:  1.403282642364502
e:  5   train_loss:  1083.8134662604023   val_loss:  620.8571817271679   time:  1.504880666732788
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  6   train_loss:  1088.5992583385678   time:  1.4088170528411865
e:  7   train_loss:  1080.008067157624   time:  1.4024055004119873
e:  8   train_loss:  1056.4485816021827   time:  1.3988497257232666
e:  9   train_loss:  1062.6754630859068   time:  1.3692677021026611
e:  10   train_loss:  1061.3456269662622   time:  1.5833542346954346
e:  10   train_loss:  1061.3456269662622   val_loss:  611.9093626769155   time:  1.6834633350372314
e:  11   train_loss:  1058.1075694517583   time:  1.3884356021881104
e:  12   train_loss:  1062.5475915482316   time:  1.3932280540466309
e:  13   train_loss:  1052.7292140935401   time:  1.373586654663086
e:  14   train_loss:  1021.167272578093   time:  1.3849451541900635
e:  15   train_loss:  1031.8508862541348   time:  1.3769793510437012
e:  15   train_loss:  1031.8508862541348   val_loss:  582.1559739040066   time:  1.4772827625274658
e:  16   train_loss:  980.7357750066227   time:  1.5412993431091309
e:  17   train_loss:  934.8142278603157   time:  1.3667008876800537
e:  18   train_loss:  848.9154501751685   time:  1.3747320175170898
e:  19   train_loss:  787.1191404221703   time:  1.379873275756836
e:  20   train_loss:  707.440106202848   time:  1.379288673400879
e:  20   train_loss:  707.440106202848   val_loss:  980.1454436970041   time:  1.4793548583984375
e:  21   train_loss:  688.9127717612133   time:  1.3880021572113037
e:  22   train_loss:  686.0909593109895   time:  1.3587863445281982
e:  23   train_loss:  659.8668097489144   time:  1.5387036800384521
e:  24   train_loss:  650.8673545263216   time:  1.3801186084747314
e:  25   train_loss:  662.9332876344557   time:  1.3813447952270508
e:  25   train_loss:  662.9332876344557   val_loss:  1143.1344352466042   time:  1.4809460639953613
e:  26   train_loss:  637.5334104583376   time:  1.3785409927368164
e:  27   train_loss:  643.1673213664789   time:  1.377650260925293
e:  28   train_loss:  635.2231554542855   time:  1.3526766300201416
e:  29   train_loss:  654.7632925751013   time:  1.3548955917358398
e:  30   train_loss:  622.050168423946   time:  1.561840295791626
e:  30   train_loss:  622.050168423946   val_loss:  1765.6635417554423   time:  1.6618943214416504
e:  31   train_loss:  623.5253669962418   time:  1.3769853115081787
e:  32   train_loss:  646.660574461935   time:  1.3861072063446045
e:  33   train_loss:  622.4739545051422   time:  1.3735713958740234
e:  34   train_loss:  618.2966033755266   time:  1.3580234050750732
e:  35   train_loss:  624.7019108383884   time:  1.3776626586914062
e:  35   train_loss:  624.7019108383884   val_loss:  741.2302211185207   time:  1.6599361896514893
e:  36   train_loss:  611.8366685962886   time:  1.377626657485962
e:  37   train_loss:  618.3742132209155   time:  1.3442463874816895
e:  38   train_loss:  624.6325318348684   time:  1.3655414581298828
e:  39   train_loss:  613.7682875692824   time:  1.377349853515625
e:  40   train_loss:  618.8497815456071   time:  1.362807035446167
e:  40   train_loss:  618.8497815456071   val_loss:  542.3500500260511   time:  1.462336540222168
e:  41   train_loss:  619.7215275081213   time:  1.5469608306884766
e:  42   train_loss:  622.487958622912   time:  1.3611228466033936
e:  43   train_loss:  611.7611229525776   time:  1.3829987049102783
e:  44   train_loss:  619.1664876339408   time:  1.3715698719024658
e:  45   train_loss:  616.2334123583273   time:  1.3816535472869873
e:  45   train_loss:  616.2334123583273   val_loss:  841.2305991879352   time:  1.4813714027404785
e:  46   train_loss:  599.0405379773085   time:  1.380666732788086
e:  47   train_loss:  604.9132496878696   time:  1.3822531700134277
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  48   train_loss:  600.948052398306   time:  1.5637753009796143
e:  49   train_loss:  604.7994586975542   time:  1.3756325244903564
e:  50   train_loss:  596.7159434208298   time:  1.3808813095092773
e:  50   train_loss:  596.7159434208298   val_loss:  582.095950034828   time:  1.4812486171722412
e:  51   train_loss:  587.2909715302427   time:  1.3819620609283447
e:  52   train_loss:  606.2316170798032   time:  1.3650414943695068
e:  53   train_loss:  591.4540339965469   time:  1.377333641052246
e:  54   train_loss:  602.0467057287401   time:  1.3963494300842285
e:  55   train_loss:  603.0068559508961   time:  1.5484840869903564
e:  55   train_loss:  603.0068559508961   val_loss:  552.7589506387799   time:  1.64790678024292
e:  56   train_loss:  596.6509748322268   time:  1.3573212623596191
e:  57   train_loss:  605.5043610788097   time:  1.3427238464355469
e:  58   train_loss:  606.6397751338047   time:  1.3760099411010742
e:  59   train_loss:  600.45500580051   time:  1.348912000656128
e:  60   train_loss:  592.0197078924115   time:  1.388455867767334
e:  60   train_loss:  592.0197078924115   val_loss:  565.1035433932336   time:  1.488091230392456
e:  61   train_loss:  591.9206655435032   time:  1.5460317134857178
e:  62   train_loss:  596.5828189614991   time:  1.3635530471801758
e:  63   train_loss:  600.4107113803158   time:  1.3756990432739258
e:  64   train_loss:  605.9270157961466   time:  1.376002550125122
e:  65   train_loss:  598.6740655601062   time:  1.3576231002807617
e:  65   train_loss:  598.6740655601062   val_loss:  568.377410985908   time:  1.4578711986541748
e:  66   train_loss:  591.5283641243539   time:  1.3875205516815186
e:  67   train_loss:  592.5249787492763   time:  1.3800179958343506
e:  68   train_loss:  595.4006703058163   time:  1.5281248092651367
e:  69   train_loss:  617.4545730378366   time:  1.38431715965271
e:  70   train_loss:  598.7100162908905   time:  1.3596937656402588
e:  70   train_loss:  598.7100162908905   val_loss:  679.7920555095717   time:  1.4589250087738037
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1098.2425602313133   time:  1.3576288223266602
e:  0   train_loss:  1098.2425602313133   val_loss:  539.7298690666612   time:  1.4596607685089111
e:  1   train_loss:  1076.9446600333185   time:  1.340343952178955
e:  2   train_loss:  1084.3081574448863   time:  1.3678247928619385
e:  3   train_loss:  1122.585835045477   time:  1.3629109859466553
e:  4   train_loss:  1081.763602283373   time:  1.5636582374572754
e:  5   train_loss:  1100.8361896817885   time:  1.355973243713379
e:  5   train_loss:  1100.8361896817885   val_loss:  533.7303848776688   time:  1.4586501121520996
e:  6   train_loss:  1091.3339362168776   time:  1.366673469543457
e:  7   train_loss:  1048.7760767166526   time:  1.3661165237426758
e:  8   train_loss:  1098.1924551875454   time:  1.3493094444274902
e:  9   train_loss:  1047.96391317043   time:  1.3539674282073975
e:  10   train_loss:  1068.4767284620584   time:  1.3669612407684326
e:  10   train_loss:  1068.4767284620584   val_loss:  525.5445446052919   time:  1.4711699485778809
e:  11   train_loss:  1067.6033161668447   time:  1.550074815750122
e:  12   train_loss:  1074.696342637235   time:  1.3619322776794434
e:  13   train_loss:  1013.3631150054435   time:  1.3611502647399902
e:  14   train_loss:  1024.5156153348473   time:  1.3575093746185303
e:  15   train_loss:  1016.8241917463145   time:  1.3716199398040771
e:  15   train_loss:  1016.8241917463145   val_loss:  475.5228283431702   time:  1.4740016460418701
e:  16   train_loss:  904.7612703885156   time:  1.3700897693634033
e:  17   train_loss:  767.0531355771082   time:  1.3604977130889893
e:  18   train_loss:  713.1269475310097   time:  1.3828065395355225
e:  19   train_loss:  689.4157240732898   time:  1.5548043251037598
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  20   train_loss:  682.1514676805202   time:  1.3639988899230957
e:  20   train_loss:  682.1514676805202   val_loss:  649.0820990896901   time:  1.4659512042999268
e:  21   train_loss:  696.4226954810464   time:  1.3696372509002686
e:  22   train_loss:  694.3342428508885   time:  1.3706130981445312
e:  23   train_loss:  658.0573494455957   time:  1.3678703308105469
e:  24   train_loss:  667.1947065129139   time:  1.368725061416626
e:  25   train_loss:  657.7497699538734   time:  1.366645097732544
e:  25   train_loss:  657.7497699538734   val_loss:  708.4453357751814   time:  1.4702668190002441
e:  26   train_loss:  648.7757333443509   time:  1.513578176498413
e:  27   train_loss:  657.0502212364835   time:  1.3532805442810059
e:  28   train_loss:  645.2863336093266   time:  1.3581602573394775
e:  29   train_loss:  662.6529760904571   time:  1.3673655986785889
e:  30   train_loss:  641.7985144945151   time:  1.3392438888549805
e:  30   train_loss:  641.7985144945151   val_loss:  734.2695381279729   time:  1.4410302639007568
e:  31   train_loss:  644.4342424021445   time:  1.3625922203063965
e:  32   train_loss:  643.8218931769183   time:  1.3537483215332031
e:  33   train_loss:  692.4607672832528   time:  1.5112841129302979
e:  34   train_loss:  683.5776752333536   time:  1.361170768737793
e:  35   train_loss:  661.6988026984023   time:  1.3678581714630127
e:  35   train_loss:  661.6988026984023   val_loss:  626.2370833524595   time:  1.4695966243743896
e:  36   train_loss:  678.0858669220119   time:  1.3593933582305908
e:  37   train_loss:  635.7236263387513   time:  1.3522257804870605
e:  38   train_loss:  620.7633517813483   time:  1.3535890579223633
e:  39   train_loss:  630.5818675776428   time:  1.3686420917510986
e:  40   train_loss:  643.7082188822069   time:  1.370232343673706
e:  40   train_loss:  643.7082188822069   val_loss:  927.4187848684847   time:  1.4726088047027588
e:  41   train_loss:  647.4435362565154   time:  1.540069341659546
e:  42   train_loss:  665.676765471255   time:  1.3593943119049072
e:  43   train_loss:  634.9576889049177   time:  1.3558862209320068
e:  44   train_loss:  640.1754760997039   time:  1.3518333435058594
e:  45   train_loss:  615.5184862620678   time:  1.355865478515625
e:  45   train_loss:  615.5184862620678   val_loss:  526.0318053194476   time:  1.458465814590454
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  1001.1440669574175   time:  1.2511932849884033
e:  0   train_loss:  1001.1440669574175   val_loss:  917.8934323377692   time:  1.35691499710083
e:  1   train_loss:  999.9758921021762   time:  1.2669525146484375
e:  2   train_loss:  998.7387163078163   time:  1.2573893070220947
e:  3   train_loss:  996.3379435810888   time:  1.2642130851745605
e:  4   train_loss:  995.1369976608648   time:  1.2694118022918701
e:  5   train_loss:  991.5835248784151   time:  1.2719364166259766
e:  5   train_loss:  991.5835248784151   val_loss:  910.7950667719873   time:  1.37760329246521
e:  6   train_loss:  990.5837592628062   time:  1.4097716808319092
e:  7   train_loss:  987.9031567289625   time:  1.2477662563323975
e:  8   train_loss:  989.9478727519647   time:  1.265718936920166
e:  9   train_loss:  986.2612663696598   time:  1.2681517601013184
e:  10   train_loss:  986.7861029807045   time:  1.268589735031128
e:  10   train_loss:  986.7861029807045   val_loss:  902.419002564141   time:  1.375605583190918
e:  11   train_loss:  982.126330810868   time:  1.246511459350586
e:  12   train_loss:  977.3954833747129   time:  1.2655248641967773
e:  13   train_loss:  976.9368501478153   time:  1.2663605213165283
e:  14   train_loss:  975.2700432219322   time:  1.2669811248779297
e:  15   train_loss:  968.7964119551874   time:  1.4500110149383545
e:  15   train_loss:  968.7964119551874   val_loss:  886.8667692115309   time:  1.5489428043365479
e:  16   train_loss:  964.7697559488739   time:  1.2517235279083252
e:  17   train_loss:  954.7257092122777   time:  1.2696645259857178
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  18   train_loss:  937.748920861262   time:  1.2782433032989502
e:  19   train_loss:  908.897327642306   time:  1.2469127178192139
e:  20   train_loss:  853.2090839134818   time:  1.2685291767120361
e:  20   train_loss:  853.2090839134818   val_loss:  759.3741008670861   time:  1.3753819465637207
e:  21   train_loss:  781.5630186036249   time:  1.260469675064087
e:  22   train_loss:  696.090870102637   time:  1.2676146030426025
e:  23   train_loss:  651.0502451971516   time:  1.2272658348083496
e:  24   train_loss:  643.9652723344892   time:  1.4482204914093018
e:  25   train_loss:  629.6144201022954   time:  1.265545129776001
e:  25   train_loss:  629.6144201022954   val_loss:  1300.9742242052391   time:  1.3717992305755615
e:  26   train_loss:  605.167565652861   time:  1.2703335285186768
e:  27   train_loss:  615.6486660677373   time:  1.2603623867034912
e:  28   train_loss:  606.6380313706364   time:  1.2414088249206543
e:  29   train_loss:  591.4019125328293   time:  1.2436003684997559
e:  30   train_loss:  591.8350967614119   time:  1.2594678401947021
e:  30   train_loss:  591.8350967614119   val_loss:  1488.6045588066906   time:  1.365818977355957
e:  31   train_loss:  593.9395940894536   time:  1.2571816444396973
e:  32   train_loss:  594.1557723432426   time:  1.262765645980835
e:  33   train_loss:  596.0804786189044   time:  1.2682819366455078
e:  34   train_loss:  583.8861496013525   time:  1.2568457126617432
e:  35   train_loss:  594.2809504894698   time:  1.4322056770324707
e:  35   train_loss:  594.2809504894698   val_loss:  6700.399495112115   time:  1.5391976833343506
e:  36   train_loss:  594.2283134541261   time:  1.2406034469604492
e:  37   train_loss:  588.5070928369597   time:  1.255871057510376
e:  38   train_loss:  579.6761534569029   time:  1.270951747894287
e:  39   train_loss:  579.5615853672467   time:  1.2502977848052979
e:  40   train_loss:  576.0722709396427   time:  1.2745254039764404
e:  40   train_loss:  576.0722709396427   val_loss:  750.9364731813728   time:  1.381486177444458
e:  41   train_loss:  570.3939096271846   time:  1.2606432437896729
e:  42   train_loss:  581.7580080288194   time:  1.2713918685913086
e:  43   train_loss:  585.4863129669117   time:  1.2620811462402344
e:  44   train_loss:  583.2881686635674   time:  1.4504539966583252
e:  45   train_loss:  576.5432552624749   time:  1.2519104480743408
e:  45   train_loss:  576.5432552624749   val_loss:  780.4834077470953   time:  1.3599300384521484
e:  46   train_loss:  582.8305635637317   time:  1.30379056930542
e:  47   train_loss:  572.5777348566634   time:  1.4375286102294922
e:  48   train_loss:  576.4277989065306   time:  1.2540185451507568
e:  49   train_loss:  567.5624147379509   time:  1.2589106559753418
e:  50   train_loss:  567.6684183840275   time:  1.25111985206604
e:  50   train_loss:  567.6684183840275   val_loss:  755.9978660991666   time:  1.3572680950164795
e:  51   train_loss:  564.8324696901243   time:  1.2500050067901611
e:  52   train_loss:  571.6868092971041   time:  1.2515819072723389
e:  53   train_loss:  569.9752519462442   time:  1.449958086013794
e:  54   train_loss:  579.9295149172564   time:  1.284144639968872
e:  55   train_loss:  573.7643456045696   time:  1.286146640777588
e:  55   train_loss:  573.7643456045696   val_loss:  742.9908026563573   time:  1.3956539630889893
e:  56   train_loss:  566.4128381644869   time:  1.2877180576324463
e:  57   train_loss:  559.6787175035072   time:  1.283959150314331
e:  58   train_loss:  571.2023181029584   time:  1.2802255153656006
e:  59   train_loss:  575.195905854436   time:  1.277059555053711
e:  60   train_loss:  564.097222386227   time:  1.289597988128662
e:  60   train_loss:  564.097222386227   val_loss:  734.9754669762057   time:  1.3975656032562256
e:  61   train_loss:  566.3031589740477   time:  1.242696762084961
e:  62   train_loss:  568.5107368401812   time:  1.2669312953948975
e:  63   train_loss:  566.4254690311845   time:  1.2738747596740723
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  64   train_loss:  563.1046698021318   time:  1.3574724197387695
e:  65   train_loss:  563.5313390984451   time:  1.2209630012512207
e:  65   train_loss:  563.5313390984451   val_loss:  818.3364011632995   time:  1.4558401107788086
e:  66   train_loss:  561.3051926020186   time:  1.2723572254180908
e:  67   train_loss:  568.8728205703479   time:  1.2581992149353027
e:  68   train_loss:  563.4464902489757   time:  1.252725601196289
e:  69   train_loss:  559.8454954807239   time:  1.2629308700561523
e:  70   train_loss:  564.629227802542   time:  1.2572705745697021
e:  70   train_loss:  564.629227802542   val_loss:  738.1533029429012   time:  1.3657257556915283
e:  71   train_loss:  560.6956866382089   time:  1.2550513744354248
e:  72   train_loss:  559.7255187101777   time:  1.246654748916626
e:  73   train_loss:  565.029317763169   time:  1.2550394535064697
e:  74   train_loss:  565.0345090947671   time:  1.4325792789459229
e:  75   train_loss:  560.5445261495521   time:  1.21992826461792
e:  75   train_loss:  560.5445261495521   val_loss:  743.5487117652955   time:  1.31953763961792
e:  76   train_loss:  562.6920583251485   time:  1.246870517730713
e:  77   train_loss:  560.4823325514088   time:  1.2461528778076172
e:  78   train_loss:  560.4306492673121   time:  1.2511579990386963
e:  79   train_loss:  561.509478566963   time:  1.2517261505126953
e:  80   train_loss:  562.6079493528881   time:  1.2505016326904297
e:  80   train_loss:  562.6079493528881   val_loss:  727.5130445537912   time:  1.3586337566375732
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1065.90422486633   time:  1.3607196807861328
e:  0   train_loss:  1065.90422486633   val_loss:  692.6926862798858   time:  1.4631004333496094
e:  1   train_loss:  1072.6918071424643   time:  1.3723618984222412
e:  2   train_loss:  1087.211271476278   time:  1.360459804534912
e:  3   train_loss:  1086.1594669643189   time:  1.5287950038909912
e:  4   train_loss:  1062.3743504162503   time:  1.3661179542541504
e:  5   train_loss:  1069.6825230802117   time:  1.362633228302002
e:  5   train_loss:  1069.6825230802117   val_loss:  685.6114888046789   time:  1.464698076248169
e:  6   train_loss:  1060.9693451219146   time:  1.3676042556762695
e:  7   train_loss:  1059.4282635457498   time:  1.366809606552124
e:  8   train_loss:  1087.197209327876   time:  1.3619630336761475
e:  9   train_loss:  1047.2659922472246   time:  1.3694071769714355
e:  10   train_loss:  1065.8117644701827   time:  1.5402956008911133
e:  10   train_loss:  1065.8117644701827   val_loss:  678.1306562825526   time:  1.6439714431762695
e:  11   train_loss:  1075.472753738052   time:  1.353003740310669
e:  12   train_loss:  1057.608283251255   time:  1.3707211017608643
e:  13   train_loss:  1070.986102919528   time:  1.363086223602295
e:  14   train_loss:  1069.0706258046184   time:  1.3501806259155273
e:  15   train_loss:  1052.6011564559515   time:  1.3651366233825684
e:  15   train_loss:  1052.6011564559515   val_loss:  666.7498254841933   time:  1.6163973808288574
e:  16   train_loss:  1031.1484655502927   time:  1.360886573791504
e:  17   train_loss:  1041.639819988041   time:  1.364530086517334
e:  18   train_loss:  1045.860584198474   time:  1.3702952861785889
e:  19   train_loss:  1012.5265943894806   time:  1.367452621459961
e:  20   train_loss:  983.2882100974667   time:  1.3531811237335205
e:  20   train_loss:  983.2882100974667   val_loss:  571.9484439840313   time:  1.454789161682129
e:  21   train_loss:  926.7578005790167   time:  1.364896297454834
e:  22   train_loss:  843.6297631318961   time:  1.5220789909362793
e:  23   train_loss:  750.077428965425   time:  1.3652527332305908
e:  24   train_loss:  706.4339607065205   time:  1.3660132884979248
e:  25   train_loss:  681.4410947290255   time:  1.3680670261383057
e:  25   train_loss:  681.4410947290255   val_loss:  595.7906639951639   time:  1.4715721607208252
e:  26   train_loss:  697.2503829479126   time:  1.3715591430664062
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  27   train_loss:  674.0095981881344   time:  1.3713698387145996
e:  28   train_loss:  681.3009211301691   time:  1.5368897914886475
e:  29   train_loss:  654.5384005928988   time:  1.364758014678955
e:  30   train_loss:  665.0232428306066   time:  1.3628566265106201
e:  30   train_loss:  665.0232428306066   val_loss:  2190.7142564923975   time:  1.4656982421875
e:  31   train_loss:  651.2059333934426   time:  1.3655500411987305
e:  32   train_loss:  639.5070198072366   time:  1.3580164909362793
e:  33   train_loss:  647.3436514173308   time:  1.367537260055542
e:  34   train_loss:  633.1959409424496   time:  1.360783576965332
e:  35   train_loss:  641.6588898795885   time:  1.5292322635650635
e:  35   train_loss:  641.6588898795885   val_loss:  651.072811814236   time:  1.6313424110412598
e:  36   train_loss:  631.4094919186279   time:  1.3565335273742676
e:  37   train_loss:  628.0162245625239   time:  1.3537359237670898
e:  38   train_loss:  625.5621795305432   time:  1.3463504314422607
e:  39   train_loss:  639.765190830077   time:  1.3685259819030762
e:  40   train_loss:  618.7472167309136   time:  1.3660871982574463
e:  40   train_loss:  618.7472167309136   val_loss:  593.242168020851   time:  1.4690277576446533
e:  41   train_loss:  626.2410271073725   time:  1.3760225772857666
e:  42   train_loss:  614.4855688678501   time:  1.526632308959961
e:  43   train_loss:  631.3714008123812   time:  1.3695576190948486
e:  44   train_loss:  620.9941557258652   time:  1.358307123184204
e:  45   train_loss:  621.3632975619157   time:  1.3661561012268066
e:  45   train_loss:  621.3632975619157   val_loss:  1390.315547636004   time:  1.4691686630249023
e:  46   train_loss:  613.5639575432549   time:  1.3624491691589355
e:  47   train_loss:  616.9588397804091   time:  1.3538379669189453
e:  48   train_loss:  614.2933472028457   time:  1.371108055114746
e:  49   train_loss:  623.2689322067854   time:  1.5250577926635742
e:  50   train_loss:  611.1690834905608   time:  1.3660778999328613
e:  50   train_loss:  611.1690834905608   val_loss:  588.4675813748636   time:  1.468801498413086
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (1, 0, 6), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (1, 0, 6) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 6) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 6) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (1, 0, 6)
kwargs: {'config': {'batch_norm': True, 'ff_0': 41, 'ff_num_layers': 3, 'gnn_0': 491, 'gnn_dropout': 0.23868205655955999, 'gnn_num_layers': 1, 'hid_0': 167, 'hid_dropout_rate': 0.28531407445078205, 'in_dropout_rate': 0.2139208235378634, 'lr': 0.00016620403527456542, 'num_hid_layers': 3, 'optimizer': 'SGD', 'ff_1': 116, 'ff_2': 149, 'hid_1': 143, 'hid_2': 95, 'sgd_momentum': 0.11676690229995361}, 'budget': 81.0, 'working_directory': '.'}
result: {'loss': 734.8329191047833, 'n_epochs': 63.2, 'info': {'validation loss': 734.8329191047833}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 6) started
DEBUG:hpbandster:job_callback for (1, 0, 6) got condition
DEBUG:hpbandster:Only 16 run(s) for budget 81.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (1, 0, 6) finished
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: trying submitting job (1, 0, 7) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 7) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 7)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 7) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 7) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (1, 0, 7)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 106, 'ff_num_layers': 2, 'gnn_0': 317, 'gnn_dropout': 0.3368733383678324, 'gnn_num_layers': 1, 'hid_0': 74, 'hid_dropout_rate': 0.29648329598290585, 'in_dropout_rate': 0.04789760399280041, 'lr': 0.0007931206855937558, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 221, 'hid_1': 555, 'hid_2': 1092}, 'budget': 81.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  669.257933915737   time:  1.2341282367706299
e:  0   train_loss:  669.257933915737   val_loss:  1477.7337426222723   time:  1.3400700092315674
e:  1   train_loss:  555.36021658805   time:  1.3243088722229004
e:  2   train_loss:  520.6902449827402   time:  1.242142677307129
e:  3   train_loss:  496.867265108413   time:  1.227445125579834
e:  4   train_loss:  484.7096399962314   time:  1.2277390956878662
e:  5   train_loss:  470.1756488909473   time:  1.2255077362060547
e:  5   train_loss:  470.1756488909473   val_loss:  1603.6530990603542   time:  1.3320424556732178
e:  6   train_loss:  465.44177961138405   time:  1.3394122123718262
e:  7   train_loss:  461.539603679721   time:  1.236802339553833
e:  8   train_loss:  456.9205656069205   time:  1.2887005805969238
e:  9   train_loss:  449.3576795026648   time:  1.3025667667388916
e:  10   train_loss:  447.81251281843737   time:  1.2650611400604248
e:  10   train_loss:  447.81251281843737   val_loss:  1438.0585909657505   time:  1.370828628540039
e:  11   train_loss:  443.8316720882424   time:  1.2588891983032227
e:  12   train_loss:  441.8103776567407   time:  1.2592830657958984
e:  13   train_loss:  438.3712738830072   time:  1.2675518989562988
e:  14   train_loss:  437.5081218766442   time:  1.254464864730835
e:  15   train_loss:  434.94195699009634   time:  1.260634183883667
e:  15   train_loss:  434.94195699009634   val_loss:  1518.9997003145272   time:  1.367687702178955
e:  16   train_loss:  430.28195675274515   time:  1.266420841217041
e:  17   train_loss:  428.361004389961   time:  1.4572575092315674
e:  18   train_loss:  424.5517948020786   time:  1.2466886043548584
e:  19   train_loss:  423.87711144097307   time:  1.2628777027130127
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  20   train_loss:  423.94960177424855   time:  1.2926082611083984
e:  20   train_loss:  423.94960177424855   val_loss:  1436.1402362175386   time:  1.3990514278411865
e:  21   train_loss:  417.2342527704403   time:  1.2597041130065918
e:  22   train_loss:  417.725987925273   time:  1.2594332695007324
e:  23   train_loss:  415.9371327572485   time:  1.2824718952178955
e:  24   train_loss:  407.4155560564006   time:  1.3106763362884521
e:  25   train_loss:  406.80779625349675   time:  1.2293336391448975
e:  25   train_loss:  406.80779625349675   val_loss:  1495.0034781206875   time:  1.3362867832183838
e:  26   train_loss:  404.61987613208123   time:  1.226980209350586
e:  27   train_loss:  402.57046657500405   time:  1.227423906326294
e:  28   train_loss:  399.57584619893106   time:  1.3488690853118896
e:  29   train_loss:  394.18929894806234   time:  1.2199764251708984
e:  30   train_loss:  395.9523656828858   time:  1.2195930480957031
e:  30   train_loss:  395.9523656828858   val_loss:  1458.3120894506596   time:  1.3257412910461426
e:  31   train_loss:  392.22203875220646   time:  1.2142798900604248
e:  32   train_loss:  383.26772909716743   time:  1.2239489555358887
e:  33   train_loss:  377.54435872789173   time:  1.2137417793273926
e:  34   train_loss:  370.8072287301181   time:  1.2278320789337158
e:  35   train_loss:  372.86004080365706   time:  1.2255096435546875
e:  35   train_loss:  372.86004080365706   val_loss:  1427.7719931142187   time:  1.3323817253112793
e:  36   train_loss:  359.56631200943264   time:  1.2333166599273682
e:  37   train_loss:  355.537265639997   time:  1.351034164428711
e:  38   train_loss:  348.5738844602545   time:  1.2084498405456543
e:  39   train_loss:  343.67373510931543   time:  1.2209439277648926
e:  40   train_loss:  338.03656644497096   time:  1.2150530815124512
e:  40   train_loss:  338.03656644497096   val_loss:  1427.7987625139288   time:  1.3225862979888916
e:  41   train_loss:  333.78927159676584   time:  1.3522586822509766
e:  42   train_loss:  329.3742443215659   time:  1.3133599758148193
e:  43   train_loss:  323.9313205324062   time:  1.2140891551971436
e:  44   train_loss:  320.7480284424544   time:  1.2124905586242676
e:  45   train_loss:  311.47847105272166   time:  1.225449562072754
e:  45   train_loss:  311.47847105272166   val_loss:  1341.9474015362096   time:  1.332374095916748
e:  46   train_loss:  308.6353891268457   time:  1.2144482135772705
e:  47   train_loss:  310.4784675800866   time:  1.225322961807251
e:  48   train_loss:  301.1222669230898   time:  1.3454415798187256
e:  49   train_loss:  292.9247760968583   time:  1.204300880432129
e:  50   train_loss:  289.17642791976834   time:  1.21417236328125
e:  50   train_loss:  289.17642791976834   val_loss:  1264.78973061237   time:  1.3207545280456543
e:  51   train_loss:  283.7374283691129   time:  1.7263939380645752
e:  52   train_loss:  277.8169652920352   time:  1.2546679973602295
e:  53   train_loss:  274.5356175768238   time:  1.215665340423584
e:  54   train_loss:  269.2292403883624   time:  1.2010667324066162
e:  55   train_loss:  265.5525315227489   time:  1.2135438919067383
e:  55   train_loss:  265.5525315227489   val_loss:  1245.52131433015   time:  1.3194613456726074
e:  56   train_loss:  259.70371673598527   time:  1.2235023975372314
e:  57   train_loss:  256.93486355076124   time:  1.2222626209259033
e:  58   train_loss:  252.13556569311925   time:  1.2216362953186035
e:  59   train_loss:  247.13188576617117   time:  1.2234373092651367
e:  60   train_loss:  246.61205942238337   time:  1.3365895748138428
e:  60   train_loss:  246.61205942238337   val_loss:  1183.9760411777668   time:  1.435241937637329
e:  61   train_loss:  241.89260755612707   time:  1.2116725444793701
e:  62   train_loss:  238.21211064615517   time:  1.2131810188293457
e:  63   train_loss:  233.05467417706353   time:  1.221832513809204
e:  64   train_loss:  228.21362517771018   time:  1.2230393886566162
e:  65   train_loss:  225.6805983332252   time:  1.2252414226531982
e:  65   train_loss:  225.6805983332252   val_loss:  1257.3784974244284   time:  1.3327782154083252
e:  66   train_loss:  224.03065752766145   time:  1.2234759330749512
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  67   train_loss:  220.6341088071937   time:  1.215395212173462
e:  68   train_loss:  219.11588091240935   time:  1.2196907997131348
e:  69   train_loss:  215.2068623818742   time:  1.2204668521881104
e:  70   train_loss:  214.64606062660786   time:  1.3600115776062012
e:  70   train_loss:  214.64606062660786   val_loss:  1254.3470965518768   time:  1.4587006568908691
e:  71   train_loss:  210.22928733366743   time:  1.2107353210449219
e:  72   train_loss:  208.80031671544438   time:  1.2206206321716309
e:  73   train_loss:  207.28856290164916   time:  1.2169735431671143
e:  74   train_loss:  204.8395568298405   time:  1.2101380825042725
e:  75   train_loss:  202.08915252263083   time:  1.217115879058838
e:  75   train_loss:  202.08915252263083   val_loss:  1329.7944151022646   time:  1.3231987953186035
e:  76   train_loss:  200.8831912453242   time:  1.219862937927246
e:  77   train_loss:  196.58401175819716   time:  1.2153174877166748
e:  78   train_loss:  194.81854106283993   time:  1.4527688026428223
e:  79   train_loss:  191.47928836691608   time:  1.4764559268951416
e:  80   train_loss:  189.79984718667882   time:  1.200850248336792
e:  80   train_loss:  189.79984718667882   val_loss:  1377.7127908039724   time:  1.3064253330230713
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1018.33555164511   time:  1.328920602798462
e:  0   train_loss:  1018.33555164511   val_loss:  539.520278853063   time:  1.4296989440917969
e:  1   train_loss:  745.3092592431533   time:  1.3202953338623047
e:  2   train_loss:  718.7963700012565   time:  1.3346645832061768
e:  3   train_loss:  683.1522923159731   time:  1.3316209316253662
e:  4   train_loss:  665.0927701982952   time:  1.3332364559173584
e:  5   train_loss:  638.7813007593684   time:  1.3351612091064453
e:  5   train_loss:  638.7813007593684   val_loss:  550.0731539772587   time:  1.4349377155303955
e:  6   train_loss:  639.764826558459   time:  1.462446928024292
e:  7   train_loss:  630.6931841442961   time:  1.334521770477295
e:  8   train_loss:  616.9355217772036   time:  1.33028244972229
e:  9   train_loss:  605.9694953369514   time:  1.3220508098602295
e:  10   train_loss:  603.0545580715248   time:  1.327000617980957
e:  10   train_loss:  603.0545580715248   val_loss:  624.5935220807748   time:  1.427438735961914
e:  11   train_loss:  612.3126151549063   time:  1.3348610401153564
e:  12   train_loss:  595.4586241809097   time:  1.4540045261383057
e:  13   train_loss:  607.2269038128131   time:  1.333111047744751
e:  14   train_loss:  591.2026687467367   time:  1.3352653980255127
e:  15   train_loss:  599.8488084308156   time:  1.5884294509887695
e:  15   train_loss:  599.8488084308156   val_loss:  690.999726615244   time:  1.6903045177459717
e:  16   train_loss:  599.8955717352696   time:  1.3252177238464355
e:  17   train_loss:  588.4636800258006   time:  1.328019142150879
e:  18   train_loss:  589.8136737973065   time:  1.435473918914795
e:  19   train_loss:  566.1324523871864   time:  1.3184678554534912
e:  20   train_loss:  562.147295861209   time:  1.3313941955566406
e:  20   train_loss:  562.147295861209   val_loss:  736.7882832082618   time:  1.4311366081237793
e:  21   train_loss:  561.1220765646801   time:  1.3339028358459473
e:  22   train_loss:  550.9820386203551   time:  1.3335309028625488
e:  23   train_loss:  554.7930585826748   time:  1.332709550857544
e:  24   train_loss:  569.4447114460231   time:  1.3221604824066162
e:  25   train_loss:  553.2747337951996   time:  1.464733600616455
e:  25   train_loss:  553.2747337951996   val_loss:  748.3354738830882   time:  1.5648589134216309
e:  26   train_loss:  553.8784461339494   time:  1.3331780433654785
e:  27   train_loss:  552.418789814221   time:  1.3395187854766846
e:  28   train_loss:  554.7090802605625   time:  1.329399824142456
e:  29   train_loss:  535.8683174136063   time:  1.3340117931365967
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
e:  30   train_loss:  536.6618322980099   time:  1.3352172374725342
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  30   train_loss:  536.6618322980099   val_loss:  842.7348833499804   time:  1.437835454940796
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  994.3439006516751   time:  1.4552674293518066
e:  0   train_loss:  994.3439006516751   val_loss:  481.6424588950457   time:  1.5589218139648438
e:  1   train_loss:  802.0182754085163   time:  1.31508207321167
e:  2   train_loss:  732.5792038773844   time:  1.3203887939453125
e:  3   train_loss:  693.7661859136759   time:  1.3208067417144775
e:  4   train_loss:  702.4648892382468   time:  1.3244707584381104
e:  5   train_loss:  643.0125228010313   time:  1.321418285369873
e:  5   train_loss:  643.0125228010313   val_loss:  475.25892508977637   time:  1.4243459701538086
e:  6   train_loss:  650.1703612175728   time:  1.3197307586669922
e:  7   train_loss:  635.8423173521013   time:  1.3334143161773682
e:  8   train_loss:  624.4518494392605   time:  1.45286226272583
e:  9   train_loss:  618.0922417769591   time:  1.3165345191955566
e:  10   train_loss:  619.8499364046179   time:  1.3023433685302734
e:  10   train_loss:  619.8499364046179   val_loss:  680.2678293358246   time:  1.4043552875518799
e:  11   train_loss:  619.0036453082054   time:  1.322176218032837
e:  12   train_loss:  610.6244966261545   time:  1.3201754093170166
e:  13   train_loss:  614.6289097488744   time:  1.3208250999450684
e:  14   train_loss:  601.3927818900671   time:  1.3184142112731934
e:  15   train_loss:  617.5791223998517   time:  1.3303029537200928
e:  15   train_loss:  617.5791223998517   val_loss:  479.94145922387384   time:  1.5574939250946045
e:  16   train_loss:  596.6587124684345   time:  1.4071574211120605
e:  17   train_loss:  598.9760562800445   time:  1.3192453384399414
e:  18   train_loss:  592.3220053656509   time:  1.3153507709503174
e:  19   train_loss:  610.4097672723959   time:  1.3079004287719727
e:  20   train_loss:  624.1747101317742   time:  1.307199239730835
e:  20   train_loss:  624.1747101317742   val_loss:  470.6786293686673   time:  1.4103012084960938
e:  21   train_loss:  624.4655527501716   time:  1.3203284740447998
e:  22   train_loss:  608.1554583027769   time:  1.3095452785491943
e:  23   train_loss:  597.4595153752593   time:  1.4319837093353271
e:  24   train_loss:  589.0906886781944   time:  1.316209316253662
e:  25   train_loss:  569.9742895985369   time:  1.3234565258026123
e:  25   train_loss:  569.9742895985369   val_loss:  483.31992215021086   time:  1.4259819984436035
e:  26   train_loss:  573.8384536556972   time:  1.32365083694458
e:  27   train_loss:  579.4513791297811   time:  1.3172125816345215
e:  28   train_loss:  557.8076151318184   time:  1.4103097915649414
e:  29   train_loss:  588.7267467654167   time:  1.336364984512329
e:  30   train_loss:  553.9786288307844   time:  1.319575548171997
e:  30   train_loss:  553.9786288307844   val_loss:  477.3864800609518   time:  1.4225456714630127
e:  31   train_loss:  564.8992448268039   time:  1.576772928237915
e:  32   train_loss:  557.0408161370243   time:  1.308772325515747
e:  33   train_loss:  561.7788802587069   time:  1.307957410812378
e:  34   train_loss:  572.0899162047634   time:  1.315840244293213
e:  35   train_loss:  570.0422388617709   time:  1.3201966285705566
e:  35   train_loss:  570.0422388617709   val_loss:  551.8638506244531   time:  1.4235546588897705
e:  36   train_loss:  572.6911402999416   time:  1.3110606670379639
e:  37   train_loss:  550.4448370146137   time:  1.3199639320373535
e:  38   train_loss:  554.1746106619544   time:  1.4371328353881836
e:  39   train_loss:  554.6941894644929   time:  1.3195323944091797
e:  40   train_loss:  538.6460615359125   time:  1.3169066905975342
e:  40   train_loss:  538.6460615359125   val_loss:  580.1327477504068   time:  1.4196078777313232
e:  41   train_loss:  541.4750198939664   time:  1.3225066661834717
e:  42   train_loss:  552.0974627449737   time:  1.3113994598388672
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  43   train_loss:  552.6657828312777   time:  1.3206920623779297
e:  44   train_loss:  554.9489081970592   time:  1.3224937915802002
e:  45   train_loss:  534.0764855461963   time:  1.4446465969085693
e:  45   train_loss:  534.0764855461963   val_loss:  679.2508534856462   time:  1.5470144748687744
e:  46   train_loss:  518.4710756512659   time:  1.310290813446045
e:  47   train_loss:  533.6904520652104   time:  1.3157308101654053
e:  48   train_loss:  520.2467261096654   time:  1.3210594654083252
e:  49   train_loss:  526.0419656303909   time:  1.3214447498321533
e:  50   train_loss:  504.62131627124666   time:  1.320833683013916
e:  50   train_loss:  504.62131627124666   val_loss:  523.0402948323124   time:  1.4238955974578857
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  951.0872206323011   time:  1.2100539207458496
e:  0   train_loss:  951.0872206323011   val_loss:  780.4591967380097   time:  1.3171534538269043
e:  1   train_loss:  731.7764717049666   time:  1.3331029415130615
e:  2   train_loss:  676.8183710722485   time:  1.214226245880127
e:  3   train_loss:  646.9445721204613   time:  1.2104425430297852
e:  4   train_loss:  622.4879562851372   time:  1.2159068584442139
e:  5   train_loss:  603.8391259024851   time:  1.2220845222473145
e:  5   train_loss:  603.8391259024851   val_loss:  813.683002614356   time:  1.3294739723205566
e:  6   train_loss:  592.5575776058874   time:  1.21038818359375
e:  7   train_loss:  588.7347480912752   time:  1.2216391563415527
e:  8   train_loss:  586.0668123661252   time:  1.2232534885406494
e:  9   train_loss:  572.0498104060632   time:  1.2231366634368896
e:  10   train_loss:  575.8661148815117   time:  1.3428797721862793
e:  10   train_loss:  575.8661148815117   val_loss:  784.5227464825776   time:  1.4427623748779297
e:  11   train_loss:  565.7750769210959   time:  1.2167880535125732
e:  12   train_loss:  560.6326766248361   time:  1.2217907905578613
e:  13   train_loss:  560.8784197689483   time:  1.2231776714324951
e:  14   train_loss:  553.1188806547405   time:  1.2225892543792725
e:  15   train_loss:  546.6866289168345   time:  1.2243986129760742
e:  15   train_loss:  546.6866289168345   val_loss:  747.9414633718317   time:  1.3321995735168457
e:  16   train_loss:  544.7071201006161   time:  1.217029333114624
e:  17   train_loss:  540.3109447795289   time:  1.2180652618408203
e:  18   train_loss:  538.5633258150652   time:  1.2090375423431396
e:  19   train_loss:  535.2257761305217   time:  1.343982219696045
e:  20   train_loss:  532.6659323913749   time:  1.219822883605957
e:  20   train_loss:  532.6659323913749   val_loss:  794.646058756798   time:  1.3264498710632324
e:  21   train_loss:  526.3334802292196   time:  1.2209515571594238
e:  22   train_loss:  530.3316113650855   time:  1.2247064113616943
e:  23   train_loss:  524.2249055575497   time:  1.2171058654785156
e:  24   train_loss:  522.9653633367466   time:  1.218207836151123
e:  25   train_loss:  530.0356519057316   time:  1.2173714637756348
e:  25   train_loss:  530.0356519057316   val_loss:  727.0770234039361   time:  1.3249006271362305
e:  26   train_loss:  513.4918059745547   time:  1.218775987625122
e:  27   train_loss:  510.3645108258029   time:  1.1958625316619873
e:  28   train_loss:  511.31833509318795   time:  1.216850757598877
e:  29   train_loss:  505.6691088267564   time:  1.2113735675811768
e:  30   train_loss:  515.1306503296174   time:  1.341919183731079
e:  30   train_loss:  515.1306503296174   val_loss:  827.913004497986   time:  1.4497933387756348
e:  31   train_loss:  514.392048537027   time:  1.2144629955291748
e:  32   train_loss:  513.5982526023402   time:  1.2224867343902588
e:  33   train_loss:  514.2586417729442   time:  1.221708059310913
e:  34   train_loss:  499.63205017967204   time:  1.2091588973999023
e:  35   train_loss:  497.5728799579758   time:  1.2279624938964844
e:  35   train_loss:  497.5728799579758   val_loss:  742.3756880250343   time:  1.3359575271606445
e:  36   train_loss:  506.88853842755816   time:  1.2155725955963135
e:  37   train_loss:  496.839058178047   time:  1.2223892211914062
e:  38   train_loss:  492.0030053853046   time:  1.2230198383331299
e:  39   train_loss:  483.05767060297626   time:  1.3409717082977295
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  40   train_loss:  477.61192462813733   time:  1.211794137954712
e:  40   train_loss:  477.61192462813733   val_loss:  740.216558515658   time:  1.3195128440856934
e:  41   train_loss:  476.02107718678565   time:  1.2254552841186523
e:  42   train_loss:  472.3935654081375   time:  1.2239303588867188
e:  43   train_loss:  475.14931909676756   time:  1.212564468383789
e:  44   train_loss:  474.66833773170816   time:  1.2228755950927734
e:  45   train_loss:  467.04125782558964   time:  1.216505527496338
e:  45   train_loss:  467.04125782558964   val_loss:  725.5241127701431   time:  1.3237948417663574
e:  46   train_loss:  459.36534810875185   time:  1.2220983505249023
e:  47   train_loss:  453.8234395247706   time:  1.2121152877807617
e:  48   train_loss:  449.443155140413   time:  1.3486261367797852
e:  49   train_loss:  452.555695595791   time:  1.2221338748931885
e:  50   train_loss:  440.37452233365144   time:  1.2205300331115723
e:  50   train_loss:  440.37452233365144   val_loss:  736.0439331750712   time:  1.327772617340088
e:  51   train_loss:  439.28058895093045   time:  1.2200725078582764
e:  52   train_loss:  427.3604883317072   time:  1.2210912704467773
e:  53   train_loss:  427.7733523137955   time:  1.2107486724853516
e:  54   train_loss:  453.98342811947936   time:  1.21864914894104
e:  55   train_loss:  437.18425154822415   time:  1.2216582298278809
e:  55   train_loss:  437.18425154822415   val_loss:  730.9213524184132   time:  1.3295745849609375
e:  56   train_loss:  437.436174817344   time:  1.2183341979980469
e:  57   train_loss:  425.37430157558424   time:  1.2235338687896729
e:  58   train_loss:  417.65828868122776   time:  1.223357915878296
e:  59   train_loss:  410.2670266318136   time:  1.221496343612671
e:  60   train_loss:  406.7178406311643   time:  1.219076156616211
e:  60   train_loss:  406.7178406311643   val_loss:  745.7314434628659   time:  1.4521331787109375
e:  61   train_loss:  400.38132456266277   time:  1.2242014408111572
e:  62   train_loss:  389.588469080003   time:  1.2201266288757324
e:  63   train_loss:  387.9843401056387   time:  1.2207586765289307
e:  64   train_loss:  380.5305095028388   time:  1.2181973457336426
e:  65   train_loss:  378.0818474745163   time:  1.2175993919372559
e:  65   train_loss:  378.0818474745163   val_loss:  734.0321472425229   time:  1.3254220485687256
e:  66   train_loss:  381.33253067444065   time:  1.224703311920166
e:  67   train_loss:  371.1961539315054   time:  1.2246618270874023
e:  68   train_loss:  375.18784526347156   time:  1.2204298973083496
e:  69   train_loss:  369.01919990010686   time:  1.3444886207580566
e:  70   train_loss:  361.2743548985378   time:  1.2080309391021729
e:  70   train_loss:  361.2743548985378   val_loss:  742.6522292328069   time:  1.3069396018981934
e:  71   train_loss:  352.54721213232204   time:  1.221980333328247
e:  72   train_loss:  348.2048679514999   time:  1.2233622074127197
e:  73   train_loss:  379.8621219034163   time:  1.2240939140319824
e:  74   train_loss:  367.4181655679369   time:  1.2170839309692383
e:  75   train_loss:  368.5690404268031   time:  1.2091546058654785
e:  75   train_loss:  368.5690404268031   val_loss:  750.522936564486   time:  1.3162477016448975
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1013.7185201598191   time:  1.3350577354431152
e:  0   train_loss:  1013.7185201598191   val_loss:  557.3655281918851   time:  1.4359278678894043
e:  1   train_loss:  782.8207429227069   time:  1.3340673446655273
e:  2   train_loss:  703.9006841870266   time:  1.334036111831665
e:  3   train_loss:  695.3553250960097   time:  1.4714539051055908
e:  4   train_loss:  669.2828368823452   time:  1.3241641521453857
e:  5   train_loss:  643.1343062276377   time:  1.333552360534668
e:  5   train_loss:  643.1343062276377   val_loss:  594.7248434731724   time:  1.4354965686798096
e:  6   train_loss:  630.6398429143151   time:  1.3380589485168457
e:  7   train_loss:  631.2862661227231   time:  1.3353614807128906
e:  8   train_loss:  625.0510167604327   time:  1.3369171619415283
e:  9   train_loss:  604.7569545734359   time:  1.3414051532745361
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  10   train_loss:  611.5795720589   time:  1.4752717018127441
e:  10   train_loss:  611.5795720589   val_loss:  600.4106381401647   time:  1.5776219367980957
e:  11   train_loss:  599.3107173112539   time:  1.3256230354309082
e:  12   train_loss:  611.1929313596489   time:  1.3275976181030273
e:  13   train_loss:  617.447488798563   time:  1.3303017616271973
e:  14   train_loss:  596.2736817925703   time:  1.3201093673706055
e:  15   train_loss:  590.5217028420533   time:  1.327402114868164
e:  15   train_loss:  590.5217028420533   val_loss:  639.2151458980019   time:  1.5529766082763672
e:  16   train_loss:  576.3512743579917   time:  1.3334612846374512
e:  17   train_loss:  579.9990134911476   time:  1.333968162536621
e:  18   train_loss:  585.0899718384992   time:  1.3315672874450684
e:  19   train_loss:  581.1440842512094   time:  1.3241140842437744
e:  20   train_loss:  583.8979439277122   time:  1.3184783458709717
e:  20   train_loss:  583.8979439277122   val_loss:  641.1575834677685   time:  1.4193458557128906
e:  21   train_loss:  595.0051043938236   time:  1.3095107078552246
e:  22   train_loss:  574.0743389209871   time:  1.4621374607086182
e:  23   train_loss:  567.7815604721653   time:  1.3329126834869385
e:  24   train_loss:  577.4520440359385   time:  1.3353419303894043
e:  25   train_loss:  570.2688747763234   time:  1.3326141834259033
e:  25   train_loss:  570.2688747763234   val_loss:  632.0158307273363   time:  1.4347729682922363
e:  26   train_loss:  565.1982822697757   time:  1.3305346965789795
e:  27   train_loss:  560.2572007256871   time:  1.3362200260162354
e:  28   train_loss:  555.3943690528827   time:  1.4635894298553467
e:  29   train_loss:  566.7289842278923   time:  1.334899663925171
e:  30   train_loss:  562.0567369354661   time:  1.3239381313323975
e:  30   train_loss:  562.0567369354661   val_loss:  638.0182047349342   time:  1.425990343093872
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (1, 0, 7), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (1, 0, 7) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 7) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 7) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (1, 0, 7)
kwargs: {'config': {'batch_norm': True, 'ff_0': 106, 'ff_num_layers': 2, 'gnn_0': 317, 'gnn_dropout': 0.3368733383678324, 'gnn_num_layers': 1, 'hid_0': 74, 'hid_dropout_rate': 0.29648329598290585, 'in_dropout_rate': 0.04789760399280041, 'lr': 0.0007931206855937558, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 221, 'hid_1': 555, 'hid_2': 1092}, 'budget': 81.0, 'working_directory': '.'}
result: {'loss': 695.412918072305, 'n_epochs': 53.2, 'info': {'validation loss': 695.412918072305}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 7) started
DEBUG:hpbandster:job_callback for (1, 0, 7) got condition
DEBUG:hpbandster:Only 17 run(s) for budget 81.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (1, 0, 7) finished
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: trying submitting job (1, 0, 8) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 8) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 8)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 8) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 8) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (1, 0, 8)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 39, 'ff_num_layers': 3, 'gnn_0': 1924, 'gnn_dropout': 0.07546291559754864, 'gnn_num_layers': 3, 'hid_0': 112, 'hid_dropout_rate': 0.2309388035450648, 'in_dropout_rate': 0.4660934753216773, 'lr': 0.004881718006072484, 'num_hid_layers': 1, 'optimizer': 'SGD', 'ff_1': 252, 'ff_2': 266, 'gnn_1': 1507, 'gnn_2': 109, 'sgd_momentum': 0.05095153200008117}, 'budget': 81.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  638.4469096806981   time:  1.5065479278564453
e:  0   train_loss:  638.4469096806981   val_loss:  1424.7829982169262   time:  1.623913049697876
e:  1   train_loss:  596.2435071460557   time:  1.5449771881103516
e:  2   train_loss:  587.4760605815242   time:  1.428609848022461
e:  3   train_loss:  579.4621255117056   time:  1.456468105316162
e:  4   train_loss:  584.7848094103616   time:  1.4553265571594238
e:  5   train_loss:  575.1823938473573   time:  1.6229925155639648
e:  5   train_loss:  575.1823938473573   val_loss:  1367.0270793917782   time:  1.7323946952819824
e:  6   train_loss:  573.2244252648211   time:  1.4428682327270508
e:  7   train_loss:  560.2810340448791   time:  1.4321880340576172
e:  8   train_loss:  553.9647755107178   time:  1.4614500999450684
e:  9   train_loss:  562.3755241697113   time:  1.4432008266448975
e:  10   train_loss:  547.3559596656162   time:  1.3964879512786865
e:  10   train_loss:  547.3559596656162   val_loss:  1364.93757626333   time:  1.5095734596252441
e:  11   train_loss:  546.429826939993   time:  1.3844890594482422
e:  12   train_loss:  540.6884711871488   time:  1.4380958080291748
e:  13   train_loss:  531.6435857630117   time:  1.6208407878875732
e:  14   train_loss:  539.8535526302071   time:  1.4142181873321533
e:  15   train_loss:  531.6595095921012   time:  1.44891357421875
e:  15   train_loss:  531.6595095921012   val_loss:  1359.7231370263871   time:  1.5654993057250977
e:  16   train_loss:  524.4055700840821   time:  1.4418747425079346
e:  17   train_loss:  526.0262826690822   time:  1.4320387840270996
e:  18   train_loss:  514.4014225934878   time:  1.4395174980163574
e:  19   train_loss:  523.0313949902512   time:  1.4277772903442383
e:  20   train_loss:  514.6422627069383   time:  1.437070369720459
e:  20   train_loss:  514.6422627069383   val_loss:  1360.958430147954   time:  1.5529003143310547
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  21   train_loss:  511.28263508199973   time:  1.505608320236206
e:  22   train_loss:  538.7864411461634   time:  1.528397798538208
e:  23   train_loss:  511.5007880306422   time:  1.6040947437286377
e:  24   train_loss:  513.3522072130875   time:  1.4795105457305908
e:  25   train_loss:  492.72929805369506   time:  1.6400792598724365
e:  25   train_loss:  492.72929805369506   val_loss:  1369.0186603344653   time:  1.7500996589660645
e:  26   train_loss:  504.65223031363576   time:  1.4381263256072998
e:  27   train_loss:  508.7308309417013   time:  1.453545093536377
e:  28   train_loss:  496.74956018706445   time:  1.4461824893951416
e:  29   train_loss:  505.98460274437906   time:  1.4561586380004883
e:  30   train_loss:  489.61881105011537   time:  1.4215257167816162
e:  30   train_loss:  489.61881105011537   val_loss:  1504.6425148241121   time:  1.5377013683319092
e:  31   train_loss:  496.7429836946938   time:  1.417459487915039
e:  32   train_loss:  491.97593182390915   time:  1.4487276077270508
e:  33   train_loss:  492.3822695999296   time:  1.4347805976867676
e:  34   train_loss:  484.7595648167369   time:  1.4381420612335205
e:  35   train_loss:  499.24188079546946   time:  1.623145580291748
e:  35   train_loss:  499.24188079546946   val_loss:  1375.3085053899842   time:  1.7329397201538086
e:  36   train_loss:  482.67193706663033   time:  1.5508911609649658
e:  37   train_loss:  479.54488432967383   time:  1.394390344619751
e:  38   train_loss:  476.09528397567294   time:  1.3982717990875244
e:  39   train_loss:  480.7934675783081   time:  1.3987398147583008
e:  40   train_loss:  483.62855123773176   time:  1.3987126350402832
e:  40   train_loss:  483.62855123773176   val_loss:  1400.6250693386735   time:  1.5160412788391113
e:  41   train_loss:  476.681770710957   time:  1.3999922275543213
e:  42   train_loss:  476.65500584111106   time:  1.397057056427002
e:  43   train_loss:  474.96604510983315   time:  1.3952751159667969
e:  44   train_loss:  468.573805368586   time:  1.5190825462341309
e:  45   train_loss:  468.6001992616948   time:  1.3832759857177734
e:  45   train_loss:  468.6001992616948   val_loss:  1466.8579247406112   time:  1.499936580657959
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  951.1656964268295   time:  1.598886489868164
e:  0   train_loss:  951.1656964268295   val_loss:  536.8084422453546   time:  1.7109954357147217
e:  1   train_loss:  905.6270749869147   time:  1.5806553363800049
e:  2   train_loss:  885.7018135892131   time:  1.533048152923584
e:  3   train_loss:  877.8404098367364   time:  1.535329818725586
e:  4   train_loss:  866.958819806692   time:  1.504145622253418
e:  5   train_loss:  861.6466696500995   time:  1.5094902515411377
e:  5   train_loss:  861.6466696500995   val_loss:  565.7399814190414   time:  1.7472083568572998
e:  6   train_loss:  813.442092279804   time:  1.5437657833099365
e:  7   train_loss:  826.2415426893637   time:  1.5355875492095947
e:  8   train_loss:  748.4581120041815   time:  1.53505539894104
e:  9   train_loss:  742.3398181729885   time:  1.540029525756836
e:  10   train_loss:  729.3496247536023   time:  1.5398914813995361
e:  10   train_loss:  729.3496247536023   val_loss:  656.3344816542608   time:  1.6514995098114014
e:  11   train_loss:  745.6218060167016   time:  1.5372529029846191
e:  12   train_loss:  702.4282807771684   time:  1.5401952266693115
e:  13   train_loss:  681.5874094371487   time:  1.5387632846832275
e:  14   train_loss:  660.9412590199412   time:  1.6637015342712402
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  15   train_loss:  663.1312005605355   time:  1.5373473167419434
e:  15   train_loss:  663.1312005605355   val_loss:  654.3050615361698   time:  1.6496224403381348
e:  16   train_loss:  724.5486888683336   time:  1.5433526039123535
e:  17   train_loss:  659.6147900735637   time:  1.5400986671447754
e:  18   train_loss:  756.557901990222   time:  1.5413169860839844
e:  19   train_loss:  672.3500629057176   time:  1.7639195919036865
e:  20   train_loss:  676.7041546560373   time:  1.6815123558044434
e:  20   train_loss:  676.7041546560373   val_loss:  543.8697273622395   time:  1.7945277690887451
e:  21   train_loss:  657.1217662397456   time:  1.5384461879730225
e:  22   train_loss:  643.7218559636435   time:  1.5374846458435059
e:  23   train_loss:  659.1789321546354   time:  1.5112199783325195
e:  24   train_loss:  631.0867478598204   time:  1.5132968425750732
e:  25   train_loss:  623.8757460849469   time:  1.5358538627624512
e:  25   train_loss:  623.8757460849469   val_loss:  556.5458466057213   time:  1.7722718715667725
e:  26   train_loss:  642.6251555952106   time:  1.5407249927520752
e:  27   train_loss:  664.0156477657251   time:  1.5412278175354004
e:  28   train_loss:  642.3138891336223   time:  1.5382721424102783
e:  29   train_loss:  642.8698262058574   time:  1.535050868988037
e:  30   train_loss:  621.311640285091   time:  1.5369176864624023
e:  30   train_loss:  621.311640285091   val_loss:  564.5095789010418   time:  1.6488494873046875
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  979.8920847631887   time:  1.5300815105438232
e:  0   train_loss:  979.8920847631887   val_loss:  497.3815318324248   time:  1.644139289855957
e:  1   train_loss:  893.183249133827   time:  1.6619713306427002
e:  2   train_loss:  910.0432445860062   time:  1.5287916660308838
e:  3   train_loss:  873.3835617925487   time:  1.5299530029296875
e:  4   train_loss:  860.7764877857919   time:  1.5311081409454346
e:  5   train_loss:  841.5167534211944   time:  1.5253536701202393
e:  5   train_loss:  841.5167534211944   val_loss:  492.62062182123907   time:  1.6399991512298584
e:  6   train_loss:  882.2065694267952   time:  1.5403313636779785
e:  7   train_loss:  814.8057969698222   time:  1.5363500118255615
e:  8   train_loss:  736.7087649304642   time:  1.523712396621704
e:  9   train_loss:  762.0155751206652   time:  1.7069766521453857
e:  10   train_loss:  891.1620796979921   time:  1.58111572265625
e:  10   train_loss:  891.1620796979921   val_loss:  498.7829874933144   time:  1.6959388256072998
e:  11   train_loss:  744.4166713842928   time:  1.4968335628509521
e:  12   train_loss:  739.171124291931   time:  1.5157370567321777
e:  13   train_loss:  727.1663380846438   time:  1.5278265476226807
e:  14   train_loss:  692.551163850794   time:  1.5251903533935547
e:  15   train_loss:  696.0808285696719   time:  1.6039597988128662
e:  15   train_loss:  696.0808285696719   val_loss:  507.9580536008454   time:  1.7170419692993164
e:  16   train_loss:  673.4280782159203   time:  1.556269884109497
e:  17   train_loss:  704.965485256891   time:  1.5783367156982422
e:  18   train_loss:  696.3717717120245   time:  1.5659797191619873
e:  19   train_loss:  674.3990955928363   time:  1.576131820678711
e:  20   train_loss:  685.5540145592292   time:  1.5739755630493164
e:  20   train_loss:  685.5540145592292   val_loss:  509.2211739298009   time:  1.6887593269348145
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  21   train_loss:  669.4334934323297   time:  1.574632167816162
e:  22   train_loss:  664.6649671855323   time:  1.7396128177642822
e:  23   train_loss:  680.6323021762055   time:  1.5710361003875732
e:  24   train_loss:  676.3871968918704   time:  1.578242540359497
e:  25   train_loss:  704.1405812514256   time:  1.579744577407837
e:  25   train_loss:  704.1405812514256   val_loss:  474.92404032500826   time:  1.6937522888183594
e:  26   train_loss:  663.8231083037011   time:  1.5682275295257568
e:  27   train_loss:  660.210149852578   time:  1.569228172302246
e:  28   train_loss:  655.7542239560028   time:  1.565354824066162
e:  29   train_loss:  649.9670244938504   time:  1.5767929553985596
e:  30   train_loss:  638.908375984033   time:  1.7273459434509277
e:  30   train_loss:  638.908375984033   val_loss:  566.9358531792102   time:  1.8460862636566162
e:  31   train_loss:  647.995564366019   time:  1.5764431953430176
e:  32   train_loss:  651.1905748434141   time:  1.5856235027313232
e:  33   train_loss:  645.6983464604124   time:  1.5674774646759033
e:  34   train_loss:  637.6461916858825   time:  1.5675413608551025
e:  35   train_loss:  634.4651750991128   time:  1.568253993988037
e:  35   train_loss:  634.4651750991128   val_loss:  554.3612265808031   time:  1.6811416149139404
e:  36   train_loss:  632.8573128806458   time:  1.7563002109527588
e:  37   train_loss:  669.3685415543603   time:  1.5565752983093262
e:  38   train_loss:  809.3689001890857   time:  1.5633208751678467
e:  39   train_loss:  705.6715381736739   time:  1.5825889110565186
e:  40   train_loss:  639.8686160860912   time:  1.5575125217437744
e:  40   train_loss:  639.8686160860912   val_loss:  467.8428019661502   time:  1.6724035739898682
e:  41   train_loss:  649.4920797089388   time:  1.5723950862884521
e:  42   train_loss:  651.3168955520871   time:  1.5710980892181396
e:  43   train_loss:  634.3248400959479   time:  1.5555286407470703
e:  44   train_loss:  640.1542318108246   time:  1.719604253768921
e:  45   train_loss:  658.2620512201714   time:  1.5728166103363037
e:  45   train_loss:  658.2620512201714   val_loss:  470.4042969829454   time:  1.6869418621063232
e:  46   train_loss:  628.528576841753   time:  1.56492018699646
e:  47   train_loss:  664.9186573061457   time:  1.5682117938995361
e:  48   train_loss:  624.9921042016554   time:  1.548025369644165
e:  49   train_loss:  647.9917332389416   time:  1.5426263809204102
e:  50   train_loss:  627.454344326701   time:  1.5699927806854248
e:  50   train_loss:  627.454344326701   val_loss:  463.7814699856771   time:  1.6834182739257812
e:  51   train_loss:  663.4332085903811   time:  1.5523569583892822
e:  52   train_loss:  635.164979031303   time:  1.7420008182525635
e:  53   train_loss:  637.0346303410329   time:  1.5673933029174805
e:  54   train_loss:  638.6437248505156   time:  1.5218241214752197
e:  55   train_loss:  810.8999672927995   time:  1.583103895187378
e:  55   train_loss:  810.8999672927995   val_loss:  598.0173354068987   time:  1.794260025024414
e:  56   train_loss:  648.7344278235499   time:  1.682307481765747
e:  57   train_loss:  624.7039231201236   time:  1.5815589427947998
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  58   train_loss:  638.5910265063197   time:  1.585564374923706
e:  59   train_loss:  637.9734379613882   time:  1.6671433448791504
e:  60   train_loss:  643.4106793492724   time:  1.5259814262390137
e:  60   train_loss:  643.4106793492724   val_loss:  524.8373663022494   time:  1.6402599811553955
e:  61   train_loss:  637.1910953911799   time:  1.5319249629974365
e:  62   train_loss:  625.8228708608474   time:  1.5322024822235107
e:  63   train_loss:  642.0048976866481   time:  1.5296509265899658
e:  64   train_loss:  625.6690456138679   time:  1.5306692123413086
e:  65   train_loss:  607.6450036189561   time:  1.5255286693572998
e:  65   train_loss:  607.6450036189561   val_loss:  489.0621965996051   time:  1.6411192417144775
e:  66   train_loss:  627.8278769481407   time:  1.546471357345581
e:  67   train_loss:  636.1628135107828   time:  1.627866268157959
e:  68   train_loss:  632.5791505784416   time:  1.5143096446990967
e:  69   train_loss:  718.8315209737622   time:  1.6511485576629639
e:  70   train_loss:  615.8928200056638   time:  1.5585153102874756
e:  70   train_loss:  615.8928200056638   val_loss:  479.39841563217965   time:  1.6740717887878418
e:  71   train_loss:  631.0870546737486   time:  1.5822620391845703
e:  72   train_loss:  631.2568492978576   time:  1.5802907943725586
e:  73   train_loss:  748.2264907151457   time:  1.5676171779632568
e:  74   train_loss:  671.7677945171758   time:  1.6066796779632568
e:  75   train_loss:  640.8354870219696   time:  1.7444660663604736
e:  75   train_loss:  640.8354870219696   val_loss:  493.82723306139513   time:  1.85927152633667
e:  76   train_loss:  641.5921141290764   time:  1.571302890777588
e:  77   train_loss:  627.9854609674812   time:  1.5683104991912842
e:  78   train_loss:  656.5842417725885   time:  1.5718817710876465
e:  79   train_loss:  614.9411932773625   time:  1.5725173950195312
e:  80   train_loss:  636.7178926347912   time:  1.5561530590057373
e:  80   train_loss:  636.7178926347912   val_loss:  514.1017212372309   time:  1.6737558841705322
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  902.4050307036074   time:  1.5882267951965332
e:  0   train_loss:  902.4050307036074   val_loss:  739.2735712603445   time:  1.709881067276001
e:  1   train_loss:  836.7607444557059   time:  1.6875994205474854
e:  2   train_loss:  819.4318328106864   time:  1.4285156726837158
e:  3   train_loss:  835.8606910046755   time:  1.4497215747833252
e:  4   train_loss:  798.2337011065601   time:  1.443725824356079
e:  5   train_loss:  847.0809062531794   time:  1.3972506523132324
e:  5   train_loss:  847.0809062531794   val_loss:  716.854562281484   time:  1.5131731033325195
e:  6   train_loss:  783.8405327099563   time:  1.5448167324066162
e:  7   train_loss:  756.0248749432765   time:  1.510786771774292
e:  8   train_loss:  744.9995705441443   time:  1.3902859687805176
e:  9   train_loss:  720.449691322679   time:  1.518343210220337
e:  10   train_loss:  701.17551831958   time:  1.3960599899291992
e:  10   train_loss:  701.17551831958   val_loss:  724.3960640508982   time:  1.513739824295044
e:  11   train_loss:  688.1036946588177   time:  1.3984615802764893
e:  12   train_loss:  676.3222132536011   time:  1.3988821506500244
e:  13   train_loss:  663.3592699918894   time:  1.4051258563995361
e:  14   train_loss:  663.2772437527366   time:  1.4397656917572021
e:  15   train_loss:  653.2081526847571   time:  1.3968801498413086
e:  15   train_loss:  653.2081526847571   val_loss:  716.1822989172342   time:  1.5149240493774414
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  16   train_loss:  649.4313508513897   time:  1.4030709266662598
e:  17   train_loss:  645.5904945412836   time:  1.395289659500122
e:  18   train_loss:  653.5036913933272   time:  1.3989646434783936
e:  19   train_loss:  639.9538321118952   time:  1.3953948020935059
e:  20   train_loss:  638.3610617408394   time:  1.4649055004119873
e:  20   train_loss:  638.3610617408394   val_loss:  700.7199375835717   time:  1.6261467933654785
e:  21   train_loss:  614.5361549473312   time:  1.5606698989868164
e:  22   train_loss:  629.4581766741004   time:  1.3921654224395752
e:  23   train_loss:  642.2467284964224   time:  1.3928141593933105
e:  24   train_loss:  615.5475637327589   time:  1.3917970657348633
e:  25   train_loss:  618.6228536389121   time:  1.3804044723510742
e:  25   train_loss:  618.6228536389121   val_loss:  684.978522302425   time:  1.4978773593902588
e:  26   train_loss:  624.724867298984   time:  1.3694279193878174
e:  27   train_loss:  633.9646033460622   time:  1.3986599445343018
e:  28   train_loss:  614.0083429999293   time:  1.3938989639282227
e:  29   train_loss:  616.6831100324642   time:  1.3936140537261963
e:  30   train_loss:  605.6028385337047   time:  1.3991248607635498
e:  30   train_loss:  605.6028385337047   val_loss:  686.6390953303427   time:  1.6374163627624512
e:  31   train_loss:  616.4468310505258   time:  1.418097734451294
e:  32   train_loss:  630.2052956195507   time:  1.474215030670166
e:  33   train_loss:  616.7878309442705   time:  1.472696304321289
e:  34   train_loss:  612.8692780839924   time:  1.4704349040985107
e:  35   train_loss:  599.9894245573712   time:  1.4896540641784668
e:  35   train_loss:  599.9894245573712   val_loss:  674.7748183329021   time:  1.6919746398925781
e:  36   train_loss:  609.4749666443493   time:  1.4354350566864014
e:  37   train_loss:  611.9131270425464   time:  1.4017117023468018
e:  38   train_loss:  598.9396011987108   time:  1.3970882892608643
e:  39   train_loss:  594.976729251931   time:  1.4160130023956299
e:  40   train_loss:  609.4615626554988   time:  1.397374153137207
e:  40   train_loss:  609.4615626554988   val_loss:  670.1906766739048   time:  1.5151965618133545
e:  41   train_loss:  607.6707358049533   time:  1.5217621326446533
e:  42   train_loss:  578.7266058099855   time:  1.3909027576446533
e:  43   train_loss:  642.2308970597278   time:  1.3842449188232422
e:  44   train_loss:  606.6900942004015   time:  1.4070158004760742
e:  45   train_loss:  592.6289112242175   time:  1.5584862232208252
e:  45   train_loss:  592.6289112242175   val_loss:  668.5045503543067   time:  1.6764583587646484
e:  46   train_loss:  600.4027730628949   time:  1.4921157360076904
e:  47   train_loss:  601.8043186081609   time:  1.5724735260009766
e:  48   train_loss:  601.7231767652504   time:  1.4058606624603271
e:  49   train_loss:  593.2908296036608   time:  1.3932273387908936
e:  50   train_loss:  593.7744682503654   time:  1.398904800415039
e:  50   train_loss:  593.7744682503654   val_loss:  681.0668912662009   time:  1.51762056350708
e:  51   train_loss:  583.691527258485   time:  1.398219347000122
e:  52   train_loss:  592.7166572283247   time:  1.3990869522094727
e:  53   train_loss:  596.2276919056794   time:  1.5139782428741455
e:  54   train_loss:  584.7557942086613   time:  1.3959240913391113
e:  55   train_loss:  596.0620183862163   time:  1.3973212242126465
e:  55   train_loss:  596.0620183862163   val_loss:  657.4895323931994   time:  1.5165660381317139
e:  56   train_loss:  586.2261355052526   time:  1.398449420928955
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  57   train_loss:  577.7016535661909   time:  1.397411584854126
e:  58   train_loss:  571.5619965268058   time:  1.3956410884857178
e:  59   train_loss:  598.1933696416891   time:  1.4114909172058105
e:  60   train_loss:  564.1744943326523   time:  1.3984713554382324
e:  60   train_loss:  564.1744943326523   val_loss:  702.5795601715165   time:  1.516986608505249
e:  61   train_loss:  591.0029036585483   time:  1.402097225189209
e:  62   train_loss:  579.2339183040745   time:  1.4016332626342773
e:  63   train_loss:  567.1116979452572   time:  1.3996622562408447
e:  64   train_loss:  580.066043721422   time:  1.3993382453918457
e:  65   train_loss:  564.4351819685158   time:  1.398904800415039
e:  65   train_loss:  564.4351819685158   val_loss:  686.9883423967204   time:  1.6338047981262207
e:  66   train_loss:  568.5239818675664   time:  1.392056941986084
e:  67   train_loss:  569.9639230656311   time:  1.3634955883026123
e:  68   train_loss:  578.3290265401236   time:  1.3916206359863281
e:  69   train_loss:  569.2776908288663   time:  1.3976869583129883
e:  70   train_loss:  570.239700498463   time:  1.396883487701416
e:  70   train_loss:  570.239700498463   val_loss:  712.6302738295904   time:  1.5151913166046143
e:  71   train_loss:  581.2016260592669   time:  1.3993847370147705
e:  72   train_loss:  574.512664277142   time:  1.3939085006713867
e:  73   train_loss:  560.1053670928252   time:  1.3984203338623047
e:  74   train_loss:  557.3164921993441   time:  1.394249439239502
e:  75   train_loss:  563.1299928366454   time:  1.5138659477233887
e:  75   train_loss:  563.1299928366454   val_loss:  670.308643036476   time:  1.6325855255126953
e:  76   train_loss:  548.4390956254271   time:  1.3961410522460938
e:  77   train_loss:  587.776660985457   time:  1.4012963771820068
e:  78   train_loss:  556.6013583942171   time:  1.4026024341583252
e:  79   train_loss:  570.2014684086028   time:  1.3952984809875488
e:  80   train_loss:  575.6079382365974   time:  1.4016749858856201
e:  80   train_loss:  575.6079382365974   val_loss:  753.987209477151   time:  1.5208158493041992
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  945.1920401884569   time:  1.694298267364502
e:  0   train_loss:  945.1920401884569   val_loss:  556.6549586177586   time:  1.8016376495361328
e:  1   train_loss:  889.2760714938468   time:  1.8518331050872803
e:  2   train_loss:  883.4578364217496   time:  1.6236765384674072
e:  3   train_loss:  889.4428957126803   time:  1.5373010635375977
e:  4   train_loss:  869.2376740789008   time:  1.5440919399261475
e:  5   train_loss:  864.3410361672381   time:  1.5294229984283447
e:  5   train_loss:  864.3410361672381   val_loss:  581.7902475265469   time:  1.6407043933868408
e:  6   train_loss:  819.1505369707951   time:  1.496345043182373
e:  7   train_loss:  779.2012164395154   time:  1.5345959663391113
e:  8   train_loss:  754.5903509020596   time:  1.6687586307525635
e:  9   train_loss:  740.3547847485535   time:  1.5337486267089844
e:  10   train_loss:  734.0668907097736   time:  1.5389840602874756
e:  10   train_loss:  734.0668907097736   val_loss:  603.8522768704307   time:  1.6527273654937744
e:  11   train_loss:  714.5820419254233   time:  1.5383446216583252
e:  12   train_loss:  759.4244571258547   time:  1.5354068279266357
e:  13   train_loss:  708.0118707848598   time:  1.5332248210906982
e:  14   train_loss:  683.5264747521725   time:  1.8500869274139404
e:  15   train_loss:  682.8795213279702   time:  1.8028631210327148
e:  15   train_loss:  682.8795213279702   val_loss:  551.0483965562742   time:  1.915269136428833
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  16   train_loss:  669.3165156795095   time:  1.537912130355835
e:  17   train_loss:  671.9851678160105   time:  1.534846305847168
e:  18   train_loss:  662.9107545609725   time:  1.5374760627746582
e:  19   train_loss:  676.2092404403805   time:  1.533750295639038
e:  20   train_loss:  646.4307083433317   time:  1.5371549129486084
e:  20   train_loss:  646.4307083433317   val_loss:  563.9563070930873   time:  1.6501514911651611
e:  21   train_loss:  651.484148646772   time:  1.6719915866851807
e:  22   train_loss:  650.1619728997011   time:  1.5405311584472656
e:  23   train_loss:  669.4871374669397   time:  1.5403563976287842
e:  24   train_loss:  675.6190119346894   time:  1.5164923667907715
e:  25   train_loss:  660.6227410285447   time:  1.5064332485198975
e:  25   train_loss:  660.6227410285447   val_loss:  536.0300834797239   time:  1.6199731826782227
e:  26   train_loss:  659.1791204154829   time:  1.5397589206695557
e:  27   train_loss:  637.7560909233948   time:  1.5377929210662842
e:  28   train_loss:  644.024729699147   time:  1.6460812091827393
e:  29   train_loss:  640.8622348842481   time:  1.5374937057495117
e:  30   train_loss:  665.5691167955879   time:  1.5389816761016846
e:  30   train_loss:  665.5691167955879   val_loss:  537.554733758086   time:  1.6514647006988525
e:  31   train_loss:  642.2305420200014   time:  1.538388729095459
e:  32   train_loss:  647.4611731797953   time:  1.5381839275360107
e:  33   train_loss:  638.4740291886528   time:  1.5361366271972656
e:  34   train_loss:  630.839316394031   time:  1.532402515411377
e:  35   train_loss:  636.4305101380432   time:  1.6701600551605225
e:  35   train_loss:  636.4305101380432   val_loss:  536.5438738267774   time:  1.7829418182373047
e:  36   train_loss:  638.4576324459717   time:  1.536895513534546
e:  37   train_loss:  655.4762261020023   time:  1.5381643772125244
e:  38   train_loss:  618.7328312665655   time:  1.7198851108551025
e:  39   train_loss:  645.8793614376945   time:  1.6204619407653809
e:  40   train_loss:  613.8868960528511   time:  1.5350987911224365
e:  40   train_loss:  613.8868960528511   val_loss:  564.9096674384932   time:  1.6480767726898193
e:  41   train_loss:  620.4182872332057   time:  1.6803169250488281
e:  42   train_loss:  624.4107273742593   time:  1.537879467010498
e:  43   train_loss:  600.4701037687631   time:  1.5081274509429932
e:  44   train_loss:  612.1917451045556   time:  1.7626111507415771
e:  45   train_loss:  620.6047800912356   time:  1.6043846607208252
e:  45   train_loss:  620.6047800912356   val_loss:  533.3437682553338   time:  1.7167067527770996
e:  46   train_loss:  609.758347919209   time:  1.6083128452301025
e:  47   train_loss:  598.4318328832408   time:  1.630817174911499
e:  48   train_loss:  604.7368651651708   time:  1.6529474258422852
e:  49   train_loss:  603.4920477526528   time:  1.5406935214996338
e:  50   train_loss:  591.9358460260265   time:  1.5377247333526611
e:  50   train_loss:  591.9358460260265   val_loss:  586.8735275785725   time:  1.65037202835083
e:  51   train_loss:  610.3484400482978   time:  1.536341905593872
e:  52   train_loss:  579.8400280638906   time:  1.635185718536377
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  53   train_loss:  616.2422205436391   time:  1.7768330574035645
e:  54   train_loss:  599.2552330083108   time:  1.5772221088409424
e:  55   train_loss:  614.422391860652   time:  1.6742913722991943
e:  55   train_loss:  614.422391860652   val_loss:  537.0330277336745   time:  1.7876994609832764
e:  56   train_loss:  593.04012718495   time:  1.5384564399719238
e:  57   train_loss:  603.4245873233035   time:  1.5378072261810303
e:  58   train_loss:  609.5744227129246   time:  1.5334768295288086
e:  59   train_loss:  599.6709200860082   time:  1.534386157989502
e:  60   train_loss:  600.2626193282244   time:  1.5390408039093018
e:  60   train_loss:  600.2626193282244   val_loss:  586.9314485573909   time:  1.7724785804748535
e:  61   train_loss:  576.9882849212   time:  1.527512788772583
e:  62   train_loss:  575.4290419025697   time:  1.4967927932739258
e:  63   train_loss:  582.5000006611643   time:  1.6463465690612793
e:  64   train_loss:  576.8535000174836   time:  1.5862603187561035
e:  65   train_loss:  574.5404101466772   time:  1.5657858848571777
e:  65   train_loss:  574.5404101466772   val_loss:  572.384761863185   time:  1.6782233715057373
e:  66   train_loss:  578.8629732450324   time:  1.6808884143829346
e:  67   train_loss:  571.6984855992547   time:  1.532050609588623
e:  68   train_loss:  564.4469845825041   time:  1.5390465259552002
e:  69   train_loss:  573.6396795408641   time:  1.5363743305206299
e:  70   train_loss:  567.8106408312249   time:  1.5399882793426514
e:  70   train_loss:  567.8106408312249   val_loss:  564.3524225960406   time:  1.6531269550323486
e:  71   train_loss:  580.5799565056643   time:  1.5372357368469238
e:  72   train_loss:  559.9607726679375   time:  1.5324535369873047
e:  73   train_loss:  566.1361924198382   time:  1.766629695892334
e:  74   train_loss:  558.6179123524485   time:  1.5363821983337402
e:  75   train_loss:  572.1048491505157   time:  1.5408456325531006
e:  75   train_loss:  572.1048491505157   val_loss:  543.2070322679757   time:  1.654754400253296
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (1, 0, 8), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (1, 0, 8) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 8) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 8) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (1, 0, 8)
kwargs: {'config': {'batch_norm': False, 'ff_0': 39, 'ff_num_layers': 3, 'gnn_0': 1924, 'gnn_dropout': 0.07546291559754864, 'gnn_num_layers': 3, 'hid_0': 112, 'hid_dropout_rate': 0.2309388035450648, 'in_dropout_rate': 0.4660934753216773, 'lr': 0.004881718006072484, 'num_hid_layers': 1, 'optimizer': 'SGD', 'ff_1': 252, 'ff_2': 266, 'gnn_1': 1507, 'gnn_2': 109, 'sgd_momentum': 0.05095153200008117}, 'budget': 81.0, 'working_directory': '.'}
result: {'loss': 710.2292699811903, 'n_epochs': 62.2, 'info': {'validation loss': 710.2292699811903}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 8) started
DEBUG:hpbandster:job_callback for (1, 0, 8) got condition
DEBUG:hpbandster:Only 18 run(s) for budget 81.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (1, 0, 8) finished
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:ITERATION: Advancing config (1, 0, 1) to next budget 243.000000
DEBUG:hpbandster:ITERATION: Advancing config (1, 0, 7) to next budget 243.000000
DEBUG:hpbandster:ITERATION: Advancing config (1, 0, 8) to next budget 243.000000
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: trying submitting job (1, 0, 1) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 1) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 1)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 1) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 1) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (1, 0, 1)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 26, 'ff_num_layers': 2, 'gnn_0': 230, 'gnn_dropout': 0.2687433749896259, 'gnn_num_layers': 2, 'hid_0': 128, 'hid_dropout_rate': 0.16439702726623406, 'in_dropout_rate': 0.35448831363775246, 'lr': 0.00013516628064470158, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 1057, 'gnn_1': 267, 'hid_1': 99, 'hid_2': 682}, 'budget': 243.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  703.8513654896708   time:  1.2594294548034668
e:  0   train_loss:  703.8513654896708   val_loss:  1668.1707042033488   time:  1.3711576461791992
e:  1   train_loss:  699.2757151112812   time:  1.3547346591949463
e:  2   train_loss:  691.4428324427163   time:  1.4637532234191895
e:  3   train_loss:  675.3530548926203   time:  1.2812910079956055
e:  4   train_loss:  646.0837831969893   time:  1.2730979919433594
e:  5   train_loss:  609.2095287083458   time:  1.2776708602905273
e:  5   train_loss:  609.2095287083458   val_loss:  1412.159177254586   time:  1.3856725692749023
e:  6   train_loss:  598.3818073482829   time:  1.2877435684204102
e:  7   train_loss:  596.8929258249088   time:  1.2995944023132324
e:  8   train_loss:  594.6868705869371   time:  1.2743399143218994
e:  9   train_loss:  593.7301234904753   time:  1.297501802444458
e:  10   train_loss:  593.7098909009907   time:  1.2785322666168213
e:  10   train_loss:  593.7098909009907   val_loss:  1405.3310106803078   time:  1.3866963386535645
e:  11   train_loss:  591.9945615016496   time:  1.262819766998291
e:  12   train_loss:  592.2776428305443   time:  1.240738868713379
e:  13   train_loss:  590.1300803488588   time:  1.3586244583129883
e:  14   train_loss:  588.9805337909133   time:  1.2229151725769043
e:  15   train_loss:  589.1252401417098   time:  1.290050983428955
e:  15   train_loss:  589.1252401417098   val_loss:  1410.5157435838025   time:  1.3978617191314697
e:  16   train_loss:  587.8239152888295   time:  1.3228769302368164
e:  17   train_loss:  586.0498316958956   time:  1.2382936477661133
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  18   train_loss:  586.2699163669314   time:  1.236391305923462
e:  19   train_loss:  585.2776828880027   time:  1.2269880771636963
e:  20   train_loss:  583.6632003019984   time:  1.238513469696045
e:  20   train_loss:  583.6632003019984   val_loss:  1411.7302224820237   time:  1.3457062244415283
e:  21   train_loss:  581.5778083059142   time:  1.2385642528533936
e:  22   train_loss:  578.7205999904104   time:  1.2381227016448975
e:  23   train_loss:  577.3623063374143   time:  1.236882209777832
e:  24   train_loss:  575.2443312116203   time:  1.2395031452178955
e:  25   train_loss:  571.0811157362089   time:  1.3512952327728271
e:  25   train_loss:  571.0811157362089   val_loss:  1403.372884630155   time:  1.4522793292999268
e:  26   train_loss:  565.575754113758   time:  1.2262933254241943
e:  27   train_loss:  561.4193973783468   time:  1.2272038459777832
e:  28   train_loss:  556.8104929951967   time:  1.3427376747131348
e:  29   train_loss:  547.8057513097937   time:  1.0654504299163818
e:  30   train_loss:  542.1242084599359   time:  1.2784326076507568
e:  30   train_loss:  542.1242084599359   val_loss:  1397.5662132055952   time:  1.3857829570770264
e:  31   train_loss:  533.7513412618895   time:  1.2381105422973633
e:  32   train_loss:  524.4708536924871   time:  1.2268738746643066
e:  33   train_loss:  512.0562656540521   time:  1.2265143394470215
e:  34   train_loss:  504.42120208938576   time:  1.235029697418213
e:  35   train_loss:  492.655657911002   time:  1.3537120819091797
e:  35   train_loss:  492.655657911002   val_loss:  1420.084365325673   time:  1.453662633895874
e:  36   train_loss:  485.7044303544434   time:  1.2262792587280273
e:  37   train_loss:  477.9874146994149   time:  1.3547172546386719
e:  38   train_loss:  473.0967361262999   time:  1.4275681972503662
e:  39   train_loss:  468.8586091665116   time:  1.2226550579071045
e:  40   train_loss:  462.4126993945608   time:  1.2313752174377441
e:  40   train_loss:  462.4126993945608   val_loss:  1416.5086017072595   time:  1.3392183780670166
e:  41   train_loss:  458.05180971787456   time:  1.2352685928344727
e:  42   train_loss:  452.45746904570365   time:  1.2959628105163574
e:  43   train_loss:  448.53062786356213   time:  1.3735723495483398
e:  44   train_loss:  444.2632656263695   time:  1.3517122268676758
e:  45   train_loss:  441.6969939296847   time:  1.2225837707519531
e:  45   train_loss:  441.6969939296847   val_loss:  1438.3285012083718   time:  1.329939365386963
e:  46   train_loss:  437.6971807114175   time:  1.2290980815887451
e:  47   train_loss:  436.8532912638552   time:  1.237610101699829
e:  48   train_loss:  433.29477091988235   time:  1.2377500534057617
e:  49   train_loss:  429.2901196226431   time:  1.23854660987854
e:  50   train_loss:  430.7481686080432   time:  1.2279882431030273
e:  50   train_loss:  430.7481686080432   val_loss:  1434.4403893137323   time:  1.4135854244232178
e:  51   train_loss:  428.6594405784897   time:  1.291095495223999
e:  52   train_loss:  426.55831529350337   time:  1.2640552520751953
e:  53   train_loss:  426.28279856695553   time:  1.281221866607666
e:  54   train_loss:  426.855592587639   time:  1.3291292190551758
e:  55   train_loss:  423.5352762482792   time:  1.3017590045928955
e:  55   train_loss:  423.5352762482792   val_loss:  1446.3220706271754   time:  1.5781874656677246
e:  56   train_loss:  420.76967237835953   time:  1.3458642959594727
e:  57   train_loss:  423.28229944905456   time:  1.3650312423706055
e:  58   train_loss:  421.3465015093953   time:  1.3542125225067139
e:  59   train_loss:  420.7157541323429   time:  1.1799852848052979
e:  60   train_loss:  419.8134633662278   time:  1.3444631099700928
e:  60   train_loss:  419.8134633662278   val_loss:  1467.4523536791316   time:  1.454160213470459
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1083.4567601738515   time:  1.4769666194915771
e:  0   train_loss:  1083.4567601738515   val_loss:  625.4850023363293   time:  1.580414056777954
e:  1   train_loss:  1061.172883878735   time:  1.4723951816558838
e:  2   train_loss:  1057.6860050773037   time:  1.467787265777588
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  3   train_loss:  1011.004852214431   time:  1.678065538406372
e:  4   train_loss:  947.7725022202366   time:  1.4665062427520752
e:  5   train_loss:  917.9028374260872   time:  1.4778172969818115
e:  5   train_loss:  917.9028374260872   val_loss:  564.7511486112106   time:  1.5810396671295166
e:  6   train_loss:  912.0726851046206   time:  1.424109935760498
e:  7   train_loss:  898.0779866081652   time:  1.4792587757110596
e:  8   train_loss:  910.0874670029164   time:  1.4783811569213867
e:  9   train_loss:  912.2763757794635   time:  1.6785869598388672
e:  10   train_loss:  896.3805811595294   time:  1.4671502113342285
e:  10   train_loss:  896.3805811595294   val_loss:  538.8607991855855   time:  1.571289300918579
e:  11   train_loss:  904.867635913643   time:  1.4154632091522217
e:  12   train_loss:  904.0886588371363   time:  1.3501975536346436
e:  13   train_loss:  894.9310383260604   time:  1.3515474796295166
e:  14   train_loss:  879.3616764870158   time:  1.3493199348449707
e:  15   train_loss:  879.5439169640887   time:  1.480292558670044
e:  15   train_loss:  879.5439169640887   val_loss:  541.1929682464112   time:  1.5821571350097656
e:  16   train_loss:  864.5530521910786   time:  1.3387818336486816
e:  17   train_loss:  872.3973683713142   time:  1.348592758178711
e:  18   train_loss:  864.4516011433053   time:  1.3499314785003662
e:  19   train_loss:  850.2936664239129   time:  1.2866168022155762
e:  20   train_loss:  815.2120123676581   time:  1.4834036827087402
e:  20   train_loss:  815.2120123676581   val_loss:  577.5534466453931   time:  1.587287425994873
e:  21   train_loss:  795.1116179110645   time:  1.442765474319458
e:  22   train_loss:  754.9573794078494   time:  1.4899096488952637
e:  23   train_loss:  739.9185757449992   time:  1.3477611541748047
e:  24   train_loss:  729.8226475164993   time:  1.3560020923614502
e:  25   train_loss:  711.2459681127493   time:  1.358307123184204
e:  25   train_loss:  711.2459681127493   val_loss:  810.6437548714822   time:  1.4604249000549316
e:  26   train_loss:  700.0037953463238   time:  1.3624267578125
e:  27   train_loss:  695.6792715117394   time:  1.365682601928711
e:  28   train_loss:  682.8081675141758   time:  1.5053067207336426
e:  29   train_loss:  686.5354493261522   time:  1.347076416015625
e:  30   train_loss:  672.032680556861   time:  1.3604369163513184
e:  30   train_loss:  672.032680556861   val_loss:  912.2292278794465   time:  1.4626421928405762
e:  31   train_loss:  659.1041819947428   time:  1.3598005771636963
e:  32   train_loss:  665.1505553362861   time:  1.354919672012329
e:  33   train_loss:  644.1728408687442   time:  1.3447017669677734
e:  34   train_loss:  647.1741469164715   time:  1.361313819885254
e:  35   train_loss:  636.9399522121195   time:  1.5048174858093262
e:  35   train_loss:  636.9399522121195   val_loss:  942.5667369422283   time:  1.6061062812805176
e:  36   train_loss:  636.5603401283048   time:  1.3481764793395996
e:  37   train_loss:  633.7673105675757   time:  1.3610951900482178
e:  38   train_loss:  631.9868842150287   time:  1.362086534500122
e:  39   train_loss:  623.6764080527153   time:  1.3587851524353027
e:  40   train_loss:  620.0192404005628   time:  1.3609938621520996
e:  40   train_loss:  620.0192404005628   val_loss:  1026.9579191160524   time:  1.463141679763794
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1058.9675959879942   time:  1.4701480865478516
e:  0   train_loss:  1058.9675959879942   val_loss:  537.1162424586831   time:  1.5680255889892578
e:  1   train_loss:  1073.4703628250402   time:  1.3475394248962402
e:  2   train_loss:  1099.4327632337015   time:  1.3480374813079834
e:  3   train_loss:  1042.801620122101   time:  1.3343589305877686
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  4   train_loss:  952.3743667692615   time:  1.3355634212493896
e:  5   train_loss:  940.7738429231522   time:  1.348978042602539
e:  5   train_loss:  940.7738429231522   val_loss:  518.5546172575603   time:  1.4530622959136963
e:  6   train_loss:  970.2927724307077   time:  1.3433194160461426
e:  7   train_loss:  910.5317434292936   time:  1.3584036827087402
e:  8   train_loss:  882.161492912022   time:  1.4834387302398682
e:  9   train_loss:  909.6788918739073   time:  1.345043420791626
e:  10   train_loss:  889.1991958612866   time:  1.349522590637207
e:  10   train_loss:  889.1991958612866   val_loss:  483.2240150019034   time:  1.4536244869232178
e:  11   train_loss:  912.4365194423602   time:  1.3357391357421875
e:  12   train_loss:  923.7073185641285   time:  1.344789981842041
e:  13   train_loss:  870.557371485736   time:  1.3373913764953613
e:  14   train_loss:  891.0500104771361   time:  1.4419031143188477
e:  15   train_loss:  951.8908696634987   time:  1.3405001163482666
e:  15   train_loss:  951.8908696634987   val_loss:  488.5095133767481   time:  1.4446337223052979
e:  16   train_loss:  876.5801391763739   time:  1.3425655364990234
e:  17   train_loss:  884.968330985619   time:  1.330127239227295
e:  18   train_loss:  881.4257638589394   time:  1.3365304470062256
e:  19   train_loss:  840.2375235001111   time:  1.369570255279541
e:  20   train_loss:  856.5962936766756   time:  1.3354108333587646
e:  20   train_loss:  856.5962936766756   val_loss:  490.4741525766336   time:  1.4389076232910156
e:  21   train_loss:  829.7070695241722   time:  1.3372292518615723
e:  22   train_loss:  803.9531551657011   time:  1.4765377044677734
e:  23   train_loss:  810.5678977732235   time:  1.3256537914276123
e:  24   train_loss:  793.8284320442524   time:  1.3316774368286133
e:  25   train_loss:  740.130359451685   time:  1.3398633003234863
e:  25   train_loss:  740.130359451685   val_loss:  486.52903600437475   time:  1.4428834915161133
e:  26   train_loss:  766.469919477931   time:  1.3410768508911133
e:  27   train_loss:  742.116394278508   time:  1.326993465423584
e:  28   train_loss:  699.7480078358942   time:  1.3398356437683105
e:  29   train_loss:  714.6343354324658   time:  1.482116937637329
e:  30   train_loss:  694.6218069901306   time:  1.3402416706085205
e:  30   train_loss:  694.6218069901306   val_loss:  495.4599201752855   time:  1.4440460205078125
e:  31   train_loss:  704.0890519750908   time:  1.340226411819458
e:  32   train_loss:  698.1520447866433   time:  1.3429460525512695
e:  33   train_loss:  678.3306950816517   time:  1.3357667922973633
e:  34   train_loss:  703.1776288229552   time:  1.3398947715759277
e:  35   train_loss:  670.8993737634489   time:  1.3161258697509766
e:  35   train_loss:  670.8993737634489   val_loss:  485.7976811917515   time:  1.4196248054504395
e:  36   train_loss:  679.7512856457245   time:  1.3446376323699951
e:  37   train_loss:  688.405561530526   time:  1.4819114208221436
e:  38   train_loss:  701.1382817557756   time:  1.3409807682037354
e:  39   train_loss:  663.847193714983   time:  1.3354406356811523
e:  40   train_loss:  670.050556175127   time:  1.3271384239196777
e:  40   train_loss:  670.050556175127   val_loss:  486.8854042675108   time:  1.4306399822235107
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  998.6146161452004   time:  1.242546796798706
e:  0   train_loss:  998.6146161452004   val_loss:  915.3293420546772   time:  1.3504390716552734
e:  1   train_loss:  994.402584426689   time:  1.2258071899414062
e:  2   train_loss:  984.1912777573949   time:  1.2387006282806396
e:  3   train_loss:  964.7780841414415   time:  1.265953779220581
e:  4   train_loss:  925.411703167957   time:  1.2326781749725342
e:  5   train_loss:  868.2387025065278   time:  1.364070177078247
e:  5   train_loss:  868.2387025065278   val_loss:  751.8399131799662   time:  1.4724297523498535
e:  6   train_loss:  841.0463119596152   time:  1.222287893295288
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  7   train_loss:  834.7714546201908   time:  1.242760181427002
e:  8   train_loss:  834.9597379104362   time:  1.2372124195098877
e:  9   train_loss:  832.8867129133224   time:  1.2388725280761719
e:  10   train_loss:  832.7006449454732   time:  1.2381553649902344
e:  10   train_loss:  832.7006449454732   val_loss:  742.5400474884514   time:  1.346379041671753
e:  11   train_loss:  827.6898627539465   time:  1.2343146800994873
e:  12   train_loss:  827.723401380186   time:  1.235947608947754
e:  13   train_loss:  826.9929171664081   time:  1.2248365879058838
e:  14   train_loss:  823.5980107410637   time:  1.365713357925415
e:  15   train_loss:  821.133954269054   time:  1.2356681823730469
e:  15   train_loss:  821.133954269054   val_loss:  742.4589080003477   time:  1.3429203033447266
e:  16   train_loss:  821.2837662451773   time:  1.2387278079986572
e:  17   train_loss:  815.8220458370422   time:  1.2252633571624756
e:  18   train_loss:  812.1410677372464   time:  1.2234563827514648
e:  19   train_loss:  808.0018308724011   time:  1.234895944595337
e:  20   train_loss:  798.0823169662384   time:  1.2369446754455566
e:  20   train_loss:  798.0823169662384   val_loss:  734.94513937632   time:  1.3450071811676025
e:  21   train_loss:  791.5500791186256   time:  1.2376906871795654
e:  22   train_loss:  781.6583331603929   time:  1.2267704010009766
e:  23   train_loss:  763.366463907294   time:  1.3137431144714355
e:  24   train_loss:  739.8135322097071   time:  1.2310154438018799
e:  25   train_loss:  721.0948167443008   time:  1.387636661529541
e:  25   train_loss:  721.0948167443008   val_loss:  732.3420194968918   time:  1.495650291442871
e:  26   train_loss:  708.9177401073877   time:  1.2233924865722656
e:  27   train_loss:  696.3849633405812   time:  1.2334229946136475
e:  28   train_loss:  688.184459620796   time:  1.2336475849151611
e:  29   train_loss:  678.6703028161568   time:  1.2213075160980225
e:  30   train_loss:  667.9219159442972   time:  1.233163833618164
e:  30   train_loss:  667.9219159442972   val_loss:  732.2789812323329   time:  1.3414669036865234
e:  31   train_loss:  671.023018091309   time:  1.2309515476226807
e:  32   train_loss:  654.7547453082755   time:  1.2916905879974365
e:  33   train_loss:  649.992493666714   time:  1.2310795783996582
e:  34   train_loss:  648.031473253398   time:  1.355269432067871
e:  35   train_loss:  648.5036068594085   time:  1.215390920639038
e:  35   train_loss:  648.5036068594085   val_loss:  722.2622735699289   time:  1.323230266571045
e:  36   train_loss:  636.2726971446623   time:  1.233515739440918
e:  37   train_loss:  629.1022965031334   time:  1.2336061000823975
e:  38   train_loss:  631.8957284984691   time:  1.22230863571167
e:  39   train_loss:  623.0656804720034   time:  1.233288049697876
e:  40   train_loss:  619.3692527606446   time:  1.2247300148010254
e:  40   train_loss:  619.3692527606446   val_loss:  713.9817395237696   time:  1.3309226036071777
e:  41   train_loss:  616.7297178710395   time:  1.216275691986084
e:  42   train_loss:  612.3267525417951   time:  1.2178049087524414
e:  43   train_loss:  605.5724811976162   time:  1.3554346561431885
e:  44   train_loss:  599.9717372139764   time:  1.2319214344024658
e:  45   train_loss:  598.8422703025226   time:  1.2325570583343506
e:  45   train_loss:  598.8422703025226   val_loss:  709.8805950682598   time:  1.340040922164917
e:  46   train_loss:  595.7246650366434   time:  1.2342488765716553
e:  47   train_loss:  591.3069321489867   time:  1.2312054634094238
e:  48   train_loss:  593.0614006971908   time:  1.2217955589294434
e:  49   train_loss:  586.8468976202311   time:  1.2292661666870117
e:  50   train_loss:  586.1772269782238   time:  1.233154296875
e:  50   train_loss:  586.1772269782238   val_loss:  704.8139535590097   time:  1.341188669204712
e:  51   train_loss:  580.5379164230177   time:  1.2290427684783936
e:  52   train_loss:  576.9514701003261   time:  1.2349328994750977
e:  53   train_loss:  576.8941192918473   time:  1.2358851432800293
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  54   train_loss:  567.5151145132553   time:  1.2360317707061768
e:  55   train_loss:  568.3938153761836   time:  1.231398344039917
e:  55   train_loss:  568.3938153761836   val_loss:  700.212122550835   time:  1.4668488502502441
e:  56   train_loss:  566.8760808621342   time:  1.2329914569854736
e:  57   train_loss:  559.4758535425008   time:  1.2311162948608398
e:  58   train_loss:  559.5444862011014   time:  1.2315797805786133
e:  59   train_loss:  554.9840727619102   time:  1.2282118797302246
e:  60   train_loss:  556.8248907229286   time:  1.0131843090057373
e:  60   train_loss:  556.8248907229286   val_loss:  700.6174460815748   time:  1.0937542915344238
e:  61   train_loss:  554.8517058544033   time:  0.9593100547790527
e:  62   train_loss:  555.9386462457065   time:  0.9626903533935547
e:  63   train_loss:  547.4048633137924   time:  1.177957534790039
e:  64   train_loss:  556.9704000355523   time:  1.3512511253356934
e:  65   train_loss:  550.1132839803242   time:  1.2058522701263428
e:  65   train_loss:  550.1132839803242   val_loss:  699.4806963010087   time:  1.3043429851531982
e:  66   train_loss:  549.1374665842021   time:  1.2230751514434814
e:  67   train_loss:  547.6959910323764   time:  1.2339787483215332
e:  68   train_loss:  547.8392304497116   time:  1.229238748550415
e:  69   train_loss:  547.0894744579049   time:  1.2333273887634277
e:  70   train_loss:  545.6949784034663   time:  1.2311184406280518
e:  70   train_loss:  545.6949784034663   val_loss:  703.0484594356694   time:  1.3386223316192627
e:  71   train_loss:  546.655640755911   time:  1.2339160442352295
e:  72   train_loss:  541.3657263874164   time:  1.2216579914093018
e:  73   train_loss:  543.841362592743   time:  1.2318103313446045
e:  74   train_loss:  542.2274327494054   time:  1.222701072692871
e:  75   train_loss:  539.4701946963074   time:  1.3576374053955078
e:  75   train_loss:  539.4701946963074   val_loss:  702.6750432101499   time:  1.4658050537109375
e:  76   train_loss:  542.6311210051524   time:  1.2247722148895264
e:  77   train_loss:  538.5595634969059   time:  1.235041856765747
e:  78   train_loss:  545.244913668181   time:  1.2352235317230225
e:  79   train_loss:  541.8011222930405   time:  1.2221813201904297
e:  80   train_loss:  540.3680761483608   time:  1.2331197261810303
e:  80   train_loss:  540.3680761483608   val_loss:  704.3928248942178   time:  1.3415305614471436
e:  81   train_loss:  537.291837817144   time:  1.22584867477417
e:  82   train_loss:  539.3208509657519   time:  1.2342934608459473
e:  83   train_loss:  540.875411137565   time:  1.233846664428711
e:  84   train_loss:  536.60373409486   time:  1.3539438247680664
e:  85   train_loss:  537.7871301393832   time:  1.2114567756652832
e:  85   train_loss:  537.7871301393832   val_loss:  705.4758049521903   time:  1.3162999153137207
e:  86   train_loss:  540.1305035489353   time:  1.2154767513275146
e:  87   train_loss:  537.328946224686   time:  1.213564395904541
e:  88   train_loss:  534.100631991427   time:  1.2266077995300293
e:  89   train_loss:  535.7225495406061   time:  1.2222504615783691
e:  90   train_loss:  533.794451868237   time:  1.218024730682373
e:  90   train_loss:  533.794451868237   val_loss:  709.4084935292772   time:  1.3251473903656006
e:  91   train_loss:  532.5102007128575   time:  1.2292392253875732
e:  92   train_loss:  535.2612841959833   time:  1.2204105854034424
e:  93   train_loss:  535.3725717581156   time:  1.354029655456543
e:  94   train_loss:  536.7855057304762   time:  1.231968879699707
e:  95   train_loss:  540.8204703822659   time:  1.231839656829834
e:  95   train_loss:  540.8204703822659   val_loss:  709.2139485687495   time:  1.3400242328643799
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1073.5975786466506   time:  1.3487260341644287
e:  0   train_loss:  1073.5975786466506   val_loss:  689.3670386469373   time:  1.4510447978973389
e:  1   train_loss:  1062.5089411511344   time:  1.3357210159301758
e:  2   train_loss:  1078.625512918619   time:  1.3468871116638184
e:  3   train_loss:  1021.7711355733845   time:  1.3489534854888916
e:  4   train_loss:  991.0194890084126   time:  1.4886071681976318
e:  5   train_loss:  929.3257047753541   time:  1.335637092590332
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  5   train_loss:  929.3257047753541   val_loss:  557.9535089001353   time:  1.4453375339508057
e:  6   train_loss:  901.6799548982012   time:  1.4105925559997559
e:  7   train_loss:  894.7390726685315   time:  1.377225637435913
e:  8   train_loss:  883.8553833914908   time:  1.391195297241211
e:  9   train_loss:  881.6617374717564   time:  1.3827879428863525
e:  10   train_loss:  887.2108450204762   time:  1.3955938816070557
e:  10   train_loss:  887.2108450204762   val_loss:  556.9984442188709   time:  1.6725983619689941
e:  11   train_loss:  898.2038443863631   time:  1.3988590240478516
e:  12   train_loss:  900.751691768298   time:  1.4117586612701416
e:  13   train_loss:  904.4312965042595   time:  1.3798284530639648
e:  14   train_loss:  883.8433495986276   time:  1.409489631652832
e:  15   train_loss:  866.8662027466662   time:  1.3958923816680908
e:  15   train_loss:  866.8662027466662   val_loss:  556.4676890017575   time:  1.4990334510803223
e:  16   train_loss:  869.8166133465961   time:  1.398430585861206
e:  17   train_loss:  857.2119841427656   time:  1.396402359008789
e:  18   train_loss:  873.3104148516401   time:  1.5411396026611328
e:  19   train_loss:  846.675805915664   time:  1.3583331108093262
e:  20   train_loss:  834.6595757487826   time:  1.3533835411071777
e:  20   train_loss:  834.6595757487826   val_loss:  556.5697613818753   time:  1.4560086727142334
e:  21   train_loss:  809.7447634116726   time:  1.3529508113861084
e:  22   train_loss:  780.3246994441618   time:  1.343228816986084
e:  23   train_loss:  769.5871032458035   time:  1.3582723140716553
e:  24   train_loss:  722.6457298938595   time:  1.4843535423278809
e:  25   train_loss:  700.475049906405   time:  1.350630283355713
e:  25   train_loss:  700.475049906405   val_loss:  572.6814166184457   time:  1.4536166191101074
e:  26   train_loss:  701.3177268322947   time:  1.3471825122833252
e:  27   train_loss:  687.1679775362377   time:  1.34999418258667
e:  28   train_loss:  679.0878689056674   time:  1.3571581840515137
e:  29   train_loss:  672.550740261688   time:  1.4129424095153809
e:  30   train_loss:  674.8215951921286   time:  1.4930016994476318
e:  30   train_loss:  674.8215951921286   val_loss:  571.8122978350215   time:  1.5958836078643799
e:  31   train_loss:  668.1233655727384   time:  1.3607771396636963
e:  32   train_loss:  656.4520727770994   time:  1.3452255725860596
e:  33   train_loss:  650.7289578964236   time:  1.3588621616363525
e:  34   train_loss:  652.2640740063252   time:  1.355863332748413
e:  35   train_loss:  661.1319910973875   time:  1.3575105667114258
e:  35   train_loss:  661.1319910973875   val_loss:  574.4365692543887   time:  1.460158109664917
e:  36   train_loss:  657.5363892836605   time:  1.3468999862670898
e:  37   train_loss:  649.6530283175981   time:  1.493396282196045
e:  38   train_loss:  647.5453564757834   time:  1.3475756645202637
e:  39   train_loss:  637.3188282116012   time:  1.3601634502410889
e:  40   train_loss:  639.9744502991143   time:  1.3614795207977295
e:  40   train_loss:  639.9744502991143   val_loss:  576.1920265894469   time:  1.4644899368286133
e:  41   train_loss:  632.1930286813938   time:  1.3744640350341797
e:  42   train_loss:  630.8952580354562   time:  1.3556854724884033
e:  43   train_loss:  627.3585945070699   time:  1.5066723823547363
e:  44   train_loss:  619.979700906546   time:  1.3656764030456543
e:  45   train_loss:  623.3366400024545   time:  1.3619976043701172
e:  45   train_loss:  623.3366400024545   val_loss:  580.4903476494878   time:  1.466538667678833
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (1, 0, 1), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (1, 0, 1) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 1) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 1) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (1, 0, 1)
kwargs: {'config': {'batch_norm': False, 'ff_0': 26, 'ff_num_layers': 2, 'gnn_0': 230, 'gnn_dropout': 0.2687433749896259, 'gnn_num_layers': 2, 'hid_0': 128, 'hid_dropout_rate': 0.16439702726623406, 'in_dropout_rate': 0.35448831363775246, 'lr': 0.00013516628064470158, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 1057, 'gnn_1': 267, 'hid_1': 99, 'hid_2': 682}, 'budget': 243.0, 'working_directory': '.'}
result: {'loss': 735.11988253917, 'n_epochs': 56.0, 'info': {'validation loss': 735.11988253917}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 1) started
DEBUG:hpbandster:job_callback for (1, 0, 1) got condition
DEBUG:hpbandster:Only 4 run(s) for budget 243.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (1, 0, 1) finished
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: trying submitting job (1, 0, 7) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 7) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 7)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 7) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 7) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (1, 0, 7)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 106, 'ff_num_layers': 2, 'gnn_0': 317, 'gnn_dropout': 0.3368733383678324, 'gnn_num_layers': 1, 'hid_0': 74, 'hid_dropout_rate': 0.29648329598290585, 'in_dropout_rate': 0.04789760399280041, 'lr': 0.0007931206855937558, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 221, 'hid_1': 555, 'hid_2': 1092}, 'budget': 243.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  662.6398351915349   time:  1.287440299987793
e:  0   train_loss:  662.6398351915349   val_loss:  1447.0311253038858   time:  1.3943636417388916
e:  1   train_loss:  556.3931399763774   time:  1.2912752628326416
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  2   train_loss:  524.6294924221796   time:  1.273378610610962
e:  3   train_loss:  506.9054797071025   time:  1.3435204029083252
e:  4   train_loss:  492.0705138768693   time:  1.2725417613983154
e:  5   train_loss:  477.35721289915904   time:  1.458345890045166
e:  5   train_loss:  477.35721289915904   val_loss:  1610.9993692309192   time:  1.558311939239502
e:  6   train_loss:  469.98558351899095   time:  1.2651312351226807
e:  7   train_loss:  459.20908518448255   time:  1.259725570678711
e:  8   train_loss:  452.89553565910046   time:  1.4688372611999512
e:  9   train_loss:  447.5162880737397   time:  1.35988450050354
e:  10   train_loss:  444.6974920189013   time:  1.3061192035675049
e:  10   train_loss:  444.6974920189013   val_loss:  1551.4706142324876   time:  1.4133527278900146
e:  11   train_loss:  440.1325062441599   time:  1.305938959121704
e:  12   train_loss:  441.05896229547284   time:  1.295111894607544
e:  13   train_loss:  435.76447455784114   time:  1.297283411026001
e:  14   train_loss:  434.01135197944956   time:  1.307220458984375
e:  15   train_loss:  432.3837304868527   time:  1.474015235900879
e:  15   train_loss:  432.3837304868527   val_loss:  1503.7058530097959   time:  1.5736308097839355
e:  16   train_loss:  431.0602113238306   time:  1.2746784687042236
e:  17   train_loss:  424.7894834402743   time:  1.2948777675628662
e:  18   train_loss:  424.2241968332104   time:  1.3393919467926025
e:  19   train_loss:  423.1854671702019   time:  1.3071973323822021
e:  20   train_loss:  416.4991917524037   time:  1.2678275108337402
e:  20   train_loss:  416.4991917524037   val_loss:  1462.2756783650723   time:  1.3747239112854004
e:  21   train_loss:  413.45297796869426   time:  1.2638945579528809
e:  22   train_loss:  412.4048237211541   time:  1.2666280269622803
e:  23   train_loss:  407.99543800823926   time:  1.2743659019470215
e:  24   train_loss:  405.71248239213145   time:  1.4078409671783447
e:  25   train_loss:  399.62722999658445   time:  1.2506237030029297
e:  25   train_loss:  399.62722999658445   val_loss:  1296.3325284175003   time:  1.3567907810211182
e:  26   train_loss:  394.9484918829293   time:  1.25980806350708
e:  27   train_loss:  390.16974895868464   time:  1.2631256580352783
e:  28   train_loss:  384.01067975565684   time:  1.2631924152374268
e:  29   train_loss:  380.1076969132071   time:  1.261915683746338
e:  30   train_loss:  391.56969504111476   time:  1.252406358718872
e:  30   train_loss:  391.56969504111476   val_loss:  1244.9741369061967   time:  1.3598628044128418
e:  31   train_loss:  381.01648419165554   time:  1.261610984802246
e:  32   train_loss:  372.01897561793965   time:  1.2626848220825195
e:  33   train_loss:  370.00391304174104   time:  1.2619681358337402
e:  34   train_loss:  361.5421252612149   time:  1.2560033798217773
e:  35   train_loss:  357.52295450896383   time:  1.2406532764434814
e:  35   train_loss:  357.52295450896383   val_loss:  1261.7056389622514   time:  1.5037636756896973
e:  36   train_loss:  350.65397233855845   time:  1.2442443370819092
e:  37   train_loss:  343.27304758587735   time:  1.2573392391204834
e:  38   train_loss:  335.9995084663667   time:  1.2576079368591309
e:  39   train_loss:  331.59471505072764   time:  1.2612202167510986
e:  40   train_loss:  329.6727159075625   time:  1.2619357109069824
e:  40   train_loss:  329.6727159075625   val_loss:  1283.8610970093468   time:  1.3693900108337402
e:  41   train_loss:  324.7486813493277   time:  1.2638659477233887
e:  42   train_loss:  313.65602696974884   time:  1.2620980739593506
e:  43   train_loss:  310.8698780205877   time:  1.2607951164245605
e:  44   train_loss:  306.24281641571974   time:  1.2640843391418457
e:  45   train_loss:  297.81381934250425   time:  1.243405818939209
e:  45   train_loss:  297.81381934250425   val_loss:  1186.1462210708548   time:  1.3500118255615234
e:  46   train_loss:  291.8915312493709   time:  1.4248244762420654
e:  47   train_loss:  289.5885622138956   time:  1.2456369400024414
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  48   train_loss:  282.32182675687335   time:  1.2689635753631592
e:  49   train_loss:  276.2220164669809   time:  1.2661709785461426
e:  50   train_loss:  272.14660107376733   time:  1.2592401504516602
e:  50   train_loss:  272.14660107376733   val_loss:  1176.6639973264503   time:  1.3663954734802246
e:  51   train_loss:  269.5976984794645   time:  1.2448663711547852
e:  52   train_loss:  262.68474223925364   time:  1.2629776000976562
e:  53   train_loss:  259.2138631602735   time:  1.2653687000274658
e:  54   train_loss:  254.57131565913647   time:  1.2502555847167969
e:  55   train_loss:  249.98717976761935   time:  1.2537720203399658
e:  55   train_loss:  249.98717976761935   val_loss:  1156.7088641145026   time:  1.5206692218780518
e:  56   train_loss:  248.8402935910783   time:  1.2646336555480957
e:  57   train_loss:  248.13210028215425   time:  1.2607786655426025
e:  58   train_loss:  240.30064819068255   time:  1.2527775764465332
e:  59   train_loss:  237.0386452971993   time:  1.2403841018676758
e:  60   train_loss:  234.58700532701687   time:  1.2647051811218262
e:  60   train_loss:  234.58700532701687   val_loss:  1144.246180234319   time:  1.3723585605621338
e:  61   train_loss:  230.93793217097445   time:  1.262439250946045
e:  62   train_loss:  228.0550666268651   time:  1.2653334140777588
e:  63   train_loss:  225.5285483609629   time:  1.2639000415802002
e:  64   train_loss:  220.83181548538164   time:  1.2644553184509277
e:  65   train_loss:  217.78052966323045   time:  1.3224272727966309
e:  65   train_loss:  217.78052966323045   val_loss:  1146.077021070524   time:  1.428853988647461
e:  66   train_loss:  217.3150621604562   time:  1.4027304649353027
e:  67   train_loss:  218.01410700356726   time:  1.249295949935913
e:  68   train_loss:  217.63785047517024   time:  1.2592344284057617
e:  69   train_loss:  212.31533458870382   time:  1.2601406574249268
e:  70   train_loss:  209.67914292964082   time:  1.2776753902435303
e:  70   train_loss:  209.67914292964082   val_loss:  1147.9102031042203   time:  1.3844716548919678
e:  71   train_loss:  205.29051611436893   time:  1.2478115558624268
e:  72   train_loss:  201.81945488048456   time:  1.2638449668884277
e:  73   train_loss:  198.75518364359635   time:  1.2615430355072021
e:  74   train_loss:  196.09137402239654   time:  1.2620465755462646
e:  75   train_loss:  193.47084868190953   time:  1.2677414417266846
e:  75   train_loss:  193.47084868190953   val_loss:  1162.9979579531807   time:  1.3760833740234375
e:  76   train_loss:  191.9390696687117   time:  1.2619588375091553
e:  77   train_loss:  191.61716706905938   time:  1.4215185642242432
e:  78   train_loss:  191.6747776629744   time:  1.247633695602417
e:  79   train_loss:  186.2787053203052   time:  1.2652311325073242
e:  80   train_loss:  185.1671274408339   time:  1.2643184661865234
e:  80   train_loss:  185.1671274408339   val_loss:  1166.2850294566479   time:  1.371563196182251
e:  81   train_loss:  182.71685898189648   time:  1.2546226978302002
e:  82   train_loss:  178.91751941212564   time:  1.437755823135376
e:  83   train_loss:  177.69631285782475   time:  1.2848868370056152
e:  84   train_loss:  173.8430272166591   time:  1.305156946182251
e:  85   train_loss:  171.71770757332268   time:  1.2776637077331543
e:  85   train_loss:  171.71770757332268   val_loss:  1217.210047951928   time:  1.3851344585418701
e:  86   train_loss:  172.2318068513755   time:  1.2777955532073975
e:  87   train_loss:  169.7720910205053   time:  1.261920690536499
e:  88   train_loss:  168.0678618150264   time:  1.4135537147521973
e:  89   train_loss:  164.99730834450781   time:  1.2507615089416504
e:  90   train_loss:  164.81031839644137   time:  1.2620904445648193
e:  90   train_loss:  164.81031839644137   val_loss:  1217.760812357509   time:  1.3690245151519775
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1027.4660217057788   time:  1.3682162761688232
e:  0   train_loss:  1027.4660217057788   val_loss:  538.857635383698   time:  1.4715521335601807
e:  1   train_loss:  774.2181787872835   time:  1.3732881546020508
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  2   train_loss:  709.1255405882735   time:  1.3756358623504639
e:  3   train_loss:  684.6865113292295   time:  1.3730027675628662
e:  4   train_loss:  648.6522848738247   time:  1.5993728637695312
e:  5   train_loss:  644.2701007488796   time:  1.401097059249878
e:  5   train_loss:  644.2701007488796   val_loss:  557.409743757799   time:  1.503492832183838
e:  6   train_loss:  610.4214978290046   time:  1.3769705295562744
e:  7   train_loss:  607.3777173664586   time:  1.3610920906066895
e:  8   train_loss:  596.3988217334293   time:  1.376476764678955
e:  9   train_loss:  615.1983004545459   time:  1.3746166229248047
e:  10   train_loss:  606.4794140592379   time:  1.3787753582000732
e:  10   train_loss:  606.4794140592379   val_loss:  831.1337228229373   time:  1.6259405612945557
e:  11   train_loss:  598.2191104529832   time:  1.3785505294799805
e:  12   train_loss:  599.6400035098437   time:  1.3635683059692383
e:  13   train_loss:  586.187973557924   time:  1.3604199886322021
e:  14   train_loss:  581.9862385396334   time:  1.379978895187378
e:  15   train_loss:  575.6257274558244   time:  1.377755880355835
e:  15   train_loss:  575.6257274558244   val_loss:  882.3275683400065   time:  1.4806029796600342
e:  16   train_loss:  584.7615603787278   time:  1.3808436393737793
e:  17   train_loss:  574.9960440791684   time:  1.3666422367095947
e:  18   train_loss:  581.5896576707299   time:  1.5485520362854004
e:  19   train_loss:  566.1095252202131   time:  1.380624532699585
e:  20   train_loss:  561.3046684043609   time:  1.37978196144104
e:  20   train_loss:  561.3046684043609   val_loss:  1077.7541393682839   time:  1.4818346500396729
e:  21   train_loss:  543.2653475051642   time:  1.377305030822754
e:  22   train_loss:  569.0361062675364   time:  1.3646941184997559
e:  23   train_loss:  545.8439055847181   time:  1.381943702697754
e:  24   train_loss:  552.8270453400029   time:  1.5285191535949707
e:  25   train_loss:  555.8990386557056   time:  1.3755278587341309
e:  25   train_loss:  555.8990386557056   val_loss:  1217.706466487402   time:  1.4784133434295654
e:  26   train_loss:  553.2759203544645   time:  1.3713493347167969
e:  27   train_loss:  549.758397498174   time:  1.374830722808838
e:  28   train_loss:  536.0984555784639   time:  1.381237506866455
e:  29   train_loss:  516.3796292020288   time:  1.3741788864135742
e:  30   train_loss:  518.6503985343011   time:  1.5009546279907227
e:  30   train_loss:  518.6503985343011   val_loss:  1412.993994118203   time:  1.6039042472839355
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1056.2823277910134   time:  1.3629193305969238
e:  0   train_loss:  1056.2823277910134   val_loss:  483.4960254071563   time:  1.4673104286193848
e:  1   train_loss:  751.2534676872424   time:  1.3615384101867676
e:  2   train_loss:  744.9147010101728   time:  1.3442881107330322
e:  3   train_loss:  688.1469503264697   time:  1.344677209854126
e:  4   train_loss:  692.3223822756227   time:  1.365478277206421
e:  5   train_loss:  643.4926117411426   time:  1.3559050559997559
e:  5   train_loss:  643.4926117411426   val_loss:  497.86288781489446   time:  1.6092784404754639
e:  6   train_loss:  626.344842089628   time:  1.3632941246032715
e:  7   train_loss:  629.8346357390807   time:  1.3659818172454834
e:  8   train_loss:  610.3964702459168   time:  1.3573529720306396
e:  9   train_loss:  622.5939698167482   time:  1.3465790748596191
e:  10   train_loss:  614.9924211830803   time:  1.363797903060913
e:  10   train_loss:  614.9924211830803   val_loss:  484.9221818360516   time:  1.4674220085144043
e:  11   train_loss:  606.2053968103703   time:  1.3654980659484863
e:  12   train_loss:  605.7056654540824   time:  1.5223846435546875
e:  13   train_loss:  621.2304559305511   time:  1.3650875091552734
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  14   train_loss:  596.2527745152985   time:  1.3688387870788574
e:  15   train_loss:  601.5121884514481   time:  1.3631041049957275
e:  15   train_loss:  601.5121884514481   val_loss:  611.0745685770754   time:  1.4657542705535889
e:  16   train_loss:  591.3547163928562   time:  1.363356351852417
e:  17   train_loss:  584.442746141154   time:  1.3649847507476807
e:  18   train_loss:  604.0821945927885   time:  1.3602514266967773
e:  19   train_loss:  578.4773149185995   time:  1.3645009994506836
e:  20   train_loss:  581.8167711274428   time:  1.5227792263031006
e:  20   train_loss:  581.8167711274428   val_loss:  476.44548989361874   time:  1.6213033199310303
e:  21   train_loss:  604.7166891211572   time:  1.349400520324707
e:  22   train_loss:  615.9541870916707   time:  1.3451979160308838
e:  23   train_loss:  588.1846672392442   time:  1.3448083400726318
e:  24   train_loss:  579.2875810076982   time:  1.3646597862243652
e:  25   train_loss:  594.7216308473576   time:  1.368175983428955
e:  25   train_loss:  594.7216308473576   val_loss:  505.50573886150084   time:  1.4719562530517578
e:  26   train_loss:  608.6277995596212   time:  1.3630456924438477
e:  27   train_loss:  568.3168666183766   time:  1.5478887557983398
e:  28   train_loss:  559.6892011010705   time:  1.3513517379760742
e:  29   train_loss:  567.6879976281311   time:  1.3633034229278564
e:  30   train_loss:  555.1849011720927   time:  1.364103078842163
e:  30   train_loss:  555.1849011720927   val_loss:  468.5486995569986   time:  1.467717170715332
e:  31   train_loss:  590.8319005359846   time:  1.3644120693206787
e:  32   train_loss:  556.0941769489024   time:  1.3186774253845215
e:  33   train_loss:  568.4548227607463   time:  1.354750394821167
e:  34   train_loss:  542.0622446098055   time:  1.3610165119171143
e:  35   train_loss:  577.1794197570846   time:  1.540419340133667
e:  35   train_loss:  577.1794197570846   val_loss:  494.4969361084362   time:  1.6432883739471436
e:  36   train_loss:  539.7267072696609   time:  1.360609531402588
e:  37   train_loss:  552.0065512314109   time:  1.3603432178497314
e:  38   train_loss:  538.2710400999343   time:  1.3629682064056396
e:  39   train_loss:  527.5453529287527   time:  1.367607831954956
e:  40   train_loss:  555.828883083286   time:  1.361311674118042
e:  40   train_loss:  555.828883083286   val_loss:  529.3752558364258   time:  1.4653737545013428
e:  41   train_loss:  577.9091039790572   time:  1.3644063472747803
e:  42   train_loss:  560.6851722666104   time:  1.3610508441925049
e:  43   train_loss:  527.0588180286354   time:  1.510120153427124
e:  44   train_loss:  529.988939040854   time:  1.3566093444824219
e:  45   train_loss:  523.7553581486255   time:  1.3490891456604004
e:  45   train_loss:  523.7553581486255   val_loss:  494.567388874958   time:  1.4527416229248047
e:  46   train_loss:  515.7291751545354   time:  1.3656463623046875
e:  47   train_loss:  507.3277797118439   time:  1.3511574268341064
e:  48   train_loss:  509.29845906350954   time:  1.3612706661224365
e:  49   train_loss:  493.8975205136237   time:  1.36295747756958
e:  50   train_loss:  500.4666042452233   time:  1.5229260921478271
e:  50   train_loss:  500.4666042452233   val_loss:  500.66828090214653   time:  1.6259329319000244
e:  51   train_loss:  485.46986071210006   time:  1.3560535907745361
e:  52   train_loss:  483.4815643761251   time:  1.359753131866455
e:  53   train_loss:  487.6163586034171   time:  1.3638086318969727
e:  54   train_loss:  468.81843132039245   time:  1.3646306991577148
e:  55   train_loss:  480.3488068326549   time:  1.363710880279541
e:  55   train_loss:  480.3488068326549   val_loss:  482.7900066514592   time:  1.4678199291229248
e:  56   train_loss:  475.20259826176374   time:  1.3636729717254639
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  57   train_loss:  448.6510523665098   time:  1.529191017150879
e:  58   train_loss:  497.18595269965226   time:  1.3643503189086914
e:  59   train_loss:  448.02485980150215   time:  1.357170581817627
e:  60   train_loss:  448.051372210246   time:  1.3627393245697021
e:  60   train_loss:  448.051372210246   val_loss:  493.9219206462405   time:  1.466890811920166
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  941.1568894704842   time:  1.2670018672943115
e:  0   train_loss:  941.1568894704842   val_loss:  780.1726433794935   time:  1.3753812313079834
e:  1   train_loss:  726.2624386185796   time:  1.2648706436157227
e:  2   train_loss:  657.8962845173968   time:  1.268242597579956
e:  3   train_loss:  645.5151401771882   time:  1.2650573253631592
e:  4   train_loss:  625.9963946159723   time:  1.2633442878723145
e:  5   train_loss:  615.7964028855338   time:  1.2528588771820068
e:  5   train_loss:  615.7964028855338   val_loss:  802.0261675799628   time:  1.5173084735870361
e:  6   train_loss:  611.8527707785529   time:  1.2577309608459473
e:  7   train_loss:  586.5857605370119   time:  1.2639806270599365
e:  8   train_loss:  580.0832754438342   time:  1.2626113891601562
e:  9   train_loss:  588.3082166856619   time:  1.2632174491882324
e:  10   train_loss:  580.2646375016378   time:  1.2646636962890625
e:  10   train_loss:  580.2646375016378   val_loss:  791.1938936342899   time:  1.3727304935455322
e:  11   train_loss:  567.8791675885402   time:  1.2652592658996582
e:  12   train_loss:  560.1173721031132   time:  1.2501635551452637
e:  13   train_loss:  558.192656824674   time:  1.2664611339569092
e:  14   train_loss:  558.1162491821212   time:  1.2590339183807373
e:  15   train_loss:  548.9376157879898   time:  1.418229103088379
e:  15   train_loss:  548.9376157879898   val_loss:  763.1230414775997   time:  1.5269927978515625
e:  16   train_loss:  553.3988469550327   time:  1.2605385780334473
e:  17   train_loss:  542.3236333766631   time:  1.2667171955108643
e:  18   train_loss:  544.1417746958007   time:  1.2663702964782715
e:  19   train_loss:  544.7401792036376   time:  1.2590851783752441
e:  20   train_loss:  532.7475132989002   time:  1.2653794288635254
e:  20   train_loss:  532.7475132989002   val_loss:  742.6464863525886   time:  1.3743972778320312
e:  21   train_loss:  533.062625693465   time:  1.2625799179077148
e:  22   train_loss:  529.607581140508   time:  1.2664947509765625
e:  23   train_loss:  529.4450015113912   time:  1.2644648551940918
e:  24   train_loss:  522.6866556581325   time:  1.4146006107330322
e:  25   train_loss:  518.3474168543962   time:  1.2506539821624756
e:  25   train_loss:  518.3474168543962   val_loss:  780.5404412681295   time:  1.3591904640197754
e:  26   train_loss:  514.5267346974484   time:  1.268611192703247
e:  27   train_loss:  511.75552602989177   time:  1.2658741474151611
e:  28   train_loss:  506.93757237884955   time:  1.252901315689087
e:  29   train_loss:  503.7488382177043   time:  1.2552850246429443
e:  30   train_loss:  501.60683488141734   time:  1.2614309787750244
e:  30   train_loss:  501.60683488141734   val_loss:  788.8881405292606   time:  1.369490623474121
e:  31   train_loss:  502.2516616322792   time:  1.264357089996338
e:  32   train_loss:  501.35607689650453   time:  1.259021520614624
e:  33   train_loss:  495.7160051717308   time:  1.4194004535675049
e:  34   train_loss:  498.4078822315041   time:  1.2650713920593262
e:  35   train_loss:  507.8928065990009   time:  1.2636840343475342
e:  35   train_loss:  507.8928065990009   val_loss:  745.9904469869415   time:  1.3722052574157715
e:  36   train_loss:  491.5678738816454   time:  1.2657694816589355
e:  37   train_loss:  483.59593016809833   time:  1.2624168395996094
e:  38   train_loss:  479.9488411659767   time:  1.2494573593139648
e:  39   train_loss:  472.35354887985125   time:  1.260026216506958
e:  40   train_loss:  470.14677741609125   time:  1.2622804641723633
e:  40   train_loss:  470.14677741609125   val_loss:  754.7335419449378   time:  1.370727300643921
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  41   train_loss:  466.580682920479   time:  1.262993574142456
e:  42   train_loss:  465.37014031153825   time:  1.2659220695495605
e:  43   train_loss:  461.63736192574123   time:  1.263380527496338
e:  44   train_loss:  461.4101670377579   time:  1.2616324424743652
e:  45   train_loss:  449.34065348146055   time:  1.2644693851470947
e:  45   train_loss:  449.34065348146055   val_loss:  719.4086683233829   time:  1.5312530994415283
e:  46   train_loss:  440.9220605545047   time:  1.265714168548584
e:  47   train_loss:  433.05668349411576   time:  1.2635626792907715
e:  48   train_loss:  430.2847756760315   time:  1.263498067855835
e:  49   train_loss:  421.05187686626545   time:  1.261669397354126
e:  50   train_loss:  432.39803764263644   time:  1.2625408172607422
e:  50   train_loss:  432.39803764263644   val_loss:  736.6764526063113   time:  1.3708667755126953
e:  51   train_loss:  433.27918569704457   time:  1.2579045295715332
e:  52   train_loss:  421.84425824078875   time:  1.2542831897735596
e:  53   train_loss:  410.92845502101477   time:  1.264601230621338
e:  54   train_loss:  400.0369355394051   time:  1.4171175956726074
e:  55   train_loss:  408.081968115743   time:  1.242513656616211
e:  55   train_loss:  408.081968115743   val_loss:  730.0386404511308   time:  1.3431739807128906
e:  56   train_loss:  406.18299774012553   time:  1.264188289642334
e:  57   train_loss:  405.50513313475125   time:  1.2628679275512695
e:  58   train_loss:  384.2109217693932   time:  1.2633068561553955
e:  59   train_loss:  374.3321849216216   time:  1.2637803554534912
e:  60   train_loss:  369.74128727734546   time:  1.262462854385376
e:  60   train_loss:  369.74128727734546   val_loss:  719.6937104656718   time:  1.3706257343292236
e:  61   train_loss:  367.7381178121771   time:  1.2642598152160645
e:  62   train_loss:  372.76756819645664   time:  1.2501096725463867
e:  63   train_loss:  362.6041740387404   time:  1.2646565437316895
e:  64   train_loss:  361.5811856785985   time:  1.259303092956543
e:  65   train_loss:  367.2831277845815   time:  1.416536808013916
e:  65   train_loss:  367.2831277845815   val_loss:  723.2734193257304   time:  1.52506685256958
e:  66   train_loss:  354.7619585133884   time:  1.2596540451049805
e:  67   train_loss:  347.71464524209904   time:  1.2661430835723877
e:  68   train_loss:  357.6941567975523   time:  1.2679438591003418
e:  69   train_loss:  340.9954862746059   time:  1.2587761878967285
e:  70   train_loss:  337.71033774045276   time:  1.266495704650879
e:  70   train_loss:  337.71033774045276   val_loss:  714.3248550927952   time:  1.3756585121154785
e:  71   train_loss:  344.33305825093265   time:  1.2613489627838135
e:  72   train_loss:  343.6315285661377   time:  1.2655889987945557
e:  73   train_loss:  339.735293107362   time:  1.264843463897705
e:  74   train_loss:  343.4510807250579   time:  1.4075708389282227
e:  75   train_loss:  331.4764170817433   time:  1.2365403175354004
e:  75   train_loss:  331.4764170817433   val_loss:  1033.4558324352708   time:  1.3449325561523438
e:  76   train_loss:  322.0406590201975   time:  1.2661325931549072
e:  77   train_loss:  326.8391199239895   time:  1.2667157649993896
e:  78   train_loss:  323.3010149241166   time:  1.2576444149017334
e:  79   train_loss:  299.8130830822963   time:  1.2651634216308594
e:  80   train_loss:  309.15637572173443   time:  1.2676398754119873
e:  80   train_loss:  309.15637572173443   val_loss:  723.528158384345   time:  1.3755412101745605
e:  81   train_loss:  310.9378111790731   time:  1.2837085723876953
e:  82   train_loss:  290.9027902125631   time:  1.268932580947876
e:  83   train_loss:  284.5889791901837   time:  1.4189116954803467
e:  84   train_loss:  282.275200236916   time:  1.267573595046997
e:  85   train_loss:  273.73799706555315   time:  1.2673726081848145
e:  85   train_loss:  273.73799706555315   val_loss:  765.2902034890985   time:  1.376009225845337
e:  86   train_loss:  265.6347894862486   time:  1.2795405387878418
e:  87   train_loss:  259.1587940096922   time:  1.264432430267334
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  88   train_loss:  258.17617541745386   time:  1.259347915649414
e:  89   train_loss:  249.97288320238823   time:  1.2641518115997314
e:  90   train_loss:  242.38134767713277   time:  1.2657878398895264
e:  90   train_loss:  242.38134767713277   val_loss:  794.5637724867203   time:  1.374718427658081
e:  91   train_loss:  237.12507993514245   time:  1.262071132659912
e:  92   train_loss:  231.90649723040468   time:  1.268324851989746
e:  93   train_loss:  223.70314219999315   time:  1.2669706344604492
e:  94   train_loss:  223.23499343070188   time:  1.265043020248413
e:  95   train_loss:  217.7839169478297   time:  1.2639408111572266
e:  95   train_loss:  217.7839169478297   val_loss:  746.5274885700949   time:  1.5316238403320312
e:  96   train_loss:  217.74605999711375   time:  1.2653021812438965
e:  97   train_loss:  214.86229906797084   time:  1.259720802307129
e:  98   train_loss:  216.4911358134438   time:  1.2472620010375977
e:  99   train_loss:  212.30041348858967   time:  1.2578094005584717
e:  100   train_loss:  208.39442035346872   time:  1.262685775756836
e:  100   train_loss:  208.39442035346872   val_loss:  790.7389421780942   time:  1.3715541362762451
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  993.990796745549   time:  1.3880138397216797
e:  0   train_loss:  993.990796745549   val_loss:  559.6413275029524   time:  1.4916810989379883
e:  1   train_loss:  746.1918394702541   time:  1.5601906776428223
e:  2   train_loss:  688.3367580845219   time:  1.4023215770721436
e:  3   train_loss:  668.7123698874724   time:  1.3952922821044922
e:  4   train_loss:  666.3318468370712   time:  1.4004030227661133
e:  5   train_loss:  630.9528890110063   time:  1.376371145248413
e:  5   train_loss:  630.9528890110063   val_loss:  632.1306073494345   time:  1.4806561470031738
e:  6   train_loss:  633.1840025600748   time:  1.3856205940246582
e:  7   train_loss:  608.1943011089744   time:  1.3801193237304688
e:  8   train_loss:  613.437889056262   time:  1.551218032836914
e:  9   train_loss:  615.1759474492844   time:  1.4034168720245361
e:  10   train_loss:  620.6557085002285   time:  1.3825440406799316
e:  10   train_loss:  620.6557085002285   val_loss:  597.3088358476707   time:  1.4862902164459229
e:  11   train_loss:  598.2319400152553   time:  1.4070420265197754
e:  12   train_loss:  599.3772074595495   time:  1.3894364833831787
e:  13   train_loss:  587.5814738485184   time:  1.3709816932678223
e:  14   train_loss:  583.3463289620636   time:  1.3835396766662598
e:  15   train_loss:  589.8742799260751   time:  1.554175853729248
e:  15   train_loss:  589.8742799260751   val_loss:  638.2180767936943   time:  1.6582448482513428
e:  16   train_loss:  592.1153011652063   time:  1.385183572769165
e:  17   train_loss:  572.8180762808739   time:  1.378065586090088
e:  18   train_loss:  585.1453077035417   time:  1.3672146797180176
e:  19   train_loss:  570.7225973550123   time:  1.3674757480621338
e:  20   train_loss:  576.182708691314   time:  1.3864986896514893
e:  20   train_loss:  576.182708691314   val_loss:  635.7009038375669   time:  1.6499152183532715
e:  21   train_loss:  574.8313388103757   time:  1.3859448432922363
e:  22   train_loss:  572.8994294445697   time:  1.3668346405029297
e:  23   train_loss:  572.0156074325872   time:  1.385873794555664
e:  24   train_loss:  573.746962905618   time:  1.386944055557251
e:  25   train_loss:  560.2544301025713   time:  1.3730182647705078
e:  25   train_loss:  560.2544301025713   val_loss:  717.1903239519546   time:  1.4759163856506348
e:  26   train_loss:  575.5951396631392   time:  1.5552361011505127
e:  27   train_loss:  549.2307255592125   time:  1.3770370483398438
e:  28   train_loss:  538.776656426043   time:  1.3887829780578613
e:  29   train_loss:  553.3098770807096   time:  1.386077880859375
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  30   train_loss:  545.2383485906915   time:  1.3941540718078613
e:  30   train_loss:  545.2383485906915   val_loss:  725.8334142383551   time:  1.4979569911956787
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (1, 0, 7), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (1, 0, 7) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 7) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 7) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (1, 0, 7)
kwargs: {'config': {'batch_norm': True, 'ff_0': 106, 'ff_num_layers': 2, 'gnn_0': 317, 'gnn_dropout': 0.3368733383678324, 'gnn_num_layers': 1, 'hid_0': 74, 'hid_dropout_rate': 0.29648329598290585, 'in_dropout_rate': 0.04789760399280041, 'lr': 0.0007931206855937558, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 221, 'hid_1': 555, 'hid_2': 1092}, 'budget': 243.0, 'working_directory': '.'}
result: {'loss': 685.1237395541526, 'n_epochs': 62.0, 'info': {'validation loss': 685.1237395541526}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 7) started
DEBUG:hpbandster:job_callback for (1, 0, 7) got condition
DEBUG:hpbandster:Only 5 run(s) for budget 243.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (1, 0, 7) finished
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: trying submitting job (1, 0, 8) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 8) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 8)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 8) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 8) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (1, 0, 8)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 39, 'ff_num_layers': 3, 'gnn_0': 1924, 'gnn_dropout': 0.07546291559754864, 'gnn_num_layers': 3, 'hid_0': 112, 'hid_dropout_rate': 0.2309388035450648, 'in_dropout_rate': 0.4660934753216773, 'lr': 0.004881718006072484, 'num_hid_layers': 1, 'optimizer': 'SGD', 'ff_1': 252, 'ff_2': 266, 'gnn_1': 1507, 'gnn_2': 109, 'sgd_momentum': 0.05095153200008117}, 'budget': 243.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  633.8829552886106   time:  1.501875400543213
e:  0   train_loss:  633.8829552886106   val_loss:  1403.9775148425324   time:  1.6201667785644531
e:  1   train_loss:  594.2021747200804   time:  1.4959776401519775
e:  2   train_loss:  587.8705943508497   time:  1.4788298606872559
e:  3   train_loss:  577.8097847277492   time:  1.6748781204223633
e:  4   train_loss:  583.5118905759059   time:  1.408756971359253
e:  5   train_loss:  562.7323637831549   time:  1.4122073650360107
e:  5   train_loss:  562.7323637831549   val_loss:  1342.3299456198054   time:  1.5299334526062012
e:  6   train_loss:  577.2102302384594   time:  1.4095609188079834
e:  7   train_loss:  562.3937790603218   time:  1.3783445358276367
e:  8   train_loss:  557.6855280556995   time:  1.4050860404968262
e:  9   train_loss:  548.3136169913886   time:  1.4101152420043945
e:  10   train_loss:  548.8261089560788   time:  1.4153361320495605
e:  10   train_loss:  548.8261089560788   val_loss:  1515.4205671719444   time:  1.5339281558990479
e:  11   train_loss:  548.7233669174528   time:  1.5312817096710205
e:  12   train_loss:  540.3290514922909   time:  1.4472475051879883
e:  13   train_loss:  531.9615900823444   time:  1.4194715023040771
e:  14   train_loss:  540.2461933550452   time:  1.4129157066345215
e:  15   train_loss:  533.6709565386818   time:  1.4086298942565918
e:  15   train_loss:  533.6709565386818   val_loss:  1374.1635482871122   time:  1.527385950088501
e:  16   train_loss:  514.7065268628181   time:  1.3988163471221924
e:  17   train_loss:  524.918445257241   time:  1.3135371208190918
e:  18   train_loss:  518.191268215553   time:  1.4643123149871826
e:  19   train_loss:  519.6373291385189   time:  1.4614875316619873
e:  20   train_loss:  508.96617629488594   time:  1.4785687923431396
e:  20   train_loss:  508.96617629488594   val_loss:  1482.1376016441427   time:  1.7810003757476807
e:  21   train_loss:  512.0273361700441   time:  1.4530103206634521
e:  22   train_loss:  506.6666053340891   time:  1.486260175704956
e:  23   train_loss:  519.0474146682615   time:  1.4818599224090576
e:  24   train_loss:  502.7242168448763   time:  1.4654715061187744
e:  25   train_loss:  510.45711910777806   time:  1.474745512008667
e:  25   train_loss:  510.45711910777806   val_loss:  1435.3815913539142   time:  1.5932061672210693
e:  26   train_loss:  509.347233620238   time:  1.4656002521514893
e:  27   train_loss:  495.78384463084524   time:  1.4490838050842285
e:  28   train_loss:  495.07999839897064   time:  1.4324278831481934
e:  29   train_loss:  502.91223099148107   time:  1.4738068580627441
e:  30   train_loss:  483.01105495651603   time:  1.4437665939331055
e:  30   train_loss:  483.01105495651603   val_loss:  1423.529694845597   time:  1.561605453491211
e:  31   train_loss:  490.34326782389064   time:  1.6481609344482422
e:  32   train_loss:  498.82627481827853   time:  1.483940839767456
e:  33   train_loss:  490.74998079171024   time:  1.4877784252166748
e:  34   train_loss:  481.6169711369174   time:  1.4792020320892334
e:  35   train_loss:  486.07417407546444   time:  1.4752020835876465
e:  35   train_loss:  486.07417407546444   val_loss:  1391.6771019610544   time:  1.5929296016693115
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  952.370418704772   time:  1.6062839031219482
e:  0   train_loss:  952.370418704772   val_loss:  553.5309282709637   time:  1.7188220024108887
e:  1   train_loss:  892.0153613235207   time:  1.6662938594818115
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  2   train_loss:  880.5577738657474   time:  1.7014029026031494
e:  3   train_loss:  891.5450068338372   time:  1.7030136585235596
e:  4   train_loss:  870.031318618929   time:  1.554689645767212
e:  5   train_loss:  851.2313425792603   time:  1.5480170249938965
e:  5   train_loss:  851.2313425792603   val_loss:  570.9142516572813   time:  1.6614282131195068
e:  6   train_loss:  807.9699349575457   time:  1.5557937622070312
e:  7   train_loss:  768.1824777420281   time:  1.5482697486877441
e:  8   train_loss:  802.9135731073003   time:  1.6837162971496582
e:  9   train_loss:  733.5064862937959   time:  1.5505397319793701
e:  10   train_loss:  680.8172882281301   time:  1.5330522060394287
e:  10   train_loss:  680.8172882281301   val_loss:  551.6160476175846   time:  1.6432421207427979
e:  11   train_loss:  699.8024440471194   time:  1.5300230979919434
e:  12   train_loss:  696.0762860835199   time:  1.5537006855010986
e:  13   train_loss:  665.8240822884306   time:  1.5516304969787598
e:  14   train_loss:  698.8393409182939   time:  1.5487003326416016
e:  15   train_loss:  661.2219797610977   time:  1.6975901126861572
e:  15   train_loss:  661.2219797610977   val_loss:  556.5624330418912   time:  1.8102617263793945
e:  16   train_loss:  707.6992706755402   time:  1.5542442798614502
e:  17   train_loss:  663.602648363272   time:  1.555241584777832
e:  18   train_loss:  644.9461404061254   time:  1.5518698692321777
e:  19   train_loss:  657.3479818535155   time:  1.5546607971191406
e:  20   train_loss:  657.6893702122395   time:  1.5557355880737305
e:  20   train_loss:  657.6893702122395   val_loss:  545.013685157413   time:  1.6689038276672363
e:  21   train_loss:  630.2941920959867   time:  1.7051668167114258
e:  22   train_loss:  677.1402834820253   time:  1.5493626594543457
e:  23   train_loss:  648.4083042282168   time:  1.5493319034576416
e:  24   train_loss:  653.4972255500621   time:  1.5523676872253418
e:  25   train_loss:  659.401140931174   time:  1.5474085807800293
e:  25   train_loss:  659.401140931174   val_loss:  573.9261219417489   time:  1.6601719856262207
e:  26   train_loss:  622.3419424849371   time:  1.5522513389587402
e:  27   train_loss:  632.5307081281877   time:  1.5517680644989014
e:  28   train_loss:  641.3456464380673   time:  1.6667213439941406
e:  29   train_loss:  622.4727680597829   time:  1.5245280265808105
e:  30   train_loss:  623.659670624239   time:  1.5328402519226074
e:  30   train_loss:  623.659670624239   val_loss:  551.1445457163803   time:  1.6454932689666748
e:  31   train_loss:  620.0406852822059   time:  1.5544805526733398
e:  32   train_loss:  628.2995529667929   time:  1.5540497303009033
e:  33   train_loss:  628.4100615753828   time:  1.5507071018218994
e:  34   train_loss:  636.6661078601747   time:  1.5514535903930664
e:  35   train_loss:  587.0987851924809   time:  1.6895272731781006
e:  35   train_loss:  587.0987851924809   val_loss:  552.7261972915405   time:  1.8025920391082764
e:  36   train_loss:  620.7764840672363   time:  1.5520477294921875
e:  37   train_loss:  613.489158960831   time:  1.550835371017456
e:  38   train_loss:  607.3877237296088   time:  1.5481534004211426
e:  39   train_loss:  610.8598860851828   time:  1.546708106994629
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  40   train_loss:  595.5794168770343   time:  1.5568552017211914
e:  40   train_loss:  595.5794168770343   val_loss:  562.3933432134729   time:  1.7976088523864746
e:  41   train_loss:  601.2236183696116   time:  1.5577731132507324
e:  42   train_loss:  603.9029555203706   time:  1.5472307205200195
e:  43   train_loss:  632.8608716017445   time:  1.5497102737426758
e:  44   train_loss:  596.2287369321513   time:  1.549269199371338
e:  45   train_loss:  591.717105932918   time:  1.5465376377105713
e:  45   train_loss:  591.717105932918   val_loss:  599.4024712666701   time:  1.6586494445800781
e:  46   train_loss:  582.4472664274388   time:  1.6839842796325684
e:  47   train_loss:  591.2746318098011   time:  1.545424222946167
e:  48   train_loss:  607.5397857469363   time:  1.5204246044158936
e:  49   train_loss:  585.3928595323285   time:  1.5416843891143799
e:  50   train_loss:  579.5737711991537   time:  1.5554900169372559
e:  50   train_loss:  579.5737711991537   val_loss:  560.2032209225429   time:  1.668311357498169
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  973.8281753550408   time:  1.5456433296203613
e:  0   train_loss:  973.8281753550408   val_loss:  514.9447924615854   time:  1.6605288982391357
e:  1   train_loss:  901.8024568464444   time:  1.5412194728851318
e:  2   train_loss:  866.113971891528   time:  1.5400185585021973
e:  3   train_loss:  853.9456646119277   time:  1.67848801612854
e:  4   train_loss:  877.7817282897445   time:  1.5356793403625488
e:  5   train_loss:  833.5752926787413   time:  1.5344688892364502
e:  5   train_loss:  833.5752926787413   val_loss:  468.2638629728481   time:  1.648772954940796
e:  6   train_loss:  813.2494856601838   time:  1.5343451499938965
e:  7   train_loss:  786.1545442238099   time:  1.5380923748016357
e:  8   train_loss:  765.1343495172559   time:  1.5371150970458984
e:  9   train_loss:  730.4012244369292   time:  1.6361479759216309
e:  10   train_loss:  739.7832620822279   time:  1.7341487407684326
e:  10   train_loss:  739.7832620822279   val_loss:  559.896006554787   time:  1.8496308326721191
e:  11   train_loss:  703.8156596238936   time:  1.5828523635864258
e:  12   train_loss:  710.9760404144736   time:  1.5711703300476074
e:  13   train_loss:  717.0412828882039   time:  1.5484728813171387
e:  14   train_loss:  678.0810743062881   time:  1.5898401737213135
e:  15   train_loss:  705.0535413801063   time:  1.5481550693511963
e:  15   train_loss:  705.0535413801063   val_loss:  524.3592210510006   time:  1.6624755859375
e:  16   train_loss:  678.3619939538444   time:  1.729264736175537
e:  17   train_loss:  722.8082854459592   time:  1.5628280639648438
e:  18   train_loss:  681.5802210870895   time:  1.5707695484161377
e:  19   train_loss:  667.0325889954385   time:  1.5744459629058838
e:  20   train_loss:  689.8273145838667   time:  1.5737390518188477
e:  20   train_loss:  689.8273145838667   val_loss:  618.5383368442283   time:  1.689021348953247
e:  21   train_loss:  690.6303026985861   time:  1.5699820518493652
e:  22   train_loss:  735.9940320984102   time:  1.5778429508209229
e:  23   train_loss:  657.1259266572102   time:  1.5750877857208252
e:  24   train_loss:  662.4793476815953   time:  1.7529923915863037
e:  25   train_loss:  652.7271892640807   time:  1.5718255043029785
e:  25   train_loss:  652.7271892640807   val_loss:  499.07603063605194   time:  1.6881365776062012
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  26   train_loss:  652.098332580889   time:  1.7191166877746582
e:  27   train_loss:  651.9188103576971   time:  1.5790565013885498
e:  28   train_loss:  686.9433717754606   time:  1.5597949028015137
e:  29   train_loss:  668.2445727516694   time:  1.5661425590515137
e:  30   train_loss:  640.1269977769539   time:  1.5753843784332275
e:  30   train_loss:  640.1269977769539   val_loss:  463.9009427018822   time:  1.6917004585266113
e:  31   train_loss:  667.3023888289288   time:  1.7435638904571533
e:  32   train_loss:  644.7243601338251   time:  1.5864403247833252
e:  33   train_loss:  644.8085971158987   time:  1.5785541534423828
e:  34   train_loss:  653.5093020618681   time:  1.526594877243042
e:  35   train_loss:  648.0711449133371   time:  1.5706408023834229
e:  35   train_loss:  648.0711449133371   val_loss:  467.60052440444974   time:  1.6865062713623047
e:  36   train_loss:  669.1501248053941   time:  1.574540138244629
e:  37   train_loss:  639.2596546768126   time:  1.5536220073699951
e:  38   train_loss:  670.2530650464273   time:  1.5982425212860107
e:  39   train_loss:  643.8099259721835   time:  1.7614789009094238
e:  40   train_loss:  649.3349679456488   time:  1.5773110389709473
e:  40   train_loss:  649.3349679456488   val_loss:  461.7493813993433   time:  1.6923210620880127
e:  41   train_loss:  661.6398188857524   time:  1.5674655437469482
e:  42   train_loss:  641.0128120553018   time:  1.5783500671386719
e:  43   train_loss:  659.7566075321888   time:  1.5775141716003418
e:  44   train_loss:  626.5083417029506   time:  1.5667803287506104
e:  45   train_loss:  611.6870563670245   time:  1.5770349502563477
e:  45   train_loss:  611.6870563670245   val_loss:  465.26818513669673   time:  1.6937260627746582
e:  46   train_loss:  625.6215727665236   time:  1.7377302646636963
e:  47   train_loss:  607.2944708958064   time:  1.553459882736206
e:  48   train_loss:  616.4650481254528   time:  1.575319766998291
e:  49   train_loss:  640.7628329732928   time:  1.5799429416656494
e:  50   train_loss:  670.4679066800699   time:  1.5669009685516357
e:  50   train_loss:  670.4679066800699   val_loss:  459.8125252737378   time:  1.6810839176177979
e:  51   train_loss:  634.8137944480511   time:  1.5784025192260742
e:  52   train_loss:  592.0718504080155   time:  1.5369889736175537
e:  53   train_loss:  622.8831829063582   time:  1.6765050888061523
e:  54   train_loss:  637.0003781258688   time:  1.5873467922210693
e:  55   train_loss:  628.8058925632214   time:  1.5764188766479492
e:  55   train_loss:  628.8058925632214   val_loss:  473.1260951367633   time:  1.692028522491455
e:  56   train_loss:  597.7132724037233   time:  1.558509111404419
e:  57   train_loss:  599.735411950579   time:  1.5892741680145264
e:  58   train_loss:  641.466047537354   time:  1.5622904300689697
e:  59   train_loss:  647.7866819993586   time:  1.5801331996917725
e:  60   train_loss:  615.5704610504833   time:  1.5727941989898682
e:  60   train_loss:  615.5704610504833   val_loss:  467.1060482132349   time:  1.6888618469238281
e:  61   train_loss:  592.5198312181401   time:  1.756443738937378
e:  62   train_loss:  596.6024124465297   time:  1.5738277435302734
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  63   train_loss:  627.7131711297917   time:  1.5681617259979248
e:  64   train_loss:  714.2927203836675   time:  1.6078453063964844
e:  65   train_loss:  621.734123426744   time:  1.5998752117156982
e:  65   train_loss:  621.734123426744   val_loss:  522.1818440557988   time:  1.7148921489715576
e:  66   train_loss:  632.1810227596243   time:  1.6006507873535156
e:  67   train_loss:  623.3544302055184   time:  1.5751888751983643
e:  68   train_loss:  635.8178858232234   time:  1.7853522300720215
e:  69   train_loss:  616.8034374744265   time:  1.590712547302246
e:  70   train_loss:  624.1661308028114   time:  1.576131820678711
e:  70   train_loss:  624.1661308028114   val_loss:  457.2583571258102   time:  1.6907191276550293
e:  71   train_loss:  600.9960006761435   time:  1.5673069953918457
e:  72   train_loss:  598.4570046618052   time:  1.564244031906128
e:  73   train_loss:  622.6764394417281   time:  1.5885286331176758
e:  74   train_loss:  611.5261929114138   time:  1.6028873920440674
e:  75   train_loss:  583.8054973145177   time:  1.7816705703735352
e:  75   train_loss:  583.8054973145177   val_loss:  498.9698957152821   time:  1.8958780765533447
e:  76   train_loss:  582.2273789598547   time:  1.6026248931884766
e:  77   train_loss:  612.2402200964668   time:  1.583150863647461
e:  78   train_loss:  711.9997326775909   time:  1.5958151817321777
e:  79   train_loss:  619.4564811691658   time:  1.60190749168396
e:  80   train_loss:  618.4544835900915   time:  1.5915679931640625
e:  80   train_loss:  618.4544835900915   val_loss:  460.106433436453   time:  1.7063653469085693
e:  81   train_loss:  597.0515964659741   time:  1.6007537841796875
e:  82   train_loss:  609.586517006071   time:  1.8086388111114502
e:  83   train_loss:  622.7904086771218   time:  1.6101007461547852
e:  84   train_loss:  589.8848383455122   time:  1.5978655815124512
e:  85   train_loss:  597.1960940384878   time:  1.5924313068389893
e:  85   train_loss:  597.1960940384878   val_loss:  718.1076460352664   time:  1.7074353694915771
e:  86   train_loss:  643.0568043039717   time:  1.5805470943450928
e:  87   train_loss:  607.3081825088723   time:  1.6036546230316162
e:  88   train_loss:  586.3537626671975   time:  1.5879621505737305
e:  89   train_loss:  591.741184417145   time:  1.5689642429351807
e:  90   train_loss:  609.4490728521627   time:  1.7791857719421387
e:  90   train_loss:  609.4490728521627   val_loss:  488.9274572638975   time:  1.8936030864715576
e:  91   train_loss:  597.0859645356836   time:  1.5893943309783936
e:  92   train_loss:  586.4778029045901   time:  1.6058416366577148
e:  93   train_loss:  582.2578847445659   time:  1.602769136428833
e:  94   train_loss:  584.1621900176386   time:  1.5859718322753906
e:  95   train_loss:  585.972091596564   time:  1.594515323638916
e:  95   train_loss:  585.972091596564   val_loss:  651.4028909195222   time:  1.7083899974822998
e:  96   train_loss:  620.7683090571841   time:  1.6015312671661377
e:  97   train_loss:  609.3203169388192   time:  1.7669215202331543
e:  98   train_loss:  584.1716774260278   time:  1.575098991394043
e:  99   train_loss:  601.9711206413248   time:  1.5788147449493408
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  100   train_loss:  597.9102822828503   time:  1.5910868644714355
e:  100   train_loss:  597.9102822828503   val_loss:  486.15988867866497   time:  1.7062616348266602
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  898.6884846354357   time:  1.489168643951416
e:  0   train_loss:  898.6884846354357   val_loss:  739.5069598278668   time:  1.6082992553710938
e:  1   train_loss:  836.7960583544926   time:  1.4485244750976562
e:  2   train_loss:  822.3625367323278   time:  1.468951940536499
e:  3   train_loss:  814.9654386878565   time:  1.4776875972747803
e:  4   train_loss:  841.029173016538   time:  1.660700798034668
e:  5   train_loss:  804.5204649424905   time:  1.4714996814727783
e:  5   train_loss:  804.5204649424905   val_loss:  731.7923171710219   time:  1.5892236232757568
e:  6   train_loss:  766.8833708982505   time:  1.4658541679382324
e:  7   train_loss:  756.4930137119519   time:  1.4472863674163818
e:  8   train_loss:  761.0326848366582   time:  1.451946496963501
e:  9   train_loss:  717.6409754969391   time:  1.450655460357666
e:  10   train_loss:  704.7958911874769   time:  1.4785714149475098
e:  10   train_loss:  704.7958911874769   val_loss:  709.1836842404299   time:  1.5970680713653564
e:  11   train_loss:  666.4708561114379   time:  1.4583022594451904
e:  12   train_loss:  703.2979232552689   time:  1.464585304260254
e:  13   train_loss:  666.1414119166864   time:  1.4713008403778076
e:  14   train_loss:  654.0743820300162   time:  1.4666645526885986
e:  15   train_loss:  655.255504668637   time:  1.4801380634307861
e:  15   train_loss:  655.255504668637   val_loss:  707.7525036765072   time:  1.5986242294311523
e:  16   train_loss:  655.8581357291434   time:  1.4678268432617188
e:  17   train_loss:  651.6001881926536   time:  1.4673123359680176
e:  18   train_loss:  646.0060864590414   time:  1.6659862995147705
e:  19   train_loss:  632.4813637890842   time:  1.4562180042266846
e:  20   train_loss:  659.2899485023769   time:  1.4601967334747314
e:  20   train_loss:  659.2899485023769   val_loss:  739.9008597794915   time:  1.5789799690246582
e:  21   train_loss:  639.2387527075701   time:  1.4760634899139404
e:  22   train_loss:  637.7746808002217   time:  1.448706865310669
e:  23   train_loss:  627.4961987535632   time:  1.4589669704437256
e:  24   train_loss:  622.556309184119   time:  1.4638397693634033
e:  25   train_loss:  620.5092668195235   time:  1.462721586227417
e:  25   train_loss:  620.5092668195235   val_loss:  713.3269654060654   time:  1.582002878189087
e:  26   train_loss:  629.3985167838235   time:  1.480071783065796
e:  27   train_loss:  626.3640026040914   time:  1.434875249862671
e:  28   train_loss:  610.7444999192478   time:  1.4514186382293701
e:  29   train_loss:  623.2484923325896   time:  1.4733989238739014
e:  30   train_loss:  617.2455666750618   time:  1.4781694412231445
e:  30   train_loss:  617.2455666750618   val_loss:  694.151221804901   time:  1.5967347621917725
e:  31   train_loss:  615.7698932902221   time:  1.6673457622528076
e:  32   train_loss:  637.5434714272317   time:  1.4703192710876465
e:  33   train_loss:  617.2905399269813   time:  1.4768807888031006
e:  34   train_loss:  600.3320495060494   time:  1.4711592197418213
e:  35   train_loss:  610.3521936254284   time:  1.4608244895935059
e:  35   train_loss:  610.3521936254284   val_loss:  734.0953876834521   time:  1.5789098739624023
e:  36   train_loss:  646.1420715964598   time:  1.4632372856140137
e:  37   train_loss:  602.2914170130431   time:  1.4508378505706787
e:  38   train_loss:  611.152324023088   time:  1.4693527221679688
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  39   train_loss:  610.8644228907765   time:  1.4802131652832031
e:  40   train_loss:  612.4132373883292   time:  1.4562675952911377
e:  40   train_loss:  612.4132373883292   val_loss:  717.9739327887295   time:  1.5749452114105225
e:  41   train_loss:  602.3892801193349   time:  1.4859507083892822
e:  42   train_loss:  586.2067031187922   time:  1.4755876064300537
e:  43   train_loss:  603.1438473858126   time:  1.676008939743042
e:  44   train_loss:  609.3643769329935   time:  1.4585850238800049
e:  45   train_loss:  594.3663534373122   time:  1.4130499362945557
e:  45   train_loss:  594.3663534373122   val_loss:  661.352423523978   time:  1.5325260162353516
e:  46   train_loss:  611.4342015170236   time:  1.4147658348083496
e:  47   train_loss:  591.825245658316   time:  1.613204002380371
e:  48   train_loss:  587.8780706028563   time:  1.4016728401184082
e:  49   train_loss:  588.2126720028624   time:  1.413318157196045
e:  50   train_loss:  588.1021838358492   time:  1.4196875095367432
e:  50   train_loss:  588.1021838358492   val_loss:  673.1474436769669   time:  1.5451171398162842
e:  51   train_loss:  601.5755957411092   time:  1.4579248428344727
e:  52   train_loss:  593.6004640877784   time:  1.557384729385376
e:  53   train_loss:  587.5092974850286   time:  1.4988157749176025
e:  54   train_loss:  574.2681171004031   time:  1.535675287246704
e:  55   train_loss:  602.5863728025114   time:  1.4074432849884033
e:  55   train_loss:  602.5863728025114   val_loss:  662.2075581809627   time:  1.5262877941131592
e:  56   train_loss:  574.6576484236954   time:  1.5411579608917236
e:  57   train_loss:  580.8965059932568   time:  1.4114117622375488
e:  58   train_loss:  581.7195689756735   time:  1.4120149612426758
e:  59   train_loss:  575.3135826554148   time:  1.4119055271148682
e:  60   train_loss:  578.9664836267336   time:  1.4092261791229248
e:  60   train_loss:  578.9664836267336   val_loss:  698.0810600097649   time:  1.5275633335113525
e:  61   train_loss:  568.1218831943606   time:  1.411726713180542
e:  62   train_loss:  580.7834817223192   time:  1.4090359210968018
e:  63   train_loss:  567.6174877023677   time:  1.4138567447662354
e:  64   train_loss:  576.5519419181335   time:  1.400646448135376
e:  65   train_loss:  582.4511841886924   time:  1.4059898853302002
e:  65   train_loss:  582.4511841886924   val_loss:  681.7997642854737   time:  1.5243332386016846
e:  66   train_loss:  576.4725368174923   time:  1.4078030586242676
e:  67   train_loss:  563.5586325477236   time:  1.3886539936065674
e:  68   train_loss:  597.5854273349446   time:  1.5075674057006836
e:  69   train_loss:  581.2145709200181   time:  1.390674114227295
e:  70   train_loss:  561.8979034610554   time:  1.410585880279541
e:  70   train_loss:  561.8979034610554   val_loss:  665.1060497004507   time:  1.5297033786773682
e:  71   train_loss:  565.0261504579403   time:  1.4122493267059326
e:  72   train_loss:  571.5694442662486   time:  1.4166767597198486
e:  73   train_loss:  572.6208522345248   time:  1.4479386806488037
e:  74   train_loss:  576.5101976808005   time:  1.4140009880065918
e:  75   train_loss:  557.998157426967   time:  1.4150891304016113
e:  75   train_loss:  557.998157426967   val_loss:  744.6754393019849   time:  1.5345432758331299
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  963.6985998159269   time:  1.5512022972106934
e:  0   train_loss:  963.6985998159269   val_loss:  555.5173268987947   time:  1.6641287803649902
e:  1   train_loss:  902.7006089892361   time:  1.6055858135223389
e:  2   train_loss:  880.1811556347965   time:  1.792400598526001
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  3   train_loss:  904.7671783185915   time:  1.5966291427612305
e:  4   train_loss:  858.9175924125941   time:  1.6508514881134033
e:  5   train_loss:  840.9318700202334   time:  1.5678753852844238
e:  5   train_loss:  840.9318700202334   val_loss:  634.8536019311183   time:  1.6817595958709717
e:  6   train_loss:  833.1328349402759   time:  1.552666187286377
e:  7   train_loss:  817.747470047962   time:  1.5544836521148682
e:  8   train_loss:  739.7153846025035   time:  1.6583187580108643
e:  9   train_loss:  723.0284857643144   time:  1.5409719944000244
e:  10   train_loss:  785.7367730610858   time:  1.5397753715515137
e:  10   train_loss:  785.7367730610858   val_loss:  573.4677254092367   time:  1.6516594886779785
e:  11   train_loss:  713.3836377341714   time:  1.5077526569366455
e:  12   train_loss:  757.3952892004046   time:  1.5470173358917236
e:  13   train_loss:  709.8894548197009   time:  1.5514552593231201
e:  14   train_loss:  693.4955064529294   time:  1.5504071712493896
e:  15   train_loss:  675.8390283163823   time:  1.7014873027801514
e:  15   train_loss:  675.8390283163823   val_loss:  555.42347067875   time:  1.8146641254425049
e:  16   train_loss:  688.592368136961   time:  1.5480875968933105
e:  17   train_loss:  673.0074321122789   time:  1.5507142543792725
e:  18   train_loss:  715.9200036828356   time:  1.5520799160003662
e:  19   train_loss:  693.9662806704403   time:  1.5504984855651855
e:  20   train_loss:  662.2852950877486   time:  1.551774024963379
e:  20   train_loss:  662.2852950877486   val_loss:  541.8394580503171   time:  1.665252685546875
e:  21   train_loss:  660.7468832208111   time:  1.5453765392303467
e:  22   train_loss:  660.9103960808579   time:  1.7032077312469482
e:  23   train_loss:  656.2520359325642   time:  1.5580732822418213
e:  24   train_loss:  660.6371813217648   time:  1.5470685958862305
e:  25   train_loss:  645.838433219375   time:  1.544116497039795
e:  25   train_loss:  645.838433219375   val_loss:  537.0926093033657   time:  1.6582863330841064
e:  26   train_loss:  647.3050643412448   time:  1.5708651542663574
e:  27   train_loss:  650.1562215281456   time:  1.5687282085418701
e:  28   train_loss:  647.7058145299125   time:  1.6842541694641113
e:  29   train_loss:  651.1984489672906   time:  1.5361731052398682
e:  30   train_loss:  629.1762715832825   time:  1.5201704502105713
e:  30   train_loss:  629.1762715832825   val_loss:  541.4896677485563   time:  1.6333951950073242
e:  31   train_loss:  654.5158699361398   time:  1.5537757873535156
e:  32   train_loss:  639.1282774893593   time:  1.5513834953308105
e:  33   train_loss:  689.0276301823408   time:  1.5523076057434082
e:  34   train_loss:  647.3415579997268   time:  1.7821359634399414
e:  35   train_loss:  632.3515631742256   time:  1.7355468273162842
e:  35   train_loss:  632.3515631742256   val_loss:  537.6385387176497   time:  1.8429503440856934
e:  36   train_loss:  643.1325195162492   time:  1.5464255809783936
e:  37   train_loss:  644.1245524198174   time:  1.5456702709197998
e:  38   train_loss:  653.0900641540957   time:  1.547745943069458
e:  39   train_loss:  616.0231798777924   time:  1.7389326095581055
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  40   train_loss:  626.8392964531763   time:  1.626861572265625
e:  40   train_loss:  626.8392964531763   val_loss:  578.4567938487793   time:  1.8728110790252686
e:  41   train_loss:  622.559075483874   time:  1.8046917915344238
e:  42   train_loss:  613.8242769396865   time:  1.5479223728179932
e:  43   train_loss:  613.609738397055   time:  1.6390442848205566
e:  44   train_loss:  613.0864796439841   time:  1.647789716720581
e:  45   train_loss:  621.7615709916371   time:  1.6252975463867188
e:  45   train_loss:  621.7615709916371   val_loss:  589.011450134402   time:  1.7379841804504395
e:  46   train_loss:  599.3580996166928   time:  1.6024038791656494
e:  47   train_loss:  618.8284699647892   time:  1.58935546875
e:  48   train_loss:  630.1926805219932   time:  1.5779690742492676
e:  49   train_loss:  600.2223003768373   time:  1.8180227279663086
e:  50   train_loss:  595.6347318283147   time:  1.595041275024414
e:  50   train_loss:  595.6347318283147   val_loss:  536.0698204736462   time:  1.7082297801971436
e:  51   train_loss:  603.5993445662144   time:  1.6200294494628906
e:  52   train_loss:  595.3437704549513   time:  1.6089859008789062
e:  53   train_loss:  601.2245828030543   time:  1.616032361984253
e:  54   train_loss:  604.6596116856989   time:  1.619661808013916
e:  55   train_loss:  590.531645880102   time:  1.839109182357788
e:  55   train_loss:  590.531645880102   val_loss:  600.0850114612689   time:  1.9530260562896729
e:  56   train_loss:  602.8079464774684   time:  1.6035258769989014
e:  57   train_loss:  595.8053912245342   time:  1.6089487075805664
e:  58   train_loss:  580.7025017552616   time:  1.6056709289550781
e:  59   train_loss:  590.4193807723092   time:  1.583272933959961
e:  60   train_loss:  588.7996965371983   time:  1.6104230880737305
e:  60   train_loss:  588.7996965371983   val_loss:  541.5361462581592   time:  1.904343843460083
e:  61   train_loss:  557.6850854655563   time:  1.61533784866333
e:  62   train_loss:  583.1256149399377   time:  1.6137199401855469
e:  63   train_loss:  566.5379479252865   time:  1.6136181354522705
e:  64   train_loss:  583.4382703846909   time:  1.6013801097869873
e:  65   train_loss:  572.8256299276641   time:  1.5926682949066162
e:  65   train_loss:  572.8256299276641   val_loss:  579.4407190333866   time:  1.70371675491333
e:  66   train_loss:  572.3222267709964   time:  1.578265905380249
e:  67   train_loss:  559.8067148523627   time:  1.8123068809509277
e:  68   train_loss:  571.0411187099146   time:  1.605846643447876
e:  69   train_loss:  566.0119529750466   time:  1.6267240047454834
e:  70   train_loss:  564.6439266013157   time:  1.6148498058319092
e:  70   train_loss:  564.6439266013157   val_loss:  551.8652316373824   time:  1.7281336784362793
e:  71   train_loss:  563.0521692729146   time:  1.6026723384857178
e:  72   train_loss:  563.1644442625624   time:  1.6234652996063232
e:  73   train_loss:  570.7019479159087   time:  1.8380930423736572
e:  74   train_loss:  565.8349581278466   time:  1.5914320945739746
e:  75   train_loss:  603.1621222086147   time:  1.5932414531707764
e:  75   train_loss:  603.1621222086147   val_loss:  571.2851083469899   time:  1.7067034244537354
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  76   train_loss:  561.8230076635786   time:  1.609757661819458
e:  77   train_loss:  533.9033022230016   time:  1.6071031093597412
e:  78   train_loss:  568.1516607097446   time:  1.6133947372436523
e:  79   train_loss:  586.9520761469937   time:  1.6068439483642578
e:  80   train_loss:  553.0159960295582   time:  1.8238835334777832
e:  80   train_loss:  553.0159960295582   val_loss:  565.8613334375202   time:  1.9367303848266602
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (1, 0, 8), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (1, 0, 8) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 8) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 8) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (1, 0, 8)
kwargs: {'config': {'batch_norm': False, 'ff_0': 39, 'ff_num_layers': 3, 'gnn_0': 1924, 'gnn_dropout': 0.07546291559754864, 'gnn_num_layers': 3, 'hid_0': 112, 'hid_dropout_rate': 0.2309388035450648, 'in_dropout_rate': 0.4660934753216773, 'lr': 0.004881718006072484, 'num_hid_layers': 1, 'optimizer': 'SGD', 'ff_1': 252, 'ff_2': 266, 'gnn_1': 1507, 'gnn_2': 109, 'sgd_momentum': 0.05095153200008117}, 'budget': 243.0, 'working_directory': '.'}
result: {'loss': 708.4048463801306, 'n_epochs': 68.0, 'info': {'validation loss': 708.4048463801306}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 8) started
DEBUG:hpbandster:job_callback for (1, 0, 8) got condition
DEBUG:hpbandster:Only 6 run(s) for budget 243.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (1, 0, 8) finished
DEBUG:hpbandster:ITERATION: Advancing config (1, 0, 7) to next budget 729.000000
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: trying submitting job (1, 0, 7) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 7) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 7)
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 7) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 7) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (1, 0, 7)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 106, 'ff_num_layers': 2, 'gnn_0': 317, 'gnn_dropout': 0.3368733383678324, 'gnn_num_layers': 1, 'hid_0': 74, 'hid_dropout_rate': 0.29648329598290585, 'in_dropout_rate': 0.04789760399280041, 'lr': 0.0007931206855937558, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 221, 'hid_1': 555, 'hid_2': 1092}, 'budget': 729.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  659.4372830808034   time:  1.304675579071045
e:  0   train_loss:  659.4372830808034   val_loss:  1434.227205641663   time:  1.4107038974761963
e:  1   train_loss:  553.2973192237912   time:  1.3061866760253906
e:  2   train_loss:  518.172438213805   time:  1.2911701202392578
e:  3   train_loss:  495.8798255537789   time:  1.2868502140045166
e:  4   train_loss:  490.9650807141928   time:  1.2662761211395264
e:  5   train_loss:  478.9420728387996   time:  1.3023698329925537
e:  5   train_loss:  478.9420728387996   val_loss:  1607.7093962101592   time:  1.408658742904663
e:  6   train_loss:  471.2747846705173   time:  1.3052177429199219
e:  7   train_loss:  465.711153703904   time:  1.28835129737854
e:  8   train_loss:  459.40722274981164   time:  1.4760291576385498
e:  9   train_loss:  453.05874705388413   time:  1.2742300033569336
e:  10   train_loss:  447.26633622664974   time:  1.2803776264190674
e:  10   train_loss:  447.26633622664974   val_loss:  1429.7705388064646   time:  1.3862614631652832
e:  11   train_loss:  450.13088107455735   time:  1.2812578678131104
e:  12   train_loss:  441.42643849546033   time:  1.261913537979126
e:  13   train_loss:  437.3564321339287   time:  1.2457935810089111
e:  14   train_loss:  433.5214409843533   time:  1.2419946193695068
e:  15   train_loss:  434.50638589319794   time:  1.2366738319396973
e:  15   train_loss:  434.50638589319794   val_loss:  1385.2855395700126   time:  1.344743251800537
e:  16   train_loss:  432.00121860189483   time:  1.2615525722503662
e:  17   train_loss:  427.9791713910984   time:  1.2379367351531982
e:  18   train_loss:  426.05530577164205   time:  1.2322731018066406
e:  19   train_loss:  421.0545967599859   time:  1.3807995319366455
e:  20   train_loss:  418.3420875310969   time:  1.2509300708770752
e:  20   train_loss:  418.3420875310969   val_loss:  1367.6831441049483   time:  1.3589274883270264
e:  21   train_loss:  415.6489046014053   time:  1.237656593322754
e:  22   train_loss:  412.4193383902006   time:  1.2458202838897705
e:  23   train_loss:  410.61234705719653   time:  1.2414751052856445
e:  24   train_loss:  407.65649016593983   time:  1.2585055828094482
e:  25   train_loss:  401.74146058901044   time:  1.247849941253662
e:  25   train_loss:  401.74146058901044   val_loss:  1361.9167922237327   time:  1.3544559478759766
e:  26   train_loss:  398.21044700155556   time:  1.2327370643615723
e:  27   train_loss:  397.21258102531135   time:  1.2344608306884766
e:  28   train_loss:  389.866293216543   time:  1.4079475402832031
e:  29   train_loss:  386.8389512094384   time:  1.227459192276001
e:  30   train_loss:  388.5359239802001   time:  1.2454097270965576
e:  30   train_loss:  388.5359239802001   val_loss:  1387.7090680658066   time:  1.3532981872558594
e:  31   train_loss:  383.2833061175939   time:  1.248288869857788
e:  32   train_loss:  376.91085725426484   time:  1.2499735355377197
e:  33   train_loss:  385.6484405931745   time:  1.1956725120544434
e:  34   train_loss:  369.36212572076516   time:  1.2431237697601318
e:  35   train_loss:  366.3371752596763   time:  1.2778677940368652
e:  35   train_loss:  366.3371752596763   val_loss:  1355.1533330250663   time:  1.4039931297302246
e:  36   train_loss:  362.9292714696703   time:  1.2460896968841553
e:  37   train_loss:  353.9894822717813   time:  1.2449040412902832
e:  38   train_loss:  348.20299360187056   time:  1.2525074481964111
e:  39   train_loss:  343.09689822267467   time:  1.2467572689056396
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  40   train_loss:  340.68497233331095   time:  1.39337158203125
e:  40   train_loss:  340.68497233331095   val_loss:  1423.6960272977476   time:  1.492995262145996
e:  41   train_loss:  332.98188589125436   time:  1.2487597465515137
e:  42   train_loss:  326.9849578326605   time:  1.2426040172576904
e:  43   train_loss:  324.9685362482198   time:  1.2423884868621826
e:  44   train_loss:  325.69245321420993   time:  1.2504074573516846
e:  45   train_loss:  318.4318556092637   time:  1.241318941116333
e:  45   train_loss:  318.4318556092637   val_loss:  1397.4103350919504   time:  1.3485751152038574
e:  46   train_loss:  314.3038562645931   time:  1.2453083992004395
e:  47   train_loss:  307.63924751884525   time:  1.2484714984893799
e:  48   train_loss:  303.81973526889055   time:  1.2426331043243408
e:  49   train_loss:  300.59967948179667   time:  1.2408859729766846
e:  50   train_loss:  292.8795407173312   time:  1.2281465530395508
e:  50   train_loss:  292.8795407173312   val_loss:  1367.5905948776742   time:  1.3346607685089111
e:  51   train_loss:  288.0972043229468   time:  1.244727611541748
e:  52   train_loss:  284.38350142588627   time:  1.4051454067230225
e:  53   train_loss:  274.543427906081   time:  1.226524829864502
e:  54   train_loss:  271.03145393841385   time:  1.250084638595581
e:  55   train_loss:  263.3594821574747   time:  1.243696928024292
e:  55   train_loss:  263.3594821574747   val_loss:  1194.6173385456195   time:  1.3502683639526367
e:  56   train_loss:  260.48213900291114   time:  1.2411112785339355
e:  57   train_loss:  251.27629701595785   time:  1.2627754211425781
e:  58   train_loss:  245.73365496957717   time:  1.331772804260254
e:  59   train_loss:  240.73729821505748   time:  1.308410882949829
e:  60   train_loss:  236.31773707099518   time:  1.2216997146606445
e:  60   train_loss:  236.31773707099518   val_loss:  1059.9621802892507   time:  1.3292856216430664
e:  61   train_loss:  234.00930414055125   time:  1.3520424365997314
e:  62   train_loss:  229.560154314843   time:  1.2259795665740967
e:  63   train_loss:  227.0423337618526   time:  1.2298972606658936
e:  64   train_loss:  221.8346367513557   time:  1.2149412631988525
e:  65   train_loss:  220.00704672231595   time:  1.2145133018493652
e:  65   train_loss:  220.00704672231595   val_loss:  1083.8950232777493   time:  1.3220126628875732
e:  66   train_loss:  214.7064463861801   time:  1.2279698848724365
e:  67   train_loss:  210.7259133693098   time:  1.2300095558166504
e:  68   train_loss:  211.12846507089597   time:  1.2254621982574463
e:  69   train_loss:  205.53302662530726   time:  1.2237815856933594
e:  70   train_loss:  204.74833222552525   time:  1.2299094200134277
e:  70   train_loss:  204.74833222552525   val_loss:  1102.8378080090731   time:  1.336442232131958
e:  71   train_loss:  200.50037430300168   time:  1.2326655387878418
e:  72   train_loss:  200.93783762658794   time:  1.3490300178527832
e:  73   train_loss:  198.63233147768327   time:  1.235276460647583
e:  74   train_loss:  196.67840840748212   time:  1.2009527683258057
e:  75   train_loss:  196.25093028021493   time:  1.2102739810943604
e:  75   train_loss:  196.25093028021493   val_loss:  1116.4679265992045   time:  1.3165323734283447
e:  76   train_loss:  193.86889448091722   time:  1.2240161895751953
e:  77   train_loss:  189.9461546030462   time:  1.2219033241271973
e:  78   train_loss:  186.55127873843907   time:  1.2135934829711914
e:  79   train_loss:  184.74085756853984   time:  1.2223408222198486
e:  80   train_loss:  182.0275661547685   time:  1.2313644886016846
e:  80   train_loss:  182.0275661547685   val_loss:  1267.6588756713631   time:  1.3367207050323486
e:  81   train_loss:  179.4738288936891   time:  1.2200963497161865
e:  82   train_loss:  178.70181558595823   time:  1.3386294841766357
e:  83   train_loss:  177.37423421240698   time:  1.2071232795715332
e:  84   train_loss:  176.07712062859994   time:  1.208226203918457
e:  85   train_loss:  173.76253001850958   time:  1.2133347988128662
e:  85   train_loss:  173.76253001850958   val_loss:  1363.2844556813263   time:  1.3195228576660156
e:  86   train_loss:  169.61353356742032   time:  1.2209999561309814
e:  87   train_loss:  167.55817712361215   time:  1.2225463390350342
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  88   train_loss:  168.24818779075812   time:  1.215080976486206
e:  89   train_loss:  164.43252133964717   time:  1.2167327404022217
e:  90   train_loss:  163.0004945549128   time:  1.2247934341430664
e:  90   train_loss:  163.0004945549128   val_loss:  1252.777809395136   time:  1.4595725536346436
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1000.3620898284623   time:  1.3408997058868408
e:  0   train_loss:  1000.3620898284623   val_loss:  541.3941721209725   time:  1.440850019454956
e:  1   train_loss:  789.4392360897865   time:  1.3330137729644775
e:  2   train_loss:  690.5590307908519   time:  1.3343040943145752
e:  3   train_loss:  661.6170501095067   time:  1.3375327587127686
e:  4   train_loss:  643.3897393800906   time:  1.3374226093292236
e:  5   train_loss:  623.5341426910871   time:  1.3355631828308105
e:  5   train_loss:  623.5341426910871   val_loss:  558.3211422922132   time:  1.5635175704956055
e:  6   train_loss:  629.0000958934075   time:  1.3136513233184814
e:  7   train_loss:  632.5429243986875   time:  1.325674295425415
e:  8   train_loss:  624.9219158749629   time:  1.329939365386963
e:  9   train_loss:  616.9818685607457   time:  1.3352594375610352
e:  10   train_loss:  592.7221992348896   time:  1.3341219425201416
e:  10   train_loss:  592.7221992348896   val_loss:  600.4576421700643   time:  1.434089183807373
e:  11   train_loss:  594.0554699231166   time:  1.4616820812225342
e:  12   train_loss:  588.9981746071576   time:  1.3291141986846924
e:  13   train_loss:  591.7133771087005   time:  1.3240966796875
e:  14   train_loss:  593.4126813687558   time:  1.3345341682434082
e:  15   train_loss:  593.2020087790715   time:  1.3365671634674072
e:  15   train_loss:  593.2020087790715   val_loss:  619.0655885934746   time:  1.4359757900238037
e:  16   train_loss:  586.4329550441734   time:  1.3341386318206787
e:  17   train_loss:  579.1938538945741   time:  1.3237833976745605
e:  18   train_loss:  562.9556540608628   time:  1.4743247032165527
e:  19   train_loss:  572.955223272594   time:  1.3360061645507812
e:  20   train_loss:  573.4251011731967   time:  1.3835608959197998
e:  20   train_loss:  573.4251011731967   val_loss:  756.5831672459301   time:  1.4837830066680908
e:  21   train_loss:  565.8194948489104   time:  1.358649492263794
e:  22   train_loss:  552.0236532961162   time:  1.4210691452026367
e:  23   train_loss:  555.3925668969985   time:  1.3418660163879395
e:  24   train_loss:  556.9165365189916   time:  1.3431015014648438
e:  25   train_loss:  546.8393284740839   time:  1.4717364311218262
e:  25   train_loss:  546.8393284740839   val_loss:  1089.0097959728819   time:  1.5665476322174072
e:  26   train_loss:  548.2605810097108   time:  1.3326716423034668
e:  27   train_loss:  548.0750143588725   time:  1.3663344383239746
e:  28   train_loss:  552.7371894546928   time:  1.3228099346160889
e:  29   train_loss:  540.5726871128577   time:  1.338841199874878
e:  30   train_loss:  540.8469430722616   time:  1.328528642654419
e:  30   train_loss:  540.8469430722616   val_loss:  1388.754344839421   time:  1.4282565116882324
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1032.847478074465   time:  1.3279190063476562
e:  0   train_loss:  1032.847478074465   val_loss:  479.82648394074954   time:  1.4303805828094482
e:  1   train_loss:  750.9744129923472   time:  1.3377532958984375
e:  2   train_loss:  702.3658837650192   time:  1.4557652473449707
e:  3   train_loss:  682.7906626376097   time:  1.3272643089294434
e:  4   train_loss:  674.9630389556329   time:  1.328495979309082
e:  5   train_loss:  662.7009842665932   time:  1.3282852172851562
e:  5   train_loss:  662.7009842665932   val_loss:  483.4632016903378   time:  1.430643081665039
e:  6   train_loss:  633.1162406140195   time:  1.2499990463256836
e:  7   train_loss:  625.8260150510844   time:  1.1880717277526855
e:  8   train_loss:  645.4427788464468   time:  1.429624080657959
e:  9   train_loss:  621.8293688664215   time:  1.3139679431915283
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  10   train_loss:  641.9444290828458   time:  1.316174030303955
e:  10   train_loss:  641.9444290828458   val_loss:  479.1844284256239   time:  1.4195187091827393
e:  11   train_loss:  619.6518352395552   time:  1.3156969547271729
e:  12   train_loss:  600.1207416862002   time:  1.324096441268921
e:  13   train_loss:  614.7493344835291   time:  1.3274288177490234
e:  14   train_loss:  602.0489044522457   time:  1.3240392208099365
e:  15   train_loss:  581.7745012952888   time:  1.314868688583374
e:  15   train_loss:  581.7745012952888   val_loss:  596.0095365261674   time:  1.4177210330963135
e:  16   train_loss:  609.4071235733259   time:  1.4655606746673584
e:  17   train_loss:  597.2365671696748   time:  1.2696568965911865
e:  18   train_loss:  582.966144726704   time:  1.32637619972229
e:  19   train_loss:  590.2205208359073   time:  1.3307478427886963
e:  20   train_loss:  594.6528189199257   time:  1.3206377029418945
e:  20   train_loss:  594.6528189199257   val_loss:  477.9598462183734   time:  1.423090934753418
e:  21   train_loss:  592.4425985558347   time:  1.3210203647613525
e:  22   train_loss:  613.4139616657699   time:  1.3335962295532227
e:  23   train_loss:  595.856095301266   time:  1.3305931091308594
e:  24   train_loss:  580.6067831455481   time:  1.471055507659912
e:  25   train_loss:  606.1392820458232   time:  1.3186841011047363
e:  25   train_loss:  606.1392820458232   val_loss:  466.178777135968   time:  1.421950340270996
e:  26   train_loss:  573.8765639472763   time:  1.3344347476959229
e:  27   train_loss:  581.9328658838868   time:  1.3303604125976562
e:  28   train_loss:  573.61866370964   time:  1.3327367305755615
e:  29   train_loss:  578.3332104431797   time:  1.3201894760131836
e:  30   train_loss:  561.6408859874593   time:  1.3245203495025635
e:  30   train_loss:  561.6408859874593   val_loss:  601.7633937255621   time:  1.4278013706207275
e:  31   train_loss:  550.2555936001833   time:  1.4655427932739258
e:  32   train_loss:  542.8708414495682   time:  1.3301849365234375
e:  33   train_loss:  550.3667956597924   time:  1.3258779048919678
e:  34   train_loss:  556.939120197755   time:  1.3205342292785645
e:  35   train_loss:  555.1564002934188   time:  1.3297019004821777
e:  35   train_loss:  555.1564002934188   val_loss:  692.774287759793   time:  1.432892084121704
e:  36   train_loss:  568.9722513943213   time:  1.3315269947052002
e:  37   train_loss:  553.8719373274821   time:  1.3292009830474854
e:  38   train_loss:  547.4708428224047   time:  1.3423693180084229
e:  39   train_loss:  547.2757512824519   time:  1.4688529968261719
e:  40   train_loss:  523.1877580827054   time:  1.327425241470337
e:  40   train_loss:  523.1877580827054   val_loss:  680.453273399527   time:  1.4294164180755615
e:  41   train_loss:  518.3125805925386   time:  1.3170957565307617
e:  42   train_loss:  525.591838992473   time:  1.3314886093139648
e:  43   train_loss:  519.2611498417043   time:  1.3293890953063965
e:  44   train_loss:  521.4178967181203   time:  1.3304517269134521
e:  45   train_loss:  516.7525036070721   time:  1.330113172531128
e:  45   train_loss:  516.7525036070721   val_loss:  514.0949433949805   time:  1.4342041015625
e:  46   train_loss:  500.5286712431686   time:  1.46114182472229
e:  47   train_loss:  498.8144960143158   time:  1.3306734561920166
e:  48   train_loss:  502.3990535080054   time:  1.327920913696289
e:  49   train_loss:  489.5012549719579   time:  1.3182554244995117
e:  50   train_loss:  478.04258479076555   time:  1.31776762008667
e:  50   train_loss:  478.04258479076555   val_loss:  508.6704587139223   time:  1.4209620952606201
e:  51   train_loss:  499.31354990750344   time:  1.331284523010254
e:  52   train_loss:  501.6712936427645   time:  1.3186938762664795
e:  53   train_loss:  452.28503323052155   time:  1.4473028182983398
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  54   train_loss:  461.79443792676767   time:  1.3323118686676025
e:  55   train_loss:  450.12319416780997   time:  1.3312036991119385
e:  55   train_loss:  450.12319416780997   val_loss:  514.0302124943121   time:  1.4341249465942383
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  952.1215559593918   time:  1.2190899848937988
e:  0   train_loss:  952.1215559593918   val_loss:  801.8803460890738   time:  1.3271915912628174
e:  1   train_loss:  760.371609994027   time:  1.2265853881835938
e:  2   train_loss:  669.8278202681377   time:  1.229487657546997
e:  3   train_loss:  679.7293270524524   time:  1.230008602142334
e:  4   train_loss:  652.9518728480215   time:  1.226586103439331
e:  5   train_loss:  612.1976192419348   time:  1.228135108947754
e:  5   train_loss:  612.1976192419348   val_loss:  831.5049080367294   time:  1.336167812347412
e:  6   train_loss:  608.2892502774278   time:  1.2274911403656006
e:  7   train_loss:  590.7088770450025   time:  1.215728759765625
e:  8   train_loss:  593.1027982601813   time:  1.2257308959960938
e:  9   train_loss:  578.8806470538934   time:  1.3498759269714355
e:  10   train_loss:  578.1436677129951   time:  1.21876859664917
e:  10   train_loss:  578.1436677129951   val_loss:  741.4865507764453   time:  1.3254847526550293
e:  11   train_loss:  569.3630449387956   time:  1.2160236835479736
e:  12   train_loss:  556.3457382366906   time:  1.2164709568023682
e:  13   train_loss:  555.6069935166146   time:  1.227372169494629
e:  14   train_loss:  555.3253638309889   time:  1.2165277004241943
e:  15   train_loss:  552.1883836351897   time:  1.2269327640533447
e:  15   train_loss:  552.1883836351897   val_loss:  739.9375753148673   time:  1.333911418914795
e:  16   train_loss:  547.5553605437201   time:  1.2255182266235352
e:  17   train_loss:  544.4877985220318   time:  1.229088306427002
e:  18   train_loss:  535.2121135698205   time:  1.229032278060913
e:  19   train_loss:  533.7484630924689   time:  1.230159044265747
e:  20   train_loss:  534.2235965116282   time:  1.2310948371887207
e:  20   train_loss:  534.2235965116282   val_loss:  717.1411632090244   time:  1.3383963108062744
e:  21   train_loss:  539.5233419101608   time:  1.2291769981384277
e:  22   train_loss:  524.9596390220801   time:  1.2278108596801758
e:  23   train_loss:  524.6314670216419   time:  1.3595349788665771
e:  24   train_loss:  520.0013630299782   time:  1.2020034790039062
e:  25   train_loss:  521.6868128615982   time:  1.2278025150299072
e:  25   train_loss:  521.6868128615982   val_loss:  724.4104954282986   time:  1.3357946872711182
e:  26   train_loss:  515.4948465902745   time:  1.2293822765350342
e:  27   train_loss:  513.0456953983276   time:  1.2255995273590088
e:  28   train_loss:  509.5788524156795   time:  1.226123571395874
e:  29   train_loss:  513.8249499260024   time:  1.2308359146118164
e:  30   train_loss:  512.1430303290457   time:  1.2300114631652832
e:  30   train_loss:  512.1430303290457   val_loss:  728.1171147991719   time:  1.3361880779266357
e:  31   train_loss:  508.46627005326957   time:  1.2102069854736328
e:  32   train_loss:  502.7013742752566   time:  1.209352970123291
e:  33   train_loss:  494.51363836691144   time:  1.2277672290802002
e:  34   train_loss:  504.1111558459213   time:  1.229964017868042
e:  35   train_loss:  489.90773558796275   time:  1.2164630889892578
e:  35   train_loss:  489.90773558796275   val_loss:  743.3741552686658   time:  1.3238284587860107
e:  36   train_loss:  489.0224176931353   time:  1.3584561347961426
e:  37   train_loss:  502.09103991521863   time:  1.227337121963501
e:  38   train_loss:  486.2974532024316   time:  1.2285652160644531
e:  39   train_loss:  491.1887457781325   time:  1.2297708988189697
e:  40   train_loss:  486.0895815631737   time:  1.228548288345337
e:  40   train_loss:  486.0895815631737   val_loss:  797.9563934471084   time:  1.3355121612548828
e:  41   train_loss:  482.24192154683317   time:  1.2295150756835938
e:  42   train_loss:  489.99523629659564   time:  1.2161221504211426
e:  43   train_loss:  481.5637942166611   time:  1.2288658618927002
e:  44   train_loss:  474.3130954002013   time:  1.229997158050537
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  45   train_loss:  478.49660598068385   time:  1.2336411476135254
e:  45   train_loss:  478.49660598068385   val_loss:  734.7070813065955   time:  1.3412046432495117
e:  46   train_loss:  468.90664942525905   time:  1.229382038116455
e:  47   train_loss:  461.3068181410743   time:  1.2283790111541748
e:  48   train_loss:  465.59749006357504   time:  1.3598504066467285
e:  49   train_loss:  458.5262433012355   time:  1.2021608352661133
e:  50   train_loss:  454.3998705217402   time:  1.2266104221343994
e:  50   train_loss:  454.3998705217402   val_loss:  700.802074609185   time:  1.334172010421753
e:  51   train_loss:  453.9712353419224   time:  1.2280058860778809
e:  52   train_loss:  451.5997132426125   time:  1.2250721454620361
e:  53   train_loss:  448.0983738616904   time:  1.2701313495635986
e:  54   train_loss:  442.67157592638   time:  1.232480764389038
e:  55   train_loss:  438.0070477282409   time:  1.2132503986358643
e:  55   train_loss:  438.0070477282409   val_loss:  695.7516341185909   time:  1.3208553791046143
e:  56   train_loss:  434.2084649567053   time:  1.2224669456481934
e:  57   train_loss:  427.86018233469474   time:  1.2153401374816895
e:  58   train_loss:  429.4029114912517   time:  1.2714805603027344
e:  59   train_loss:  431.7427076011056   time:  1.2570340633392334
e:  60   train_loss:  422.7357280516759   time:  1.2494876384735107
e:  60   train_loss:  422.7357280516759   val_loss:  721.2112551096403   time:  1.3570990562438965
e:  61   train_loss:  413.36392502474774   time:  1.4171569347381592
e:  62   train_loss:  414.59394292314585   time:  1.261695146560669
e:  63   train_loss:  420.7104652057894   time:  1.3249869346618652
e:  64   train_loss:  397.02798704492903   time:  1.3498148918151855
e:  65   train_loss:  403.73021832896836   time:  1.2502822875976562
e:  65   train_loss:  403.73021832896836   val_loss:  705.1053329792567   time:  1.3578081130981445
e:  66   train_loss:  386.872528154491   time:  1.2371962070465088
e:  67   train_loss:  389.2143255170841   time:  1.2318377494812012
e:  68   train_loss:  379.6810299054566   time:  1.3454694747924805
e:  69   train_loss:  383.4493412937326   time:  1.4816865921020508
e:  70   train_loss:  386.39431254433356   time:  1.447493553161621
e:  70   train_loss:  386.39431254433356   val_loss:  754.5344716580628   time:  1.557433843612671
e:  71   train_loss:  384.0947543520781   time:  1.301072597503662
e:  72   train_loss:  382.7604195970658   time:  1.3465092182159424
e:  73   train_loss:  375.7799130375313   time:  1.5747809410095215
e:  74   train_loss:  370.89792107711213   time:  1.3251817226409912
e:  75   train_loss:  366.1750379241227   time:  1.3418102264404297
e:  75   train_loss:  366.1750379241227   val_loss:  740.0478834912825   time:  1.4526920318603516
e:  76   train_loss:  376.46708424760504   time:  1.3414313793182373
e:  77   train_loss:  356.0602035936989   time:  1.2167227268218994
e:  78   train_loss:  356.7543582064048   time:  1.2215511798858643
e:  79   train_loss:  362.4151900176317   time:  1.232067346572876
e:  80   train_loss:  347.05147432220866   time:  1.2330710887908936
e:  80   train_loss:  347.05147432220866   val_loss:  744.9340114854597   time:  1.3413746356964111
e:  81   train_loss:  345.94979344161663   time:  1.23374342918396
e:  82   train_loss:  337.40394305173766   time:  1.2244174480438232
e:  83   train_loss:  340.14116292241346   time:  1.2345128059387207
e:  84   train_loss:  334.4821707309238   time:  1.2368333339691162
e:  85   train_loss:  333.09085325723754   time:  1.223562240600586
e:  85   train_loss:  333.09085325723754   val_loss:  801.0833416062547   time:  1.3318076133728027
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  993.4625524253061   time:  1.4942576885223389
e:  0   train_loss:  993.4625524253061   val_loss:  556.322763474031   time:  1.5968341827392578
e:  1   train_loss:  741.9960599601386   time:  1.3566691875457764
e:  2   train_loss:  689.2303001727914   time:  1.337712049484253
e:  3   train_loss:  687.2204457867538   time:  1.3464939594268799
e:  4   train_loss:  661.4444700071016   time:  1.3322999477386475
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  5   train_loss:  635.9626461003986   time:  1.4776489734649658
e:  5   train_loss:  635.9626461003986   val_loss:  596.8284788558216   time:  1.57257080078125
e:  6   train_loss:  649.4016312182848   time:  1.336503505706787
e:  7   train_loss:  652.415078723239   time:  1.345881700515747
e:  8   train_loss:  648.1196304402615   time:  1.344557285308838
e:  9   train_loss:  639.9435677981855   time:  1.3354361057281494
e:  10   train_loss:  631.0281777548512   time:  1.332096815109253
e:  10   train_loss:  631.0281777548512   val_loss:  599.5204417374827   time:  1.433762788772583
e:  11   train_loss:  611.1064353816773   time:  1.3339827060699463
e:  12   train_loss:  612.1632010339309   time:  1.4814774990081787
e:  13   train_loss:  607.7975400723202   time:  1.3411455154418945
e:  14   train_loss:  613.7134915432584   time:  1.340566635131836
e:  15   train_loss:  597.0489638943315   time:  1.3444864749908447
e:  15   train_loss:  597.0489638943315   val_loss:  599.42584871331   time:  1.4467928409576416
e:  16   train_loss:  602.9874028931449   time:  1.3425140380859375
e:  17   train_loss:  596.2473382316383   time:  1.3476853370666504
e:  18   train_loss:  598.9185752591029   time:  1.4858367443084717
e:  19   train_loss:  592.541425107836   time:  1.3480451107025146
e:  20   train_loss:  581.4127609985303   time:  1.3346216678619385
e:  20   train_loss:  581.4127609985303   val_loss:  624.8894546848534   time:  1.4362783432006836
e:  21   train_loss:  592.1883992321556   time:  1.3447847366333008
e:  22   train_loss:  581.1174282398775   time:  1.3460569381713867
e:  23   train_loss:  593.9996597537339   time:  1.348783016204834
e:  24   train_loss:  591.7468398414143   time:  1.3478739261627197
e:  25   train_loss:  584.8906893582312   time:  1.4790563583374023
e:  25   train_loss:  584.8906893582312   val_loss:  658.0181898371515   time:  1.5804054737091064
e:  26   train_loss:  577.8458971413534   time:  1.334961175918579
e:  27   train_loss:  579.9601357663014   time:  1.3440775871276855
e:  28   train_loss:  575.0263573164953   time:  1.3330976963043213
e:  29   train_loss:  586.9167883818492   time:  1.3451812267303467
e:  30   train_loss:  571.5608081761261   time:  1.3458225727081299
e:  30   train_loss:  571.5608081761261   val_loss:  670.8720173028569   time:  1.4476959705352783
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (1, 0, 7), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (1, 0, 7) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 7) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 7) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (1, 0, 7)
kwargs: {'config': {'batch_norm': True, 'ff_0': 106, 'ff_num_layers': 2, 'gnn_0': 317, 'gnn_dropout': 0.3368733383678324, 'gnn_num_layers': 1, 'hid_0': 74, 'hid_dropout_rate': 0.29648329598290585, 'in_dropout_rate': 0.04789760399280041, 'lr': 0.0007931206855937558, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 221, 'hid_1': 555, 'hid_2': 1092}, 'budget': 729.0, 'working_directory': '.'}
result: {'loss': 663.9219054277627, 'n_epochs': 58.0, 'info': {'validation loss': 663.9219054277627}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 7) started
DEBUG:hpbandster:job_callback for (1, 0, 7) got condition
DEBUG:hpbandster:Only 2 run(s) for budget 729.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (1, 0, 7) finished
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: trying submitting job (2, 0, 0) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 0) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 0)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 0) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 0) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (2, 0, 0)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 1189, 'ff_num_layers': 1, 'gnn_0': 148, 'gnn_dropout': 0.3638746711639574, 'gnn_num_layers': 1, 'hid_0': 920, 'hid_dropout_rate': 0.45112037731197413, 'in_dropout_rate': 0.08092535011517843, 'lr': 3.791412174075131e-05, 'num_hid_layers': 3, 'optimizer': 'Adam', 'hid_1': 80, 'hid_2': 1620}, 'budget': 243.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  706.5036422309481   time:  1.451570749282837
e:  0   train_loss:  706.5036422309481   val_loss:  1674.0090080774332   time:  1.667490005493164
e:  1   train_loss:  704.3860028331942   time:  1.4021992683410645
e:  2   train_loss:  701.9915538053903   time:  1.4525434970855713
e:  3   train_loss:  697.4565354490313   time:  1.44984769821167
e:  4   train_loss:  688.1830330319802   time:  1.3940062522888184
e:  5   train_loss:  675.4738174122265   time:  1.4485464096069336
e:  5   train_loss:  675.4738174122265   val_loss:  1601.2473671806204   time:  1.5606105327606201
e:  6   train_loss:  655.1328693705925   time:  1.453993797302246
e:  7   train_loss:  630.2457456075289   time:  1.4563169479370117
e:  8   train_loss:  606.5067222309431   time:  1.4591917991638184
e:  9   train_loss:  598.8829174888377   time:  1.455265760421753
e:  10   train_loss:  600.7763603763622   time:  1.4551620483398438
e:  10   train_loss:  600.7763603763622   val_loss:  1388.271579699508   time:  1.5671591758728027
e:  11   train_loss:  598.2090023145145   time:  1.583054780960083
e:  12   train_loss:  597.1228377511476   time:  1.4403526782989502
e:  13   train_loss:  596.200650125189   time:  1.4549212455749512
e:  14   train_loss:  596.085926654493   time:  1.4501299858093262
e:  15   train_loss:  595.7463857788478   time:  1.4551584720611572
e:  15   train_loss:  595.7463857788478   val_loss:  1402.9360760378192   time:  1.5669236183166504
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  16   train_loss:  593.8885212172162   time:  1.455423355102539
e:  17   train_loss:  593.7341045762872   time:  1.4531223773956299
e:  18   train_loss:  593.3104188769113   time:  1.4595608711242676
e:  19   train_loss:  593.7269727704178   time:  1.4795141220092773
e:  20   train_loss:  592.4771008374987   time:  1.486032485961914
e:  20   train_loss:  592.4771008374987   val_loss:  1404.6691637509061   time:  1.598747730255127
e:  21   train_loss:  591.7154424112521   time:  1.4665329456329346
e:  22   train_loss:  590.9410117467041   time:  1.6104109287261963
e:  23   train_loss:  590.3618397531618   time:  1.473604440689087
e:  24   train_loss:  589.2442074046686   time:  1.4874377250671387
e:  25   train_loss:  587.9800938898159   time:  1.4469428062438965
e:  25   train_loss:  587.9800938898159   val_loss:  1404.184646914406   time:  1.560495376586914
e:  26   train_loss:  587.6511131659493   time:  1.5310239791870117
e:  27   train_loss:  587.1607776516436   time:  1.4998464584350586
e:  28   train_loss:  586.932474102177   time:  1.593005657196045
e:  29   train_loss:  584.6694647638545   time:  1.4689216613769531
e:  30   train_loss:  583.5753504564902   time:  1.577575922012329
e:  30   train_loss:  583.5753504564902   val_loss:  1405.6885565724037   time:  1.7009944915771484
e:  31   train_loss:  583.310034181954   time:  1.608668327331543
e:  32   train_loss:  580.8923731474829   time:  1.509324073791504
e:  33   train_loss:  580.3532923468855   time:  1.6654298305511475
e:  34   train_loss:  578.370648121596   time:  1.4824187755584717
e:  35   train_loss:  576.0409703462733   time:  1.4784314632415771
e:  35   train_loss:  576.0409703462733   val_loss:  1397.0838799653804   time:  1.589721918106079
e:  36   train_loss:  574.1562229365085   time:  1.4939181804656982
e:  37   train_loss:  572.5163706850759   time:  1.5407001972198486
e:  38   train_loss:  569.1364793564696   time:  1.5040252208709717
e:  39   train_loss:  567.8048271302016   time:  1.494328498840332
e:  40   train_loss:  563.433029610148   time:  1.489565372467041
e:  40   train_loss:  563.433029610148   val_loss:  1390.8972128520463   time:  1.6014680862426758
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1070.7299047277565   time:  1.7938454151153564
e:  0   train_loss:  1070.7299047277565   val_loss:  626.2244310369721   time:  1.8991351127624512
e:  1   train_loss:  1067.0019441799263   time:  1.6322388648986816
e:  2   train_loss:  1059.994759105692   time:  1.5514411926269531
e:  3   train_loss:  1062.9738180424538   time:  1.6133291721343994
e:  4   train_loss:  1034.1324666712223   time:  1.618013858795166
e:  5   train_loss:  1018.7446452454319   time:  1.6212949752807617
e:  5   train_loss:  1018.7446452454319   val_loss:  567.7612964063005   time:  1.7251386642456055
e:  6   train_loss:  969.4531369687973   time:  1.618628978729248
e:  7   train_loss:  937.1432576331188   time:  1.7775158882141113
e:  8   train_loss:  930.685587195112   time:  1.6267733573913574
e:  9   train_loss:  915.3124627595124   time:  1.5828297138214111
e:  10   train_loss:  916.6619542153676   time:  1.6150736808776855
e:  10   train_loss:  916.6619542153676   val_loss:  539.2417308626602   time:  1.72102952003479
e:  11   train_loss:  899.989742204681   time:  1.6017875671386719
e:  12   train_loss:  916.766362349525   time:  1.6155173778533936
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  13   train_loss:  899.4365701649757   time:  1.614976167678833
e:  14   train_loss:  896.9544905696025   time:  1.7574031352996826
e:  15   train_loss:  907.4914677535432   time:  1.637751817703247
e:  15   train_loss:  907.4914677535432   val_loss:  539.7805907067606   time:  1.7425861358642578
e:  16   train_loss:  902.5685705470928   time:  1.5966026782989502
e:  17   train_loss:  885.1994598063756   time:  1.6250083446502686
e:  18   train_loss:  889.7945123406131   time:  1.6095988750457764
e:  19   train_loss:  903.0053200048045   time:  1.6234190464019775
e:  20   train_loss:  889.2923962350303   time:  1.5620512962341309
e:  20   train_loss:  889.2923962350303   val_loss:  539.0332801708395   time:  1.8163487911224365
e:  21   train_loss:  895.5867173554606   time:  1.5988023281097412
e:  22   train_loss:  891.3170082857237   time:  1.6150527000427246
e:  23   train_loss:  890.3228816997278   time:  1.6214885711669922
e:  24   train_loss:  883.4032424557934   time:  1.6047782897949219
e:  25   train_loss:  875.8233851492627   time:  1.617755651473999
e:  25   train_loss:  875.8233851492627   val_loss:  537.7657009345528   time:  1.7221567630767822
e:  26   train_loss:  873.3035933452403   time:  1.6107301712036133
e:  27   train_loss:  871.325433462865   time:  1.7771925926208496
e:  28   train_loss:  863.4383315648314   time:  1.6191339492797852
e:  29   train_loss:  861.8199533082882   time:  1.6085219383239746
e:  30   train_loss:  858.0590355933614   time:  1.6105718612670898
e:  30   train_loss:  858.0590355933614   val_loss:  537.848331203462   time:  1.7166259288787842
e:  31   train_loss:  845.8465141807123   time:  1.608499526977539
e:  32   train_loss:  841.3262863831199   time:  1.6265361309051514
e:  33   train_loss:  830.1398424835305   time:  1.760838508605957
e:  34   train_loss:  819.8457170869203   time:  1.6102313995361328
e:  35   train_loss:  793.3313551256417   time:  1.5970351696014404
e:  35   train_loss:  793.3313551256417   val_loss:  546.4697403426595   time:  1.703010082244873
e:  36   train_loss:  782.6656456442826   time:  1.6197285652160645
e:  37   train_loss:  777.628187010981   time:  1.5942158699035645
e:  38   train_loss:  761.6635461250705   time:  1.55702805519104
e:  39   train_loss:  735.7852640837503   time:  1.5850493907928467
e:  40   train_loss:  720.1262747901559   time:  1.7774994373321533
e:  40   train_loss:  720.1262747901559   val_loss:  610.530336303938   time:  1.881575107574463
e:  41   train_loss:  712.3691241181009   time:  1.6042506694793701
e:  42   train_loss:  698.2532516021729   time:  1.6132915019989014
e:  43   train_loss:  677.467273688974   time:  1.6173899173736572
e:  44   train_loss:  664.6557570667078   time:  1.609837293624878
e:  45   train_loss:  660.7386467187503   time:  1.5892977714538574
e:  45   train_loss:  660.7386467187503   val_loss:  722.0903845003929   time:  1.6953308582305908
e:  46   train_loss:  656.601197105514   time:  1.6670844554901123
e:  47   train_loss:  656.1012284650454   time:  1.809328317642212
e:  48   train_loss:  643.5387998595947   time:  1.5860176086425781
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  49   train_loss:  636.7380297283286   time:  1.5879206657409668
e:  50   train_loss:  642.0341206969842   time:  1.5891211032867432
e:  50   train_loss:  642.0341206969842   val_loss:  766.0533458607553   time:  1.6948482990264893
e:  51   train_loss:  622.462307283161   time:  1.587061882019043
e:  52   train_loss:  631.71800166163   time:  1.584136724472046
e:  53   train_loss:  620.3397980425774   time:  1.6942710876464844
e:  54   train_loss:  617.9281493949361   time:  1.9518778324127197
e:  55   train_loss:  618.1703641868919   time:  1.5899600982666016
e:  55   train_loss:  618.1703641868919   val_loss:  791.3842907691721   time:  1.6930959224700928
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1135.7442833161085   time:  1.52266263961792
e:  0   train_loss:  1135.7442833161085   val_loss:  538.4768940378174   time:  1.628213882446289
e:  1   train_loss:  1107.2636559453967   time:  1.5473856925964355
e:  2   train_loss:  1066.1032629610868   time:  1.5722131729125977
e:  3   train_loss:  1122.1882144100387   time:  1.5870532989501953
e:  4   train_loss:  1042.7140676625222   time:  1.7106573581695557
e:  5   train_loss:  1018.0758297029055   time:  1.5630161762237549
e:  5   train_loss:  1018.0758297029055   val_loss:  494.9707609500398   time:  1.6697118282318115
e:  6   train_loss:  996.5365658269857   time:  1.5669069290161133
e:  7   train_loss:  927.3321623248214   time:  1.56304931640625
e:  8   train_loss:  983.9979470340835   time:  1.5598421096801758
e:  9   train_loss:  915.274366655104   time:  1.5671164989471436
e:  10   train_loss:  928.173837769314   time:  1.5578515529632568
e:  10   train_loss:  928.173837769314   val_loss:  486.3396194919712   time:  1.6655590534210205
e:  11   train_loss:  916.2677289163416   time:  1.7589664459228516
e:  12   train_loss:  891.9586560530911   time:  1.6907832622528076
e:  13   train_loss:  953.2199519848065   time:  1.559476375579834
e:  14   train_loss:  896.2993776027881   time:  1.5728719234466553
e:  15   train_loss:  945.5942209276104   time:  1.5736479759216309
e:  15   train_loss:  945.5942209276104   val_loss:  486.9945708611152   time:  1.680424451828003
e:  16   train_loss:  909.7334426207559   time:  1.5600016117095947
e:  17   train_loss:  888.6501717834901   time:  1.5674824714660645
e:  18   train_loss:  877.4306165524423   time:  1.7111563682556152
e:  19   train_loss:  883.3895949870613   time:  1.5084075927734375
e:  20   train_loss:  908.3311733181387   time:  1.561840534210205
e:  20   train_loss:  908.3311733181387   val_loss:  484.4257596961905   time:  1.6683695316314697
e:  21   train_loss:  923.885951672484   time:  1.5607974529266357
e:  22   train_loss:  899.0087434046673   time:  1.5729460716247559
e:  23   train_loss:  919.7633160826224   time:  1.565418004989624
e:  24   train_loss:  852.3552589969032   time:  1.5607273578643799
e:  25   train_loss:  866.6118739943627   time:  1.5615384578704834
e:  25   train_loss:  866.6118739943627   val_loss:  483.8345119172373   time:  1.6687896251678467
e:  26   train_loss:  905.1030691863772   time:  1.7146565914154053
e:  27   train_loss:  863.3509560109262   time:  1.5622708797454834
e:  28   train_loss:  899.7422623091795   time:  1.576873540878296
e:  29   train_loss:  874.2521704306569   time:  1.5592591762542725
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  30   train_loss:  925.0189191976671   time:  1.5685906410217285
e:  30   train_loss:  925.0189191976671   val_loss:  486.21060273421426   time:  1.6759815216064453
e:  31   train_loss:  869.5321765188619   time:  1.57767915725708
e:  32   train_loss:  838.6919106176913   time:  1.559189796447754
e:  33   train_loss:  856.0878763174414   time:  1.7224900722503662
e:  34   train_loss:  830.2891985006884   time:  1.5617561340332031
e:  35   train_loss:  847.1481696634488   time:  1.5641717910766602
e:  35   train_loss:  847.1481696634488   val_loss:  486.6578688472249   time:  1.6713078022003174
e:  36   train_loss:  814.1612525603311   time:  1.560513973236084
e:  37   train_loss:  800.8367167591853   time:  1.5388612747192383
e:  38   train_loss:  811.5085860252163   time:  1.527489185333252
e:  39   train_loss:  792.3717193647221   time:  1.561647891998291
e:  40   train_loss:  792.0494454020471   time:  1.7216246128082275
e:  40   train_loss:  792.0494454020471   val_loss:  494.506181216873   time:  1.8276951313018799
e:  41   train_loss:  762.7333106864954   time:  1.5751395225524902
e:  42   train_loss:  790.9006514506474   time:  1.5575487613677979
e:  43   train_loss:  782.9449534339957   time:  1.5632901191711426
e:  44   train_loss:  746.4688911786201   time:  1.5602691173553467
e:  45   train_loss:  727.0288706092186   time:  1.5582268238067627
e:  45   train_loss:  727.0288706092186   val_loss:  506.6355799046084   time:  1.6653611660003662
e:  46   train_loss:  725.235294945543   time:  1.5615482330322266
e:  47   train_loss:  732.1320150043633   time:  1.7137513160705566
e:  48   train_loss:  723.0143379111711   time:  1.563157558441162
e:  49   train_loss:  713.907045137951   time:  1.5749032497406006
e:  50   train_loss:  697.1949435891266   time:  1.5587596893310547
e:  50   train_loss:  697.1949435891266   val_loss:  520.3746280092116   time:  1.6657702922821045
e:  51   train_loss:  689.3766699468379   time:  1.5585851669311523
e:  52   train_loss:  686.0212759589637   time:  1.555147647857666
e:  53   train_loss:  692.260000632667   time:  1.5688855648040771
e:  54   train_loss:  655.432866868457   time:  1.5610759258270264
e:  55   train_loss:  660.2706720670037   time:  1.710308313369751
e:  55   train_loss:  660.2706720670037   val_loss:  512.8385999240693   time:  1.816587209701538
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  999.4150042800004   time:  1.4061927795410156
e:  0   train_loss:  999.4150042800004   val_loss:  916.3521301275545   time:  1.5170176029205322
e:  1   train_loss:  995.5728288237024   time:  1.4353010654449463
e:  2   train_loss:  993.9367095050736   time:  1.4574799537658691
e:  3   train_loss:  983.9472407083967   time:  1.4517185688018799
e:  4   train_loss:  977.7130207973319   time:  1.4499127864837646
e:  5   train_loss:  955.8907313367208   time:  1.453392505645752
e:  5   train_loss:  955.8907313367208   val_loss:  856.9176502628253   time:  1.5657799243927002
e:  6   train_loss:  921.43182152093   time:  1.454097032546997
e:  7   train_loss:  890.2861640860044   time:  1.45615553855896
e:  8   train_loss:  849.5498125905434   time:  1.4512615203857422
e:  9   train_loss:  836.6366261701694   time:  1.582543134689331
e:  10   train_loss:  839.6479158640524   time:  1.4477770328521729
e:  10   train_loss:  839.6479158640524   val_loss:  742.7860987741469   time:  1.5592567920684814
e:  11   train_loss:  837.4549343205962   time:  1.4503405094146729
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  12   train_loss:  834.0606962208685   time:  1.453993558883667
e:  13   train_loss:  833.8860872223488   time:  1.449352741241455
e:  14   train_loss:  831.0887996674638   time:  1.4511744976043701
e:  15   train_loss:  829.7718680270498   time:  1.451061487197876
e:  15   train_loss:  829.7718680270498   val_loss:  743.0685586692011   time:  1.5625813007354736
e:  16   train_loss:  829.0463421174691   time:  1.4493541717529297
e:  17   train_loss:  829.394855295669   time:  1.4557428359985352
e:  18   train_loss:  826.1164855278753   time:  1.454650640487671
e:  19   train_loss:  827.0582785591356   time:  1.4560787677764893
e:  20   train_loss:  826.7442989658815   time:  1.5436434745788574
e:  20   train_loss:  826.7442989658815   val_loss:  741.5123367366026   time:  1.6549019813537598
e:  21   train_loss:  824.4241769509158   time:  1.436758041381836
e:  22   train_loss:  825.9537822315982   time:  1.4517393112182617
e:  23   train_loss:  824.3629060405523   time:  1.4533023834228516
e:  24   train_loss:  821.8410230007032   time:  1.4553775787353516
e:  25   train_loss:  818.9599388581242   time:  1.4502146244049072
e:  25   train_loss:  818.9599388581242   val_loss:  739.2883298045543   time:  1.5626530647277832
e:  26   train_loss:  817.3730822100314   time:  1.4502019882202148
e:  27   train_loss:  816.3296970070177   time:  1.451115369796753
e:  28   train_loss:  816.0831683364705   time:  1.4502828121185303
e:  29   train_loss:  812.7470896189478   time:  1.6038124561309814
e:  30   train_loss:  809.2549815443186   time:  1.431286096572876
e:  30   train_loss:  809.2549815443186   val_loss:  735.9314014796983   time:  1.5431888103485107
e:  31   train_loss:  806.7235763533686   time:  1.4574460983276367
e:  32   train_loss:  804.5550100818866   time:  1.5363092422485352
e:  33   train_loss:  799.1863475576432   time:  1.5450866222381592
e:  34   train_loss:  797.4971249859892   time:  1.4541819095611572
e:  35   train_loss:  792.7430535540183   time:  1.4526023864746094
e:  35   train_loss:  792.7430535540183   val_loss:  728.7730801552026   time:  1.5640041828155518
e:  36   train_loss:  787.2785626532441   time:  1.4536731243133545
e:  37   train_loss:  780.6441220587403   time:  1.4844837188720703
e:  38   train_loss:  775.3854893288901   time:  1.6122324466705322
e:  39   train_loss:  769.1063839603243   time:  1.451174020767212
e:  40   train_loss:  758.4284308904208   time:  1.4123930931091309
e:  40   train_loss:  758.4284308904208   val_loss:  715.9994093272095   time:  1.5230536460876465
e:  41   train_loss:  752.4314107513244   time:  1.4254021644592285
e:  42   train_loss:  738.2599231101699   time:  1.4514915943145752
e:  43   train_loss:  728.8836411887535   time:  1.4570658206939697
e:  44   train_loss:  718.0624480941659   time:  1.5584349632263184
e:  45   train_loss:  707.3142285694007   time:  1.6443226337432861
e:  45   train_loss:  707.3142285694007   val_loss:  701.6083941059027   time:  1.8403708934783936
e:  46   train_loss:  695.6723401471897   time:  1.4514594078063965
e:  47   train_loss:  686.300040411212   time:  1.4607646465301514
e:  48   train_loss:  674.8650448583452   time:  1.456587791442871
e:  49   train_loss:  664.202609461093   time:  1.4512171745300293
e:  50   train_loss:  657.1398461915279   time:  1.4518647193908691
e:  50   train_loss:  657.1398461915279   val_loss:  698.073867986098   time:  1.7010242938995361
e:  51   train_loss:  647.6756000153783   time:  1.4536678791046143
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  52   train_loss:  640.1098841742495   time:  1.4505469799041748
e:  53   train_loss:  632.6222999185406   time:  1.4498827457427979
e:  54   train_loss:  626.1043598969318   time:  1.4611566066741943
e:  55   train_loss:  622.5703150120534   time:  1.4498589038848877
e:  55   train_loss:  622.5703150120534   val_loss:  700.1715906840006   time:  1.562312364578247
e:  56   train_loss:  613.4788588504812   time:  1.4521324634552002
e:  57   train_loss:  610.097744417408   time:  1.453019142150879
e:  58   train_loss:  606.4826551203824   time:  1.4498231410980225
e:  59   train_loss:  602.1153741361444   time:  1.6103339195251465
e:  60   train_loss:  597.6237433878813   time:  1.4825105667114258
e:  60   train_loss:  597.6237433878813   val_loss:  701.2390357265313   time:  1.5858914852142334
e:  61   train_loss:  592.633636481519   time:  1.4246394634246826
e:  62   train_loss:  588.696395178674   time:  1.443652868270874
e:  63   train_loss:  586.4082567112536   time:  1.4422800540924072
e:  64   train_loss:  586.7966223735845   time:  1.442756175994873
e:  65   train_loss:  581.0148780450462   time:  1.442136287689209
e:  65   train_loss:  581.0148780450462   val_loss:  699.1333938918859   time:  1.5546081066131592
e:  66   train_loss:  580.6232931918378   time:  1.6158859729766846
e:  67   train_loss:  576.7851830459108   time:  1.4483914375305176
e:  68   train_loss:  573.4279205900211   time:  1.5308191776275635
e:  69   train_loss:  574.7163626451654   time:  1.4302661418914795
e:  70   train_loss:  570.875845755108   time:  1.5540943145751953
e:  70   train_loss:  570.875845755108   val_loss:  697.2432177074033   time:  1.6654813289642334
e:  71   train_loss:  566.2295688556407   time:  1.4296655654907227
e:  72   train_loss:  566.4225072755585   time:  1.433701992034912
e:  73   train_loss:  563.1826188285067   time:  1.4362595081329346
e:  74   train_loss:  563.1914681891234   time:  1.4296410083770752
e:  75   train_loss:  560.4823940904176   time:  1.4351191520690918
e:  75   train_loss:  560.4823940904176   val_loss:  696.9831305358172   time:  1.5470266342163086
e:  76   train_loss:  559.4584783276371   time:  1.472684383392334
e:  77   train_loss:  556.8729722806333   time:  1.457711935043335
e:  78   train_loss:  558.0816262405108   time:  1.4381382465362549
e:  79   train_loss:  554.7092095566438   time:  1.5617012977600098
e:  80   train_loss:  553.4798494680731   time:  1.3900229930877686
e:  80   train_loss:  553.4798494680731   val_loss:  697.9560248499156   time:  1.5009064674377441
e:  81   train_loss:  548.4076643776899   time:  1.4068679809570312
e:  82   train_loss:  551.5670075214985   time:  1.440561056137085
e:  83   train_loss:  544.3411356247422   time:  1.433492660522461
e:  84   train_loss:  547.4686896474391   time:  1.4407317638397217
e:  85   train_loss:  547.8755694234044   time:  1.435232400894165
e:  85   train_loss:  547.8755694234044   val_loss:  700.8100170971353   time:  1.5468084812164307
e:  86   train_loss:  548.4824406921595   time:  1.4379146099090576
e:  87   train_loss:  547.5909367131234   time:  1.4334287643432617
e:  88   train_loss:  544.7017829080664   time:  1.5555403232574463
e:  89   train_loss:  544.1538162361514   time:  1.4388318061828613
e:  90   train_loss:  543.5887266890294   time:  1.438025712966919
e:  90   train_loss:  543.5887266890294   val_loss:  704.3704612279724   time:  1.5502948760986328
e:  91   train_loss:  542.0270102968988   time:  1.439971923828125
e:  92   train_loss:  540.9672905844922   time:  1.4396522045135498
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  93   train_loss:  540.6702092660697   time:  1.4407908916473389
e:  94   train_loss:  541.3257780348314   time:  1.4372923374176025
e:  95   train_loss:  539.7739230262559   time:  1.4398624897003174
e:  95   train_loss:  539.7739230262559   val_loss:  709.0537825005155   time:  1.5521628856658936
e:  96   train_loss:  540.8538156928852   time:  1.4354054927825928
e:  97   train_loss:  541.1517526267274   time:  1.4392292499542236
e:  98   train_loss:  540.2703881075929   time:  1.4414303302764893
e:  99   train_loss:  535.8727953636358   time:  1.4380643367767334
e:  100   train_loss:  535.0650987336812   time:  1.431830883026123
e:  100   train_loss:  535.0650987336812   val_loss:  705.6050801760452   time:  1.6674716472625732
e:  101   train_loss:  537.6009014751734   time:  1.3863296508789062
e:  102   train_loss:  540.6846624619595   time:  1.4380626678466797
e:  103   train_loss:  534.794100143246   time:  1.4369800090789795
e:  104   train_loss:  535.7969795012325   time:  1.4366273880004883
e:  105   train_loss:  534.7164128898933   time:  1.4359009265899658
e:  105   train_loss:  534.7164128898933   val_loss:  706.0213077997757   time:  1.5484588146209717
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1067.6959791101744   time:  1.5736100673675537
e:  0   train_loss:  1067.6959791101744   val_loss:  689.4909841080485   time:  1.678720474243164
e:  1   train_loss:  1058.7652051244381   time:  1.7140791416168213
e:  2   train_loss:  1078.478511365603   time:  1.5645852088928223
e:  3   train_loss:  1046.8499157882127   time:  1.56195068359375
e:  4   train_loss:  1038.2956997956385   time:  1.5642476081848145
e:  5   train_loss:  1017.1351084477642   time:  1.5613200664520264
e:  5   train_loss:  1017.1351084477642   val_loss:  617.2390019525504   time:  1.666489601135254
e:  6   train_loss:  946.3591780447291   time:  1.5656673908233643
e:  7   train_loss:  916.8403050843185   time:  1.5655837059020996
e:  8   train_loss:  898.2605031368648   time:  1.6684985160827637
e:  9   train_loss:  883.8470402358853   time:  1.5580906867980957
e:  10   train_loss:  891.1337236645202   time:  1.5622541904449463
e:  10   train_loss:  891.1337236645202   val_loss:  557.4396482992976   time:  1.6666858196258545
e:  11   train_loss:  889.8810898491579   time:  1.5588984489440918
e:  12   train_loss:  888.0718344163104   time:  1.5626778602600098
e:  13   train_loss:  893.762477652871   time:  1.54899001121521
e:  14   train_loss:  884.0883866905092   time:  1.505342721939087
e:  15   train_loss:  903.3789691651826   time:  1.701094150543213
e:  15   train_loss:  903.3789691651826   val_loss:  556.8514264985921   time:  1.8064720630645752
e:  16   train_loss:  903.8901336009601   time:  1.5651676654815674
e:  17   train_loss:  880.2978210608076   time:  1.563974380493164
e:  18   train_loss:  893.0171850154655   time:  1.5602009296417236
e:  19   train_loss:  876.5800449878789   time:  1.5618164539337158
e:  20   train_loss:  899.4669570712553   time:  1.565636396408081
e:  20   train_loss:  899.4669570712553   val_loss:  556.2734209919995   time:  1.7996978759765625
e:  21   train_loss:  872.3673199801356   time:  1.5620512962341309
e:  22   train_loss:  876.116139192011   time:  1.5597779750823975
e:  23   train_loss:  868.1937839345313   time:  1.5592200756072998
e:  24   train_loss:  874.4795255309798   time:  1.5613410472869873
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  25   train_loss:  867.8930298070701   time:  1.5642085075378418
e:  25   train_loss:  867.8930298070701   val_loss:  555.4970659512568   time:  1.6681509017944336
e:  26   train_loss:  866.5730508670355   time:  1.69303560256958
e:  27   train_loss:  853.3131437226955   time:  1.5595097541809082
e:  28   train_loss:  877.4553871461369   time:  1.5634639263153076
e:  29   train_loss:  844.4841147225044   time:  1.559450387954712
e:  30   train_loss:  834.9168835783776   time:  1.5634911060333252
e:  30   train_loss:  834.9168835783776   val_loss:  554.8218863785199   time:  1.6685726642608643
e:  31   train_loss:  832.3939776859702   time:  1.5610277652740479
e:  32   train_loss:  834.8672902567397   time:  1.5306572914123535
e:  33   train_loss:  833.0216849347926   time:  1.6573233604431152
e:  34   train_loss:  805.2049965460595   time:  1.5570881366729736
e:  35   train_loss:  818.1366538211469   time:  1.5620174407958984
e:  35   train_loss:  818.1366538211469   val_loss:  558.3000905190341   time:  1.667389154434204
e:  36   train_loss:  791.0673573037361   time:  1.5631895065307617
e:  37   train_loss:  779.6373991888892   time:  1.560359001159668
e:  38   train_loss:  759.263567584048   time:  1.560279369354248
e:  39   train_loss:  734.167289104682   time:  1.583714246749878
e:  40   train_loss:  722.6334056873005   time:  1.7005698680877686
e:  40   train_loss:  722.6334056873005   val_loss:  579.391116728929   time:  1.8048474788665771
e:  41   train_loss:  711.1302300415359   time:  1.5637965202331543
e:  42   train_loss:  698.0569947505364   time:  1.5604360103607178
e:  43   train_loss:  697.389523292111   time:  1.5634865760803223
e:  44   train_loss:  695.7979881034648   time:  1.5623202323913574
e:  45   train_loss:  668.7732588232167   time:  1.559983253479004
e:  45   train_loss:  668.7732588232167   val_loss:  585.8687576858212   time:  1.664710521697998
e:  46   train_loss:  661.7297891582876   time:  1.6999273300170898
e:  47   train_loss:  657.7630849395782   time:  1.5631511211395264
e:  48   train_loss:  660.8295260220389   time:  1.5631721019744873
e:  49   train_loss:  664.5673307857846   time:  1.5596873760223389
e:  50   train_loss:  649.1439386795779   time:  1.5579001903533936
e:  50   train_loss:  649.1439386795779   val_loss:  580.5893552516739   time:  1.6631217002868652
e:  51   train_loss:  644.1746503411536   time:  1.518251657485962
e:  52   train_loss:  654.1976261104141   time:  1.54156494140625
e:  53   train_loss:  633.4854512618616   time:  1.6740233898162842
e:  54   train_loss:  638.040076288366   time:  1.562819480895996
e:  55   train_loss:  633.9154860741265   time:  1.562269926071167
e:  55   train_loss:  633.9154860741265   val_loss:  579.4278696525528   time:  1.6669087409973145
e:  56   train_loss:  634.3185671332503   time:  1.5628182888031006
e:  57   train_loss:  626.5542775935432   time:  1.5622901916503906
e:  58   train_loss:  616.7355880055961   time:  1.5637102127075195
e:  59   train_loss:  623.3280205854576   time:  1.55863618850708
e:  60   train_loss:  626.3198711006987   time:  1.7011353969573975
e:  60   train_loss:  626.3198711006987   val_loss:  575.131594519711   time:  1.805830478668213
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (2, 0, 0), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (2, 0, 0) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 0) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 0) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (2, 0, 0)
kwargs: {'config': {'batch_norm': False, 'ff_0': 1189, 'ff_num_layers': 1, 'gnn_0': 148, 'gnn_dropout': 0.3638746711639574, 'gnn_num_layers': 1, 'hid_0': 920, 'hid_dropout_rate': 0.45112037731197413, 'in_dropout_rate': 0.08092535011517843, 'lr': 3.791412174075131e-05, 'num_hid_layers': 3, 'optimizer': 'Adam', 'hid_1': 80, 'hid_2': 1620}, 'budget': 243.0, 'working_directory': '.'}
result: {'loss': 732.3353618931271, 'n_epochs': 63.0, 'info': {'validation loss': 732.3353618931271}}
exception: None

DEBUG:hpbandster:job_callback for (2, 0, 0) started
DEBUG:hpbandster:job_callback for (2, 0, 0) got condition
DEBUG:hpbandster:Only 7 run(s) for budget 243.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (2, 0, 0) finished
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: trying submitting job (2, 0, 1) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 1) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 1)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 1) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 1) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (2, 0, 1)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 94, 'ff_num_layers': 2, 'gnn_0': 88, 'gnn_dropout': 0.12344238113981926, 'gnn_num_layers': 3, 'hid_0': 147, 'hid_dropout_rate': 0.07011858026193535, 'in_dropout_rate': 0.2657419403485913, 'lr': 1.4626974739127854e-05, 'num_hid_layers': 3, 'optimizer': 'SGD', 'ff_1': 106, 'gnn_1': 489, 'gnn_2': 126, 'hid_1': 120, 'hid_2': 542, 'sgd_momentum': 0.6112822132866309}, 'budget': 243.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  705.1982330090025   time:  1.2676997184753418
e:  0   train_loss:  705.1982330090025   val_loss:  1674.3604570521745   time:  1.3776249885559082
e:  1   train_loss:  704.7524321449123   time:  1.2588427066802979
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  2   train_loss:  704.0102965084867   time:  1.26326584815979
e:  3   train_loss:  704.2345726495292   time:  1.2580511569976807
e:  4   train_loss:  704.0207290879708   time:  1.2513172626495361
e:  5   train_loss:  704.2626935962621   time:  1.2598350048065186
e:  5   train_loss:  704.2626935962621   val_loss:  1671.8763384057015   time:  1.3689000606536865
e:  6   train_loss:  703.5541478893637   time:  1.2632231712341309
e:  7   train_loss:  703.8124816235802   time:  1.261702060699463
e:  8   train_loss:  702.6963755818572   time:  1.2574989795684814
e:  9   train_loss:  703.5299805073074   time:  1.2578301429748535
e:  10   train_loss:  702.3217979942368   time:  1.51430082321167
e:  10   train_loss:  702.3217979942368   val_loss:  1669.3672368245543   time:  1.6156432628631592
e:  11   train_loss:  702.4456094492263   time:  1.2302632331848145
e:  12   train_loss:  703.0673561138759   time:  1.2453184127807617
e:  13   train_loss:  701.6189766891774   time:  1.2810771465301514
e:  14   train_loss:  700.809230852278   time:  1.3375308513641357
e:  15   train_loss:  700.2640124123413   time:  1.2857334613800049
e:  15   train_loss:  700.2640124123413   val_loss:  1666.8192058654793   time:  1.3973579406738281
e:  16   train_loss:  700.5328228751473   time:  1.3161654472351074
e:  17   train_loss:  700.3487556176261   time:  1.296668529510498
e:  18   train_loss:  700.6083380401542   time:  1.3070247173309326
e:  19   train_loss:  700.0306824262003   time:  1.257211446762085
e:  20   train_loss:  699.4237763680311   time:  1.3829476833343506
e:  20   train_loss:  699.4237763680311   val_loss:  1664.2695832403203   time:  1.485177755355835
e:  21   train_loss:  700.1574113550708   time:  1.246483564376831
e:  22   train_loss:  699.1079727287675   time:  1.2653756141662598
e:  23   train_loss:  699.2822217917948   time:  1.2586238384246826
e:  24   train_loss:  698.2678837629975   time:  1.2475311756134033
e:  25   train_loss:  698.3377381709734   time:  1.2595140933990479
e:  25   train_loss:  698.3377381709734   val_loss:  1661.6383416243896   time:  1.3691716194152832
e:  26   train_loss:  698.259052059627   time:  1.2632052898406982
e:  27   train_loss:  697.7477219313589   time:  1.2527382373809814
e:  28   train_loss:  697.463766438214   time:  1.245915412902832
e:  29   train_loss:  696.2172521839404   time:  1.372046947479248
e:  30   train_loss:  696.6270255752576   time:  1.2435014247894287
e:  30   train_loss:  696.6270255752576   val_loss:  1658.8876334198571   time:  1.3528544902801514
e:  31   train_loss:  696.8059979356611   time:  1.2542674541473389
e:  32   train_loss:  696.1162857833189   time:  1.262578010559082
e:  33   train_loss:  695.7277208623015   time:  1.2600064277648926
e:  34   train_loss:  694.4267016094979   time:  1.2506964206695557
e:  35   train_loss:  694.6772838074681   time:  1.240527868270874
e:  35   train_loss:  694.6772838074681   val_loss:  1655.9759823147945   time:  1.351130723953247
e:  36   train_loss:  695.1722590355956   time:  1.2558858394622803
e:  37   train_loss:  695.3602175479103   time:  1.257523536682129
e:  38   train_loss:  693.7357296618135   time:  1.2646989822387695
e:  39   train_loss:  693.8580677245527   time:  1.2535340785980225
e:  40   train_loss:  694.1915075879888   time:  1.2585430145263672
e:  40   train_loss:  694.1915075879888   val_loss:  1652.8364543322366   time:  1.501725673675537
e:  41   train_loss:  693.8110132033094   time:  1.239069938659668
e:  42   train_loss:  693.2745886210773   time:  1.2475426197052002
e:  43   train_loss:  691.8351380421146   time:  1.2586395740509033
e:  44   train_loss:  692.2263205684735   time:  1.2643144130706787
e:  45   train_loss:  692.5300662314726   time:  1.2565555572509766
e:  45   train_loss:  692.5300662314726   val_loss:  1649.380493172488   time:  1.366478681564331
e:  46   train_loss:  691.0829579736945   time:  1.2654767036437988
e:  47   train_loss:  691.1554585683853   time:  1.2579240798950195
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  48   train_loss:  690.9908565599414   time:  1.2642772197723389
e:  49   train_loss:  689.6147634287082   time:  1.2629189491271973
e:  50   train_loss:  689.6712070132726   time:  1.246467113494873
e:  50   train_loss:  689.6712070132726   val_loss:  1645.481906876019   time:  1.3559775352478027
e:  51   train_loss:  688.5535965369313   time:  1.4027702808380127
e:  52   train_loss:  688.7146479652332   time:  1.2490484714508057
e:  53   train_loss:  687.631485019635   time:  1.2543234825134277
e:  54   train_loss:  687.1539096163156   time:  1.2608275413513184
e:  55   train_loss:  687.4688210562731   time:  1.247084140777588
e:  55   train_loss:  687.4688210562731   val_loss:  1640.9410612561878   time:  1.3569002151489258
e:  56   train_loss:  686.155147153171   time:  1.2479164600372314
e:  57   train_loss:  686.0194346767419   time:  1.242927074432373
e:  58   train_loss:  684.9896898283954   time:  1.2492847442626953
e:  59   train_loss:  685.0495196810098   time:  1.246737003326416
e:  60   train_loss:  684.1571799043822   time:  1.2445430755615234
e:  60   train_loss:  684.1571799043822   val_loss:  1635.4374598700774   time:  1.4902167320251465
e:  61   train_loss:  683.3572028481565   time:  1.2545149326324463
e:  62   train_loss:  682.8311133254604   time:  1.255124568939209
e:  63   train_loss:  681.6610569100538   time:  1.2572076320648193
e:  64   train_loss:  681.2349996029568   time:  1.2419989109039307
e:  65   train_loss:  680.7848460352882   time:  1.2594330310821533
e:  65   train_loss:  680.7848460352882   val_loss:  1628.475388936519   time:  1.3696582317352295
e:  66   train_loss:  679.7008125771886   time:  1.2573730945587158
e:  67   train_loss:  678.1455223729644   time:  1.2586264610290527
e:  68   train_loss:  677.4929675356557   time:  1.2647368907928467
e:  69   train_loss:  676.2880136551001   time:  1.2555058002471924
e:  70   train_loss:  675.2642381405715   time:  1.2592005729675293
e:  70   train_loss:  675.2642381405715   val_loss:  1619.1843910058217   time:  1.3688933849334717
e:  71   train_loss:  674.2339208036708   time:  1.3780038356781006
e:  72   train_loss:  672.3507789678542   time:  1.2397193908691406
e:  73   train_loss:  671.5748506713148   time:  1.248955488204956
e:  74   train_loss:  669.8339416036688   time:  1.249284267425537
e:  75   train_loss:  668.0871110664535   time:  1.262782335281372
e:  75   train_loss:  668.0871110664535   val_loss:  1606.1423543679782   time:  1.3718299865722656
e:  76   train_loss:  666.8351458188166   time:  1.2486765384674072
e:  77   train_loss:  665.7922522322469   time:  1.258906364440918
e:  78   train_loss:  662.3496623032429   time:  1.2575767040252686
e:  79   train_loss:  661.2687085687171   time:  1.2529542446136475
e:  80   train_loss:  659.2838098492133   time:  1.2551605701446533
e:  80   train_loss:  659.2838098492133   val_loss:  1587.216230030228   time:  1.3657512664794922
e:  81   train_loss:  656.8962187262831   time:  1.2388520240783691
e:  82   train_loss:  653.2786882225753   time:  1.3912694454193115
e:  83   train_loss:  651.1137396184486   time:  1.2499113082885742
e:  84   train_loss:  647.6709925158652   time:  1.2576298713684082
e:  85   train_loss:  645.1940221040506   time:  1.2607002258300781
e:  85   train_loss:  645.1940221040506   val_loss:  1559.1799528738518   time:  1.371189832687378
e:  86   train_loss:  642.2274040339985   time:  1.263451337814331
e:  87   train_loss:  638.0885418666857   time:  1.2621910572052002
e:  88   train_loss:  634.7593969084568   time:  1.2579710483551025
e:  89   train_loss:  629.784526398992   time:  1.2590909004211426
e:  90   train_loss:  625.9167830918195   time:  1.2582883834838867
e:  90   train_loss:  625.9167830918195   val_loss:  1520.0487278492149   time:  1.3682093620300293
e:  91   train_loss:  622.2545446922987   time:  1.2613933086395264
e:  92   train_loss:  616.7435459499236   time:  1.26043701171875
e:  93   train_loss:  613.5511833580489   time:  1.393932819366455
e:  94   train_loss:  607.8837823163308   time:  1.2496893405914307
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  95   train_loss:  604.1258171243032   time:  1.2615375518798828
e:  95   train_loss:  604.1258171243032   val_loss:  1473.5025276155775   time:  1.3712422847747803
e:  96   train_loss:  600.7899009708241   time:  1.2558674812316895
e:  97   train_loss:  596.2620930564899   time:  1.2586493492126465
e:  98   train_loss:  593.2733640530813   time:  1.2507166862487793
e:  99   train_loss:  589.3537409965062   time:  1.2677192687988281
e:  100   train_loss:  585.8694262451947   time:  1.2554879188537598
e:  100   train_loss:  585.8694262451947   val_loss:  1433.554162469293   time:  1.3658242225646973
e:  101   train_loss:  582.6487396246844   time:  1.261946678161621
e:  102   train_loss:  580.1448761267347   time:  1.2566659450531006
e:  103   train_loss:  577.5134544180302   time:  1.2566421031951904
e:  104   train_loss:  573.1975414146635   time:  1.37868332862854
e:  105   train_loss:  571.2646397643196   time:  1.2568838596343994
e:  105   train_loss:  571.2646397643196   val_loss:  1413.9864872784397   time:  1.3677523136138916
e:  106   train_loss:  567.2777661809437   time:  1.2607429027557373
e:  107   train_loss:  563.6975243351469   time:  1.258901834487915
e:  108   train_loss:  561.9767871329844   time:  1.2478528022766113
e:  109   train_loss:  557.3035223001366   time:  1.2529704570770264
e:  110   train_loss:  552.2659758545338   time:  1.2593557834625244
e:  110   train_loss:  552.2659758545338   val_loss:  1412.6422015887276   time:  1.368215799331665
e:  111   train_loss:  548.3236643350301   time:  1.2603776454925537
e:  112   train_loss:  543.4281024391234   time:  1.3749151229858398
e:  113   train_loss:  539.1511370075079   time:  1.2626354694366455
e:  114   train_loss:  536.408747088171   time:  1.2571589946746826
e:  115   train_loss:  528.725578417242   time:  1.2467889785766602
e:  115   train_loss:  528.725578417242   val_loss:  1419.9140346663212   time:  1.3566110134124756
e:  116   train_loss:  525.1438133667446   time:  1.2627511024475098
e:  117   train_loss:  520.9561430618659   time:  1.2561993598937988
e:  118   train_loss:  516.8398076373792   time:  1.261995792388916
e:  119   train_loss:  510.5342893740274   time:  1.2592592239379883
e:  120   train_loss:  505.4193659182082   time:  1.2584104537963867
e:  120   train_loss:  505.4193659182082   val_loss:  1437.1289974617284   time:  1.3696277141571045
e:  121   train_loss:  500.91258734854205   time:  1.2662091255187988
e:  122   train_loss:  498.50146251879886   time:  1.256789207458496
e:  123   train_loss:  494.03180609058126   time:  1.372636318206787
e:  124   train_loss:  490.6816064016261   time:  1.260833978652954
e:  125   train_loss:  486.27845587049194   time:  1.254509687423706
e:  125   train_loss:  486.27845587049194   val_loss:  1426.385774236746   time:  1.364743709564209
e:  126   train_loss:  481.7212058585773   time:  1.254352331161499
e:  127   train_loss:  481.27806441644964   time:  1.248021125793457
e:  128   train_loss:  475.80436658427743   time:  1.2508962154388428
e:  129   train_loss:  473.0306553243021   time:  1.2573542594909668
e:  130   train_loss:  467.9700345073861   time:  1.2575039863586426
e:  130   train_loss:  467.9700345073861   val_loss:  1427.7676618888086   time:  1.3681857585906982
e:  131   train_loss:  468.16583575876774   time:  1.2478480339050293
e:  132   train_loss:  466.0613922688659   time:  1.3880290985107422
e:  133   train_loss:  463.24896948600605   time:  1.2532711029052734
e:  134   train_loss:  459.0617667682275   time:  1.253993272781372
e:  135   train_loss:  457.6911051541406   time:  1.267681360244751
e:  135   train_loss:  457.6911051541406   val_loss:  1388.3740540305148   time:  1.3780410289764404
e:  136   train_loss:  455.00994892444476   time:  1.258976697921753
e:  137   train_loss:  451.926993067695   time:  1.2605328559875488
e:  138   train_loss:  454.9191365056639   time:  1.261756420135498
e:  139   train_loss:  452.387473732591   time:  1.2481343746185303
e:  140   train_loss:  455.0232844574863   time:  1.2602152824401855
e:  140   train_loss:  455.0232844574863   val_loss:  1464.1336839319974   time:  1.3699965476989746
e:  141   train_loss:  450.47707011747843   time:  1.2589051723480225
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  142   train_loss:  449.42451802793073   time:  1.2610969543457031
e:  143   train_loss:  447.46642935626096   time:  1.3932430744171143
e:  144   train_loss:  448.12112215736363   time:  1.2581167221069336
e:  145   train_loss:  447.87808234927763   time:  1.2544584274291992
e:  145   train_loss:  447.87808234927763   val_loss:  1388.662860659054   time:  1.36387300491333
e:  146   train_loss:  448.2300583975811   time:  1.26346755027771
e:  147   train_loss:  445.0008456176681   time:  1.2649996280670166
e:  148   train_loss:  445.2024821346321   time:  1.2523329257965088
e:  149   train_loss:  444.25196221034656   time:  1.2588341236114502
e:  150   train_loss:  445.48306376119933   time:  1.253174066543579
e:  150   train_loss:  445.48306376119933   val_loss:  1566.9133922867004   time:  1.3631021976470947
e:  151   train_loss:  444.398208340586   time:  1.2518229484558105
e:  152   train_loss:  442.03212619498845   time:  1.3929438591003418
e:  153   train_loss:  444.4641986918716   time:  1.2434706687927246
e:  154   train_loss:  442.6956770804697   time:  1.2557194232940674
e:  155   train_loss:  442.97459709720476   time:  1.2489750385284424
e:  155   train_loss:  442.97459709720476   val_loss:  1358.6542688743666   time:  1.3594865798950195
e:  156   train_loss:  443.8733026199466   time:  1.256871223449707
e:  157   train_loss:  441.2502441441581   time:  1.2604126930236816
e:  158   train_loss:  441.9301115157449   time:  1.2455556392669678
e:  159   train_loss:  440.7363609925337   time:  1.2423200607299805
e:  160   train_loss:  442.7224349047584   time:  1.258765459060669
e:  160   train_loss:  442.7224349047584   val_loss:  1387.9462828453773   time:  1.3690478801727295
e:  161   train_loss:  440.9343701169238   time:  1.244891881942749
e:  162   train_loss:  441.80194970627326   time:  1.261565923690796
e:  163   train_loss:  442.3906529777297   time:  1.3889853954315186
e:  164   train_loss:  440.6056799984027   time:  1.2400269508361816
e:  165   train_loss:  440.50829767514597   time:  1.2478477954864502
e:  165   train_loss:  440.50829767514597   val_loss:  1505.9370100668536   time:  1.3577518463134766
e:  166   train_loss:  439.36806232487123   time:  1.2626144886016846
e:  167   train_loss:  442.8216443471118   time:  1.2602407932281494
e:  168   train_loss:  438.58208941545536   time:  1.266510248184204
e:  169   train_loss:  442.1328416825932   time:  1.2457952499389648
e:  170   train_loss:  442.0667241031302   time:  1.261437177658081
e:  170   train_loss:  442.0667241031302   val_loss:  1504.4895487010558   time:  1.3707795143127441
e:  171   train_loss:  436.9672980353065   time:  1.263854742050171
e:  172   train_loss:  437.7187711937669   time:  1.2578575611114502
e:  173   train_loss:  440.120236069269   time:  1.2583808898925781
e:  174   train_loss:  439.51857629381226   time:  1.2532811164855957
e:  175   train_loss:  439.01002812922775   time:  1.3792147636413574
e:  175   train_loss:  439.01002812922775   val_loss:  1471.3122399904337   time:  1.4802916049957275
e:  176   train_loss:  440.8908522511864   time:  1.2457294464111328
e:  177   train_loss:  438.8630195034988   time:  1.2519786357879639
e:  178   train_loss:  439.26944333159406   time:  1.2609713077545166
e:  179   train_loss:  441.02066470581684   time:  1.2611300945281982
e:  180   train_loss:  440.8761577020668   time:  1.2635626792907715
e:  180   train_loss:  440.8761577020668   val_loss:  1450.8396778160873   time:  1.3737571239471436
e:  181   train_loss:  438.3674279470277   time:  1.259565830230713
e:  182   train_loss:  441.2152099536472   time:  1.252629041671753
e:  183   train_loss:  438.4163832393797   time:  1.2540314197540283
e:  184   train_loss:  436.0690755367699   time:  1.2607336044311523
e:  185   train_loss:  440.81945387160397   time:  1.3861422538757324
e:  185   train_loss:  440.81945387160397   val_loss:  1394.041082336604   time:  1.4887495040893555
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1078.7030444993272   time:  1.3804562091827393
e:  0   train_loss:  1078.7030444993272   val_loss:  628.0009646605833   time:  1.4851222038269043
e:  1   train_loss:  1071.7743440959696   time:  1.3729629516601562
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  2   train_loss:  1065.73510867387   time:  1.3776650428771973
e:  3   train_loss:  1074.6355846412562   time:  1.3758938312530518
e:  4   train_loss:  1072.1287996221972   time:  1.3766894340515137
e:  5   train_loss:  1079.8485851395435   time:  1.37886381149292
e:  5   train_loss:  1079.8485851395435   val_loss:  626.021548522301   time:  1.6131219863891602
e:  6   train_loss:  1080.3904645921234   time:  1.3887817859649658
e:  7   train_loss:  1070.4068055673386   time:  1.3783960342407227
e:  8   train_loss:  1081.4684994356724   time:  1.37738037109375
e:  9   train_loss:  1077.907032489832   time:  1.3753340244293213
e:  10   train_loss:  1082.1288441400186   time:  1.3525571823120117
e:  10   train_loss:  1082.1288441400186   val_loss:  623.9291079232993   time:  1.4565696716308594
e:  11   train_loss:  1076.773760545672   time:  1.521082878112793
e:  12   train_loss:  1075.4359728803784   time:  1.3809609413146973
e:  13   train_loss:  1086.3207839450943   time:  1.3788831233978271
e:  14   train_loss:  1081.485252430819   time:  1.3791556358337402
e:  15   train_loss:  1073.171729451762   time:  1.3753676414489746
e:  15   train_loss:  1073.171729451762   val_loss:  621.7520274449518   time:  1.4802649021148682
e:  16   train_loss:  1077.7610987259918   time:  1.3848679065704346
e:  17   train_loss:  1078.457061444578   time:  1.3818376064300537
e:  18   train_loss:  1065.6042142113183   time:  1.4982244968414307
e:  19   train_loss:  1074.933997391662   time:  1.3807463645935059
e:  20   train_loss:  1061.7287080890924   time:  1.3815295696258545
e:  20   train_loss:  1061.7287080890924   val_loss:  619.4129680740299   time:  1.4851210117340088
e:  21   train_loss:  1060.1586145994295   time:  1.3837499618530273
e:  22   train_loss:  1077.9920021370367   time:  1.3841087818145752
e:  23   train_loss:  1093.2578495214698   time:  1.381155252456665
e:  24   train_loss:  1052.9942153661586   time:  1.3699615001678467
e:  25   train_loss:  1066.3994099487552   time:  1.5265161991119385
e:  25   train_loss:  1066.3994099487552   val_loss:  616.752606553293   time:  1.630997896194458
e:  26   train_loss:  1071.288205061041   time:  1.3845396041870117
e:  27   train_loss:  1065.7741884241436   time:  1.3823952674865723
e:  28   train_loss:  1070.9956039792182   time:  1.3801307678222656
e:  29   train_loss:  1053.4051402684793   time:  1.385225534439087
e:  30   train_loss:  1065.5505361227358   time:  1.3784031867980957
e:  30   train_loss:  1065.5505361227358   val_loss:  613.5257069786593   time:  1.4825282096862793
e:  31   train_loss:  1052.8957894756204   time:  1.5146584510803223
e:  32   train_loss:  1057.102692914371   time:  1.3813867568969727
e:  33   train_loss:  1058.8540158117055   time:  1.3741300106048584
e:  34   train_loss:  1046.1346753123948   time:  1.3818106651306152
e:  35   train_loss:  1043.275838779115   time:  1.3704259395599365
e:  35   train_loss:  1043.275838779115   val_loss:  609.2637068625571   time:  1.4747536182403564
e:  36   train_loss:  1072.1829315279879   time:  1.379112958908081
e:  37   train_loss:  1052.867437504261   time:  1.3815057277679443
e:  38   train_loss:  1051.6128159768973   time:  1.4976780414581299
e:  39   train_loss:  1056.7750252196906   time:  1.3794541358947754
e:  40   train_loss:  1061.1727624278606   time:  1.3804409503936768
e:  40   train_loss:  1061.1727624278606   val_loss:  603.0604399798156   time:  1.484830379486084
e:  41   train_loss:  1042.4656826194396   time:  1.3752334117889404
e:  42   train_loss:  1028.5277721191767   time:  1.3805615901947021
e:  43   train_loss:  1043.1144467299382   time:  1.3688127994537354
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  44   train_loss:  1040.6993863566959   time:  1.3786096572875977
e:  45   train_loss:  1042.3329610873282   time:  1.5244543552398682
e:  45   train_loss:  1042.3329610873282   val_loss:  593.153204904315   time:  1.6294734477996826
e:  46   train_loss:  1033.9365018514868   time:  1.385725736618042
e:  47   train_loss:  1031.3936073815114   time:  1.3828392028808594
e:  48   train_loss:  1027.8654329620595   time:  1.3795530796051025
e:  49   train_loss:  999.9629719347779   time:  1.3700485229492188
e:  50   train_loss:  1028.9746602464593   time:  1.3798608779907227
e:  50   train_loss:  1028.9746602464593   val_loss:  575.3184678256213   time:  1.617368221282959
e:  51   train_loss:  988.8105115286263   time:  1.3797147274017334
e:  52   train_loss:  976.3609408398253   time:  1.3511996269226074
e:  53   train_loss:  945.2089051294554   time:  1.373530387878418
e:  54   train_loss:  953.3625797528803   time:  1.3791136741638184
e:  55   train_loss:  926.591023299875   time:  1.3717269897460938
e:  55   train_loss:  926.591023299875   val_loss:  545.8253697667085   time:  1.475966215133667
e:  56   train_loss:  880.5284432156701   time:  1.5180115699768066
e:  57   train_loss:  875.6750884138861   time:  1.3724117279052734
e:  58   train_loss:  827.0588272847598   time:  1.387747049331665
e:  59   train_loss:  793.9452021605762   time:  1.3781239986419678
e:  60   train_loss:  761.3196063639955   time:  1.3883473873138428
e:  60   train_loss:  761.3196063639955   val_loss:  539.8254502777801   time:  1.4930026531219482
e:  61   train_loss:  734.879568930693   time:  1.3759210109710693
e:  62   train_loss:  719.1401524812636   time:  1.376709222793579
e:  63   train_loss:  704.2056981190423   time:  1.52878999710083
e:  64   train_loss:  682.6934714817402   time:  1.378821849822998
e:  65   train_loss:  676.0977689053099   time:  1.385565996170044
e:  65   train_loss:  676.0977689053099   val_loss:  565.1028617765752   time:  1.4907565116882324
e:  66   train_loss:  684.1674138030517   time:  1.3834452629089355
e:  67   train_loss:  662.1444403508856   time:  1.376512050628662
e:  68   train_loss:  655.0181890826477   time:  1.3705761432647705
e:  69   train_loss:  647.4122839069458   time:  1.3965020179748535
e:  70   train_loss:  644.6592616293916   time:  1.528151273727417
e:  70   train_loss:  644.6592616293916   val_loss:  554.21746154875   time:  1.6324312686920166
e:  71   train_loss:  637.6948571560894   time:  1.3807997703552246
e:  72   train_loss:  624.6053699713962   time:  1.3690924644470215
e:  73   train_loss:  632.3216942203234   time:  1.3635215759277344
e:  74   train_loss:  620.8283834356577   time:  1.3633661270141602
e:  75   train_loss:  610.6655840912746   time:  1.3776850700378418
e:  75   train_loss:  610.6655840912746   val_loss:  553.5018760470634   time:  1.4821016788482666
e:  76   train_loss:  609.341267167277   time:  1.5242033004760742
e:  77   train_loss:  604.140707346053   time:  1.386059045791626
e:  78   train_loss:  612.8235123232971   time:  1.3841955661773682
e:  79   train_loss:  606.629776670731   time:  1.381025791168213
e:  80   train_loss:  613.1268163864447   time:  1.3736190795898438
e:  80   train_loss:  613.1268163864447   val_loss:  549.4800507249932   time:  1.4785919189453125
e:  81   train_loss:  604.0783335028365   time:  1.3850412368774414
e:  82   train_loss:  599.2737085355748   time:  1.3819756507873535
e:  83   train_loss:  602.372230028236   time:  1.4951519966125488
e:  84   train_loss:  593.6098328479816   time:  1.385361909866333
e:  85   train_loss:  612.0070169091913   time:  1.38649320602417
e:  85   train_loss:  612.0070169091913   val_loss:  1077.8604520229117   time:  1.490626335144043
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  86   train_loss:  603.6579004152599   time:  1.3864874839782715
e:  87   train_loss:  599.6451906386147   time:  1.3908741474151611
e:  88   train_loss:  598.7255165671884   time:  1.382162094116211
e:  89   train_loss:  591.2972947810289   time:  1.3708899021148682
e:  90   train_loss:  591.3251367880334   time:  1.5266311168670654
e:  90   train_loss:  591.3251367880334   val_loss:  651.447461500528   time:  1.6311254501342773
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1092.5351983722364   time:  1.3690316677093506
e:  0   train_loss:  1092.5351983722364   val_loss:  539.9072074722565   time:  1.4754045009613037
e:  1   train_loss:  1082.4801009726157   time:  1.3542876243591309
e:  2   train_loss:  1063.5437459943128   time:  1.3666205406188965
e:  3   train_loss:  1130.1691280746402   time:  1.355128526687622
e:  4   train_loss:  1080.1389674333973   time:  1.3610494136810303
e:  5   train_loss:  1071.860021050502   time:  1.3661258220672607
e:  5   train_loss:  1071.860021050502   val_loss:  538.3131200385304   time:  1.4732661247253418
e:  6   train_loss:  1073.1538323195796   time:  1.508390188217163
e:  7   train_loss:  1114.1435963212955   time:  1.3536574840545654
e:  8   train_loss:  1074.3659077845352   time:  1.3667242527008057
e:  9   train_loss:  1106.8775892848334   time:  1.358525037765503
e:  10   train_loss:  1101.4815504187513   time:  1.3732690811157227
e:  10   train_loss:  1101.4815504187513   val_loss:  536.6868399090448   time:  1.4801511764526367
e:  11   train_loss:  1068.4472903412427   time:  1.3675570487976074
e:  12   train_loss:  1064.7690440524311   time:  1.3666975498199463
e:  13   train_loss:  1057.4738079197066   time:  1.3664238452911377
e:  14   train_loss:  1114.648895622304   time:  1.4923388957977295
e:  15   train_loss:  1057.3000784131982   time:  1.3644185066223145
e:  15   train_loss:  1057.3000784131982   val_loss:  535.1006611990387   time:  1.471006155014038
e:  16   train_loss:  1064.7635863490057   time:  1.3690261840820312
e:  17   train_loss:  1057.7422217545184   time:  1.3695714473724365
e:  18   train_loss:  1133.8514493607365   time:  1.352041244506836
e:  19   train_loss:  1075.4262000815645   time:  1.3658661842346191
e:  20   train_loss:  1055.4558083441257   time:  1.3624906539916992
e:  20   train_loss:  1055.4558083441257   val_loss:  533.5035625912959   time:  1.5982353687286377
e:  21   train_loss:  1081.6120058279864   time:  1.3643264770507812
e:  22   train_loss:  1076.1659707660178   time:  1.3655552864074707
e:  23   train_loss:  1061.3740801134213   time:  1.3645715713500977
e:  24   train_loss:  1051.658138531815   time:  1.3625543117523193
e:  25   train_loss:  1129.5244144478213   time:  1.3498857021331787
e:  25   train_loss:  1129.5244144478213   val_loss:  531.8692427182182   time:  1.4573304653167725
e:  26   train_loss:  1048.6734452908058   time:  1.3661561012268066
e:  27   train_loss:  1057.0139017289903   time:  1.3646562099456787
e:  28   train_loss:  1042.2299999915529   time:  1.4958739280700684
e:  29   train_loss:  1065.1894351395822   time:  1.3621799945831299
e:  30   train_loss:  1122.9330525018954   time:  1.3669061660766602
e:  30   train_loss:  1122.9330525018954   val_loss:  530.1673971195254   time:  1.473757266998291
e:  31   train_loss:  1057.8784837615908   time:  1.3690118789672852
e:  32   train_loss:  1097.297575787475   time:  1.2298612594604492
e:  33   train_loss:  1096.5976743109995   time:  1.1831581592559814
e:  34   train_loss:  1144.8687977592297   time:  1.1796245574951172
e:  35   train_loss:  1058.0752849012338   time:  1.5297541618347168
e:  35   train_loss:  1058.0752849012338   val_loss:  528.3420612116647   time:  1.6370046138763428
e:  36   train_loss:  1065.6825032816512   time:  1.4537885189056396
e:  37   train_loss:  1043.2970956836489   time:  1.4680569171905518
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  38   train_loss:  1039.3243913344907   time:  1.5874288082122803
e:  39   train_loss:  1097.8489572957524   time:  1.5712707042694092
e:  40   train_loss:  1087.8020905958185   time:  1.5074684619903564
e:  40   train_loss:  1087.8020905958185   val_loss:  526.3562476129914   time:  1.616424798965454
e:  41   train_loss:  1041.5038205657993   time:  1.6583192348480225
e:  42   train_loss:  1038.4301137902792   time:  1.4793572425842285
e:  43   train_loss:  1041.0575931032201   time:  1.4707069396972656
e:  44   train_loss:  1093.0042322825393   time:  1.4749445915222168
e:  45   train_loss:  1049.308704695616   time:  1.4597463607788086
e:  45   train_loss:  1049.308704695616   val_loss:  524.0997694493608   time:  1.5673935413360596
e:  46   train_loss:  1059.0864823234429   time:  1.4575855731964111
e:  47   train_loss:  1059.5577443275436   time:  1.471205234527588
e:  48   train_loss:  1071.9406814370097   time:  1.6747806072235107
e:  49   train_loss:  1029.484791371984   time:  1.4737091064453125
e:  50   train_loss:  1039.6700209325224   time:  1.4766168594360352
e:  50   train_loss:  1039.6700209325224   val_loss:  521.3764763815093   time:  1.584519863128662
e:  51   train_loss:  1148.2967099034734   time:  1.4645519256591797
e:  52   train_loss:  1036.3328164304505   time:  1.4731988906860352
e:  53   train_loss:  1052.1358798158496   time:  1.4730334281921387
e:  54   train_loss:  1073.0671854076327   time:  1.4716219902038574
e:  55   train_loss:  1075.0903970090972   time:  1.473832130432129
e:  55   train_loss:  1075.0903970090972   val_loss:  517.7841400003413   time:  1.5820190906524658
e:  56   train_loss:  1047.385124256692   time:  1.6474876403808594
e:  57   train_loss:  1088.0260411831005   time:  1.3557631969451904
e:  58   train_loss:  1033.641315351755   time:  1.3747444152832031
e:  59   train_loss:  1029.6563697666506   time:  1.3472352027893066
e:  60   train_loss:  1057.7526276019462   time:  1.3508214950561523
e:  60   train_loss:  1057.7526276019462   val_loss:  512.6616418738139   time:  1.456434965133667
e:  61   train_loss:  1020.8657006017074   time:  1.34000825881958
e:  62   train_loss:  1057.9245654762653   time:  1.350060224533081
e:  63   train_loss:  1028.025591183667   time:  1.4726526737213135
e:  64   train_loss:  1047.9069533377565   time:  1.3498966693878174
e:  65   train_loss:  1066.8354746059267   time:  1.3423101902008057
e:  65   train_loss:  1066.8354746059267   val_loss:  504.7747495052852   time:  1.4469285011291504
e:  66   train_loss:  1031.2378327957324   time:  1.3367116451263428
e:  67   train_loss:  1075.8421518636378   time:  1.3402819633483887
e:  68   train_loss:  1003.7895678171852   time:  1.3476643562316895
e:  69   train_loss:  1083.2045696285638   time:  1.3522300720214844
e:  70   train_loss:  1009.7329798690603   time:  1.4809091091156006
e:  70   train_loss:  1009.7329798690603   val_loss:  491.8639681130474   time:  1.5863332748413086
e:  71   train_loss:  964.7181228875579   time:  1.3423442840576172
e:  72   train_loss:  946.138629261225   time:  1.3483262062072754
e:  73   train_loss:  922.2145607525586   time:  1.353769302368164
e:  74   train_loss:  901.8747300944437   time:  1.3536176681518555
e:  75   train_loss:  967.2761862569203   time:  1.3539490699768066
e:  75   train_loss:  967.2761862569203   val_loss:  478.41968234970483   time:  1.4597580432891846
e:  76   train_loss:  875.0764016355449   time:  1.3531785011291504
e:  77   train_loss:  890.9065641567315   time:  1.4909329414367676
e:  78   train_loss:  834.3313020028027   time:  1.3868043422698975
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  79   train_loss:  784.9680950024552   time:  1.3776071071624756
e:  80   train_loss:  764.2514671031519   time:  1.371821641921997
e:  80   train_loss:  764.2514671031519   val_loss:  503.7506989944842   time:  1.478261947631836
e:  81   train_loss:  741.177020042585   time:  1.3618922233581543
e:  82   train_loss:  756.1132311756622   time:  1.3689537048339844
e:  83   train_loss:  714.1958230921712   time:  1.3654606342315674
e:  84   train_loss:  685.354344419018   time:  1.36783766746521
e:  85   train_loss:  714.9274728264689   time:  1.5154931545257568
e:  85   train_loss:  714.9274728264689   val_loss:  483.5259853567534   time:  1.6226603984832764
e:  86   train_loss:  681.0237273881212   time:  1.3683032989501953
e:  87   train_loss:  660.2706788458784   time:  1.3543565273284912
e:  88   train_loss:  694.2172239387564   time:  1.3582475185394287
e:  89   train_loss:  636.4198498487522   time:  1.3639602661132812
e:  90   train_loss:  644.699075311583   time:  1.3690528869628906
e:  90   train_loss:  644.699075311583   val_loss:  1039.859979392594   time:  1.47438383102417
e:  91   train_loss:  670.5222425568187   time:  1.3656606674194336
e:  92   train_loss:  650.7819529876512   time:  1.5094571113586426
e:  93   train_loss:  643.8624633066353   time:  1.364842176437378
e:  94   train_loss:  628.6703201372651   time:  1.364800214767456
e:  95   train_loss:  637.1102404109464   time:  1.3690550327301025
e:  95   train_loss:  637.1102404109464   val_loss:  503.3984853588075   time:  1.4755465984344482
e:  96   train_loss:  622.4171968302894   time:  1.3625760078430176
e:  97   train_loss:  644.0592515269864   time:  1.3547821044921875
e:  98   train_loss:  627.4885100436111   time:  1.357982873916626
e:  99   train_loss:  642.913688144906   time:  1.3696229457855225
e:  100   train_loss:  664.5863698480341   time:  1.5109775066375732
e:  100   train_loss:  664.5863698480341   val_loss:  484.3832968200348   time:  1.6171276569366455
e:  101   train_loss:  652.2628058815845   time:  1.3682787418365479
e:  102   train_loss:  623.0448055289244   time:  1.3690392971038818
e:  103   train_loss:  623.0786183404001   time:  1.367401361465454
e:  104   train_loss:  611.1901319207703   time:  1.365072250366211
e:  105   train_loss:  620.8800219235454   time:  1.3686854839324951
e:  105   train_loss:  620.8800219235454   val_loss:  655.1957951116234   time:  1.4747328758239746
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  999.6306758530735   time:  1.2450110912322998
e:  0   train_loss:  999.6306758530735   val_loss:  917.6854668927384   time:  1.354825735092163
e:  1   train_loss:  999.1690165746546   time:  1.403878927230835
e:  2   train_loss:  998.6498425458722   time:  1.2627441883087158
e:  3   train_loss:  997.5552547709331   time:  1.246727466583252
e:  4   train_loss:  999.5811915399323   time:  1.248410701751709
e:  5   train_loss:  999.301133356564   time:  1.2597084045410156
e:  5   train_loss:  999.301133356564   val_loss:  915.3782487996652   time:  1.3699884414672852
e:  6   train_loss:  995.2523550686801   time:  1.261101245880127
e:  7   train_loss:  996.018845681592   time:  1.257629632949829
e:  8   train_loss:  995.987104834056   time:  1.291503667831421
e:  9   train_loss:  995.5031416949598   time:  1.2787556648254395
e:  10   train_loss:  999.8295768252715   time:  1.2629129886627197
e:  10   train_loss:  999.8295768252715   val_loss:  913.165251391122   time:  1.3733134269714355
e:  11   train_loss:  993.412782208446   time:  1.2621591091156006
e:  12   train_loss:  996.9363100065359   time:  1.259770154953003
e:  13   train_loss:  992.5364443316408   time:  1.3929476737976074
e:  14   train_loss:  994.408472367069   time:  1.261962652206421
e:  15   train_loss:  992.7935951867591   time:  1.2646291255950928
e:  15   train_loss:  992.7935951867591   val_loss:  910.9116415854518   time:  1.376727819442749
e:  16   train_loss:  992.2260692847321   time:  1.2558410167694092
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  17   train_loss:  995.6993308400572   time:  1.2486293315887451
e:  18   train_loss:  992.561696388819   time:  1.2596344947814941
e:  19   train_loss:  989.3811915438963   time:  1.2545764446258545
e:  20   train_loss:  992.6517064096079   time:  1.2549889087677002
e:  20   train_loss:  992.6517064096079   val_loss:  908.6234146260288   time:  1.3657867908477783
e:  21   train_loss:  990.8707564196732   time:  1.2548918724060059
e:  22   train_loss:  988.5726786366508   time:  1.256274938583374
e:  23   train_loss:  990.0168351183795   time:  1.2542788982391357
e:  24   train_loss:  987.0108536682532   time:  1.252110481262207
e:  25   train_loss:  986.4852039579246   time:  1.2493882179260254
e:  25   train_loss:  986.4852039579246   val_loss:  906.268161336444   time:  1.483402967453003
e:  26   train_loss:  988.1455791858305   time:  1.2756009101867676
e:  27   train_loss:  988.4761315038835   time:  1.261951208114624
e:  28   train_loss:  983.292072028653   time:  1.2502264976501465
e:  29   train_loss:  985.407411944726   time:  1.250603199005127
e:  30   train_loss:  989.4157817978156   time:  1.2522118091583252
e:  30   train_loss:  989.4157817978156   val_loss:  903.802656974469   time:  1.3624770641326904
e:  31   train_loss:  987.0454159917286   time:  1.2531754970550537
e:  32   train_loss:  982.4662896248681   time:  1.2410171031951904
e:  33   train_loss:  983.351665770455   time:  1.2522861957550049
e:  34   train_loss:  985.1562506708772   time:  1.2431068420410156
e:  35   train_loss:  981.6567714495055   time:  1.3779058456420898
e:  35   train_loss:  981.6567714495055   val_loss:  901.1690062004053   time:  1.4882440567016602
e:  36   train_loss:  982.79095711223   time:  1.2488362789154053
e:  37   train_loss:  982.4697065043115   time:  1.2533626556396484
e:  38   train_loss:  980.806131276441   time:  1.254737377166748
e:  39   train_loss:  979.5016751367359   time:  1.243802547454834
e:  40   train_loss:  981.7102212927945   time:  1.254528284072876
e:  40   train_loss:  981.7102212927945   val_loss:  898.2807347824003   time:  1.3654799461364746
e:  41   train_loss:  979.5614175596733   time:  1.2493035793304443
e:  42   train_loss:  978.9023717071086   time:  1.2558205127716064
e:  43   train_loss:  977.9410125482509   time:  1.2512171268463135
e:  44   train_loss:  978.6522548468853   time:  1.3760960102081299
e:  45   train_loss:  980.3322277577084   time:  1.2305114269256592
e:  45   train_loss:  980.3322277577084   val_loss:  894.9921359998682   time:  1.340456485748291
e:  46   train_loss:  977.2618764654167   time:  1.253467321395874
e:  47   train_loss:  977.471674291346   time:  1.3460328578948975
e:  48   train_loss:  972.2700142750671   time:  1.239975929260254
e:  49   train_loss:  973.8964433069419   time:  1.2393505573272705
e:  50   train_loss:  971.4552127388814   time:  1.357825756072998
e:  50   train_loss:  971.4552127388814   val_loss:  891.0553055742123   time:  1.4678001403808594
e:  51   train_loss:  970.9524574799455   time:  1.251415729522705
e:  52   train_loss:  971.7067934314094   time:  1.2433788776397705
e:  53   train_loss:  972.988320524745   time:  1.377216100692749
e:  54   train_loss:  969.234551006161   time:  1.2524855136871338
e:  55   train_loss:  969.0611835162589   time:  1.252152681350708
e:  55   train_loss:  969.0611835162589   val_loss:  886.1172446215808   time:  1.3622655868530273
e:  56   train_loss:  968.4671831234094   time:  1.254507064819336
e:  57   train_loss:  966.1344860611481   time:  1.2518670558929443
e:  58   train_loss:  963.2903630129764   time:  1.2411999702453613
e:  59   train_loss:  962.9160235439655   time:  1.24879789352417
e:  60   train_loss:  961.3685224994513   time:  1.2525334358215332
e:  60   train_loss:  961.3685224994513   val_loss:  879.4957085726348   time:  1.3627643585205078
e:  61   train_loss:  959.4250405162329   time:  1.248145341873169
e:  62   train_loss:  958.5543488418937   time:  1.2528128623962402
e:  63   train_loss:  961.6408386632971   time:  1.25258207321167
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  64   train_loss:  953.6643828654201   time:  1.2563953399658203
e:  65   train_loss:  954.0593229046518   time:  1.2508859634399414
e:  65   train_loss:  954.0593229046518   val_loss:  869.9694174658832   time:  1.4909119606018066
e:  66   train_loss:  952.9572667601019   time:  1.2520246505737305
e:  67   train_loss:  946.8412272312869   time:  1.2502682209014893
e:  68   train_loss:  944.7114014031033   time:  1.2503783702850342
e:  69   train_loss:  942.8598233372884   time:  1.2494440078735352
e:  70   train_loss:  939.5308295428285   time:  1.5649702548980713
e:  70   train_loss:  939.5308295428285   val_loss:  855.415731984346   time:  1.675525426864624
e:  71   train_loss:  935.7187738484224   time:  1.3170475959777832
e:  72   train_loss:  932.0252125779095   time:  1.3553271293640137
e:  73   train_loss:  928.6991044897323   time:  1.3108761310577393
e:  74   train_loss:  921.9045703151659   time:  1.4988880157470703
e:  75   train_loss:  916.4386382109786   time:  1.2881948947906494
e:  75   train_loss:  916.4386382109786   val_loss:  832.2625136889228   time:  1.390655755996704
e:  76   train_loss:  912.7998553616708   time:  1.3164393901824951
e:  77   train_loss:  903.2924221857932   time:  1.316572666168213
e:  78   train_loss:  894.9678730250856   time:  1.314251184463501
e:  79   train_loss:  889.4320049320672   time:  1.3137776851654053
e:  80   train_loss:  879.1079916201494   time:  1.31349778175354
e:  80   train_loss:  879.1079916201494   val_loss:  797.7497978889293   time:  1.4236094951629639
e:  81   train_loss:  866.1172753789385   time:  1.3165762424468994
e:  82   train_loss:  857.3694538739117   time:  1.302304744720459
e:  83   train_loss:  842.453251267004   time:  1.3142199516296387
e:  84   train_loss:  830.054468553494   time:  1.3250336647033691
e:  85   train_loss:  816.0258253334672   time:  1.4945378303527832
e:  85   train_loss:  816.0258253334672   val_loss:  759.8144509479539   time:  1.6040458679199219
e:  86   train_loss:  800.3477751766908   time:  1.3070635795593262
e:  87   train_loss:  780.7672539053852   time:  1.3000130653381348
e:  88   train_loss:  767.6494436311605   time:  1.30607271194458
e:  89   train_loss:  753.31841049271   time:  1.2963805198669434
e:  90   train_loss:  735.1992657982485   time:  1.3027441501617432
e:  90   train_loss:  735.1992657982485   val_loss:  738.8640068933917   time:  1.4135046005249023
e:  91   train_loss:  718.8354456144892   time:  1.297842264175415
e:  92   train_loss:  707.3136158197328   time:  1.301112413406372
e:  93   train_loss:  695.8565620932733   time:  1.300976037979126
e:  94   train_loss:  678.0721397790319   time:  1.459455966949463
e:  95   train_loss:  666.0626257368908   time:  1.275083065032959
e:  95   train_loss:  666.0626257368908   val_loss:  731.9461140128175   time:  1.38527512550354
e:  96   train_loss:  656.5184957307902   time:  1.3014793395996094
e:  97   train_loss:  641.156652626009   time:  1.3022217750549316
e:  98   train_loss:  634.0854001190941   time:  1.2945940494537354
e:  99   train_loss:  619.3286579015208   time:  1.3008909225463867
e:  100   train_loss:  608.8963675200705   time:  1.297356128692627
e:  100   train_loss:  608.8963675200705   val_loss:  729.1896091930281   time:  1.407283067703247
e:  101   train_loss:  607.1948624973763   time:  1.3015480041503906
e:  102   train_loss:  595.1028959565817   time:  1.2975144386291504
e:  103   train_loss:  590.0743818253659   time:  1.475067377090454
e:  104   train_loss:  589.7219228709546   time:  1.302027940750122
e:  105   train_loss:  585.8419892796213   time:  1.2991249561309814
e:  105   train_loss:  585.8419892796213   val_loss:  721.3118500645428   time:  1.40921950340271
e:  106   train_loss:  589.68143132753   time:  1.299482822418213
e:  107   train_loss:  577.3923708830296   time:  1.2983510494232178
e:  108   train_loss:  572.863090898654   time:  1.2899346351623535
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  109   train_loss:  567.7798411535973   time:  1.303032636642456
e:  110   train_loss:  574.3705995665558   time:  1.291719675064087
e:  110   train_loss:  574.3705995665558   val_loss:  739.9893765901111   time:  1.4022800922393799
e:  111   train_loss:  572.5783545380376   time:  1.2876005172729492
e:  112   train_loss:  562.5592241215934   time:  1.2968604564666748
e:  113   train_loss:  568.9081046807801   time:  1.2910492420196533
e:  114   train_loss:  570.4717581150953   time:  1.2968950271606445
e:  115   train_loss:  570.5031549983655   time:  1.2877509593963623
e:  115   train_loss:  570.5031549983655   val_loss:  741.7829003978903   time:  1.565267562866211
e:  116   train_loss:  567.1327940480729   time:  1.2851526737213135
e:  117   train_loss:  571.2547354044905   time:  1.2740886211395264
e:  118   train_loss:  569.3883069598969   time:  1.2903757095336914
e:  119   train_loss:  575.0972786210456   time:  1.287424087524414
e:  120   train_loss:  562.7042220710911   time:  1.287919521331787
e:  120   train_loss:  562.7042220710911   val_loss:  760.3130458547289   time:  1.3980345726013184
e:  121   train_loss:  562.2613750325309   time:  1.2892076969146729
e:  122   train_loss:  556.9111233832928   time:  1.2883057594299316
e:  123   train_loss:  562.1438627139931   time:  1.2896397113800049
e:  124   train_loss:  567.60652632506   time:  1.4516425132751465
e:  125   train_loss:  572.2722668380824   time:  1.2661676406860352
e:  125   train_loss:  572.2722668380824   val_loss:  720.4442866854896   time:  1.367976427078247
e:  126   train_loss:  559.0482612790634   time:  1.2919692993164062
e:  127   train_loss:  559.4876881940932   time:  1.2906849384307861
e:  128   train_loss:  557.8267484955705   time:  1.2884371280670166
e:  129   train_loss:  561.1926980422468   time:  1.2884492874145508
e:  130   train_loss:  561.4600342233413   time:  1.2885420322418213
e:  130   train_loss:  561.4600342233413   val_loss:  748.4882769498337   time:  1.3984642028808594
e:  131   train_loss:  555.5840490743562   time:  1.292677402496338
e:  132   train_loss:  556.0835791892014   time:  1.2763586044311523
e:  133   train_loss:  562.6990890228769   time:  1.2893712520599365
e:  134   train_loss:  558.8914206973603   time:  1.2829525470733643
e:  135   train_loss:  556.5630229858971   time:  1.453467607498169
e:  135   train_loss:  556.5630229858971   val_loss:  740.9320702011111   time:  1.5640268325805664
e:  136   train_loss:  555.3882226352923   time:  1.2847979068756104
e:  137   train_loss:  563.7881140315666   time:  1.2879667282104492
e:  138   train_loss:  556.7749775467137   time:  1.2905240058898926
e:  139   train_loss:  560.0998545388267   time:  1.2730071544647217
e:  140   train_loss:  554.6997189217266   time:  1.2837116718292236
e:  140   train_loss:  554.6997189217266   val_loss:  724.2947468809293   time:  1.394453763961792
e:  141   train_loss:  560.1208556726431   time:  1.2858941555023193
e:  142   train_loss:  562.7568004312024   time:  1.2906301021575928
e:  143   train_loss:  560.0028688972246   time:  1.4856054782867432
e:  144   train_loss:  556.9243149553528   time:  1.4423091411590576
e:  145   train_loss:  559.6612703642413   time:  1.2707152366638184
e:  145   train_loss:  559.6612703642413   val_loss:  739.54548234407   time:  1.380202054977417
e:  146   train_loss:  551.7692085930423   time:  1.2886042594909668
e:  147   train_loss:  552.401706216211   time:  1.2896478176116943
e:  148   train_loss:  553.0294390074658   time:  1.281848430633545
e:  149   train_loss:  552.6298217208899   time:  1.2892982959747314
e:  150   train_loss:  551.8461713053888   time:  1.2845525741577148
e:  150   train_loss:  551.8461713053888   val_loss:  722.8247980721865   time:  1.3941056728363037
e:  151   train_loss:  554.9518050412372   time:  1.287842035293579
e:  152   train_loss:  552.1072512856877   time:  1.2833807468414307
e:  153   train_loss:  558.480769930295   time:  1.4492409229278564
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  154   train_loss:  558.5878043014897   time:  1.2893927097320557
e:  155   train_loss:  552.9301331787955   time:  1.2885146141052246
e:  155   train_loss:  552.9301331787955   val_loss:  768.5632849499367   time:  1.3986048698425293
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1077.5139680026457   time:  1.4019629955291748
e:  0   train_loss:  1077.5139680026457   val_loss:  691.0810964071914   time:  1.50709867477417
e:  1   train_loss:  1067.6615638844125   time:  1.3974573612213135
e:  2   train_loss:  1073.363372283654   time:  1.3833601474761963
e:  3   train_loss:  1083.1310805912187   time:  1.405444860458374
e:  4   train_loss:  1083.5010465090322   time:  1.580439567565918
e:  5   train_loss:  1057.759292310234   time:  1.3950307369232178
e:  5   train_loss:  1057.759292310234   val_loss:  688.909994222476   time:  1.4985430240631104
e:  6   train_loss:  1066.519353102071   time:  1.4004132747650146
e:  7   train_loss:  1079.5877780145609   time:  1.4023957252502441
e:  8   train_loss:  1080.126873822288   time:  1.4040179252624512
e:  9   train_loss:  1079.5488227057576   time:  1.3937528133392334
e:  10   train_loss:  1057.756638735988   time:  1.4014747142791748
e:  10   train_loss:  1057.756638735988   val_loss:  686.6271462801435   time:  1.5055077075958252
e:  11   train_loss:  1066.0793147626132   time:  1.583252191543579
e:  12   train_loss:  1057.2651573847043   time:  1.4028410911560059
e:  13   train_loss:  1068.5807305718818   time:  1.4045429229736328
e:  14   train_loss:  1067.0613278394553   time:  1.4032485485076904
e:  15   train_loss:  1060.62940308021   time:  1.3977277278900146
e:  15   train_loss:  1060.62940308021   val_loss:  684.2737487145228   time:  1.502661943435669
e:  16   train_loss:  1063.408506775585   time:  1.4058938026428223
e:  17   train_loss:  1062.5284046693637   time:  1.4049122333526611
e:  18   train_loss:  1048.200688824694   time:  1.5429108142852783
e:  19   train_loss:  1055.7973334179715   time:  1.4047067165374756
e:  20   train_loss:  1055.3842123509742   time:  1.4073028564453125
e:  20   train_loss:  1055.3842123509742   val_loss:  681.7597106638015   time:  1.5114085674285889
e:  21   train_loss:  1051.7063293324793   time:  1.4052305221557617
e:  22   train_loss:  1064.776084756776   time:  1.4054970741271973
e:  23   train_loss:  1063.162766766483   time:  1.402928113937378
e:  24   train_loss:  1054.7046016616596   time:  1.3854365348815918
e:  25   train_loss:  1062.8420165112282   time:  1.5851025581359863
e:  25   train_loss:  1062.8420165112282   val_loss:  678.921805595414   time:  1.6887168884277344
e:  26   train_loss:  1070.3369593014513   time:  1.390923261642456
e:  27   train_loss:  1058.179782992055   time:  1.4025793075561523
e:  28   train_loss:  1049.9664064184215   time:  1.402726650238037
e:  29   train_loss:  1047.0595987323948   time:  1.4056925773620605
e:  30   train_loss:  1048.06190098823   time:  1.4050946235656738
e:  30   train_loss:  1048.06190098823   val_loss:  675.5104511678772   time:  1.5099129676818848
e:  31   train_loss:  1046.5460532340549   time:  1.5890681743621826
e:  32   train_loss:  1069.216813547767   time:  1.4036290645599365
e:  33   train_loss:  1052.4752793705422   time:  1.403609275817871
e:  34   train_loss:  1051.1298202559828   time:  1.4054865837097168
e:  35   train_loss:  1060.8513547614632   time:  1.5001459121704102
e:  35   train_loss:  1060.8513547614632   val_loss:  671.011329327824   time:  1.6030352115631104
e:  36   train_loss:  1075.3105588392605   time:  1.6902971267700195
e:  37   train_loss:  1068.4582626164847   time:  1.4944396018981934
e:  38   train_loss:  1044.999207925848   time:  1.718935489654541
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  39   train_loss:  1056.6754458387402   time:  1.430572748184204
e:  40   train_loss:  1049.5261286692703   time:  1.4111828804016113
e:  40   train_loss:  1049.5261286692703   val_loss:  664.3461796568814   time:  1.5158812999725342
e:  41   train_loss:  1023.4457634472476   time:  1.4095842838287354
e:  42   train_loss:  1026.0463657454566   time:  1.4101371765136719
e:  43   train_loss:  1031.210162730826   time:  1.388451099395752
e:  44   train_loss:  1043.4015252335569   time:  1.4076759815216064
e:  45   train_loss:  1027.6102909144752   time:  1.5861642360687256
e:  45   train_loss:  1027.6102909144752   val_loss:  653.5229324483167   time:  1.6911356449127197
e:  46   train_loss:  1006.3250903759997   time:  1.3976902961730957
e:  47   train_loss:  1029.530485067166   time:  1.4002385139465332
e:  48   train_loss:  1016.4283890735272   time:  1.4053137302398682
e:  49   train_loss:  1008.8903500314352   time:  1.4126598834991455
e:  50   train_loss:  983.6653002434913   time:  1.4182097911834717
e:  50   train_loss:  983.6653002434913   val_loss:  634.2788594753758   time:  1.6941988468170166
e:  51   train_loss:  993.8616578411353   time:  1.4052214622497559
e:  52   train_loss:  985.1107986808058   time:  1.3868670463562012
e:  53   train_loss:  960.5309069234991   time:  1.4038677215576172
e:  54   train_loss:  957.1580290922989   time:  1.4072630405426025
e:  55   train_loss:  972.6649471810914   time:  1.385514259338379
e:  55   train_loss:  972.6649471810914   val_loss:  600.659193474406   time:  1.4893856048583984
e:  56   train_loss:  945.0241207208805   time:  1.581700086593628
e:  57   train_loss:  917.1551679819926   time:  1.3962395191192627
e:  58   train_loss:  897.0087563818786   time:  1.4068176746368408
e:  59   train_loss:  879.3401126762948   time:  1.4036636352539062
e:  60   train_loss:  879.9429091368202   time:  1.4077229499816895
e:  60   train_loss:  879.9429091368202   val_loss:  563.4145557693315   time:  1.5123608112335205
e:  61   train_loss:  852.4491364703348   time:  1.4037537574768066
e:  62   train_loss:  810.255037232355   time:  1.4050147533416748
e:  63   train_loss:  800.0306145783145   time:  1.5806851387023926
e:  64   train_loss:  777.2939061951176   time:  1.4009652137756348
e:  65   train_loss:  756.9880677379564   time:  1.4076218605041504
e:  65   train_loss:  756.9880677379564   val_loss:  555.8543977082592   time:  1.5129637718200684
e:  66   train_loss:  747.3902073015527   time:  1.5449504852294922
e:  67   train_loss:  724.396185209507   time:  1.4021496772766113
e:  68   train_loss:  722.2720782329774   time:  1.430992841720581
e:  69   train_loss:  684.3079364834103   time:  1.4827229976654053
e:  70   train_loss:  673.5435820132931   time:  1.608551263809204
e:  70   train_loss:  673.5435820132931   val_loss:  556.1015148745471   time:  1.7129499912261963
e:  71   train_loss:  665.798415218252   time:  1.4096708297729492
e:  72   train_loss:  655.6392987047203   time:  1.3875086307525635
e:  73   train_loss:  659.5426858839971   time:  1.409492015838623
e:  74   train_loss:  641.4104424850391   time:  1.3996365070343018
e:  75   train_loss:  636.5890571938631   time:  1.4086263179779053
e:  75   train_loss:  636.5890571938631   val_loss:  609.4918472761315   time:  1.5143218040466309
e:  76   train_loss:  627.8510007440827   time:  1.765000343322754
e:  77   train_loss:  625.1683543538526   time:  1.4268393516540527
e:  78   train_loss:  629.4775114266447   time:  1.4147567749023438
e:  79   train_loss:  619.9451620785164   time:  1.4348561763763428
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  80   train_loss:  617.3619681598643   time:  1.434598445892334
e:  80   train_loss:  617.3619681598643   val_loss:  609.0446422605594   time:  1.5398082733154297
e:  81   train_loss:  606.5678690754214   time:  1.3905789852142334
e:  82   train_loss:  612.6517730731417   time:  1.424225091934204
e:  83   train_loss:  605.0411682301273   time:  1.5333847999572754
e:  84   train_loss:  621.2133962840633   time:  1.4174480438232422
e:  85   train_loss:  606.1571059263136   time:  1.4171257019042969
e:  85   train_loss:  606.1571059263136   val_loss:  600.6696045133375   time:  1.5215914249420166
e:  86   train_loss:  607.3716184928473   time:  1.394726276397705
e:  87   train_loss:  601.2827500150498   time:  1.3867204189300537
e:  88   train_loss:  602.7053992397178   time:  1.4102084636688232
e:  89   train_loss:  599.7340718134515   time:  1.3887560367584229
e:  90   train_loss:  612.0191825284014   time:  1.5894243717193604
e:  90   train_loss:  612.0191825284014   val_loss:  659.1480511885169   time:  1.6952083110809326
e:  91   train_loss:  616.7483023085427   time:  1.3893065452575684
e:  92   train_loss:  596.9780892575011   time:  1.4513776302337646
e:  93   train_loss:  596.3129602209361   time:  1.425727128982544
e:  94   train_loss:  603.1808815347424   time:  1.4297645092010498
e:  95   train_loss:  601.7096524331777   time:  1.4288926124572754
e:  95   train_loss:  601.7096524331777   val_loss:  603.3505799260636   time:  1.533947229385376
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (2, 0, 1), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (2, 0, 1) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 1) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 1) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (2, 0, 1)
kwargs: {'config': {'batch_norm': True, 'ff_0': 94, 'ff_num_layers': 2, 'gnn_0': 88, 'gnn_dropout': 0.12344238113981926, 'gnn_num_layers': 3, 'hid_0': 147, 'hid_dropout_rate': 0.07011858026193535, 'in_dropout_rate': 0.2657419403485913, 'lr': 1.4626974739127854e-05, 'num_hid_layers': 3, 'optimizer': 'SGD', 'ff_1': 106, 'gnn_1': 489, 'gnn_2': 126, 'hid_1': 120, 'hid_2': 542, 'sgd_momentum': 0.6112822132866309}, 'budget': 243.0, 'working_directory': '.'}
result: {'loss': 730.63961717912, 'n_epochs': 126.0, 'info': {'validation loss': 730.63961717912}}
exception: None

DEBUG:hpbandster:job_callback for (2, 0, 1) started
DEBUG:hpbandster:job_callback for (2, 0, 1) got condition
DEBUG:hpbandster:Only 8 run(s) for budget 243.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (2, 0, 1) finished
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: trying submitting job (2, 0, 2) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 2) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 2)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 2) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 2) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (2, 0, 2)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': True, 'ff_0': 114, 'ff_num_layers': 1, 'gnn_0': 1507, 'gnn_dropout': 0.22419896291123764, 'gnn_num_layers': 2, 'hid_0': 236, 'hid_dropout_rate': 0.21567683294353168, 'in_dropout_rate': 0.3352539524993557, 'lr': 1.7229795394464675e-05, 'num_hid_layers': 1, 'optimizer': 'Adam', 'gnn_1': 90}, 'budget': 243.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  704.4528719052284   time:  1.5963799953460693
e:  0   train_loss:  704.4528719052284   val_loss:  1673.0646206366212   time:  1.698864221572876
e:  1   train_loss:  704.7016478893679   time:  1.318077802658081
e:  2   train_loss:  702.2855069425467   time:  1.3226940631866455
e:  3   train_loss:  701.6373545321842   time:  1.322972059249878
e:  4   train_loss:  699.5197612079949   time:  1.3168187141418457
e:  5   train_loss:  698.8394306871272   time:  1.3044288158416748
e:  5   train_loss:  698.8394306871272   val_loss:  1662.9101389847685   time:  1.4148824214935303
e:  6   train_loss:  696.2011436621796   time:  1.314119815826416
e:  7   train_loss:  695.3408549943044   time:  1.3374550342559814
e:  8   train_loss:  692.9275782701277   time:  1.501101016998291
e:  9   train_loss:  691.7855801387145   time:  1.3150560855865479
e:  10   train_loss:  690.0524616673763   time:  1.3334705829620361
e:  10   train_loss:  690.0524616673763   val_loss:  1652.21607559511   time:  1.446972370147705
e:  11   train_loss:  687.7866903643323   time:  1.3319823741912842
e:  12   train_loss:  685.7846681688206   time:  1.2992606163024902
e:  13   train_loss:  683.8923113775122   time:  1.30039644241333
e:  14   train_loss:  681.798194837304   time:  1.300117015838623
e:  15   train_loss:  680.3300916452881   time:  1.316391944885254
e:  15   train_loss:  680.3300916452881   val_loss:  1642.7667558160535   time:  1.425886869430542
e:  16   train_loss:  678.0833237810702   time:  1.3167757987976074
e:  17   train_loss:  676.1363769129725   time:  1.3185884952545166
e:  18   train_loss:  673.055339133002   time:  1.3163502216339111
e:  19   train_loss:  671.4575440474567   time:  1.3173291683197021
e:  20   train_loss:  668.9562107417935   time:  1.483208417892456
e:  20   train_loss:  668.9562107417935   val_loss:  1633.6757286223299   time:  1.5855927467346191
e:  21   train_loss:  667.989680721668   time:  1.3105332851409912
e:  22   train_loss:  664.5160550671221   time:  1.313941240310669
e:  23   train_loss:  661.9376984805648   time:  1.3167285919189453
e:  24   train_loss:  659.8605243861402   time:  1.314793586730957
e:  25   train_loss:  657.1416463152731   time:  1.3198957443237305
e:  25   train_loss:  657.1416463152731   val_loss:  1626.0745835146988   time:  1.4301857948303223
e:  26   train_loss:  654.8640074372113   time:  1.3163177967071533
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  27   train_loss:  651.7185206922311   time:  1.3136696815490723
e:  28   train_loss:  649.0481284194805   time:  1.3125543594360352
e:  29   train_loss:  645.655968516103   time:  1.3158059120178223
e:  30   train_loss:  643.1618458134919   time:  1.4754369258880615
e:  30   train_loss:  643.1618458134919   val_loss:  1618.0841126725823   time:  1.5784835815429688
e:  31   train_loss:  640.5073548561646   time:  1.2991836071014404
e:  32   train_loss:  637.1964512259358   time:  1.318953514099121
e:  33   train_loss:  634.0841089322279   time:  1.3155934810638428
e:  34   train_loss:  632.2033613941287   time:  1.2957525253295898
e:  35   train_loss:  628.0271117901473   time:  1.2978122234344482
e:  35   train_loss:  628.0271117901473   val_loss:  1612.1933952590784   time:  1.407623529434204
e:  36   train_loss:  625.0641202668043   time:  1.3184008598327637
e:  37   train_loss:  621.5668713950163   time:  1.3184051513671875
e:  38   train_loss:  620.0361532743568   time:  1.3057947158813477
e:  39   train_loss:  616.801020854752   time:  1.4714930057525635
e:  40   train_loss:  612.703674949102   time:  1.3014979362487793
e:  40   train_loss:  612.703674949102   val_loss:  1607.9624662342378   time:  1.410731315612793
e:  41   train_loss:  610.6061041919024   time:  1.3145577907562256
e:  42   train_loss:  606.9946233383998   time:  1.317570686340332
e:  43   train_loss:  603.4265763196773   time:  1.3155734539031982
e:  44   train_loss:  601.0341303526709   time:  1.3166799545288086
e:  45   train_loss:  597.6730333829498   time:  1.3075158596038818
e:  45   train_loss:  597.6730333829498   val_loss:  1604.776237155474   time:  1.418402910232544
e:  46   train_loss:  594.0506754952826   time:  1.3162806034088135
e:  47   train_loss:  591.1688524118523   time:  1.3696086406707764
e:  48   train_loss:  588.7545770980395   time:  1.3134839534759521
e:  49   train_loss:  585.1330124451139   time:  1.3110058307647705
e:  50   train_loss:  581.3890605851952   time:  1.315622329711914
e:  50   train_loss:  581.3890605851952   val_loss:  1596.4732899240346   time:  1.5923938751220703
e:  51   train_loss:  578.7785899069687   time:  1.2972722053527832
e:  52   train_loss:  576.7646264084519   time:  1.309532642364502
e:  53   train_loss:  573.9145961024309   time:  1.3082561492919922
e:  54   train_loss:  569.6636350786596   time:  1.311305046081543
e:  55   train_loss:  567.6122791709931   time:  1.311629295349121
e:  55   train_loss:  567.6122791709931   val_loss:  1591.776260394946   time:  1.4213457107543945
e:  56   train_loss:  563.9791569997193   time:  1.6036343574523926
e:  57   train_loss:  561.012710336036   time:  1.3358838558197021
e:  58   train_loss:  558.8788023302646   time:  1.3086192607879639
e:  59   train_loss:  554.9808308832683   time:  1.3152804374694824
e:  60   train_loss:  550.9948193417512   time:  1.2943646907806396
e:  60   train_loss:  550.9948193417512   val_loss:  1581.8173938917778   time:  1.403785228729248
e:  61   train_loss:  550.7590687625934   time:  1.48911452293396
e:  62   train_loss:  546.3772106554752   time:  1.3026163578033447
e:  63   train_loss:  544.4981287176586   time:  1.3164176940917969
e:  64   train_loss:  541.4316202466226   time:  1.3195440769195557
e:  65   train_loss:  538.5585185843817   time:  1.3140316009521484
e:  65   train_loss:  538.5585185843817   val_loss:  1578.9677357313358   time:  1.42458176612854
e:  66   train_loss:  536.4431737114587   time:  1.2979505062103271
e:  67   train_loss:  533.4358560917537   time:  1.318286657333374
e:  68   train_loss:  531.5636599693096   time:  1.3182623386383057
e:  69   train_loss:  528.0963617969339   time:  1.3055884838104248
e:  70   train_loss:  528.186816875423   time:  1.3064773082733154
e:  70   train_loss:  528.186816875423   val_loss:  1569.038239654293   time:  1.5854711532592773
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  71   train_loss:  524.3404994863798   time:  1.333733081817627
e:  72   train_loss:  522.3268636271492   time:  1.3143770694732666
e:  73   train_loss:  519.4365910519437   time:  1.2996594905853271
e:  74   train_loss:  516.6543658139643   time:  1.2928509712219238
e:  75   train_loss:  514.5376932933304   time:  1.3237595558166504
e:  75   train_loss:  514.5376932933304   val_loss:  1568.8000333811635   time:  1.434157371520996
e:  76   train_loss:  512.3874586511515   time:  1.3203246593475342
e:  77   train_loss:  510.1346357796416   time:  1.2961478233337402
e:  78   train_loss:  507.76521653604914   time:  1.326181173324585
e:  79   train_loss:  506.1095216003471   time:  1.3133196830749512
e:  80   train_loss:  502.831242155735   time:  1.3211419582366943
e:  80   train_loss:  502.831242155735   val_loss:  1560.5706745651848   time:  1.4312405586242676
e:  81   train_loss:  501.8713898649098   time:  1.4949924945831299
e:  82   train_loss:  501.2632324293627   time:  1.3179023265838623
e:  83   train_loss:  498.04338689685875   time:  1.3211369514465332
e:  84   train_loss:  496.7844623585062   time:  1.326653003692627
e:  85   train_loss:  494.8857724780888   time:  1.301020622253418
e:  85   train_loss:  494.8857724780888   val_loss:  1558.8848073371144   time:  1.411846399307251
e:  86   train_loss:  492.5843760816361   time:  1.3105692863464355
e:  87   train_loss:  492.8831207042817   time:  1.3216454982757568
e:  88   train_loss:  489.68744692793524   time:  1.297255516052246
e:  89   train_loss:  488.840742796134   time:  1.318751573562622
e:  90   train_loss:  487.06242056251665   time:  1.3153929710388184
e:  90   train_loss:  487.06242056251665   val_loss:  1559.5697283044776   time:  1.4264626502990723
e:  91   train_loss:  486.3433218012622   time:  1.3275978565216064
e:  92   train_loss:  484.2842438207384   time:  1.4701707363128662
e:  93   train_loss:  482.4834469193742   time:  1.299572229385376
e:  94   train_loss:  480.66462255317964   time:  1.335139513015747
e:  95   train_loss:  479.4909257393192   time:  1.3408799171447754
e:  95   train_loss:  479.4909257393192   val_loss:  1546.9278976054986   time:  1.4515483379364014
e:  96   train_loss:  478.04742191552447   time:  1.3379669189453125
e:  97   train_loss:  477.90999603576535   time:  1.351320505142212
e:  98   train_loss:  475.36823234159107   time:  1.3325579166412354
e:  99   train_loss:  474.49388217197355   time:  1.3176159858703613
e:  100   train_loss:  472.6048108626859   time:  1.3266327381134033
e:  100   train_loss:  472.6048108626859   val_loss:  1547.766330104916   time:  1.4356491565704346
e:  101   train_loss:  472.15223954027636   time:  1.297863483428955
e:  102   train_loss:  470.95292553964464   time:  1.3155746459960938
e:  103   train_loss:  470.3100154992029   time:  1.4779658317565918
e:  104   train_loss:  469.0738143710105   time:  1.3041861057281494
e:  105   train_loss:  467.7179011169581   time:  1.3290719985961914
e:  105   train_loss:  467.7179011169581   val_loss:  1542.8631402309582   time:  1.440063714981079
e:  106   train_loss:  466.47174816624704   time:  1.334545373916626
e:  107   train_loss:  465.98413654593344   time:  1.326094627380371
e:  108   train_loss:  465.3377906850006   time:  1.3193275928497314
e:  109   train_loss:  465.28265331714795   time:  1.3034639358520508
e:  110   train_loss:  462.3452197817411   time:  1.3201560974121094
e:  110   train_loss:  462.3452197817411   val_loss:  1526.3089579448822   time:  1.4300873279571533
e:  111   train_loss:  462.7905696801632   time:  1.4643909931182861
e:  112   train_loss:  460.5722746377034   time:  1.3435068130493164
e:  113   train_loss:  459.5331785799039   time:  1.3522143363952637
e:  114   train_loss:  459.6433297697061   time:  1.314598560333252
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  115   train_loss:  458.2963328661236   time:  1.330228567123413
e:  115   train_loss:  458.2963328661236   val_loss:  1545.392539221118   time:  1.4410898685455322
e:  116   train_loss:  457.09473249992277   time:  1.320547342300415
e:  117   train_loss:  456.99856666703124   time:  1.3311727046966553
e:  118   train_loss:  456.87858598093203   time:  1.3304612636566162
e:  119   train_loss:  455.04389786618333   time:  1.3585255146026611
e:  120   train_loss:  453.8065126834081   time:  1.3226919174194336
e:  120   train_loss:  453.8065126834081   val_loss:  1519.0708755939354   time:  1.4333629608154297
e:  121   train_loss:  454.06818280906543   time:  1.3423376083374023
e:  122   train_loss:  454.27396352402104   time:  1.4768495559692383
e:  123   train_loss:  453.03549475587573   time:  1.3230395317077637
e:  124   train_loss:  451.2066579520968   time:  1.3272802829742432
e:  125   train_loss:  451.71769913717856   time:  1.3176863193511963
e:  125   train_loss:  451.71769913717856   val_loss:  1539.2561455784976   time:  1.4277925491333008
e:  126   train_loss:  450.84755297399244   time:  1.3279228210449219
e:  127   train_loss:  450.4279105539714   time:  1.3184125423431396
e:  128   train_loss:  449.1740249899851   time:  1.3106038570404053
e:  129   train_loss:  448.66267851185614   time:  1.339784860610962
e:  130   train_loss:  448.0949976057725   time:  1.2962288856506348
e:  130   train_loss:  448.0949976057725   val_loss:  1547.4983992135437   time:  1.4058506488800049
e:  131   train_loss:  448.0236979741714   time:  1.3008413314819336
e:  132   train_loss:  446.70744007222424   time:  1.4931097030639648
e:  133   train_loss:  445.6540004327796   time:  1.3165602684020996
e:  134   train_loss:  446.95349655730934   time:  1.3111462593078613
e:  135   train_loss:  445.8919674785987   time:  1.3070948123931885
e:  135   train_loss:  445.8919674785987   val_loss:  1540.9550086964668   time:  1.4177072048187256
e:  136   train_loss:  444.11864257493147   time:  1.3362212181091309
e:  137   train_loss:  444.24614156462   time:  1.336709976196289
e:  138   train_loss:  443.5276607570531   time:  1.2998051643371582
e:  139   train_loss:  442.33154842665374   time:  1.3599505424499512
e:  140   train_loss:  441.56336870656065   time:  1.3235719203948975
e:  140   train_loss:  441.56336870656065   val_loss:  1564.3622748633495   time:  1.4343774318695068
e:  141   train_loss:  441.0648416826842   time:  1.4815380573272705
e:  142   train_loss:  441.8944123367454   time:  1.3200664520263672
e:  143   train_loss:  440.16878661802133   time:  1.3224494457244873
e:  144   train_loss:  439.2842016348905   time:  1.3131535053253174
e:  145   train_loss:  440.3932177061752   time:  1.315382957458496
e:  145   train_loss:  440.3932177061752   val_loss:  1570.4028345757404   time:  1.424800157546997
e:  146   train_loss:  438.27046170200845   time:  1.317868947982788
e:  147   train_loss:  438.39290400429684   time:  1.3602149486541748
e:  148   train_loss:  437.66297954922703   time:  1.3144252300262451
e:  149   train_loss:  438.06157970829906   time:  1.3252410888671875
e:  150   train_loss:  436.6091418523995   time:  1.3179728984832764
e:  150   train_loss:  436.6091418523995   val_loss:  1575.1588061608181   time:  1.4295635223388672
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1078.0247461651466   time:  1.669989824295044
e:  0   train_loss:  1078.0247461651466   val_loss:  628.2292952321806   time:  1.7684645652770996
e:  1   train_loss:  1069.8449838208128   time:  1.4455032348632812
e:  2   train_loss:  1074.958272709277   time:  1.457021951675415
e:  3   train_loss:  1072.90292060749   time:  1.4525578022003174
e:  4   train_loss:  1070.8385398608252   time:  1.4394786357879639
e:  5   train_loss:  1089.320701751059   time:  1.431530475616455
e:  5   train_loss:  1089.320701751059   val_loss:  621.7504087317731   time:  1.5349094867706299
e:  6   train_loss:  1059.245843255426   time:  1.6545007228851318
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  7   train_loss:  1076.880410321027   time:  1.441720962524414
e:  8   train_loss:  1073.5055811981001   time:  1.4568264484405518
e:  9   train_loss:  1051.8151190121835   time:  1.430596113204956
e:  10   train_loss:  1061.1282882497608   time:  1.4557454586029053
e:  10   train_loss:  1061.1282882497608   val_loss:  615.2690788479491   time:  1.5600290298461914
e:  11   train_loss:  1047.4014538338236   time:  1.445887565612793
e:  12   train_loss:  1041.007247335336   time:  1.639017105102539
e:  13   train_loss:  1045.2677572433317   time:  1.440840721130371
e:  14   train_loss:  1044.0053922852449   time:  1.439650535583496
e:  15   train_loss:  1038.66181788154   time:  1.4386684894561768
e:  15   train_loss:  1038.66181788154   val_loss:  611.1209611915932   time:  1.543395757675171
e:  16   train_loss:  1048.4236711689082   time:  1.4433865547180176
e:  17   train_loss:  1022.2190128335047   time:  1.456127643585205
e:  18   train_loss:  1012.3860374557365   time:  1.5777523517608643
e:  19   train_loss:  1005.6384667401692   time:  1.4455854892730713
e:  20   train_loss:  1010.4218504389365   time:  1.3896775245666504
e:  20   train_loss:  1010.4218504389365   val_loss:  606.2946084638821   time:  1.4958219528198242
e:  21   train_loss:  1013.2794843672546   time:  1.4348180294036865
e:  22   train_loss:  999.4476563388635   time:  1.422537088394165
e:  23   train_loss:  1010.0506301868772   time:  1.4241182804107666
e:  24   train_loss:  996.6748887064012   time:  1.4165172576904297
e:  25   train_loss:  979.003778882584   time:  1.5935256481170654
e:  25   train_loss:  979.003778882584   val_loss:  600.0876281145934   time:  1.6990315914154053
e:  26   train_loss:  988.3412999914389   time:  1.4285874366760254
e:  27   train_loss:  992.6916047072905   time:  1.4278016090393066
e:  28   train_loss:  956.3775774955138   time:  1.4309022426605225
e:  29   train_loss:  956.1757720703442   time:  1.432952642440796
e:  30   train_loss:  968.4060989487264   time:  1.4285545349121094
e:  30   train_loss:  968.4060989487264   val_loss:  595.3219219697819   time:  1.5343618392944336
e:  31   train_loss:  946.1253139367101   time:  1.5982105731964111
e:  32   train_loss:  934.5933390491878   time:  1.4263551235198975
e:  33   train_loss:  931.3315306353977   time:  1.4212257862091064
e:  34   train_loss:  941.2774360812668   time:  1.421234130859375
e:  35   train_loss:  928.1713845550762   time:  1.400026559829712
e:  35   train_loss:  928.1713845550762   val_loss:  592.7304708507332   time:  1.504455804824829
e:  36   train_loss:  924.907919256626   time:  1.425786018371582
e:  37   train_loss:  913.5606858993583   time:  1.441481113433838
e:  38   train_loss:  906.4585449702234   time:  1.548858642578125
e:  39   train_loss:  915.8481516636023   time:  1.4280743598937988
e:  40   train_loss:  903.7548258764607   time:  1.4220647811889648
e:  40   train_loss:  903.7548258764607   val_loss:  589.2783588449411   time:  1.5276641845703125
e:  41   train_loss:  883.0915158120632   time:  1.4262709617614746
e:  42   train_loss:  877.6389262745947   time:  1.4263951778411865
e:  43   train_loss:  879.5097031216317   time:  1.4124298095703125
e:  44   train_loss:  874.338169099057   time:  1.4256792068481445
e:  45   train_loss:  872.9492550765254   time:  1.5804336071014404
e:  45   train_loss:  872.9492550765254   val_loss:  585.4790260055742   time:  1.6862006187438965
e:  46   train_loss:  848.6138694306726   time:  1.430464744567871
e:  47   train_loss:  849.9062734878587   time:  1.429481029510498
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  48   train_loss:  847.9403553228715   time:  1.421586275100708
e:  49   train_loss:  854.876656199767   time:  1.414543867111206
e:  50   train_loss:  844.0228182556477   time:  1.4292669296264648
e:  50   train_loss:  844.0228182556477   val_loss:  588.5512953269885   time:  1.6768040657043457
e:  51   train_loss:  837.0885737654548   time:  1.425793170928955
e:  52   train_loss:  823.382816941319   time:  1.414360761642456
e:  53   train_loss:  814.521205320089   time:  1.4255385398864746
e:  54   train_loss:  818.7692735242525   time:  1.4319078922271729
e:  55   train_loss:  797.4192014848603   time:  1.3944196701049805
e:  55   train_loss:  797.4192014848603   val_loss:  581.6920907511224   time:  1.4991278648376465
e:  56   train_loss:  800.4667236140103   time:  1.569265365600586
e:  57   train_loss:  798.5547508202965   time:  1.4243206977844238
e:  58   train_loss:  784.9848406104686   time:  1.428649663925171
e:  59   train_loss:  788.351846585007   time:  1.4275517463684082
e:  60   train_loss:  774.6334999653146   time:  1.4342782497406006
e:  60   train_loss:  774.6334999653146   val_loss:  579.4162346199977   time:  1.5406055450439453
e:  61   train_loss:  776.8954228332167   time:  1.4135620594024658
e:  62   train_loss:  751.3228711711456   time:  1.421912431716919
e:  63   train_loss:  751.0346270264351   time:  1.5803041458129883
e:  64   train_loss:  736.9783791800006   time:  1.423860788345337
e:  65   train_loss:  746.6385343848701   time:  1.4272243976593018
e:  65   train_loss:  746.6385343848701   val_loss:  575.4632435674115   time:  1.533353567123413
e:  66   train_loss:  743.8475517347747   time:  1.4287896156311035
e:  67   train_loss:  737.497047921307   time:  1.4251298904418945
e:  68   train_loss:  746.3141903400532   time:  1.4165966510772705
e:  69   train_loss:  719.6984340124806   time:  1.4460597038269043
e:  70   train_loss:  717.261131066988   time:  1.5800189971923828
e:  70   train_loss:  717.261131066988   val_loss:  575.3658019317203   time:  1.6855604648590088
e:  71   train_loss:  707.9157013876745   time:  1.4293465614318848
e:  72   train_loss:  719.5252443866603   time:  1.418010950088501
e:  73   train_loss:  711.1431704535938   time:  1.4339358806610107
e:  74   train_loss:  701.6592694944105   time:  1.4198174476623535
e:  75   train_loss:  698.2982631148079   time:  1.414971113204956
e:  75   train_loss:  698.2982631148079   val_loss:  574.8922767668423   time:  1.5200386047363281
e:  76   train_loss:  686.6782828177257   time:  1.5637125968933105
e:  77   train_loss:  688.7092243649099   time:  1.4289538860321045
e:  78   train_loss:  701.6231190728199   time:  1.4289026260375977
e:  79   train_loss:  693.5778260262424   time:  1.4265379905700684
e:  80   train_loss:  688.9626826591759   time:  1.429340124130249
e:  80   train_loss:  688.9626826591759   val_loss:  572.7705947227588   time:  1.5356152057647705
e:  81   train_loss:  677.0723193948667   time:  1.4317691326141357
e:  82   train_loss:  676.9552067820998   time:  1.426041841506958
e:  83   train_loss:  665.4070216087822   time:  1.5542094707489014
e:  84   train_loss:  670.3481719208467   time:  1.4286189079284668
e:  85   train_loss:  664.3641936405178   time:  1.4357807636260986
e:  85   train_loss:  664.3641936405178   val_loss:  574.195640081181   time:  1.5409436225891113
e:  86   train_loss:  663.1125418548797   time:  1.435861349105835
e:  87   train_loss:  660.0540589683086   time:  1.435490608215332
e:  88   train_loss:  656.0043830437029   time:  1.4292206764221191
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  89   train_loss:  655.6094057459385   time:  1.4154813289642334
e:  90   train_loss:  643.3084231045825   time:  1.58274507522583
e:  90   train_loss:  643.3084231045825   val_loss:  570.0926846369179   time:  1.688603401184082
e:  91   train_loss:  642.4912492824265   time:  1.4271583557128906
e:  92   train_loss:  655.095191733345   time:  1.4283688068389893
e:  93   train_loss:  645.8876673953644   time:  1.4243834018707275
e:  94   train_loss:  633.896708058237   time:  1.429602861404419
e:  95   train_loss:  633.6426488543743   time:  1.4286272525787354
e:  95   train_loss:  633.6426488543743   val_loss:  571.3131885156986   time:  1.5341908931732178
e:  96   train_loss:  637.291744610085   time:  1.5678937435150146
e:  97   train_loss:  647.1550307067747   time:  1.4258322715759277
e:  98   train_loss:  634.0767237669983   time:  1.4273955821990967
e:  99   train_loss:  632.5383574429322   time:  1.4258511066436768
e:  100   train_loss:  636.7402425697649   time:  1.4278309345245361
e:  100   train_loss:  636.7402425697649   val_loss:  569.0313160365935   time:  1.533841848373413
e:  101   train_loss:  629.4369037094089   time:  1.4294071197509766
e:  102   train_loss:  622.3720251281907   time:  1.4352307319641113
e:  103   train_loss:  629.7261131189979   time:  1.5520191192626953
e:  104   train_loss:  616.4709306019795   time:  1.4283854961395264
e:  105   train_loss:  625.5750287190419   time:  1.4268219470977783
e:  105   train_loss:  625.5750287190419   val_loss:  573.5852423380525   time:  1.5321271419525146
e:  106   train_loss:  612.6957119844024   time:  1.4252066612243652
e:  107   train_loss:  617.9784259750274   time:  1.431415319442749
e:  108   train_loss:  619.8540522080381   time:  1.4149410724639893
e:  109   train_loss:  617.806739824704   time:  1.4324207305908203
e:  110   train_loss:  603.8303109781411   time:  1.5830976963043213
e:  110   train_loss:  603.8303109781411   val_loss:  576.8815993465254   time:  1.6887521743774414
e:  111   train_loss:  615.9198635162679   time:  1.4270422458648682
e:  112   train_loss:  605.3210966099598   time:  1.4274828433990479
e:  113   train_loss:  608.0518636925487   time:  1.4286353588104248
e:  114   train_loss:  610.1162041803159   time:  1.4182608127593994
e:  115   train_loss:  611.0474580901791   time:  1.436039686203003
e:  115   train_loss:  611.0474580901791   val_loss:  572.5664233391834   time:  1.6953763961791992
e:  116   train_loss:  601.3068272941765   time:  1.5045239925384521
e:  117   train_loss:  601.0267535653076   time:  1.4023840427398682
e:  118   train_loss:  604.1677231618582   time:  1.4304521083831787
e:  119   train_loss:  596.9014140982307   time:  1.4298889636993408
e:  120   train_loss:  601.7162786020995   time:  1.4154670238494873
e:  120   train_loss:  601.7162786020995   val_loss:  580.0971910677646   time:  1.5208346843719482
e:  121   train_loss:  603.0608736080543   time:  1.591665267944336
e:  122   train_loss:  592.3723469811943   time:  1.4208109378814697
e:  123   train_loss:  605.4768407132138   time:  1.4311087131500244
e:  124   train_loss:  594.1569945823962   time:  1.4251940250396729
e:  125   train_loss:  598.661795162414   time:  1.4271390438079834
e:  125   train_loss:  598.661795162414   val_loss:  584.8582909561711   time:  1.532792568206787
e:  126   train_loss:  595.7443911562347   time:  1.4132170677185059
e:  127   train_loss:  590.3472614558517   time:  1.4222872257232666
e:  128   train_loss:  587.9848547509031   time:  1.578629732131958
e:  129   train_loss:  600.0691104490165   time:  1.4218103885650635
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  130   train_loss:  594.3748638982131   time:  1.4273958206176758
e:  130   train_loss:  594.3748638982131   val_loss:  599.8649031925469   time:  1.5334692001342773
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1151.771665572623   time:  1.409160852432251
e:  0   train_loss:  1151.771665572623   val_loss:  538.1386881339632   time:  1.5176725387573242
e:  1   train_loss:  1072.9838299100827   time:  1.4168541431427002
e:  2   train_loss:  1089.2473721129325   time:  1.5420312881469727
e:  3   train_loss:  1076.6752484451981   time:  1.4100689888000488
e:  4   train_loss:  1058.0023216131635   time:  1.4175260066986084
e:  5   train_loss:  1095.260040529407   time:  1.4045443534851074
e:  5   train_loss:  1095.260040529407   val_loss:  533.0822171137859   time:  1.511359453201294
e:  6   train_loss:  1074.2627092765931   time:  1.3873012065887451
e:  7   train_loss:  1064.3729548082488   time:  1.4292147159576416
e:  8   train_loss:  1038.1168003842001   time:  1.4117896556854248
e:  9   train_loss:  1079.9378282862128   time:  1.5548534393310547
e:  10   train_loss:  1052.5471080854418   time:  1.4102296829223633
e:  10   train_loss:  1052.5471080854418   val_loss:  528.590268214785   time:  1.5179164409637451
e:  11   train_loss:  1058.8661343938247   time:  1.4178411960601807
e:  12   train_loss:  1135.6921645030654   time:  1.4074065685272217
e:  13   train_loss:  1063.2714796148548   time:  1.4076387882232666
e:  14   train_loss:  1036.781907961299   time:  1.4073610305786133
e:  15   train_loss:  1048.690011798443   time:  1.411341667175293
e:  15   train_loss:  1048.690011798443   val_loss:  524.249996058547   time:  1.5180995464324951
e:  16   train_loss:  1011.2947982684499   time:  1.561596393585205
e:  17   train_loss:  1105.2350738025145   time:  1.4103825092315674
e:  18   train_loss:  1009.0441934322516   time:  1.409977674484253
e:  19   train_loss:  1052.845645676639   time:  1.4094696044921875
e:  20   train_loss:  997.2009231942274   time:  1.4137616157531738
e:  20   train_loss:  997.2009231942274   val_loss:  522.1768178051652   time:  1.521721601486206
e:  21   train_loss:  1079.0938820038762   time:  1.3988838195800781
e:  22   train_loss:  1052.841287184071   time:  1.414069652557373
e:  23   train_loss:  1012.6713812043001   time:  1.5451228618621826
e:  24   train_loss:  1019.6393926579037   time:  1.4139347076416016
e:  25   train_loss:  965.6311251900299   time:  1.411520004272461
e:  25   train_loss:  965.6311251900299   val_loss:  518.7966808599225   time:  1.5190763473510742
e:  26   train_loss:  977.6758413732055   time:  1.4010579586029053
e:  27   train_loss:  968.8241853145714   time:  1.390251636505127
e:  28   train_loss:  1003.2296675721516   time:  1.4176008701324463
e:  29   train_loss:  937.8066861463633   time:  1.4141714572906494
e:  30   train_loss:  956.9210694122596   time:  1.5600416660308838
e:  30   train_loss:  956.9210694122596   val_loss:  514.6243055019966   time:  1.6676061153411865
e:  31   train_loss:  982.0728409354334   time:  1.405609369277954
e:  32   train_loss:  949.9613018133374   time:  1.4058864116668701
e:  33   train_loss:  927.6953311263055   time:  1.412322759628296
e:  34   train_loss:  920.9323210029165   time:  1.4121458530426025
e:  35   train_loss:  904.5379986173527   time:  1.4128835201263428
e:  35   train_loss:  904.5379986173527   val_loss:  512.5635581350828   time:  1.5209033489227295
e:  36   train_loss:  963.6216988595211   time:  1.4125940799713135
e:  37   train_loss:  907.0147289516625   time:  1.5654089450836182
e:  38   train_loss:  896.8161413669503   time:  1.4140522480010986
e:  39   train_loss:  906.0884706922519   time:  1.4174048900604248
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  40   train_loss:  887.8476482073586   time:  1.412672519683838
e:  40   train_loss:  887.8476482073586   val_loss:  511.06043507810386   time:  1.5210380554199219
e:  41   train_loss:  878.4434678617827   time:  1.414461612701416
e:  42   train_loss:  894.3658025574235   time:  1.4203097820281982
e:  43   train_loss:  870.3854077701667   time:  1.4085843563079834
e:  44   train_loss:  846.709937255082   time:  1.4121639728546143
e:  45   train_loss:  906.0837694680481   time:  1.5743582248687744
e:  45   train_loss:  906.0837694680481   val_loss:  506.1982326447001   time:  1.6823546886444092
e:  46   train_loss:  854.3074619207065   time:  1.411773443222046
e:  47   train_loss:  833.3772211339233   time:  1.3899469375610352
e:  48   train_loss:  861.5677453992682   time:  1.414180040359497
e:  49   train_loss:  870.4503670334135   time:  1.4128329753875732
e:  50   train_loss:  823.1371164038634   time:  1.4178261756896973
e:  50   train_loss:  823.1371164038634   val_loss:  508.200904185122   time:  1.5253098011016846
e:  51   train_loss:  840.5314348137476   time:  1.4124767780303955
e:  52   train_loss:  826.735148160084   time:  1.547475814819336
e:  53   train_loss:  798.6290497890815   time:  1.410045862197876
e:  54   train_loss:  815.2268078082082   time:  1.411982536315918
e:  55   train_loss:  856.1342543340506   time:  1.4196887016296387
e:  55   train_loss:  856.1342543340506   val_loss:  506.4251729307026   time:  1.5282695293426514
e:  56   train_loss:  832.1166218248845   time:  1.4160349369049072
e:  57   train_loss:  797.9609787238022   time:  1.3998031616210938
e:  58   train_loss:  822.8857969929389   time:  1.4001986980438232
e:  59   train_loss:  819.2324599977908   time:  1.4110722541809082
e:  60   train_loss:  767.2182780240651   time:  1.5656628608703613
e:  60   train_loss:  767.2182780240651   val_loss:  505.92806059126804   time:  1.6741068363189697
e:  61   train_loss:  768.7127194838389   time:  1.4076552391052246
e:  62   train_loss:  795.8932925739114   time:  1.414961814880371
e:  63   train_loss:  775.0713497410565   time:  1.4142239093780518
e:  64   train_loss:  773.3866111599447   time:  1.412013292312622
e:  65   train_loss:  752.6349930859625   time:  1.4092495441436768
e:  65   train_loss:  752.6349930859625   val_loss:  503.4165110400215   time:  1.5171167850494385
e:  66   train_loss:  733.8144581178452   time:  1.5720417499542236
e:  67   train_loss:  731.560186539012   time:  1.3866212368011475
e:  68   train_loss:  752.4428802618055   time:  1.3954463005065918
e:  69   train_loss:  751.6719413198011   time:  1.415647268295288
e:  70   train_loss:  810.6923454110511   time:  1.4096264839172363
e:  70   train_loss:  810.6923454110511   val_loss:  504.311326932919   time:  1.51778244972229
e:  71   train_loss:  740.0230258525503   time:  1.410309076309204
e:  72   train_loss:  724.9831444426532   time:  1.4171075820922852
e:  73   train_loss:  716.5546922110996   time:  1.3986084461212158
e:  74   train_loss:  709.1515200374524   time:  1.5369269847869873
e:  75   train_loss:  721.7212831534657   time:  1.4102272987365723
e:  75   train_loss:  721.7212831534657   val_loss:  500.08628723021604   time:  1.5185151100158691
e:  76   train_loss:  695.8650090186677   time:  1.4173238277435303
e:  77   train_loss:  695.888734545022   time:  1.4041290283203125
e:  78   train_loss:  704.6401452907578   time:  1.408905267715454
e:  79   train_loss:  685.9026835683433   time:  1.4095830917358398
e:  80   train_loss:  693.2513006293732   time:  1.4068105220794678
e:  80   train_loss:  693.2513006293732   val_loss:  499.55629654073766   time:  1.5146334171295166
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  81   train_loss:  699.9981567883483   time:  1.4129841327667236
e:  82   train_loss:  677.0018173971284   time:  1.5612359046936035
e:  83   train_loss:  686.297018048228   time:  1.4017651081085205
e:  84   train_loss:  678.6700325630989   time:  1.4152026176452637
e:  85   train_loss:  666.5538358001407   time:  1.4115536212921143
e:  85   train_loss:  666.5538358001407   val_loss:  500.1509636326777   time:  1.5191290378570557
e:  86   train_loss:  709.3628085109102   time:  1.4115769863128662
e:  87   train_loss:  668.0591932120215   time:  1.4031016826629639
e:  88   train_loss:  658.8166751941726   time:  1.3929710388183594
e:  89   train_loss:  675.0058708516174   time:  1.5540783405303955
e:  90   train_loss:  654.4153643656946   time:  1.416797161102295
e:  90   train_loss:  654.4153643656946   val_loss:  497.4053757761344   time:  1.5250129699707031
e:  91   train_loss:  708.887742355243   time:  1.4113390445709229
e:  92   train_loss:  664.8384389482976   time:  1.4112603664398193
e:  93   train_loss:  678.3829201952542   time:  1.4145689010620117
e:  94   train_loss:  656.5749385033882   time:  1.4138469696044922
e:  95   train_loss:  663.4628430766602   time:  1.40340256690979
e:  95   train_loss:  663.4628430766602   val_loss:  499.0228140278436   time:  1.5116467475891113
e:  96   train_loss:  695.5177909925637   time:  1.4278795719146729
e:  97   train_loss:  637.1825735779959   time:  1.565192699432373
e:  98   train_loss:  639.232806901938   time:  1.4120526313781738
e:  99   train_loss:  646.3682585750628   time:  1.415452003479004
e:  100   train_loss:  657.274323954342   time:  1.4020140171051025
e:  100   train_loss:  657.274323954342   val_loss:  496.99834625891356   time:  1.5096230506896973
e:  101   train_loss:  662.8897379188288   time:  1.4115755558013916
e:  102   train_loss:  651.63804044615   time:  1.4123642444610596
e:  103   train_loss:  659.9984212794099   time:  1.4109618663787842
e:  104   train_loss:  667.86313640726   time:  1.4289004802703857
e:  105   train_loss:  634.0774624112646   time:  1.5649547576904297
e:  105   train_loss:  634.0774624112646   val_loss:  497.4169787540815   time:  1.672377109527588
e:  106   train_loss:  651.3099306281308   time:  1.4111673831939697
e:  107   train_loss:  639.0375755117707   time:  1.400653600692749
e:  108   train_loss:  630.4193161198682   time:  1.3964953422546387
e:  109   train_loss:  643.5014995087469   time:  1.3796932697296143
e:  110   train_loss:  645.5661341200988   time:  1.3925487995147705
e:  110   train_loss:  645.5661341200988   val_loss:  498.67138124619964   time:  1.5009253025054932
e:  111   train_loss:  622.063123917731   time:  1.5339548587799072
e:  112   train_loss:  633.0389660361493   time:  1.4090800285339355
e:  113   train_loss:  639.5894452775933   time:  1.4164769649505615
e:  114   train_loss:  625.482016956625   time:  1.4070467948913574
e:  115   train_loss:  624.9120804241977   time:  1.4010906219482422
e:  115   train_loss:  624.9120804241977   val_loss:  493.6385980916451   time:  1.5089917182922363
e:  116   train_loss:  636.9091450487264   time:  1.4124541282653809
e:  117   train_loss:  626.2356865467273   time:  1.3980991840362549
e:  118   train_loss:  646.1189144885243   time:  1.4110479354858398
e:  119   train_loss:  641.8248719182035   time:  1.4144940376281738
e:  120   train_loss:  622.3299897565618   time:  1.5567843914031982
e:  120   train_loss:  622.3299897565618   val_loss:  493.0804317539768   time:  1.6645450592041016
e:  121   train_loss:  630.743460949401   time:  1.4139320850372314
e:  122   train_loss:  626.4661543075739   time:  1.409118890762329
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  123   train_loss:  609.8644269354894   time:  1.415952444076538
e:  124   train_loss:  628.2776061983064   time:  1.4116129875183105
e:  125   train_loss:  624.9697698891533   time:  1.410841464996338
e:  125   train_loss:  624.9697698891533   val_loss:  495.46836194396747   time:  1.5188639163970947
e:  126   train_loss:  615.5280576537835   time:  1.4121019840240479
e:  127   train_loss:  612.0166916426956   time:  1.5984981060028076
e:  128   train_loss:  610.6738115718754   time:  1.4098851680755615
e:  129   train_loss:  625.4507214187764   time:  1.4033477306365967
e:  130   train_loss:  614.8568305721951   time:  1.4014561176300049
e:  130   train_loss:  614.8568305721951   val_loss:  491.54421741526517   time:  1.5098257064819336
e:  131   train_loss:  642.0869511639476   time:  1.4170236587524414
e:  132   train_loss:  621.2535091850548   time:  1.41213059425354
e:  133   train_loss:  672.6987509359645   time:  1.407914638519287
e:  134   train_loss:  615.8764914030894   time:  1.4105150699615479
e:  135   train_loss:  608.5822194332223   time:  1.5622918605804443
e:  135   train_loss:  608.5822194332223   val_loss:  492.71499140636024   time:  1.6701500415802002
e:  136   train_loss:  613.8025653401395   time:  1.4106669425964355
e:  137   train_loss:  604.984118579075   time:  1.4104993343353271
e:  138   train_loss:  616.728588346043   time:  1.423846960067749
e:  139   train_loss:  614.1380547324555   time:  1.410346269607544
e:  140   train_loss:  600.6247931003746   time:  1.409987211227417
e:  140   train_loss:  600.6247931003746   val_loss:  494.6083825511845   time:  1.517634391784668
e:  141   train_loss:  620.880417379205   time:  1.4107458591461182
e:  142   train_loss:  607.9315145519724   time:  1.5438647270202637
e:  143   train_loss:  607.9348943862774   time:  1.4107701778411865
e:  144   train_loss:  608.5716524475354   time:  1.415114164352417
e:  145   train_loss:  599.1550437258386   time:  1.4130628108978271
e:  145   train_loss:  599.1550437258386   val_loss:  497.62977595908313   time:  1.522193431854248
e:  146   train_loss:  626.4908251725412   time:  1.413895845413208
e:  147   train_loss:  630.6999402792433   time:  1.411022424697876
e:  148   train_loss:  613.1514778906053   time:  1.3991367816925049
e:  149   train_loss:  620.2474366323135   time:  1.4053337574005127
e:  150   train_loss:  597.6825474365628   time:  1.5588250160217285
e:  150   train_loss:  597.6825474365628   val_loss:  495.81095895377945   time:  1.6663856506347656
e:  151   train_loss:  614.7275658684034   time:  1.3935248851776123
e:  152   train_loss:  613.9947957548295   time:  1.4132192134857178
e:  153   train_loss:  606.607121710417   time:  1.4120221138000488
e:  154   train_loss:  604.7549977404694   time:  1.4131824970245361
e:  155   train_loss:  596.239147386245   time:  1.4075813293457031
e:  155   train_loss:  596.239147386245   val_loss:  496.52610889631126   time:  1.5147919654846191
e:  156   train_loss:  603.3922350853885   time:  1.5707261562347412
e:  157   train_loss:  610.7911916140906   time:  1.396449089050293
e:  158   train_loss:  599.759237621859   time:  1.4090118408203125
e:  159   train_loss:  590.3741295896559   time:  1.4115705490112305
e:  160   train_loss:  616.8726483636733   time:  1.4086658954620361
e:  160   train_loss:  616.8726483636733   val_loss:  496.085158448469   time:  1.5168359279632568
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  999.6979358947121   time:  1.3027832508087158
e:  0   train_loss:  999.6979358947121   val_loss:  916.6293723311272   time:  1.4149222373962402
e:  1   train_loss:  995.2823656235653   time:  1.291626214981079
e:  2   train_loss:  991.5158842214979   time:  1.3033299446105957
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  3   train_loss:  992.4306370346505   time:  1.445819616317749
e:  4   train_loss:  991.7843014002319   time:  1.2871434688568115
e:  5   train_loss:  988.7752305475935   time:  1.3029839992523193
e:  5   train_loss:  988.7752305475935   val_loss:  908.072242792164   time:  1.415125846862793
e:  6   train_loss:  987.8953627146064   time:  1.3101797103881836
e:  7   train_loss:  986.1450714240502   time:  1.3168573379516602
e:  8   train_loss:  980.9197577893922   time:  1.295072078704834
e:  9   train_loss:  978.9434600718404   time:  1.299130916595459
e:  10   train_loss:  974.5959769298198   time:  1.297494649887085
e:  10   train_loss:  974.5959769298198   val_loss:  899.5708781391904   time:  1.4094781875610352
e:  11   train_loss:  973.2677369689645   time:  1.2804558277130127
e:  12   train_loss:  969.9575347725519   time:  1.314418077468872
e:  13   train_loss:  970.0134531482382   time:  1.3043477535247803
e:  14   train_loss:  962.5086119858886   time:  1.3048975467681885
e:  15   train_loss:  963.0097058480931   time:  1.3010377883911133
e:  15   train_loss:  963.0097058480931   val_loss:  892.6117275755729   time:  1.5540735721588135
e:  16   train_loss:  956.0503870015477   time:  1.3033397197723389
e:  17   train_loss:  955.5542613594258   time:  1.3013052940368652
e:  18   train_loss:  949.4691784036722   time:  1.3008630275726318
e:  19   train_loss:  944.2384165457604   time:  1.3000049591064453
e:  20   train_loss:  941.7056870068706   time:  1.3002891540527344
e:  20   train_loss:  941.7056870068706   val_loss:  885.4371037422176   time:  1.412876844406128
e:  21   train_loss:  940.0460391991913   time:  1.3015100955963135
e:  22   train_loss:  934.7159280124748   time:  1.3026847839355469
e:  23   train_loss:  931.2185044304197   time:  1.302170753479004
e:  24   train_loss:  923.6517992464891   time:  1.4409985542297363
e:  25   train_loss:  920.8473363716313   time:  1.2861642837524414
e:  25   train_loss:  920.8473363716313   val_loss:  877.1392864021681   time:  1.3900330066680908
e:  26   train_loss:  914.12958331511   time:  1.3031084537506104
e:  27   train_loss:  907.0140168441843   time:  1.3031885623931885
e:  28   train_loss:  903.3357109621287   time:  1.3013556003570557
e:  29   train_loss:  900.9749763731897   time:  1.302461862564087
e:  30   train_loss:  895.9262359074147   time:  1.3003554344177246
e:  30   train_loss:  895.9262359074147   val_loss:  874.7250813690223   time:  1.4126896858215332
e:  31   train_loss:  891.2534316251049   time:  1.303393840789795
e:  32   train_loss:  881.9107064200097   time:  1.2942869663238525
e:  33   train_loss:  879.1916846939018   time:  1.285501480102539
e:  34   train_loss:  874.3486923797146   time:  1.2859418392181396
e:  35   train_loss:  870.8245252639401   time:  1.44236159324646
e:  35   train_loss:  870.8245252639401   val_loss:  868.7861941778549   time:  1.5548443794250488
e:  36   train_loss:  865.7830525193798   time:  1.2977824211120605
e:  37   train_loss:  857.607995846106   time:  1.3031535148620605
e:  38   train_loss:  853.1225065977153   time:  1.3039348125457764
e:  39   train_loss:  849.2669594815839   time:  1.2967934608459473
e:  40   train_loss:  843.677199112794   time:  1.3024542331695557
e:  40   train_loss:  843.677199112794   val_loss:  866.8583282998875   time:  1.4156019687652588
e:  41   train_loss:  837.2005003517014   time:  1.3551876544952393
e:  42   train_loss:  829.9896047235629   time:  1.3045837879180908
e:  43   train_loss:  825.9952121519465   time:  1.3031995296478271
e:  44   train_loss:  818.1714786702364   time:  1.4370980262756348
e:  45   train_loss:  816.2211599374234   time:  1.2871308326721191
e:  45   train_loss:  816.2211599374234   val_loss:  870.9845613905178   time:  1.3995022773742676
e:  46   train_loss:  806.6026330873235   time:  1.3037002086639404
e:  47   train_loss:  798.8167262930865   time:  1.3040659427642822
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  48   train_loss:  793.0242925730632   time:  1.2984492778778076
e:  49   train_loss:  791.2561959573534   time:  1.2876958847045898
e:  50   train_loss:  785.7427279870635   time:  1.3034048080444336
e:  50   train_loss:  785.7427279870635   val_loss:  860.5618483115438   time:  1.4146113395690918
e:  51   train_loss:  777.6258166574418   time:  1.3016972541809082
e:  52   train_loss:  774.1797206219162   time:  1.3019418716430664
e:  53   train_loss:  764.9837378227196   time:  1.3091890811920166
e:  54   train_loss:  764.0473829112514   time:  1.3032031059265137
e:  55   train_loss:  760.3102661335877   time:  1.3045923709869385
e:  55   train_loss:  760.3102661335877   val_loss:  856.2856332190969   time:  1.4160761833190918
e:  56   train_loss:  754.4966614449595   time:  1.4211182594299316
e:  57   train_loss:  745.8162150581961   time:  1.2981305122375488
e:  58   train_loss:  745.3560207017454   time:  1.3034381866455078
e:  59   train_loss:  738.8775425522558   time:  1.3024616241455078
e:  60   train_loss:  735.3147292717404   time:  1.3026559352874756
e:  60   train_loss:  735.3147292717404   val_loss:  854.5903424775843   time:  1.4151942729949951
e:  61   train_loss:  731.9139894818734   time:  1.2894680500030518
e:  62   train_loss:  728.8181847909483   time:  1.3034441471099854
e:  63   train_loss:  717.0620724439038   time:  1.3038291931152344
e:  64   train_loss:  712.3171993136739   time:  1.3133139610290527
e:  65   train_loss:  708.4247119437293   time:  1.4426558017730713
e:  65   train_loss:  708.4247119437293   val_loss:  851.9211303066575   time:  1.5473675727844238
e:  66   train_loss:  703.2263357394653   time:  1.2985188961029053
e:  67   train_loss:  700.0939095020068   time:  1.3036384582519531
e:  68   train_loss:  697.4433076470658   time:  1.3038341999053955
e:  69   train_loss:  694.0291816471802   time:  1.3035283088684082
e:  70   train_loss:  691.8019343070546   time:  1.303947925567627
e:  70   train_loss:  691.8019343070546   val_loss:  850.1593921991492   time:  1.4166533946990967
e:  71   train_loss:  684.7364416741045   time:  1.2998781204223633
e:  72   train_loss:  681.7014580656681   time:  1.3027899265289307
e:  73   train_loss:  670.1160120129687   time:  1.286203145980835
e:  74   train_loss:  671.6978269248915   time:  1.4431796073913574
e:  75   train_loss:  669.9031885382645   time:  1.2990648746490479
e:  75   train_loss:  669.9031885382645   val_loss:  844.9725695558842   time:  1.4109601974487305
e:  76   train_loss:  667.0991040517134   time:  1.3034741878509521
e:  77   train_loss:  662.8993161642886   time:  1.300870656967163
e:  78   train_loss:  656.1819685073624   time:  1.2815947532653809
e:  79   train_loss:  653.9644917707272   time:  1.2937979698181152
e:  80   train_loss:  653.8179732000247   time:  1.3003957271575928
e:  80   train_loss:  653.8179732000247   val_loss:  847.6233269323719   time:  1.412593126296997
e:  81   train_loss:  651.7766240190322   time:  1.303114652633667
e:  82   train_loss:  647.0504989445949   time:  1.2895405292510986
e:  83   train_loss:  643.5860402075266   time:  1.302938461303711
e:  84   train_loss:  644.0530674160364   time:  1.2952642440795898
e:  85   train_loss:  634.3199067868469   time:  1.4391911029815674
e:  85   train_loss:  634.3199067868469   val_loss:  838.9624467140904   time:  1.5520434379577637
e:  86   train_loss:  633.5420493506324   time:  1.2975895404815674
e:  87   train_loss:  631.6039921697071   time:  1.3026161193847656
e:  88   train_loss:  627.2722119013397   time:  1.303713321685791
e:  89   train_loss:  627.7119484083772   time:  1.2966279983520508
e:  90   train_loss:  626.8788290816052   time:  1.303471326828003
e:  90   train_loss:  626.8788290816052   val_loss:  831.4004884110974   time:  1.4164016246795654
e:  91   train_loss:  624.11160038613   time:  1.2998530864715576
e:  92   train_loss:  618.9905528504153   time:  1.305130958557129
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  93   train_loss:  618.8060907148893   time:  1.2986228466033936
e:  94   train_loss:  614.4746980088062   time:  1.4361670017242432
e:  95   train_loss:  616.2176442057768   time:  1.2960221767425537
e:  95   train_loss:  616.2176442057768   val_loss:  833.7408546721988   time:  1.4085865020751953
e:  96   train_loss:  612.2607849054839   time:  1.304685115814209
e:  97   train_loss:  606.7042237992796   time:  1.3038415908813477
e:  98   train_loss:  607.8217156273271   time:  1.300093412399292
e:  99   train_loss:  607.6786605647173   time:  1.3030657768249512
e:  100   train_loss:  604.9972066190091   time:  1.287731409072876
e:  100   train_loss:  604.9972066190091   val_loss:  835.6605252232141   time:  1.3990552425384521
e:  101   train_loss:  603.750301532267   time:  1.288048267364502
e:  102   train_loss:  602.8410821878258   time:  1.2971632480621338
e:  103   train_loss:  600.2914557444313   time:  1.4432783126831055
e:  104   train_loss:  597.1958784418888   time:  1.304229736328125
e:  105   train_loss:  597.3572363180061   time:  1.3034119606018066
e:  105   train_loss:  597.3572363180061   val_loss:  814.3678747124802   time:  1.4156813621520996
e:  106   train_loss:  597.767965366404   time:  1.3044273853302002
e:  107   train_loss:  593.7765077927997   time:  1.3023738861083984
e:  108   train_loss:  593.3805394507082   time:  1.2906992435455322
e:  109   train_loss:  590.287160488087   time:  1.299006700515747
e:  110   train_loss:  591.7064436680203   time:  1.3030180931091309
e:  110   train_loss:  591.7064436680203   val_loss:  822.8543753139858   time:  1.4156761169433594
e:  111   train_loss:  588.2996199350913   time:  1.3003528118133545
e:  112   train_loss:  587.0629139117916   time:  1.3052449226379395
e:  113   train_loss:  584.998861281165   time:  1.305737018585205
e:  114   train_loss:  584.6495807840137   time:  1.303241491317749
e:  115   train_loss:  581.3808555479503   time:  1.3016705513000488
e:  115   train_loss:  581.3808555479503   val_loss:  828.7125370085565   time:  1.5554630756378174
e:  116   train_loss:  582.6439437381644   time:  1.3028178215026855
e:  117   train_loss:  583.9922461842912   time:  1.3075599670410156
e:  118   train_loss:  581.8357421373387   time:  1.3021600246429443
e:  119   train_loss:  577.7214171594587   time:  1.3010613918304443
e:  120   train_loss:  576.8528148932833   time:  1.3004734516143799
e:  120   train_loss:  576.8528148932833   val_loss:  822.3612245028045   time:  1.4130277633666992
e:  121   train_loss:  574.5863932727264   time:  1.3028833866119385
e:  122   train_loss:  575.6918470733335   time:  1.303398609161377
e:  123   train_loss:  574.5493594213194   time:  1.2835524082183838
e:  124   train_loss:  572.8950780507819   time:  1.4385766983032227
e:  125   train_loss:  574.2797075876115   time:  1.2853937149047852
e:  125   train_loss:  574.2797075876115   val_loss:  827.2099733117701   time:  1.389078140258789
e:  126   train_loss:  573.2012438079717   time:  1.3024396896362305
e:  127   train_loss:  572.0054507105916   time:  1.305098295211792
e:  128   train_loss:  568.408201879125   time:  1.3012065887451172
e:  129   train_loss:  567.9574440822306   time:  1.3024215698242188
e:  130   train_loss:  567.9644303947638   time:  1.3014976978302002
e:  130   train_loss:  567.9644303947638   val_loss:  830.086541115123   time:  1.413675308227539
e:  131   train_loss:  568.7744289695603   time:  1.304717779159546
e:  132   train_loss:  567.2067255343895   time:  1.2873597145080566
e:  133   train_loss:  565.7132941596303   time:  1.30230712890625
e:  134   train_loss:  566.4591506120083   time:  1.298757553100586
e:  135   train_loss:  565.2111609890193   time:  1.4401991367340088
e:  135   train_loss:  565.2111609890193   val_loss:  835.5151927582316   time:  1.5529000759124756
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1067.659484829858   time:  1.4314217567443848
e:  0   train_loss:  1067.659484829858   val_loss:  689.8298783855819   time:  1.5375068187713623
e:  1   train_loss:  1079.203832116225   time:  1.4282679557800293
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  2   train_loss:  1077.617441286312   time:  1.4269969463348389
e:  3   train_loss:  1063.2346294344386   time:  1.4275414943695068
e:  4   train_loss:  1079.4224496428678   time:  1.563887357711792
e:  5   train_loss:  1061.538483673582   time:  1.4223413467407227
e:  5   train_loss:  1061.538483673582   val_loss:  682.3880390301007   time:  1.5289239883422852
e:  6   train_loss:  1067.0933412463805   time:  1.4250330924987793
e:  7   train_loss:  1048.5017373105338   time:  1.4248080253601074
e:  8   train_loss:  1065.9619315443895   time:  1.4115219116210938
e:  9   train_loss:  1049.9913867218384   time:  1.397052526473999
e:  10   train_loss:  1045.0024090123575   time:  1.4126553535461426
e:  10   train_loss:  1045.0024090123575   val_loss:  674.264922128157   time:  1.677201747894287
e:  11   train_loss:  1027.8957796600025   time:  1.4277946949005127
e:  12   train_loss:  1027.8755089928197   time:  1.4221704006195068
e:  13   train_loss:  1038.3942720935595   time:  1.4169228076934814
e:  14   train_loss:  1023.3302162010287   time:  1.4249346256256104
e:  15   train_loss:  1028.4449249711133   time:  1.4270782470703125
e:  15   train_loss:  1028.4449249711133   val_loss:  668.1438118214945   time:  1.5331337451934814
e:  16   train_loss:  1017.6767249815558   time:  1.423114538192749
e:  17   train_loss:  1023.4235626086546   time:  1.4264681339263916
e:  18   train_loss:  1015.8041000492412   time:  1.4241759777069092
e:  19   train_loss:  1000.871549464761   time:  1.5728693008422852
e:  20   train_loss:  1025.4700009967898   time:  1.416661262512207
e:  20   train_loss:  1025.4700009967898   val_loss:  663.3197819920837   time:  1.5232656002044678
e:  21   train_loss:  1014.9573158066293   time:  1.42775559425354
e:  22   train_loss:  982.0108133239646   time:  1.4252848625183105
e:  23   train_loss:  990.849441779265   time:  1.4269256591796875
e:  24   train_loss:  972.546489844859   time:  1.4275567531585693
e:  25   train_loss:  967.7761133865484   time:  1.680187702178955
e:  25   train_loss:  967.7761133865484   val_loss:  658.0842887171044   time:  1.7874045372009277
e:  26   train_loss:  980.8948988736452   time:  1.399961233139038
e:  27   train_loss:  956.2790317049398   time:  1.4068777561187744
e:  28   train_loss:  968.0977017485651   time:  1.4032809734344482
e:  29   train_loss:  935.7197720547962   time:  1.374659538269043
e:  30   train_loss:  933.6497949436495   time:  1.4042253494262695
e:  30   train_loss:  933.6497949436495   val_loss:  652.9630174447981   time:  1.6394047737121582
e:  31   train_loss:  948.8502853878147   time:  1.4098200798034668
e:  32   train_loss:  933.3297880641704   time:  1.460806131362915
e:  33   train_loss:  917.4635172848751   time:  1.3966243267059326
e:  34   train_loss:  910.1584044017249   time:  1.3986077308654785
e:  35   train_loss:  906.9672575522859   time:  1.398672342300415
e:  35   train_loss:  906.9672575522859   val_loss:  647.9449722993376   time:  1.5043237209320068
e:  36   train_loss:  890.8329486184117   time:  1.4005398750305176
e:  37   train_loss:  904.1495671363793   time:  1.551189661026001
e:  38   train_loss:  878.7919209321623   time:  1.4126765727996826
e:  39   train_loss:  886.790876167644   time:  1.4127113819122314
e:  40   train_loss:  868.7850230905174   time:  1.4093360900878906
e:  40   train_loss:  868.7850230905174   val_loss:  644.2854599531931   time:  1.515845775604248
e:  41   train_loss:  879.4084417043819   time:  1.408198595046997
e:  42   train_loss:  866.7499787376369   time:  1.4153354167938232
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  43   train_loss:  839.732166919593   time:  1.5568222999572754
e:  44   train_loss:  837.8289845664528   time:  1.412235975265503
e:  45   train_loss:  846.2809416058559   time:  1.401427984237671
e:  45   train_loss:  846.2809416058559   val_loss:  640.0142122741988   time:  1.507904291152954
e:  46   train_loss:  824.4566429370466   time:  1.4198155403137207
e:  47   train_loss:  812.6250459314409   time:  1.3974721431732178
e:  48   train_loss:  831.651624641678   time:  1.4086921215057373
e:  49   train_loss:  803.0038573891295   time:  1.3981385231018066
e:  50   train_loss:  809.9902420623683   time:  1.5295393466949463
e:  50   train_loss:  809.9902420623683   val_loss:  640.6662183570098   time:  1.6351721286773682
e:  51   train_loss:  792.3919130308037   time:  1.4019649028778076
e:  52   train_loss:  789.8445963588524   time:  1.409266471862793
e:  53   train_loss:  782.1644381954837   time:  1.3980669975280762
e:  54   train_loss:  780.1836078561822   time:  1.4102654457092285
e:  55   train_loss:  771.2374135512117   time:  1.4122228622436523
e:  55   train_loss:  771.2374135512117   val_loss:  640.5445984960155   time:  1.5186686515808105
e:  56   train_loss:  765.1117454610868   time:  1.4276607036590576
e:  57   train_loss:  757.1931307251001   time:  1.5527572631835938
e:  58   train_loss:  759.2627171333232   time:  1.4119746685028076
e:  59   train_loss:  750.4025377570771   time:  1.3947679996490479
e:  60   train_loss:  750.5086916294467   time:  1.4968934059143066
e:  60   train_loss:  750.5086916294467   val_loss:  642.9517823395641   time:  1.6019551753997803
e:  61   train_loss:  753.7380578667216   time:  1.3935794830322266
e:  62   train_loss:  744.2338351561182   time:  1.3863422870635986
e:  63   train_loss:  726.2009734084685   time:  1.392956018447876
e:  64   train_loss:  731.1088672688106   time:  1.5297622680664062
e:  65   train_loss:  728.6769702593427   time:  1.388681173324585
e:  65   train_loss:  728.6769702593427   val_loss:  642.0641982834449   time:  1.4935510158538818
e:  66   train_loss:  707.0860815288537   time:  1.3977677822113037
e:  67   train_loss:  712.3537033358315   time:  1.396679401397705
e:  68   train_loss:  692.4535504106635   time:  1.3915860652923584
e:  69   train_loss:  698.9693170158723   time:  1.3871359825134277
e:  70   train_loss:  696.195239711905   time:  1.3905110359191895
e:  70   train_loss:  696.195239711905   val_loss:  641.3946703247282   time:  1.62068510055542
e:  71   train_loss:  685.4513003015576   time:  1.3822765350341797
e:  72   train_loss:  690.6835762239319   time:  1.38631272315979
e:  73   train_loss:  681.2179534664799   time:  1.3942506313323975
e:  74   train_loss:  677.9159099782922   time:  1.3967862129211426
e:  75   train_loss:  673.7884001597978   time:  1.3869428634643555
e:  75   train_loss:  673.7884001597978   val_loss:  635.2267143195603   time:  1.4928603172302246
e:  76   train_loss:  672.684925536854   time:  1.5147688388824463
e:  77   train_loss:  658.2385812753326   time:  1.3970534801483154
e:  78   train_loss:  667.233487433892   time:  1.386589765548706
e:  79   train_loss:  660.8225989930372   time:  1.3966596126556396
e:  80   train_loss:  655.6307160578704   time:  1.3970005512237549
e:  80   train_loss:  655.6307160578704   val_loss:  635.3775819070366   time:  1.5021107196807861
e:  81   train_loss:  657.6499753184795   time:  1.3887386322021484
e:  82   train_loss:  654.0833118494327   time:  1.5342977046966553
e:  83   train_loss:  650.5834010339188   time:  1.3867709636688232
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  84   train_loss:  650.4802296474793   time:  1.411935567855835
e:  85   train_loss:  646.2556153203892   time:  1.3928191661834717
e:  85   train_loss:  646.2556153203892   val_loss:  625.4822380052867   time:  1.498072862625122
e:  86   train_loss:  654.3761540251627   time:  1.3858468532562256
e:  87   train_loss:  638.9774068935227   time:  1.3881182670593262
e:  88   train_loss:  645.3321529742044   time:  1.535466194152832
e:  89   train_loss:  629.833291145523   time:  1.3943536281585693
e:  90   train_loss:  645.4380538534438   time:  1.3963682651519775
e:  90   train_loss:  645.4380538534438   val_loss:  623.5862932903619   time:  1.500852346420288
e:  91   train_loss:  633.0853719366177   time:  1.3641564846038818
e:  92   train_loss:  637.5602672678793   time:  1.369560718536377
e:  93   train_loss:  638.9852620948305   time:  1.3870861530303955
e:  94   train_loss:  626.1847758371013   time:  1.5245366096496582
e:  95   train_loss:  621.634061773444   time:  1.3864891529083252
e:  95   train_loss:  621.634061773444   val_loss:  625.5120413664929   time:  1.4908475875854492
e:  96   train_loss:  623.3636068516629   time:  1.388789415359497
e:  97   train_loss:  639.5275366402149   time:  1.3939006328582764
e:  98   train_loss:  613.2416809014167   time:  1.3878791332244873
e:  99   train_loss:  620.5272272016884   time:  1.3790431022644043
e:  100   train_loss:  626.4622722881135   time:  1.3866353034973145
e:  100   train_loss:  626.4622722881135   val_loss:  627.2740889335013   time:  1.490574598312378
e:  101   train_loss:  625.7297319602229   time:  1.5248758792877197
e:  102   train_loss:  615.5081405924021   time:  1.3894920349121094
e:  103   train_loss:  623.5663844585018   time:  1.3874192237854004
e:  104   train_loss:  615.1077760430564   time:  1.3873450756072998
e:  105   train_loss:  631.0152625305186   time:  1.378993034362793
e:  105   train_loss:  631.0152625305186   val_loss:  618.403599435446   time:  1.4835543632507324
e:  106   train_loss:  621.3377309016466   time:  1.3962733745574951
e:  107   train_loss:  617.8830850188627   time:  1.3890979290008545
e:  108   train_loss:  615.4649859526447   time:  1.421947956085205
e:  109   train_loss:  614.4373885310835   time:  1.379880428314209
e:  110   train_loss:  615.6074090048043   time:  1.3846445083618164
e:  110   train_loss:  615.6074090048043   val_loss:  629.4543329601516   time:  1.4883432388305664
e:  111   train_loss:  617.3795192352351   time:  1.3876183032989502
e:  112   train_loss:  602.3165458211645   time:  1.3743677139282227
e:  113   train_loss:  615.6639917012965   time:  1.3750455379486084
e:  114   train_loss:  601.6113541691707   time:  1.3779358863830566
e:  115   train_loss:  615.8103760493616   time:  1.5217230319976807
e:  115   train_loss:  615.8103760493616   val_loss:  633.9736897404798   time:  1.6265127658843994
e:  116   train_loss:  613.7693052721263   time:  1.3892931938171387
e:  117   train_loss:  604.4733738298996   time:  1.3894340991973877
e:  118   train_loss:  609.6050334127619   time:  1.3850829601287842
e:  119   train_loss:  603.2732272087779   time:  1.3906283378601074
e:  120   train_loss:  599.1958863338857   time:  1.3895385265350342
e:  120   train_loss:  599.1958863338857   val_loss:  639.6381773639297   time:  1.4938466548919678
e:  121   train_loss:  600.0823216815232   time:  1.531769037246704
e:  122   train_loss:  606.492125609841   time:  1.3886759281158447
e:  123   train_loss:  600.7904132819014   time:  1.3844993114471436
e:  124   train_loss:  606.1720566794759   time:  1.3904635906219482
e:  125   train_loss:  605.8370848660876   time:  1.3827667236328125
e:  125   train_loss:  605.8370848660876   val_loss:  655.1109174198932   time:  1.4875659942626953
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  126   train_loss:  605.3837068954031   time:  1.394883632659912
e:  127   train_loss:  605.6922456321258   time:  1.3874099254608154
e:  128   train_loss:  599.8951727989244   time:  1.523747205734253
e:  129   train_loss:  600.187786123251   time:  1.38820219039917
e:  130   train_loss:  597.0645532809709   time:  1.386861801147461
e:  130   train_loss:  597.0645532809709   val_loss:  658.0286362237304   time:  1.4909017086029053
e:  131   train_loss:  594.7232284750634   time:  1.3857314586639404
e:  132   train_loss:  591.851768795431   time:  1.3916449546813965
e:  133   train_loss:  592.2877530334422   time:  1.3628010749816895
e:  134   train_loss:  601.8982100497918   time:  1.3711600303649902
e:  135   train_loss:  592.6572485801306   time:  1.5193192958831787
e:  135   train_loss:  592.6572485801306   val_loss:  678.3702320634472   time:  1.623655080795288
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (2, 0, 2), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (2, 0, 2) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 2) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 2) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (2, 0, 2)
kwargs: {'config': {'batch_norm': True, 'ff_0': 114, 'ff_num_layers': 1, 'gnn_0': 1507, 'gnn_dropout': 0.22419896291123764, 'gnn_num_layers': 2, 'hid_0': 236, 'hid_dropout_rate': 0.21567683294353168, 'in_dropout_rate': 0.3352539524993557, 'lr': 1.7229795394464675e-05, 'num_hid_layers': 1, 'optimizer': 'Adam', 'gnn_1': 90}, 'budget': 243.0, 'working_directory': '.'}
result: {'loss': 802.4835766387441, 'n_epochs': 142.0, 'info': {'validation loss': 802.4835766387441}}
exception: None

DEBUG:hpbandster:job_callback for (2, 0, 2) started
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:job_callback for (2, 0, 2) got condition
DEBUG:hpbandster:Only 9 run(s) for budget 243.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (2, 0, 2) finished
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: trying submitting job (2, 0, 3) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 3) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 3)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 3) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 3) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (2, 0, 3)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 158, 'ff_num_layers': 2, 'gnn_0': 1037, 'gnn_dropout': 0.4159381407912401, 'gnn_num_layers': 3, 'hid_0': 362, 'hid_dropout_rate': 0.0015934472827938695, 'in_dropout_rate': 0.24414691946777917, 'lr': 0.0007279250329450922, 'num_hid_layers': 2, 'optimizer': 'SGD', 'ff_1': 421, 'gnn_1': 161, 'gnn_2': 311, 'hid_1': 276, 'sgd_momentum': 0.033203490940577535}, 'budget': 243.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  704.7092878451692   time:  1.3025572299957275
e:  0   train_loss:  704.7092878451692   val_loss:  1666.5728796970873   time:  1.414177417755127
e:  1   train_loss:  698.3019334216935   time:  1.3132672309875488
e:  2   train_loss:  683.5284369590463   time:  1.3159072399139404
e:  3   train_loss:  644.3243860889258   time:  1.3168370723724365
e:  4   train_loss:  601.967898983328   time:  1.308725357055664
e:  5   train_loss:  596.7697084320307   time:  1.3187005519866943
e:  5   train_loss:  596.7697084320307   val_loss:  1402.381490212953   time:  1.43001127243042
e:  6   train_loss:  594.2212321470047   time:  1.311239242553711
e:  7   train_loss:  594.0453519989086   time:  1.3114840984344482
e:  8   train_loss:  593.3428400680589   time:  1.438002586364746
e:  9   train_loss:  591.0961637444385   time:  1.3156089782714844
e:  10   train_loss:  589.362547873359   time:  1.313628911972046
e:  10   train_loss:  589.362547873359   val_loss:  1391.593959626557   time:  1.4245290756225586
e:  11   train_loss:  588.3135006493059   time:  1.3193471431732178
e:  12   train_loss:  586.773160298128   time:  1.3210301399230957
e:  13   train_loss:  586.0633518450212   time:  1.3103044033050537
e:  14   train_loss:  582.801005757085   time:  1.3187315464019775
e:  15   train_loss:  581.1521971735535   time:  1.3190114498138428
e:  15   train_loss:  581.1521971735535   val_loss:  1391.2620558217925   time:  1.4308478832244873
e:  16   train_loss:  578.2944155108959   time:  1.3203198909759521
e:  17   train_loss:  575.4943942776667   time:  1.44661283493042
e:  18   train_loss:  572.9060610457954   time:  1.3029751777648926
e:  19   train_loss:  569.7266710533368   time:  1.2894563674926758
e:  20   train_loss:  565.675054159241   time:  1.2919154167175293
e:  20   train_loss:  565.675054159241   val_loss:  1392.801044058828   time:  1.4040913581848145
e:  21   train_loss:  561.7746702816437   time:  1.315356731414795
e:  22   train_loss:  558.253806619342   time:  1.3086605072021484
e:  23   train_loss:  554.019364431427   time:  1.3009779453277588
e:  24   train_loss:  550.1269230884611   time:  1.3048512935638428
e:  25   train_loss:  546.8951255779751   time:  1.3186922073364258
e:  25   train_loss:  546.8951255779751   val_loss:  1363.915972922059   time:  1.4299304485321045
e:  26   train_loss:  542.8137356885355   time:  1.3095626831054688
e:  27   train_loss:  539.9906257516444   time:  1.3175685405731201
e:  28   train_loss:  535.206848166127   time:  1.4411594867706299
e:  29   train_loss:  531.5565132545411   time:  1.3003344535827637
e:  30   train_loss:  530.7202581285522   time:  1.3099641799926758
e:  30   train_loss:  530.7202581285522   val_loss:  1400.3681114813105   time:  1.4207720756530762
e:  31   train_loss:  527.3778876249   time:  1.3198912143707275
e:  32   train_loss:  521.21242826656   time:  1.3162705898284912
e:  33   train_loss:  520.8940070664765   time:  1.3151865005493164
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  34   train_loss:  526.4547037347012   time:  1.3140795230865479
e:  35   train_loss:  520.2547491066683   time:  1.3180944919586182
e:  35   train_loss:  520.2547491066683   val_loss:  1360.6695510971974   time:  1.4291701316833496
e:  36   train_loss:  510.0178947068734   time:  1.3188765048980713
e:  37   train_loss:  514.5881014870776   time:  1.3184492588043213
e:  38   train_loss:  520.0968672956446   time:  1.3169209957122803
e:  39   train_loss:  502.1638466430476   time:  1.3205571174621582
e:  40   train_loss:  516.191476057144   time:  1.4376578330993652
e:  40   train_loss:  516.191476057144   val_loss:  1521.2065193009146   time:  1.541856050491333
e:  41   train_loss:  511.05171462159836   time:  1.2961266040802002
e:  42   train_loss:  507.24983083729194   time:  1.2877991199493408
e:  43   train_loss:  505.76835995065096   time:  1.316648006439209
e:  44   train_loss:  503.7424049130885   time:  1.3166542053222656
e:  45   train_loss:  503.9606506634883   time:  1.3186750411987305
e:  45   train_loss:  503.9606506634883   val_loss:  1365.9294956751262   time:  1.4306621551513672
e:  46   train_loss:  499.1390216881341   time:  1.318671703338623
e:  47   train_loss:  491.5749660231392   time:  1.3083076477050781
e:  48   train_loss:  506.1779190022738   time:  1.322190523147583
e:  49   train_loss:  498.3463204375524   time:  1.3146474361419678
e:  50   train_loss:  490.9710324996875   time:  1.4377877712249756
e:  50   train_loss:  490.9710324996875   val_loss:  1379.8123551281144   time:  1.5412933826446533
e:  51   train_loss:  486.0835853360978   time:  1.310948133468628
e:  52   train_loss:  491.3406337393386   time:  1.3183953762054443
e:  53   train_loss:  501.1938002321283   time:  1.3153939247131348
e:  54   train_loss:  484.27838510262865   time:  1.3098769187927246
e:  55   train_loss:  484.6164793990256   time:  1.3146908283233643
e:  55   train_loss:  484.6164793990256   val_loss:  1380.4519554193973   time:  1.4261627197265625
e:  56   train_loss:  490.4288304131792   time:  1.3876457214355469
e:  57   train_loss:  466.98872199571053   time:  1.3152709007263184
e:  58   train_loss:  483.3177313752162   time:  1.3118765354156494
e:  59   train_loss:  476.27383949444544   time:  1.5633366107940674
e:  60   train_loss:  477.00306283745965   time:  1.360482931137085
e:  60   train_loss:  477.00306283745965   val_loss:  1408.1545651888766   time:  1.471592664718628
e:  61   train_loss:  480.7796271840292   time:  1.3671059608459473
e:  62   train_loss:  480.568471615063   time:  1.3712422847747803
e:  63   train_loss:  474.90299660681035   time:  1.3622252941131592
e:  64   train_loss:  471.5005277380438   time:  1.3566851615905762
e:  65   train_loss:  469.29070904992824   time:  1.3783588409423828
e:  65   train_loss:  469.29070904992824   val_loss:  1407.7572623850922   time:  1.490776777267456
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1080.1875613290656   time:  1.442845106124878
e:  0   train_loss:  1080.1875613290656   val_loss:  619.809308338841   time:  1.5482776165008545
e:  1   train_loss:  1058.6909771993587   time:  1.438551664352417
e:  2   train_loss:  990.5869992913437   time:  1.5678300857543945
e:  3   train_loss:  915.3684468855115   time:  1.4370954036712646
e:  4   train_loss:  893.1543022480621   time:  1.4326410293579102
e:  5   train_loss:  895.2499911874   time:  1.4254302978515625
e:  5   train_loss:  895.2499911874   val_loss:  554.9185617111759   time:  1.5300400257110596
e:  6   train_loss:  899.3625272528496   time:  1.4333817958831787
e:  7   train_loss:  906.6586276827184   time:  1.4390311241149902
e:  8   train_loss:  893.5521662723795   time:  1.4386827945709229
e:  9   train_loss:  881.241750589194   time:  1.5685594081878662
e:  10   train_loss:  872.7770526842417   time:  1.440181016921997
e:  10   train_loss:  872.7770526842417   val_loss:  557.5629115632399   time:  1.5454866886138916
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  11   train_loss:  857.9119893688518   time:  1.439929723739624
e:  12   train_loss:  850.4695127606961   time:  1.431929349899292
e:  13   train_loss:  831.7297976505423   time:  1.4394676685333252
e:  14   train_loss:  840.4535686462782   time:  1.440523624420166
e:  15   train_loss:  820.1126991465825   time:  1.438037633895874
e:  15   train_loss:  820.1126991465825   val_loss:  608.1934720221321   time:  1.6636693477630615
e:  16   train_loss:  766.6089500121475   time:  1.4400744438171387
e:  17   train_loss:  771.6503672760666   time:  1.434422492980957
e:  18   train_loss:  746.9822557996972   time:  1.4109725952148438
e:  19   train_loss:  746.3215186210733   time:  1.4284040927886963
e:  20   train_loss:  731.0783267228575   time:  1.4235751628875732
e:  20   train_loss:  731.0783267228575   val_loss:  561.0666132960723   time:  1.5285167694091797
e:  21   train_loss:  704.9353265637109   time:  1.57059907913208
e:  22   train_loss:  706.608450410978   time:  1.438140869140625
e:  23   train_loss:  659.680081918251   time:  1.488842487335205
e:  24   train_loss:  670.1113999341508   time:  1.4975700378417969
e:  25   train_loss:  644.3549373068028   time:  1.4739153385162354
e:  25   train_loss:  644.3549373068028   val_loss:  562.5774494035929   time:  1.5795817375183105
e:  26   train_loss:  660.7759819007074   time:  1.4955449104309082
e:  27   train_loss:  654.5270953736492   time:  1.492840051651001
e:  28   train_loss:  660.0026009343832   time:  1.6447217464447021
e:  29   train_loss:  633.9757084146643   time:  1.4776079654693604
e:  30   train_loss:  644.8061036020317   time:  1.5045735836029053
e:  30   train_loss:  644.8061036020317   val_loss:  627.8136295987969   time:  1.6092963218688965
e:  31   train_loss:  644.5735339215246   time:  1.4938733577728271
e:  32   train_loss:  634.8870285237231   time:  1.4788739681243896
e:  33   train_loss:  621.3880089417366   time:  1.5010066032409668
e:  34   train_loss:  624.2886815441564   time:  1.4319522380828857
e:  35   train_loss:  637.7088268620088   time:  1.5776748657226562
e:  35   train_loss:  637.7088268620088   val_loss:  578.2648928541334   time:  1.6828820705413818
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1062.6739954788654   time:  1.4964382648468018
e:  0   train_loss:  1062.6739954788654   val_loss:  534.1430451795532   time:  1.6170587539672852
e:  1   train_loss:  1150.6608391486452   time:  1.5399045944213867
e:  2   train_loss:  989.180765693059   time:  1.4916799068450928
e:  3   train_loss:  897.8496207806332   time:  1.5024323463439941
e:  4   train_loss:  896.9355114085523   time:  1.569258213043213
e:  5   train_loss:  895.9305203846872   time:  1.5725970268249512
e:  5   train_loss:  895.9305203846872   val_loss:  500.3363288008414   time:  1.684504508972168
e:  6   train_loss:  905.7701454055215   time:  1.6852710247039795
e:  7   train_loss:  883.962846462099   time:  1.4675252437591553
e:  8   train_loss:  874.9479155799322   time:  1.470088005065918
e:  9   train_loss:  879.5569807941316   time:  1.4462480545043945
e:  10   train_loss:  877.985990941049   time:  1.4657936096191406
e:  10   train_loss:  877.985990941049   val_loss:  488.93885736081313   time:  1.5752406120300293
e:  11   train_loss:  872.087107517652   time:  1.4716734886169434
e:  12   train_loss:  870.9273383132212   time:  1.471642017364502
e:  13   train_loss:  845.8901951398198   time:  1.4685847759246826
e:  14   train_loss:  848.6856837906157   time:  1.6154005527496338
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  15   train_loss:  849.2668487531308   time:  1.4666674137115479
e:  15   train_loss:  849.2668487531308   val_loss:  512.5594817883874   time:  1.5740196704864502
e:  16   train_loss:  804.21647727443   time:  1.459864854812622
e:  17   train_loss:  810.0990724381927   time:  1.4688069820404053
e:  18   train_loss:  790.7160173439369   time:  1.4609649181365967
e:  19   train_loss:  769.6309246390196   time:  1.5934412479400635
e:  20   train_loss:  721.0647857738542   time:  1.4761993885040283
e:  20   train_loss:  721.0647857738542   val_loss:  469.29822854287795   time:  1.7426683902740479
e:  21   train_loss:  744.0132244116376   time:  1.4926834106445312
e:  22   train_loss:  720.0588298865526   time:  1.5318059921264648
e:  23   train_loss:  736.0557260767816   time:  1.4880423545837402
e:  24   train_loss:  718.1159998386187   time:  1.408977746963501
e:  25   train_loss:  709.2737963647429   time:  1.4760794639587402
e:  25   train_loss:  709.2737963647429   val_loss:  516.4976146042715   time:  1.5853204727172852
e:  26   train_loss:  705.7213595794115   time:  1.4837462902069092
e:  27   train_loss:  931.0259349721395   time:  1.482970952987671
e:  28   train_loss:  747.6971700819205   time:  1.647895097732544
e:  29   train_loss:  714.2798724633162   time:  1.4784541130065918
e:  30   train_loss:  673.4846730331637   time:  1.4802770614624023
e:  30   train_loss:  673.4846730331637   val_loss:  486.71068900398546   time:  1.5895109176635742
e:  31   train_loss:  688.7313122749742   time:  1.4866504669189453
e:  32   train_loss:  683.2669926741015   time:  1.4760196208953857
e:  33   train_loss:  668.5957195147294   time:  1.473816156387329
e:  34   train_loss:  673.5721635840819   time:  1.4804394245147705
e:  35   train_loss:  662.3675008109826   time:  1.650200366973877
e:  35   train_loss:  662.3675008109826   val_loss:  466.1614518429476   time:  1.7586658000946045
e:  36   train_loss:  672.4424844029827   time:  1.4760510921478271
e:  37   train_loss:  676.7792246267776   time:  1.4758641719818115
e:  38   train_loss:  664.3902099619343   time:  1.4857053756713867
e:  39   train_loss:  672.3073505666845   time:  1.4835262298583984
e:  40   train_loss:  648.8376597096468   time:  1.473811149597168
e:  40   train_loss:  648.8376597096468   val_loss:  765.5180406807184   time:  1.5822415351867676
e:  41   train_loss:  720.6978585472516   time:  1.4506220817565918
e:  42   train_loss:  658.4613140408695   time:  1.6564245223999023
e:  43   train_loss:  634.6372827004312   time:  1.4799377918243408
e:  44   train_loss:  633.345377031034   time:  1.4754319190979004
e:  45   train_loss:  637.5225065469093   time:  1.483025074005127
e:  45   train_loss:  637.5225065469093   val_loss:  466.9830193568518   time:  1.5923068523406982
e:  46   train_loss:  650.9578526496783   time:  1.4783174991607666
e:  47   train_loss:  651.9411139072357   time:  1.4781126976013184
e:  48   train_loss:  641.4507000108491   time:  1.4763314723968506
e:  49   train_loss:  632.5632047962624   time:  1.4830527305603027
e:  50   train_loss:  633.8902250146099   time:  1.6577377319335938
e:  50   train_loss:  633.8902250146099   val_loss:  466.4940829334586   time:  1.7665791511535645
e:  51   train_loss:  666.312190177846   time:  1.4780783653259277
e:  52   train_loss:  887.8981203701258   time:  1.4822962284088135
e:  53   train_loss:  761.179993627543   time:  1.4801273345947266
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  54   train_loss:  724.0962414869743   time:  1.479292392730713
e:  55   train_loss:  669.0421230644475   time:  1.479166030883789
e:  55   train_loss:  669.0421230644475   val_loss:  503.31718974948666   time:  1.5866336822509766
e:  56   train_loss:  698.9328102155082   time:  1.4740405082702637
e:  57   train_loss:  664.34206440545   time:  1.6368718147277832
e:  58   train_loss:  652.4567245421318   time:  1.4802567958831787
e:  59   train_loss:  650.458166418317   time:  1.4792602062225342
e:  60   train_loss:  662.1351448954044   time:  1.4642980098724365
e:  60   train_loss:  662.1351448954044   val_loss:  537.827912755402   time:  1.5728232860565186
e:  61   train_loss:  638.2234006977773   time:  1.4596474170684814
e:  62   train_loss:  659.6777518589606   time:  1.4720628261566162
e:  63   train_loss:  666.6267576393421   time:  1.4646873474121094
e:  64   train_loss:  647.2356539907928   time:  1.4864609241485596
e:  65   train_loss:  642.9022688643853   time:  1.7045552730560303
e:  65   train_loss:  642.9022688643853   val_loss:  471.2078945035501   time:  1.8136415481567383
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  998.5434577900978   time:  1.3667194843292236
e:  0   train_loss:  998.5434577900978   val_loss:  908.7100537631671   time:  1.480682373046875
e:  1   train_loss:  983.3182104501457   time:  1.373490571975708
e:  2   train_loss:  935.5739884413875   time:  1.3715360164642334
e:  3   train_loss:  851.2933310764313   time:  1.372631311416626
e:  4   train_loss:  841.4458115396486   time:  1.3624956607818604
e:  5   train_loss:  836.961433441025   time:  1.367713212966919
e:  5   train_loss:  836.961433441025   val_loss:  739.8745061173925   time:  1.4816162586212158
e:  6   train_loss:  836.4850687658998   time:  1.3654160499572754
e:  7   train_loss:  834.0791209601512   time:  1.5375392436981201
e:  8   train_loss:  833.8455118657798   time:  1.366762399673462
e:  9   train_loss:  827.6842664769299   time:  1.3662230968475342
e:  10   train_loss:  821.678964264676   time:  1.347618579864502
e:  10   train_loss:  821.678964264676   val_loss:  733.855438695585   time:  1.4609029293060303
e:  11   train_loss:  819.7672485757043   time:  1.3743650913238525
e:  12   train_loss:  817.5043890068989   time:  1.3703467845916748
e:  13   train_loss:  812.6093697918892   time:  1.358901023864746
e:  14   train_loss:  804.6519530376163   time:  1.368983507156372
e:  15   train_loss:  796.0086606230552   time:  1.343473196029663
e:  15   train_loss:  796.0086606230552   val_loss:  721.4705400055823   time:  1.4552524089813232
e:  16   train_loss:  787.3089105303233   time:  1.3519418239593506
e:  17   train_loss:  778.1732274455258   time:  1.3692107200622559
e:  18   train_loss:  764.5964322323572   time:  1.5316810607910156
e:  19   train_loss:  752.3660775933863   time:  1.3542389869689941
e:  20   train_loss:  739.2999538790305   time:  1.3752524852752686
e:  20   train_loss:  739.2999538790305   val_loss:  704.3222481571195   time:  1.4884541034698486
e:  21   train_loss:  731.6608988777626   time:  1.3703114986419678
e:  22   train_loss:  732.3211508604865   time:  1.3656799793243408
e:  23   train_loss:  708.4084109241148   time:  1.3649389743804932
e:  24   train_loss:  710.2634436468855   time:  1.3649756908416748
e:  25   train_loss:  682.9018122243364   time:  1.3671226501464844
e:  25   train_loss:  682.9018122243364   val_loss:  704.3132346397787   time:  1.4804589748382568
e:  26   train_loss:  678.7350715996938   time:  1.3653662204742432
e:  27   train_loss:  674.5384044672903   time:  1.3694758415222168
e:  28   train_loss:  668.608242954826   time:  1.3704867362976074
e:  29   train_loss:  654.1727062033225   time:  1.3672945499420166
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  30   train_loss:  649.5105768377545   time:  1.3689181804656982
e:  30   train_loss:  649.5105768377545   val_loss:  705.7697195412886   time:  1.6511726379394531
e:  31   train_loss:  635.902783357684   time:  1.3693275451660156
e:  32   train_loss:  638.1098106765807   time:  1.36757230758667
e:  33   train_loss:  628.6152557024974   time:  1.3670973777770996
e:  34   train_loss:  665.824626321726   time:  1.369523286819458
e:  35   train_loss:  627.2325981437749   time:  1.365544080734253
e:  35   train_loss:  627.2325981437749   val_loss:  735.1450445556842   time:  1.4789621829986572
e:  36   train_loss:  629.7806708250414   time:  1.3445115089416504
e:  37   train_loss:  619.0740024456414   time:  1.341804027557373
e:  38   train_loss:  637.0244640223166   time:  1.363889217376709
e:  39   train_loss:  627.944737856329   time:  1.5363914966583252
e:  40   train_loss:  619.7696867903888   time:  1.3476877212524414
e:  40   train_loss:  619.7696867903888   val_loss:  695.6855357370783   time:  1.4538779258728027
e:  41   train_loss:  615.9851304823935   time:  1.4467041492462158
e:  42   train_loss:  605.426850475416   time:  1.3819866180419922
e:  43   train_loss:  609.3151336230779   time:  1.3661859035491943
e:  44   train_loss:  607.3779059196031   time:  1.3686378002166748
e:  45   train_loss:  607.840691512699   time:  1.3708341121673584
e:  45   train_loss:  607.840691512699   val_loss:  684.7576964115333   time:  1.4850904941558838
e:  46   train_loss:  603.1285077692864   time:  1.4368038177490234
e:  47   train_loss:  608.3988357094735   time:  1.4057815074920654
e:  48   train_loss:  621.7725501897634   time:  1.4582555294036865
e:  49   train_loss:  602.510723058917   time:  1.3927254676818848
e:  50   train_loss:  604.814559192918   time:  1.5434961318969727
e:  50   train_loss:  604.814559192918   val_loss:  687.4784959881323   time:  1.6572651863098145
e:  51   train_loss:  597.601809071589   time:  1.4200944900512695
e:  52   train_loss:  631.9808254761034   time:  1.3610622882843018
e:  53   train_loss:  599.8636135819055   time:  1.3589680194854736
e:  54   train_loss:  588.883349903548   time:  1.351546287536621
e:  55   train_loss:  592.3264467883108   time:  1.3572747707366943
e:  55   train_loss:  592.3264467883108   val_loss:  675.5433494791556   time:  1.4713666439056396
e:  56   train_loss:  589.8319867623767   time:  1.3540644645690918
e:  57   train_loss:  594.3202229892635   time:  1.3509912490844727
e:  58   train_loss:  583.8437223006242   time:  1.3297898769378662
e:  59   train_loss:  583.6061831914374   time:  1.4994089603424072
e:  60   train_loss:  600.8893494316902   time:  1.3404829502105713
e:  60   train_loss:  600.8893494316902   val_loss:  678.0808161855986   time:  1.4535880088806152
e:  61   train_loss:  580.3790627806252   time:  1.3570377826690674
e:  62   train_loss:  586.3191481170685   time:  1.3580365180969238
e:  63   train_loss:  581.1326108563791   time:  1.3515005111694336
e:  64   train_loss:  570.9104675244964   time:  1.356370210647583
e:  65   train_loss:  573.8728041306841   time:  1.352515697479248
e:  65   train_loss:  573.8728041306841   val_loss:  709.7884001990933   time:  1.46549654006958
e:  66   train_loss:  569.4919842851459   time:  1.3555302619934082
e:  67   train_loss:  573.7936292803098   time:  1.3508641719818115
e:  68   train_loss:  574.2497724626273   time:  1.5083415508270264
e:  69   train_loss:  579.8719400338716   time:  1.3549473285675049
e:  70   train_loss:  588.239057659971   time:  1.3546578884124756
e:  70   train_loss:  588.239057659971   val_loss:  705.568493650323   time:  1.4678394794464111
e:  71   train_loss:  567.4323379050118   time:  1.3567910194396973
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  72   train_loss:  570.7638274215446   time:  1.3589847087860107
e:  73   train_loss:  574.4384014658484   time:  1.3431391716003418
e:  74   train_loss:  565.2605311776916   time:  1.3524913787841797
e:  75   train_loss:  561.7139754432195   time:  1.3557844161987305
e:  75   train_loss:  561.7139754432195   val_loss:  668.1165456601784   time:  1.4693794250488281
e:  76   train_loss:  575.286084282282   time:  1.3523948192596436
e:  77   train_loss:  568.8277258083721   time:  1.3562514781951904
e:  78   train_loss:  557.5158686377915   time:  1.3576009273529053
e:  79   train_loss:  561.4611552505827   time:  1.3344745635986328
e:  80   train_loss:  579.3498956768894   time:  1.3354053497314453
e:  80   train_loss:  579.3498956768894   val_loss:  676.8323079271154   time:  1.6030781269073486
e:  81   train_loss:  545.7244415970175   time:  1.3543102741241455
e:  82   train_loss:  562.2735746302396   time:  1.3523235321044922
e:  83   train_loss:  572.5269625676885   time:  1.353874683380127
e:  84   train_loss:  549.2462672971135   time:  1.3517756462097168
e:  85   train_loss:  550.8915868128609   time:  1.3696842193603516
e:  85   train_loss:  550.8915868128609   val_loss:  692.1992274307673   time:  1.4827780723571777
e:  86   train_loss:  555.6432089869276   time:  1.3907926082611084
e:  87   train_loss:  551.6890336979919   time:  1.384389877319336
e:  88   train_loss:  542.3240837275858   time:  1.373692512512207
e:  89   train_loss:  565.5809093408109   time:  1.5954499244689941
e:  90   train_loss:  527.4940878160307   time:  1.369445562362671
e:  90   train_loss:  527.4940878160307   val_loss:  671.1519688452639   time:  1.4737017154693604
e:  91   train_loss:  553.737702138924   time:  1.370556354522705
e:  92   train_loss:  556.7453751747669   time:  1.3931076526641846
e:  93   train_loss:  550.1329617800712   time:  1.3695833683013916
e:  94   train_loss:  548.3994114939046   time:  1.3702812194824219
e:  95   train_loss:  527.5913769456989   time:  1.3841118812561035
e:  95   train_loss:  527.5913769456989   val_loss:  770.1982040948138   time:  1.4968225955963135
e:  96   train_loss:  534.3857945850166   time:  1.3708488941192627
e:  97   train_loss:  550.201629497819   time:  1.3992035388946533
e:  98   train_loss:  553.3485728282569   time:  1.392134666442871
e:  99   train_loss:  540.3630640877278   time:  1.3961570262908936
e:  100   train_loss:  556.9783600792013   time:  1.552457571029663
e:  100   train_loss:  556.9783600792013   val_loss:  695.8242354646064   time:  1.6645500659942627
e:  101   train_loss:  524.7863168475554   time:  1.3522553443908691
e:  102   train_loss:  544.015632815801   time:  1.3884508609771729
e:  103   train_loss:  546.7677517252429   time:  1.3958215713500977
e:  104   train_loss:  521.9159446224651   time:  1.387836217880249
e:  105   train_loss:  525.0788240384588   time:  1.3925793170928955
e:  105   train_loss:  525.0788240384588   val_loss:  679.9795563387203   time:  1.5064060688018799
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1087.5354025913746   time:  1.4847028255462646
e:  0   train_loss:  1087.5354025913746   val_loss:  681.6275198622445   time:  1.591745376586914
e:  1   train_loss:  1055.498891330392   time:  1.6469175815582275
e:  2   train_loss:  986.5482773092457   time:  1.4795207977294922
e:  3   train_loss:  898.9491768454268   time:  1.4782791137695312
e:  4   train_loss:  911.0964647448628   time:  1.4809176921844482
e:  5   train_loss:  890.4654914266406   time:  1.479820966720581
e:  5   train_loss:  890.4654914266406   val_loss:  555.5635419083744   time:  1.5870394706726074
e:  6   train_loss:  892.3517771028869   time:  1.4769539833068848
e:  7   train_loss:  885.047229161771   time:  1.4775018692016602
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  8   train_loss:  894.5553996445534   time:  1.6492583751678467
e:  9   train_loss:  874.0735627888483   time:  1.4760339260101318
e:  10   train_loss:  867.2760553057192   time:  1.4803636074066162
e:  10   train_loss:  867.2760553057192   val_loss:  554.0792183284756   time:  1.5882203578948975
e:  11   train_loss:  856.0220159637929   time:  1.4806578159332275
e:  12   train_loss:  860.2465870686235   time:  1.4781696796417236
e:  13   train_loss:  856.9520221479482   time:  1.4699277877807617
e:  14   train_loss:  823.7464947212039   time:  1.4746880531311035
e:  15   train_loss:  825.6157015427214   time:  1.6251320838928223
e:  15   train_loss:  825.6157015427214   val_loss:  599.718108251913   time:  1.7318320274353027
e:  16   train_loss:  794.882276685027   time:  1.4776597023010254
e:  17   train_loss:  775.2332829556406   time:  1.4627685546875
e:  18   train_loss:  771.075099368366   time:  1.4771990776062012
e:  19   train_loss:  744.1624635323145   time:  1.4642131328582764
e:  20   train_loss:  737.7513580915214   time:  1.4751427173614502
e:  20   train_loss:  737.7513580915214   val_loss:  567.1163818697502   time:  1.5833837985992432
e:  21   train_loss:  719.0703049533615   time:  1.64316725730896
e:  22   train_loss:  713.1895063453717   time:  1.4785914421081543
e:  23   train_loss:  700.2481634413069   time:  1.4773962497711182
e:  24   train_loss:  684.2381160885718   time:  1.4783191680908203
e:  25   train_loss:  688.9271518018431   time:  1.472482681274414
e:  25   train_loss:  688.9271518018431   val_loss:  557.645414768447   time:  1.5801050662994385
e:  26   train_loss:  672.5592736956282   time:  1.4786121845245361
e:  27   train_loss:  677.9357862061875   time:  1.4860069751739502
e:  28   train_loss:  678.5786479948783   time:  1.6323425769805908
e:  29   train_loss:  658.2185613921766   time:  1.4838380813598633
e:  30   train_loss:  671.878340815663   time:  1.481593132019043
e:  30   train_loss:  671.878340815663   val_loss:  562.9747510140735   time:  1.588230848312378
e:  31   train_loss:  672.5916581031239   time:  1.4811201095581055
e:  32   train_loss:  669.5203594820092   time:  1.4810969829559326
e:  33   train_loss:  664.8286716285781   time:  1.482865810394287
e:  34   train_loss:  666.8716782283459   time:  1.435997724533081
e:  35   train_loss:  647.8615798007379   time:  1.6450142860412598
e:  35   train_loss:  647.8615798007379   val_loss:  596.6873004633769   time:  1.7524113655090332
e:  36   train_loss:  674.8138007466415   time:  1.47947096824646
e:  37   train_loss:  627.0940096878808   time:  1.479513168334961
e:  38   train_loss:  637.191570102809   time:  1.4781582355499268
e:  39   train_loss:  631.9492457072404   time:  1.4803948402404785
e:  40   train_loss:  622.1990307353   time:  1.4809625148773193
e:  40   train_loss:  622.1990307353   val_loss:  550.7953095441939   time:  1.58726167678833
e:  41   train_loss:  630.0403793740775   time:  1.7412159442901611
e:  42   train_loss:  607.494616405772   time:  1.5668420791625977
e:  43   train_loss:  622.4206133741586   time:  1.5939762592315674
e:  44   train_loss:  621.9628451303556   time:  1.599163293838501
e:  45   train_loss:  622.7542767149548   time:  1.5940215587615967
e:  45   train_loss:  622.7542767149548   val_loss:  535.1125797741742   time:  1.7033979892730713
e:  46   train_loss:  617.9546354404736   time:  1.599811315536499
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  47   train_loss:  643.9862503431723   time:  1.5964324474334717
e:  48   train_loss:  624.2753559086227   time:  1.8317010402679443
e:  49   train_loss:  633.7166801149294   time:  1.597602367401123
e:  50   train_loss:  615.9601457241627   time:  1.5968892574310303
e:  50   train_loss:  615.9601457241627   val_loss:  584.1489632886394   time:  1.7063486576080322
e:  51   train_loss:  610.7329064261693   time:  1.5939137935638428
e:  52   train_loss:  604.9365070423078   time:  1.5830397605895996
e:  53   train_loss:  617.8227921933291   time:  1.611274242401123
e:  54   train_loss:  690.4228987514138   time:  1.5901415348052979
e:  55   train_loss:  605.9281635918895   time:  1.846717119216919
e:  55   train_loss:  605.9281635918895   val_loss:  539.2614452021326   time:  1.9556787014007568
e:  56   train_loss:  596.9523764896112   time:  1.5525729656219482
e:  57   train_loss:  590.0249059174132   time:  1.548250436782837
e:  58   train_loss:  609.9389865911191   time:  1.5511560440063477
e:  59   train_loss:  606.3166661133042   time:  1.5836074352264404
e:  60   train_loss:  578.0274007316378   time:  1.6003344058990479
e:  60   train_loss:  578.0274007316378   val_loss:  550.5620219289785   time:  1.9549179077148438
e:  61   train_loss:  594.5150340622904   time:  1.5993194580078125
e:  62   train_loss:  606.7588614484375   time:  1.5956788063049316
e:  63   train_loss:  598.9392611321621   time:  1.5959744453430176
e:  64   train_loss:  599.042635380089   time:  1.5997705459594727
e:  65   train_loss:  576.0948747068702   time:  1.5298631191253662
e:  65   train_loss:  576.0948747068702   val_loss:  540.0042095227475   time:  1.6363012790679932
e:  66   train_loss:  574.5734154326576   time:  1.8019099235534668
e:  67   train_loss:  566.3051938219103   time:  1.5569672584533691
e:  68   train_loss:  578.4041811273988   time:  1.550426721572876
e:  69   train_loss:  591.1465153425224   time:  1.5449717044830322
e:  70   train_loss:  590.0589378417288   time:  1.5491890907287598
e:  70   train_loss:  590.0589378417288   val_loss:  544.1557527739761   time:  1.655465841293335
e:  71   train_loss:  577.7219488915649   time:  1.5090289115905762
e:  72   train_loss:  592.4054176511422   time:  1.5229356288909912
e:  73   train_loss:  571.7043002200317   time:  1.7756152153015137
e:  74   train_loss:  570.7971174107329   time:  1.5320932865142822
e:  75   train_loss:  608.5570219613071   time:  1.5378036499023438
e:  75   train_loss:  608.5570219613071   val_loss:  554.3520484414357   time:  1.6455986499786377
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (2, 0, 3), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (2, 0, 3) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 3) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 3) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (2, 0, 3)
kwargs: {'config': {'batch_norm': False, 'ff_0': 158, 'ff_num_layers': 2, 'gnn_0': 1037, 'gnn_dropout': 0.4159381407912401, 'gnn_num_layers': 3, 'hid_0': 362, 'hid_dropout_rate': 0.0015934472827938695, 'in_dropout_rate': 0.24414691946777917, 'lr': 0.0007279250329450922, 'num_hid_layers': 2, 'optimizer': 'SGD', 'ff_1': 421, 'gnn_1': 161, 'gnn_2': 311, 'hid_1': 276, 'sgd_momentum': 0.033203490940577535}, 'budget': 243.0, 'working_directory': '.'}
result: {'loss': 716.9957380171347, 'n_epochs': 69.0, 'info': {'validation loss': 716.9957380171347}}
exception: None

DEBUG:hpbandster:job_callback for (2, 0, 3) started
DEBUG:hpbandster:job_callback for (2, 0, 3) got condition
DEBUG:hpbandster:Only 10 run(s) for budget 243.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (2, 0, 3) finished
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: trying submitting job (2, 0, 4) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 4) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 4)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 4) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 4) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (2, 0, 4)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 1367, 'ff_num_layers': 1, 'gnn_0': 921, 'gnn_dropout': 0.41296454900911433, 'gnn_num_layers': 2, 'hid_0': 1906, 'hid_dropout_rate': 0.2868031356579865, 'in_dropout_rate': 0.4283977738400382, 'lr': 0.0003425347762745268, 'num_hid_layers': 1, 'optimizer': 'SGD', 'gnn_1': 341, 'sgd_momentum': 0.43265642667228815}, 'budget': 243.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  699.1834982267238   time:  1.772648572921753
e:  0   train_loss:  699.1834982267238   val_loss:  1641.263703673401   time:  1.91896390914917
e:  1   train_loss:  672.2638368260922   time:  1.8013570308685303
e:  2   train_loss:  630.1132356207519   time:  1.9277894496917725
e:  3   train_loss:  602.2184350169186   time:  1.7687139511108398
e:  4   train_loss:  596.0839699280554   time:  1.794748067855835
e:  5   train_loss:  595.1871873630403   time:  1.7669682502746582
e:  5   train_loss:  595.1871873630403   val_loss:  1398.3143657199403   time:  1.889805793762207
e:  6   train_loss:  594.433419170959   time:  1.7609615325927734
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  7   train_loss:  593.7822463831267   time:  1.7876982688903809
e:  8   train_loss:  592.9580452603742   time:  1.7643611431121826
e:  9   train_loss:  592.3077623623548   time:  1.741713285446167
e:  10   train_loss:  591.0556577462628   time:  1.7247638702392578
e:  10   train_loss:  591.0556577462628   val_loss:  1393.850733813615   time:  1.8463644981384277
e:  11   train_loss:  590.5475549044437   time:  1.792093276977539
e:  12   train_loss:  589.6007300774893   time:  1.7547218799591064
e:  13   train_loss:  588.7334107205882   time:  1.856651782989502
e:  14   train_loss:  588.1706872824766   time:  1.6813178062438965
e:  15   train_loss:  586.7683061307871   time:  1.8390564918518066
e:  15   train_loss:  586.7683061307871   val_loss:  1393.5804973592042   time:  1.9595096111297607
e:  16   train_loss:  585.6694425909236   time:  1.690981388092041
e:  17   train_loss:  584.4925176906864   time:  1.7150547504425049
e:  18   train_loss:  583.8460894649154   time:  1.7159090042114258
e:  19   train_loss:  582.3209052861772   time:  1.717458724975586
e:  20   train_loss:  581.087833849357   time:  1.7102344036102295
e:  20   train_loss:  581.087833849357   val_loss:  1390.6210413623294   time:  1.900174856185913
e:  21   train_loss:  581.2511106688538   time:  1.7349674701690674
e:  22   train_loss:  579.5250295616061   time:  1.7202889919281006
e:  23   train_loss:  578.4845380470265   time:  1.8097202777862549
e:  24   train_loss:  577.3170910657528   time:  1.7909367084503174
e:  25   train_loss:  576.2819663446965   time:  1.995373010635376
e:  25   train_loss:  576.2819663446965   val_loss:  1385.2002662078537   time:  2.1080265045166016
e:  26   train_loss:  574.2417373931451   time:  1.8065361976623535
e:  27   train_loss:  573.6890470230031   time:  1.7407448291778564
e:  28   train_loss:  572.6527137597515   time:  1.7769782543182373
e:  29   train_loss:  571.1806524087834   time:  1.7035222053527832
e:  30   train_loss:  569.7549431010885   time:  1.7544915676116943
e:  30   train_loss:  569.7549431010885   val_loss:  1383.2893493690312   time:  1.8751945495605469
e:  31   train_loss:  568.3995620974902   time:  1.7300729751586914
e:  32   train_loss:  566.4369523918479   time:  1.7467944622039795
e:  33   train_loss:  565.2058012167302   time:  1.7374625205993652
e:  34   train_loss:  564.15244711509   time:  1.7212879657745361
e:  35   train_loss:  562.1453677941703   time:  1.9171943664550781
e:  35   train_loss:  562.1453677941703   val_loss:  1382.6675485064259   time:  2.030526638031006
e:  36   train_loss:  561.0847543086564   time:  1.7506136894226074
e:  37   train_loss:  560.0498267390496   time:  1.7780077457427979
e:  38   train_loss:  557.495102938218   time:  1.7152745723724365
e:  39   train_loss:  555.8645596891471   time:  1.7303287982940674
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  40   train_loss:  555.2817444124571   time:  1.7279040813446045
e:  40   train_loss:  555.2817444124571   val_loss:  1380.6175346205857   time:  1.848041296005249
e:  41   train_loss:  553.9224171725295   time:  1.7507243156433105
e:  42   train_loss:  552.7209678443215   time:  1.7427802085876465
e:  43   train_loss:  552.348183960208   time:  1.7107338905334473
e:  44   train_loss:  549.1624468391246   time:  1.8586280345916748
e:  45   train_loss:  548.5648403371023   time:  1.6907424926757812
e:  45   train_loss:  548.5648403371023   val_loss:  1365.9591320002612   time:  1.8088915348052979
e:  46   train_loss:  546.8266093384449   time:  1.6991801261901855
e:  47   train_loss:  546.0556856206051   time:  1.6987006664276123
e:  48   train_loss:  544.3571640187074   time:  1.7288484573364258
e:  49   train_loss:  543.1165370719093   time:  1.7365617752075195
e:  50   train_loss:  541.7178437277145   time:  1.7327656745910645
e:  50   train_loss:  541.7178437277145   val_loss:  1374.3975221716937   time:  1.853583812713623
e:  51   train_loss:  540.5690884246391   time:  1.7209277153015137
e:  52   train_loss:  539.4458065285108   time:  1.7403979301452637
e:  53   train_loss:  538.0444525320263   time:  1.8692066669464111
e:  54   train_loss:  537.174806862141   time:  1.742650032043457
e:  55   train_loss:  535.1674896878122   time:  1.7173447608947754
e:  55   train_loss:  535.1674896878122   val_loss:  1370.9617741611933   time:  1.9079296588897705
e:  56   train_loss:  534.6136583511684   time:  1.751814603805542
e:  57   train_loss:  532.990533820427   time:  1.7387969493865967
e:  58   train_loss:  531.9997119230597   time:  1.7153241634368896
e:  59   train_loss:  530.7497227142777   time:  1.7173941135406494
e:  60   train_loss:  529.7531401624332   time:  1.7348873615264893
e:  60   train_loss:  529.7531401624332   val_loss:  1363.2616170619233   time:  1.855193853378296
e:  61   train_loss:  528.4598334473595   time:  1.8059914112091064
e:  62   train_loss:  527.2661066991566   time:  1.7613167762756348
e:  63   train_loss:  526.5204647160986   time:  1.708925724029541
e:  64   train_loss:  525.0455724360879   time:  1.8008103370666504
e:  65   train_loss:  524.4049156695571   time:  1.965980052947998
e:  65   train_loss:  524.4049156695571   val_loss:  1372.936662140118   time:  2.078834056854248
e:  66   train_loss:  523.2664198416903   time:  1.771418809890747
e:  67   train_loss:  521.6059674084618   time:  1.7822022438049316
e:  68   train_loss:  520.5520421861186   time:  1.7850511074066162
e:  69   train_loss:  520.1951162489395   time:  1.7770349979400635
e:  70   train_loss:  518.5701857829939   time:  1.7633938789367676
e:  70   train_loss:  518.5701857829939   val_loss:  1359.5169596365138   time:  1.881964921951294
e:  71   train_loss:  517.6217814943232   time:  1.720141887664795
e:  72   train_loss:  515.780819701753   time:  1.7048468589782715
e:  73   train_loss:  514.6301733237088   time:  1.7817950248718262
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  74   train_loss:  513.90433372491   time:  1.8752470016479492
e:  75   train_loss:  513.1597788242005   time:  1.7582614421844482
e:  75   train_loss:  513.1597788242005   val_loss:  1368.6021153623062   time:  1.8791096210479736
e:  76   train_loss:  511.7197580800615   time:  1.7337913513183594
e:  77   train_loss:  509.9633747602087   time:  1.740894079208374
e:  78   train_loss:  509.8327258014006   time:  1.740210771560669
e:  79   train_loss:  508.66263754755096   time:  1.712052345275879
e:  80   train_loss:  506.09556545138383   time:  1.7153196334838867
e:  80   train_loss:  506.09556545138383   val_loss:  1362.9309089826256   time:  1.8552470207214355
e:  81   train_loss:  505.81695207474036   time:  1.7385916709899902
e:  82   train_loss:  504.40280619448896   time:  1.7891855239868164
e:  83   train_loss:  502.73368302698304   time:  1.9715394973754883
e:  84   train_loss:  502.86172989814065   time:  1.7375972270965576
e:  85   train_loss:  501.8393770162134   time:  1.7909541130065918
e:  85   train_loss:  501.8393770162134   val_loss:  1355.242383796881   time:  1.9111170768737793
e:  86   train_loss:  500.6285044911723   time:  1.7928946018218994
e:  87   train_loss:  499.4767227416206   time:  1.7887694835662842
e:  88   train_loss:  498.2406991622808   time:  1.7837822437286377
e:  89   train_loss:  497.1086637746232   time:  1.795541524887085
e:  90   train_loss:  497.61984807478734   time:  1.7665526866912842
e:  90   train_loss:  497.61984807478734   val_loss:  1372.9781620667939   time:  1.886451005935669
e:  91   train_loss:  494.83014093759255   time:  1.8044254779815674
e:  92   train_loss:  494.49714756653583   time:  1.779740571975708
e:  93   train_loss:  493.59803802221245   time:  1.786700963973999
e:  94   train_loss:  493.3841672842873   time:  1.7854580879211426
e:  95   train_loss:  492.1922785724541   time:  2.0031075477600098
e:  95   train_loss:  492.1922785724541   val_loss:  1363.2654889342245   time:  2.113694429397583
e:  96   train_loss:  490.3864220656876   time:  1.7233755588531494
e:  97   train_loss:  489.70145937657804   time:  1.7823007106781006
e:  98   train_loss:  488.9911837756523   time:  1.7812063694000244
e:  99   train_loss:  488.42341591396314   time:  1.790912389755249
e:  100   train_loss:  486.91747381099776   time:  1.7969553470611572
e:  100   train_loss:  486.91747381099776   val_loss:  1372.5293319924701   time:  1.9179291725158691
e:  101   train_loss:  485.84781295568814   time:  1.7874855995178223
e:  102   train_loss:  485.6999459419306   time:  1.81532621383667
e:  103   train_loss:  484.68648896666986   time:  1.7750611305236816
e:  104   train_loss:  484.426724380139   time:  1.787621021270752
e:  105   train_loss:  482.56087400033636   time:  1.961761713027954
e:  105   train_loss:  482.56087400033636   val_loss:  1385.6273025400276   time:  2.075469732284546
e:  106   train_loss:  482.7010522498347   time:  1.7954347133636475
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  107   train_loss:  480.51006379577234   time:  1.783634901046753
e:  108   train_loss:  481.3523481714266   time:  1.777360200881958
e:  109   train_loss:  478.8917864603952   time:  1.770991325378418
e:  110   train_loss:  478.81306791737035   time:  1.7402801513671875
e:  110   train_loss:  478.81306791737035   val_loss:  1398.290638131879   time:  1.8602104187011719
e:  111   train_loss:  477.88937626045066   time:  1.7948293685913086
e:  112   train_loss:  477.43054330919426   time:  1.7076773643493652
e:  113   train_loss:  475.7643370571259   time:  1.7098994255065918
e:  114   train_loss:  475.43619361905735   time:  1.928931474685669
e:  115   train_loss:  474.6549406966002   time:  1.757735252380371
e:  115   train_loss:  474.6549406966002   val_loss:  1353.4215018105897   time:  1.8782024383544922
e:  116   train_loss:  485.53406253061627   time:  1.7701165676116943
e:  117   train_loss:  480.12675027572556   time:  1.804823637008667
e:  118   train_loss:  473.61489151174396   time:  1.8027567863464355
e:  119   train_loss:  471.4605054011171   time:  1.7977781295776367
e:  120   train_loss:  470.862244837769   time:  1.7996296882629395
e:  120   train_loss:  470.862244837769   val_loss:  1389.5522732676004   time:  1.9210569858551025
e:  121   train_loss:  476.46423687824483   time:  1.7954609394073486
e:  122   train_loss:  477.8675142938462   time:  1.784965991973877
e:  123   train_loss:  472.7673761215866   time:  1.7778780460357666
e:  124   train_loss:  470.71155258645445   time:  1.7812440395355225
e:  125   train_loss:  477.3608068980706   time:  1.7907941341400146
e:  125   train_loss:  477.3608068980706   val_loss:  1416.106167983821   time:  2.0985991954803467
e:  126   train_loss:  468.6653259427894   time:  1.7840700149536133
e:  127   train_loss:  467.061089117562   time:  1.8183934688568115
e:  128   train_loss:  470.7255249883644   time:  1.7145099639892578
e:  129   train_loss:  468.4730280293607   time:  1.6848258972167969
e:  130   train_loss:  473.0548955837534   time:  1.7043912410736084
e:  130   train_loss:  473.0548955837534   val_loss:  1397.9410066127605   time:  1.8228061199188232
e:  131   train_loss:  473.4204935354735   time:  1.7677052021026611
e:  132   train_loss:  475.6086035295773   time:  1.789628028869629
e:  133   train_loss:  475.54185568508507   time:  1.7695608139038086
e:  134   train_loss:  464.7291811411069   time:  1.7857296466827393
e:  135   train_loss:  463.49377965884185   time:  1.7215888500213623
e:  135   train_loss:  463.49377965884185   val_loss:  1410.0721667489306   time:  1.8399956226348877
e:  136   train_loss:  462.7730517249961   time:  1.9045147895812988
e:  137   train_loss:  464.54087414347725   time:  1.7936031818389893
e:  138   train_loss:  465.0024900950013   time:  1.7280125617980957
e:  139   train_loss:  466.32914636437795   time:  1.7748749256134033
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  140   train_loss:  462.18088727853456   time:  1.7852435111999512
e:  140   train_loss:  462.18088727853456   val_loss:  1386.9198854684246   time:  1.9059302806854248
e:  141   train_loss:  465.36544633378855   time:  1.7707810401916504
e:  142   train_loss:  460.24133372176533   time:  1.7657740116119385
e:  143   train_loss:  461.4019630335729   time:  1.785405158996582
e:  144   train_loss:  460.36843497974667   time:  1.7421388626098633
e:  145   train_loss:  459.1992293668999   time:  1.7170631885528564
e:  145   train_loss:  459.1992293668999   val_loss:  1397.0731592948607   time:  2.0196268558502197
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1078.487439552348   time:  1.8398749828338623
e:  0   train_loss:  1078.487439552348   val_loss:  598.9577364864064   time:  1.950486660003662
e:  1   train_loss:  1009.7856128712137   time:  1.890866756439209
e:  2   train_loss:  914.5326885291482   time:  1.8510181903839111
e:  3   train_loss:  907.1112242046969   time:  1.8131508827209473
e:  4   train_loss:  901.2619430537047   time:  1.8780057430267334
e:  5   train_loss:  893.4119081568213   time:  1.842820405960083
e:  5   train_loss:  893.4119081568213   val_loss:  553.9062373944854   time:  2.081885814666748
e:  6   train_loss:  907.8894615557525   time:  1.7817928791046143
e:  7   train_loss:  905.3851354046968   time:  1.779616355895996
e:  8   train_loss:  887.9598941103496   time:  1.7840938568115234
e:  9   train_loss:  904.5529201986758   time:  1.7798316478729248
e:  10   train_loss:  892.6468668266393   time:  1.7952299118041992
e:  10   train_loss:  892.6468668266393   val_loss:  552.8234887904763   time:  1.9064555168151855
e:  11   train_loss:  919.0811846774923   time:  1.8722343444824219
e:  12   train_loss:  890.4886587852689   time:  1.8191721439361572
e:  13   train_loss:  899.7584364799553   time:  1.9697186946868896
e:  14   train_loss:  882.4691977335711   time:  1.876392126083374
e:  15   train_loss:  870.3931263890897   time:  1.8165833950042725
e:  15   train_loss:  870.3931263890897   val_loss:  548.5777376979678   time:  1.9257099628448486
e:  16   train_loss:  863.4431032648931   time:  1.806455135345459
e:  17   train_loss:  869.2454043921523   time:  1.7807292938232422
e:  18   train_loss:  864.4398476373731   time:  1.7796008586883545
e:  19   train_loss:  857.487454290765   time:  1.9048261642456055
e:  20   train_loss:  842.8534819276441   time:  1.7871885299682617
e:  20   train_loss:  842.8534819276441   val_loss:  542.2168321365367   time:  1.8968994617462158
e:  21   train_loss:  847.7214316504361   time:  1.7753896713256836
e:  22   train_loss:  839.1288863171034   time:  1.8604824542999268
e:  23   train_loss:  837.2490999010959   time:  1.8691697120666504
e:  24   train_loss:  831.7939708634899   time:  1.789402723312378
e:  25   train_loss:  816.4261222606877   time:  1.9681260585784912
e:  25   train_loss:  816.4261222606877   val_loss:  542.0594395683771   time:  2.0806334018707275
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  26   train_loss:  809.5257890349371   time:  1.8773503303527832
e:  27   train_loss:  800.6289627449594   time:  1.84708571434021
e:  28   train_loss:  790.2796125149086   time:  1.7965171337127686
e:  29   train_loss:  789.8070777161699   time:  1.84059476852417
e:  30   train_loss:  766.9149367519021   time:  1.8465688228607178
e:  30   train_loss:  766.9149367519021   val_loss:  542.0513266227878   time:  1.9568126201629639
e:  31   train_loss:  762.3795807334404   time:  1.8076140880584717
e:  32   train_loss:  745.18323103301   time:  1.9557862281799316
e:  33   train_loss:  732.6808448099558   time:  1.8768627643585205
e:  34   train_loss:  724.6144181539962   time:  1.871567964553833
e:  35   train_loss:  706.361543065449   time:  1.8661320209503174
e:  35   train_loss:  706.361543065449   val_loss:  642.0010059629655   time:  1.9761378765106201
e:  36   train_loss:  699.0087413188319   time:  1.7841746807098389
e:  37   train_loss:  687.1707022578526   time:  1.8249280452728271
e:  38   train_loss:  683.2339743417888   time:  1.9897053241729736
e:  39   train_loss:  668.2648930974706   time:  1.8693461418151855
e:  40   train_loss:  676.3026280677007   time:  1.865962028503418
e:  40   train_loss:  676.3026280677007   val_loss:  845.0370419830231   time:  1.9771103858947754
e:  41   train_loss:  678.8150555972503   time:  1.818082571029663
e:  42   train_loss:  663.4733682361971   time:  1.8322761058807373
e:  43   train_loss:  669.7532283184105   time:  1.807969093322754
e:  44   train_loss:  665.1348438080686   time:  2.036073684692383
e:  45   train_loss:  656.0255535372929   time:  1.869335412979126
e:  45   train_loss:  656.0255535372929   val_loss:  831.1464475739573   time:  1.9786911010742188
e:  46   train_loss:  662.2103993379595   time:  1.7838702201843262
e:  47   train_loss:  655.7498169497044   time:  1.8143346309661865
e:  48   train_loss:  656.8288947150248   time:  1.8031392097473145
e:  49   train_loss:  650.3592205484626   time:  1.8584511280059814
e:  50   train_loss:  657.017173457284   time:  1.8542141914367676
e:  50   train_loss:  657.017173457284   val_loss:  818.6096915172586   time:  1.9657623767852783
e:  51   train_loss:  652.8743480159751   time:  2.02640700340271
e:  52   train_loss:  642.649181883323   time:  1.8700408935546875
e:  53   train_loss:  653.8175907629154   time:  1.8698022365570068
e:  54   train_loss:  641.9660148728151   time:  1.777489185333252
e:  55   train_loss:  646.450813815091   time:  1.8227458000183105
e:  55   train_loss:  646.450813815091   val_loss:  955.8126720461732   time:  1.9344027042388916
e:  56   train_loss:  657.9328300979339   time:  1.834672212600708
e:  57   train_loss:  639.3659279988219   time:  1.8653736114501953
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  58   train_loss:  635.1989399746573   time:  1.9830079078674316
e:  59   train_loss:  638.7791377412167   time:  1.8724722862243652
e:  60   train_loss:  632.3178314364748   time:  1.7809722423553467
e:  60   train_loss:  632.3178314364748   val_loss:  916.0674641236104   time:  1.8908579349517822
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1074.65658003852   time:  1.815617322921753
e:  0   train_loss:  1074.65658003852   val_loss:  516.8992546085663   time:  1.9284000396728516
e:  1   train_loss:  1004.7545380010077   time:  1.7932491302490234
e:  2   train_loss:  908.8152321618439   time:  1.7656455039978027
e:  3   train_loss:  893.9601350026373   time:  1.7485954761505127
e:  4   train_loss:  921.4682426099573   time:  1.7835533618927002
e:  5   train_loss:  868.8162496529767   time:  1.957965612411499
e:  5   train_loss:  868.8162496529767   val_loss:  495.5646499374361   time:  2.0724027156829834
e:  6   train_loss:  899.7581816490505   time:  1.784769058227539
e:  7   train_loss:  879.4939984484473   time:  1.8263742923736572
e:  8   train_loss:  913.3593570154709   time:  1.7889578342437744
e:  9   train_loss:  872.8540821825384   time:  1.7703466415405273
e:  10   train_loss:  913.5720174511666   time:  1.833533763885498
e:  10   train_loss:  913.5720174511666   val_loss:  498.5388552129819   time:  1.9488794803619385
e:  11   train_loss:  900.1479635346776   time:  1.9944465160369873
e:  12   train_loss:  887.9392597176675   time:  1.843686580657959
e:  13   train_loss:  884.4763429267018   time:  1.7801616191864014
e:  14   train_loss:  907.8701817369251   time:  1.7585012912750244
e:  15   train_loss:  862.2579205962734   time:  1.808074951171875
e:  15   train_loss:  862.2579205962734   val_loss:  493.10813233610094   time:  1.9226596355438232
e:  16   train_loss:  872.6473738964478   time:  1.8408868312835693
e:  17   train_loss:  885.6857505002573   time:  1.8455994129180908
e:  18   train_loss:  919.6710532522642   time:  1.8041620254516602
e:  19   train_loss:  825.7833797753351   time:  1.9071762561798096
e:  20   train_loss:  844.4078546007846   time:  1.845315933227539
e:  20   train_loss:  844.4078546007846   val_loss:  489.28666421300267   time:  1.9591104984283447
e:  21   train_loss:  870.0450938459626   time:  1.7697899341583252
e:  22   train_loss:  868.4043903437388   time:  1.8181195259094238
e:  23   train_loss:  834.0457991917365   time:  1.8206429481506348
e:  24   train_loss:  832.8035921158953   time:  1.7987611293792725
e:  25   train_loss:  808.4238543681595   time:  1.7988932132720947
e:  25   train_loss:  808.4238543681595   val_loss:  491.9438384237996   time:  1.9141156673431396
e:  26   train_loss:  825.9952864749725   time:  1.9779114723205566
e:  27   train_loss:  804.2723713054882   time:  1.8437604904174805
e:  28   train_loss:  804.3621789563158   time:  1.822540521621704
e:  29   train_loss:  800.4099935640093   time:  1.7547650337219238
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  30   train_loss:  793.0723495812701   time:  1.7679626941680908
e:  30   train_loss:  793.0723495812701   val_loss:  497.5670785411327   time:  1.8822271823883057
e:  31   train_loss:  761.4987784676039   time:  1.792856216430664
e:  32   train_loss:  772.5719128766593   time:  1.755345106124878
e:  33   train_loss:  753.1786775568196   time:  1.8610281944274902
e:  34   train_loss:  766.0950653164485   time:  1.9675006866455078
e:  35   train_loss:  746.2481480005598   time:  1.7637712955474854
e:  35   train_loss:  746.2481480005598   val_loss:  593.4674866956797   time:  1.876936435699463
e:  36   train_loss:  730.2816547142971   time:  1.781240701675415
e:  37   train_loss:  768.7983280237672   time:  1.8273842334747314
e:  38   train_loss:  719.8951722102457   time:  1.8295400142669678
e:  39   train_loss:  706.0555846826461   time:  1.7562966346740723
e:  40   train_loss:  701.1590388523776   time:  1.804950475692749
e:  40   train_loss:  701.1590388523776   val_loss:  493.6772220362581   time:  1.9214136600494385
e:  41   train_loss:  710.1253013000351   time:  1.968839168548584
e:  42   train_loss:  694.9922131599022   time:  1.7557594776153564
e:  43   train_loss:  680.137398260818   time:  1.7948145866394043
e:  44   train_loss:  674.0071600442833   time:  1.8018295764923096
e:  45   train_loss:  695.7095650947828   time:  1.76289963722229
e:  45   train_loss:  695.7095650947828   val_loss:  465.799478884188   time:  1.877166509628296
e:  46   train_loss:  719.5443047535023   time:  1.8368802070617676
e:  47   train_loss:  690.9269792903119   time:  1.7576801776885986
e:  48   train_loss:  673.4870995027879   time:  1.9236540794372559
e:  49   train_loss:  696.9332941811803   time:  1.846947193145752
e:  50   train_loss:  687.3032004549087   time:  1.8399579524993896
e:  50   train_loss:  687.3032004549087   val_loss:  471.34329441996397   time:  1.9553923606872559
e:  51   train_loss:  658.3112065236337   time:  1.7635080814361572
e:  52   train_loss:  687.914741547727   time:  1.7506639957427979
e:  53   train_loss:  676.6566162781995   time:  1.7536330223083496
e:  54   train_loss:  660.8705878242422   time:  1.8196351528167725
e:  55   train_loss:  671.3543961103637   time:  1.838806390762329
e:  55   train_loss:  671.3543961103637   val_loss:  551.811655008962   time:  2.0820810794830322
e:  56   train_loss:  678.3592745871792   time:  1.8430225849151611
e:  57   train_loss:  682.6278362174077   time:  1.8351233005523682
e:  58   train_loss:  651.3103538747932   time:  1.7594964504241943
e:  59   train_loss:  654.7623417340003   time:  1.8116505146026611
e:  60   train_loss:  677.9430686807179   time:  1.8347506523132324
e:  60   train_loss:  677.9430686807179   val_loss:  522.0804976823783   time:  1.95054292678833
e:  61   train_loss:  676.5772957175311   time:  1.844132900238037
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  62   train_loss:  653.4996983835223   time:  1.8419337272644043
e:  63   train_loss:  697.0525695894002   time:  1.9609816074371338
e:  64   train_loss:  657.8283594409936   time:  1.841296672821045
e:  65   train_loss:  662.731315495409   time:  1.8392677307128906
e:  65   train_loss:  662.731315495409   val_loss:  507.60738525213696   time:  1.9550063610076904
e:  66   train_loss:  663.5882002708547   time:  1.854893445968628
e:  67   train_loss:  663.061211097469   time:  1.7787666320800781
e:  68   train_loss:  661.8136820130211   time:  1.780637502670288
e:  69   train_loss:  638.0011160577836   time:  1.8353276252746582
e:  70   train_loss:  674.3103640857312   time:  1.966238021850586
e:  70   train_loss:  674.3103640857312   val_loss:  462.9814020734751   time:  2.0802981853485107
e:  71   train_loss:  657.446112392267   time:  1.8020100593566895
e:  72   train_loss:  648.3890671239611   time:  1.7575910091400146
e:  73   train_loss:  640.8594482177357   time:  1.785287618637085
e:  74   train_loss:  651.7778258998901   time:  1.8415780067443848
e:  75   train_loss:  711.1388797256391   time:  1.8371853828430176
e:  75   train_loss:  711.1388797256391   val_loss:  538.7946968758406   time:  1.9527254104614258
e:  76   train_loss:  647.1636584915375   time:  1.843646764755249
e:  77   train_loss:  636.6754436830815   time:  1.97969388961792
e:  78   train_loss:  684.3296855605905   time:  1.7740767002105713
e:  79   train_loss:  672.3423957277147   time:  1.794661521911621
e:  80   train_loss:  639.3316293678865   time:  1.7596373558044434
e:  80   train_loss:  639.3316293678865   val_loss:  536.482832962559   time:  1.8743314743041992
e:  81   train_loss:  638.4664435745443   time:  1.8318684101104736
e:  82   train_loss:  659.0285947941134   time:  1.8353650569915771
e:  83   train_loss:  656.1455928068975   time:  1.7966597080230713
e:  84   train_loss:  645.7672087136901   time:  1.7901654243469238
e:  85   train_loss:  642.7111843703098   time:  1.9556150436401367
e:  85   train_loss:  642.7111843703098   val_loss:  578.6900339174352   time:  2.071460008621216
e:  86   train_loss:  646.589413751724   time:  1.842402458190918
e:  87   train_loss:  645.3050896280606   time:  1.839660882949829
e:  88   train_loss:  685.676054992139   time:  1.8428692817687988
e:  89   train_loss:  675.7520326038383   time:  1.8403534889221191
e:  90   train_loss:  653.7198460303239   time:  1.7509446144104004
e:  90   train_loss:  653.7198460303239   val_loss:  514.3485616031513   time:  1.863534688949585
e:  91   train_loss:  645.7601356240273   time:  1.7632725238800049
e:  92   train_loss:  630.1418124376391   time:  1.8788750171661377
e:  93   train_loss:  622.709561706796   time:  1.8187763690948486
e:  94   train_loss:  633.471039055794   time:  1.845717191696167
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  95   train_loss:  629.0679469316051   time:  1.8423633575439453
e:  95   train_loss:  629.0679469316051   val_loss:  480.0383746243537   time:  1.9588687419891357
e:  96   train_loss:  621.7784829739778   time:  1.8410155773162842
e:  97   train_loss:  626.5570012105286   time:  1.8112754821777344
e:  98   train_loss:  644.0343509027068   time:  1.8049750328063965
e:  99   train_loss:  642.4204673904483   time:  1.8141276836395264
e:  100   train_loss:  618.7473790606778   time:  1.904675006866455
e:  100   train_loss:  618.7473790606778   val_loss:  524.8211050616957   time:  2.0201165676116943
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  987.528682488672   time:  1.709026575088501
e:  0   train_loss:  987.528682488672   val_loss:  886.3257561405044   time:  1.8309454917907715
e:  1   train_loss:  942.7975174131685   time:  1.7039356231689453
e:  2   train_loss:  871.6059577682416   time:  1.6975517272949219
e:  3   train_loss:  839.1954981225084   time:  1.7278153896331787
e:  4   train_loss:  837.030118081719   time:  1.7184338569641113
e:  5   train_loss:  838.7541428463344   time:  1.6927976608276367
e:  5   train_loss:  838.7541428463344   val_loss:  740.5121143318363   time:  1.8128364086151123
e:  6   train_loss:  835.8840813946168   time:  1.6585872173309326
e:  7   train_loss:  832.7980812092288   time:  1.6565430164337158
e:  8   train_loss:  829.9269165899342   time:  1.6794049739837646
e:  9   train_loss:  829.8742515628651   time:  1.8309733867645264
e:  10   train_loss:  828.6808427187985   time:  1.71445631980896
e:  10   train_loss:  828.6808427187985   val_loss:  737.307114693145   time:  1.8357014656066895
e:  11   train_loss:  827.5505254358445   time:  1.7239539623260498
e:  12   train_loss:  824.8794081457249   time:  1.7220380306243896
e:  13   train_loss:  822.2798655821056   time:  1.715015172958374
e:  14   train_loss:  826.8505016856868   time:  1.7154903411865234
e:  15   train_loss:  822.342571997393   time:  1.6878635883331299
e:  15   train_loss:  822.342571997393   val_loss:  733.3765197285131   time:  1.8069195747375488
e:  16   train_loss:  819.1713906529666   time:  1.6408040523529053
e:  17   train_loss:  817.9128541244949   time:  1.6385014057159424
e:  18   train_loss:  814.5704277433975   time:  1.6350383758544922
e:  19   train_loss:  811.9875682982109   time:  1.6974422931671143
e:  20   train_loss:  810.484701378033   time:  1.833909273147583
e:  20   train_loss:  810.484701378033   val_loss:  728.6562696740195   time:  1.9561293125152588
e:  21   train_loss:  805.844236365232   time:  1.712045431137085
e:  22   train_loss:  805.2885889686518   time:  1.709266185760498
e:  23   train_loss:  799.1261836305954   time:  1.7145466804504395
e:  24   train_loss:  800.5626262936048   time:  1.7332587242126465
e:  25   train_loss:  792.4877274315403   time:  1.749251127243042
e:  25   train_loss:  792.4877274315403   val_loss:  722.541819594899   time:  1.8721590042114258
e:  26   train_loss:  791.6225783394153   time:  1.7228784561157227
e:  27   train_loss:  782.8985431217249   time:  1.7401387691497803
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  28   train_loss:  781.9570875080409   time:  1.7200331687927246
e:  29   train_loss:  775.8207018251295   time:  1.875382661819458
e:  30   train_loss:  774.1312423212576   time:  1.7515037059783936
e:  30   train_loss:  774.1312423212576   val_loss:  715.9135379274867   time:  1.86421799659729
e:  31   train_loss:  767.4989423210159   time:  1.7353463172912598
e:  32   train_loss:  762.5262410901544   time:  1.718864917755127
e:  33   train_loss:  756.3284064170282   time:  1.774688959121704
e:  34   train_loss:  751.8157030581597   time:  1.705336093902588
e:  35   train_loss:  742.099176873352   time:  1.737114667892456
e:  35   train_loss:  742.099176873352   val_loss:  710.2038516506589   time:  1.857666015625
e:  36   train_loss:  735.1338906468945   time:  1.7429132461547852
e:  37   train_loss:  730.3352509503043   time:  1.7066948413848877
e:  38   train_loss:  719.29926698306   time:  1.82542085647583
e:  39   train_loss:  711.2628961953958   time:  1.7434308528900146
e:  40   train_loss:  703.4184983392148   time:  1.7093420028686523
e:  40   train_loss:  703.4184983392148   val_loss:  705.0850947466466   time:  1.829698085784912
e:  41   train_loss:  697.247977276497   time:  1.73671555519104
e:  42   train_loss:  687.850291681698   time:  1.7707252502441406
e:  43   train_loss:  684.5207827358497   time:  1.7770543098449707
e:  44   train_loss:  673.0668620364745   time:  1.7182896137237549
e:  45   train_loss:  672.8928311809204   time:  1.7782740592956543
e:  45   train_loss:  672.8928311809204   val_loss:  705.1840194431034   time:  1.9003355503082275
e:  46   train_loss:  662.4237705647109   time:  1.7691164016723633
e:  47   train_loss:  658.7247882573811   time:  1.7936854362487793
e:  48   train_loss:  653.3713953781611   time:  1.7921130657196045
e:  49   train_loss:  650.1322463462024   time:  1.7509171962738037
e:  50   train_loss:  645.3874539271726   time:  1.6972308158874512
e:  50   train_loss:  645.3874539271726   val_loss:  713.4002953549368   time:  1.9507255554199219
e:  51   train_loss:  648.341538291237   time:  1.6637742519378662
e:  52   train_loss:  644.8116962226727   time:  1.7172696590423584
e:  53   train_loss:  643.8014128715355   time:  1.7320995330810547
e:  54   train_loss:  635.8068749246427   time:  1.7257988452911377
e:  55   train_loss:  637.1082462483265   time:  1.717583417892456
e:  55   train_loss:  637.1082462483265   val_loss:  707.4019776167625   time:  1.8387959003448486
e:  56   train_loss:  638.2147633341092   time:  1.739403486251831
e:  57   train_loss:  635.2515355116635   time:  1.7344393730163574
e:  58   train_loss:  632.3041606765246   time:  1.7325611114501953
e:  59   train_loss:  630.9689154475775   time:  1.8585431575775146
e:  60   train_loss:  626.5592675744535   time:  1.6840119361877441
e:  60   train_loss:  626.5592675744535   val_loss:  698.3027471414264   time:  1.7958011627197266
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  61   train_loss:  630.6470929661643   time:  1.7470805644989014
e:  62   train_loss:  630.5064120439501   time:  1.7318904399871826
e:  63   train_loss:  630.3485493165654   time:  1.7369897365570068
e:  64   train_loss:  624.3444100474725   time:  1.7349820137023926
e:  65   train_loss:  623.3509694932789   time:  1.8489525318145752
e:  65   train_loss:  623.3509694932789   val_loss:  693.0774178611323   time:  1.9711716175079346
e:  66   train_loss:  626.4208420413478   time:  1.7325537204742432
e:  67   train_loss:  625.5888544803211   time:  1.7158725261688232
e:  68   train_loss:  642.5000410093743   time:  1.7679438591003418
e:  69   train_loss:  621.2366039762434   time:  1.7657713890075684
e:  70   train_loss:  618.9166947530712   time:  1.797642469406128
e:  70   train_loss:  618.9166947530712   val_loss:  697.0294599079008   time:  1.9206202030181885
e:  71   train_loss:  622.7950708702859   time:  1.9579768180847168
e:  72   train_loss:  618.8341647568709   time:  1.8157169818878174
e:  73   train_loss:  615.1324300290535   time:  1.7629141807556152
e:  74   train_loss:  616.5969908793035   time:  1.8234951496124268
e:  75   train_loss:  617.3415068171489   time:  1.79404878616333
e:  75   train_loss:  617.3415068171489   val_loss:  689.8848636116164   time:  1.967677354812622
e:  76   train_loss:  619.3893018473129   time:  1.829204797744751
e:  77   train_loss:  611.4015295375136   time:  1.8352713584899902
e:  78   train_loss:  617.6537107041752   time:  1.8146321773529053
e:  79   train_loss:  617.0622895530282   time:  1.8389739990234375
e:  80   train_loss:  618.5681036576219   time:  1.7602324485778809
e:  80   train_loss:  618.5681036576219   val_loss:  682.85769006213   time:  2.0248138904571533
e:  81   train_loss:  614.4462605097167   time:  1.7464423179626465
e:  82   train_loss:  619.4802957530034   time:  1.7912139892578125
e:  83   train_loss:  621.5295102550529   time:  1.8297984600067139
e:  84   train_loss:  607.3714767942485   time:  1.745739459991455
e:  85   train_loss:  609.4096435661091   time:  1.781736135482788
e:  85   train_loss:  609.4096435661091   val_loss:  692.2327051214598   time:  1.9058771133422852
e:  86   train_loss:  607.8216458674868   time:  1.739706039428711
e:  87   train_loss:  604.5534580070433   time:  1.8032262325286865
e:  88   train_loss:  608.1914729479012   time:  1.7454490661621094
e:  89   train_loss:  604.659107151546   time:  1.767725944519043
e:  90   train_loss:  606.7599320920461   time:  1.7506957054138184
e:  90   train_loss:  606.7599320920461   val_loss:  691.1218749315776   time:  1.8990986347198486
e:  91   train_loss:  611.7197230597928   time:  1.9031808376312256
e:  92   train_loss:  605.4061521802856   time:  1.7237765789031982
e:  93   train_loss:  607.1162600555508   time:  1.7354989051818848
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  94   train_loss:  604.0891084023905   time:  1.7418897151947021
e:  95   train_loss:  618.4435362891167   time:  1.7321975231170654
e:  95   train_loss:  618.4435362891167   val_loss:  693.6192622278555   time:  1.9052839279174805
e:  96   train_loss:  602.6387967254072   time:  1.7706334590911865
e:  97   train_loss:  599.5436914131636   time:  1.7672417163848877
e:  98   train_loss:  598.0000720174365   time:  1.7803499698638916
e:  99   train_loss:  598.201451865617   time:  1.7431986331939697
e:  100   train_loss:  601.1269542147822   time:  1.737257480621338
e:  100   train_loss:  601.1269542147822   val_loss:  675.6743078170338   time:  1.8594090938568115
e:  101   train_loss:  595.2597548892537   time:  1.7733500003814697
e:  102   train_loss:  622.923325740045   time:  1.7679808139801025
e:  103   train_loss:  599.3270033342231   time:  1.912644863128662
e:  104   train_loss:  598.7966209966494   time:  1.7589468955993652
e:  105   train_loss:  599.6005553499516   time:  1.760401725769043
e:  105   train_loss:  599.6005553499516   val_loss:  686.639064013439   time:  1.883591651916504
e:  106   train_loss:  593.163125439871   time:  1.7677795886993408
e:  107   train_loss:  610.9302702093077   time:  1.7618825435638428
e:  108   train_loss:  602.0206181269574   time:  1.7411987781524658
e:  109   train_loss:  593.698426975133   time:  1.7512233257293701
e:  110   train_loss:  597.3527423952141   time:  1.7524700164794922
e:  110   train_loss:  597.3527423952141   val_loss:  672.5762238169707   time:  1.8963913917541504
e:  111   train_loss:  596.0597656912198   time:  1.7933430671691895
e:  112   train_loss:  594.2965519362492   time:  1.7820029258728027
e:  113   train_loss:  592.9809854840024   time:  1.7830560207366943
e:  114   train_loss:  617.7250500012663   time:  1.757204532623291
e:  115   train_loss:  588.9268685855225   time:  1.772089958190918
e:  115   train_loss:  588.9268685855225   val_loss:  668.1961719835972   time:  2.02581787109375
e:  116   train_loss:  593.443436889573   time:  1.7439892292022705
e:  117   train_loss:  586.6676341474093   time:  1.7068710327148438
e:  118   train_loss:  592.2982289431268   time:  1.7387983798980713
e:  119   train_loss:  589.7815686489348   time:  1.7462782859802246
e:  120   train_loss:  604.3725833024946   time:  1.7595975399017334
e:  120   train_loss:  604.3725833024946   val_loss:  668.2313040012117   time:  1.8820774555206299
e:  121   train_loss:  591.5272671168311   time:  1.7519540786743164
e:  122   train_loss:  587.6275566119353   time:  1.8172502517700195
e:  123   train_loss:  589.1175590468249   time:  1.7317228317260742
e:  124   train_loss:  583.9699575910698   time:  1.7716774940490723
e:  125   train_loss:  605.1229440239161   time:  1.85490083694458
e:  125   train_loss:  605.1229440239161   val_loss:  695.3579489218703   time:  1.9771077632904053
e:  126   train_loss:  589.5096408687826   time:  1.7502925395965576
e:  127   train_loss:  585.7582822725661   time:  1.789909839630127
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  128   train_loss:  580.7193147867532   time:  1.7452311515808105
e:  129   train_loss:  608.0414427643125   time:  1.7652654647827148
e:  130   train_loss:  583.0709810344939   time:  1.755955696105957
e:  130   train_loss:  583.0709810344939   val_loss:  665.1207821633698   time:  1.8785533905029297
e:  131   train_loss:  585.1044576551714   time:  1.7464945316314697
e:  132   train_loss:  590.2332288675515   time:  1.774714708328247
e:  133   train_loss:  579.422405618336   time:  1.706453561782837
e:  134   train_loss:  577.8323048459233   time:  1.8745372295379639
e:  135   train_loss:  582.6228603323848   time:  1.6778144836425781
e:  135   train_loss:  582.6228603323848   val_loss:  713.9554799326437   time:  1.7975871562957764
e:  136   train_loss:  595.328879220104   time:  1.7114675045013428
e:  137   train_loss:  575.7400655319672   time:  1.7453649044036865
e:  138   train_loss:  584.4368633559876   time:  1.7639095783233643
e:  139   train_loss:  582.1040349559103   time:  1.7571086883544922
e:  140   train_loss:  586.8146994875083   time:  1.7819926738739014
e:  140   train_loss:  586.8146994875083   val_loss:  665.8877916512205   time:  1.9038724899291992
e:  141   train_loss:  573.5464285778487   time:  1.7630131244659424
e:  142   train_loss:  576.9464194364588   time:  1.764284610748291
e:  143   train_loss:  575.0090653049189   time:  1.900951862335205
e:  144   train_loss:  577.4518527342636   time:  1.7922959327697754
e:  145   train_loss:  575.6332928703894   time:  1.7749667167663574
e:  145   train_loss:  575.6332928703894   val_loss:  712.0497229021764   time:  1.8969697952270508
e:  146   train_loss:  584.7169873261691   time:  1.7740912437438965
e:  147   train_loss:  574.2104480870751   time:  1.7561943531036377
e:  148   train_loss:  577.7003752042297   time:  1.7494471073150635
e:  149   train_loss:  570.3960321186523   time:  1.6822569370269775
e:  150   train_loss:  613.5786956039228   time:  1.7103252410888672
e:  150   train_loss:  613.5786956039228   val_loss:  672.3601706144084   time:  1.8325598239898682
e:  151   train_loss:  589.6371596459278   time:  1.754737377166748
e:  152   train_loss:  578.4343228911192   time:  1.778557538986206
e:  153   train_loss:  571.977821234201   time:  1.7631478309631348
e:  154   train_loss:  571.7253582512142   time:  1.7605419158935547
e:  155   train_loss:  567.9431213000358   time:  1.7561450004577637
e:  155   train_loss:  567.9431213000358   val_loss:  676.2406358875642   time:  2.0254368782043457
e:  156   train_loss:  598.0802383832065   time:  1.776642084121704
e:  157   train_loss:  575.5078230009478   time:  1.7683000564575195
e:  158   train_loss:  578.8179531411262   time:  1.7852013111114502
e:  159   train_loss:  567.4333750177246   time:  1.771543025970459
e:  160   train_loss:  569.4304189441575   time:  1.756112813949585
e:  160   train_loss:  569.4304189441575   val_loss:  676.7390310648074   time:  1.878725290298462
FOLD:  4
Model initialization done
Model training starts
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  0   train_loss:  1051.6865244831597   time:  1.9333572387695312
e:  0   train_loss:  1051.6865244831597   val_loss:  659.275353113289   time:  2.046313762664795
e:  1   train_loss:  1000.9876599563935   time:  1.8545498847961426
e:  2   train_loss:  943.2526753931365   time:  2.032010316848755
e:  3   train_loss:  897.9647037463282   time:  1.9292283058166504
e:  4   train_loss:  916.5040536312404   time:  1.8905270099639893
e:  5   train_loss:  887.6591822084484   time:  1.800288200378418
e:  5   train_loss:  887.6591822084484   val_loss:  556.5107276555643   time:  1.9124372005462646
e:  6   train_loss:  898.0474505691368   time:  1.8014676570892334
e:  7   train_loss:  896.7865167437677   time:  1.8133790493011475
e:  8   train_loss:  900.6844423495406   time:  2.0315914154052734
e:  9   train_loss:  915.1404263317818   time:  1.8448026180267334
e:  10   train_loss:  896.0286024140786   time:  1.8944931030273438
e:  10   train_loss:  896.0286024140786   val_loss:  555.7583958459983   time:  2.007422924041748
e:  11   train_loss:  883.0874073102075   time:  1.9794585704803467
e:  12   train_loss:  875.8106035940534   time:  1.983205795288086
e:  13   train_loss:  880.5304513537385   time:  1.9744987487792969
e:  14   train_loss:  880.2307470716577   time:  2.2180700302124023
e:  15   train_loss:  869.5440584888732   time:  1.921799898147583
e:  15   train_loss:  869.5440584888732   val_loss:  554.6722309218156   time:  2.0366294384002686
e:  16   train_loss:  870.8470337551173   time:  1.9670231342315674
e:  17   train_loss:  892.1440761033232   time:  1.946610450744629
e:  18   train_loss:  847.9797847357592   time:  1.9598243236541748
e:  19   train_loss:  848.7566956226087   time:  1.937215805053711
e:  20   train_loss:  858.0958030105489   time:  1.8689601421356201
e:  20   train_loss:  858.0958030105489   val_loss:  554.9394608901562   time:  2.2052035331726074
e:  21   train_loss:  838.1537665368763   time:  1.8570141792297363
e:  22   train_loss:  841.5444529732972   time:  1.8791260719299316
e:  23   train_loss:  818.9822935642421   time:  1.951019048690796
e:  24   train_loss:  811.7484046023051   time:  1.9456334114074707
e:  25   train_loss:  799.2070304166526   time:  1.8665804862976074
e:  25   train_loss:  799.2070304166526   val_loss:  558.0991699294339   time:  1.9788432121276855
e:  26   train_loss:  801.7392705316136   time:  1.9272761344909668
e:  27   train_loss:  791.5042421702271   time:  1.9517807960510254
e:  28   train_loss:  779.5116127604992   time:  1.95119309425354
e:  29   train_loss:  764.9701556186039   time:  2.140627861022949
e:  30   train_loss:  759.9556649140935   time:  1.9429585933685303
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  30   train_loss:  759.9556649140935   val_loss:  568.8405505458904   time:  2.0618555545806885
e:  31   train_loss:  743.0195651189911   time:  1.9545323848724365
e:  32   train_loss:  733.6016556460993   time:  1.8940563201904297
e:  33   train_loss:  719.371299687675   time:  1.878589391708374
e:  34   train_loss:  716.4883387798993   time:  1.8995203971862793
e:  35   train_loss:  710.3194840840679   time:  2.022487163543701
e:  35   train_loss:  710.3194840840679   val_loss:  582.9124470626487   time:  2.1350691318511963
e:  36   train_loss:  705.7791747651237   time:  1.8320016860961914
e:  37   train_loss:  684.7686715747108   time:  1.88889479637146
e:  38   train_loss:  680.6759436072522   time:  1.8899693489074707
e:  39   train_loss:  685.7729195243942   time:  1.8638393878936768
e:  40   train_loss:  672.3185938554511   time:  2.0373928546905518
e:  40   train_loss:  672.3185938554511   val_loss:  577.1388779194995   time:  2.1458733081817627
e:  41   train_loss:  667.2680487772988   time:  1.8998215198516846
e:  42   train_loss:  668.875427933796   time:  1.8953335285186768
e:  43   train_loss:  679.8617490802476   time:  1.8481993675231934
e:  44   train_loss:  672.7450936518496   time:  1.8344688415527344
e:  45   train_loss:  687.6820990263429   time:  1.8874118328094482
e:  45   train_loss:  687.6820990263429   val_loss:  597.3304188961636   time:  2.000682830810547
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (2, 0, 4), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (2, 0, 4) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 4) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 4) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (2, 0, 4)
kwargs: {'config': {'batch_norm': False, 'ff_0': 1367, 'ff_num_layers': 1, 'gnn_0': 921, 'gnn_dropout': 0.41296454900911433, 'gnn_num_layers': 2, 'hid_0': 1906, 'hid_dropout_rate': 0.2868031356579865, 'in_dropout_rate': 0.4283977738400382, 'lr': 0.0003425347762745268, 'num_hid_layers': 1, 'optimizer': 'SGD', 'gnn_1': 341, 'sgd_momentum': 0.43265642667228815}, 'budget': 243.0, 'working_directory': '.'}
result: {'loss': 715.6494487184076, 'n_epochs': 102.0, 'info': {'validation loss': 715.6494487184076}}
exception: None

DEBUG:hpbandster:job_callback for (2, 0, 4) started
DEBUG:hpbandster:job_callback for (2, 0, 4) got condition
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:Only 11 run(s) for budget 243.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (2, 0, 4) finished
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:start sampling a new configuration.
DEBUG:hpbandster:done sampling a new configuration.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: trying submitting job (2, 0, 5) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 5) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 5)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 5) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 5) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (2, 0, 5)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 1281, 'ff_num_layers': 3, 'gnn_0': 305, 'gnn_dropout': 0.1830051894187627, 'gnn_num_layers': 2, 'hid_0': 134, 'hid_dropout_rate': 0.4047384058252916, 'in_dropout_rate': 0.041029374763747295, 'lr': 0.007711710172126553, 'num_hid_layers': 1, 'optimizer': 'Adam', 'ff_1': 376, 'ff_2': 29, 'gnn_1': 96}, 'budget': 243.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  712.4277661911425   time:  1.2485466003417969
e:  0   train_loss:  712.4277661911425   val_loss:  1545.5238043701395   time:  1.356191873550415
e:  1   train_loss:  621.742467485201   time:  1.3924477100372314
e:  2   train_loss:  588.8033531250272   time:  1.383814811706543
e:  3   train_loss:  585.6171826266351   time:  1.244750738143921
e:  4   train_loss:  575.8499861185719   time:  1.2441236972808838
e:  5   train_loss:  568.5663550963827   time:  1.244971513748169
e:  5   train_loss:  568.5663550963827   val_loss:  1389.9493284885714   time:  1.3514950275421143
e:  6   train_loss:  558.8608621194415   time:  1.2480838298797607
e:  7   train_loss:  548.0488073628867   time:  1.21968674659729
e:  8   train_loss:  535.366086842658   time:  1.2387375831604004
e:  9   train_loss:  519.9862270477165   time:  1.2274823188781738
e:  10   train_loss:  503.75080532244226   time:  1.2534151077270508
e:  10   train_loss:  503.75080532244226   val_loss:  1372.5603369007074   time:  1.3607001304626465
e:  11   train_loss:  487.6567539699246   time:  1.3869431018829346
e:  12   train_loss:  471.9603877254824   time:  1.3041231632232666
e:  13   train_loss:  458.25316734475865   time:  1.300245761871338
e:  14   train_loss:  446.0820689265476   time:  1.2824599742889404
e:  15   train_loss:  436.57266599667344   time:  1.284388780593872
e:  15   train_loss:  436.57266599667344   val_loss:  1365.636327429525   time:  1.3918306827545166
e:  16   train_loss:  428.41313894685527   time:  1.2823302745819092
e:  17   train_loss:  422.3292543130524   time:  1.2247462272644043
e:  18   train_loss:  418.8706025027737   time:  1.2486555576324463
e:  19   train_loss:  415.7834836198815   time:  1.320152997970581
e:  20   train_loss:  412.98116574278583   time:  1.362785816192627
e:  20   train_loss:  412.98116574278583   val_loss:  1382.949887418316   time:  1.6545131206512451
e:  21   train_loss:  411.52517996406107   time:  1.3058202266693115
e:  22   train_loss:  410.5333816574734   time:  1.304738998413086
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  23   train_loss:  408.9059673416225   time:  1.3299508094787598
e:  24   train_loss:  407.6604956936712   time:  1.3766069412231445
e:  25   train_loss:  407.1904063826734   time:  1.2816100120544434
e:  25   train_loss:  407.1904063826734   val_loss:  1391.6927313548215   time:  1.3883514404296875
e:  26   train_loss:  406.2089150211   time:  1.2854678630828857
e:  27   train_loss:  404.91432512970283   time:  1.3046963214874268
e:  28   train_loss:  403.5277192091489   time:  1.285656452178955
e:  29   train_loss:  402.73629476547484   time:  1.4360642433166504
e:  30   train_loss:  400.78246148450006   time:  1.3872530460357666
e:  30   train_loss:  400.78246148450006   val_loss:  1390.0639676085787   time:  1.5263893604278564
e:  31   train_loss:  399.44584436768173   time:  1.5073814392089844
e:  32   train_loss:  398.75080191701244   time:  1.2793488502502441
e:  33   train_loss:  397.3131948584967   time:  1.2857282161712646
e:  34   train_loss:  396.4839985814409   time:  1.3032710552215576
e:  35   train_loss:  394.94624479519507   time:  1.2901968955993652
e:  35   train_loss:  394.94624479519507   val_loss:  1387.4944029110986   time:  1.3970980644226074
e:  36   train_loss:  393.5674537229143   time:  1.2699863910675049
e:  37   train_loss:  391.920179901741   time:  1.3023245334625244
e:  38   train_loss:  390.56412734273624   time:  1.295827865600586
e:  39   train_loss:  388.3111618324588   time:  1.2812535762786865
e:  40   train_loss:  387.0559107076731   time:  1.2918527126312256
e:  40   train_loss:  387.0559107076731   val_loss:  1381.9853565931166   time:  1.5827851295471191
e:  41   train_loss:  385.642749946949   time:  1.2897515296936035
e:  42   train_loss:  385.7779753737556   time:  1.31996750831604
e:  43   train_loss:  384.5728541670029   time:  1.3157281875610352
e:  44   train_loss:  381.29606813409697   time:  1.2980923652648926
e:  45   train_loss:  378.6584811146024   time:  1.332582950592041
e:  45   train_loss:  378.6584811146024   val_loss:  1390.0954383778676   time:  1.439993143081665
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  965.6543773244913   time:  1.3665192127227783
e:  0   train_loss:  965.6543773244913   val_loss:  558.1457948235503   time:  1.4673666954040527
e:  1   train_loss:  899.6735305160811   time:  1.3638103008270264
e:  2   train_loss:  864.1167653459299   time:  1.5315732955932617
e:  3   train_loss:  823.4397662521416   time:  1.3600342273712158
e:  4   train_loss:  728.4294487459604   time:  1.3598575592041016
e:  5   train_loss:  670.1533254225247   time:  1.357666254043579
e:  5   train_loss:  670.1533254225247   val_loss:  756.4135714264937   time:  1.45849609375
e:  6   train_loss:  655.3340634782085   time:  1.3309171199798584
e:  7   train_loss:  655.980558724389   time:  1.3629651069641113
e:  8   train_loss:  605.9172442630397   time:  1.3607547283172607
e:  9   train_loss:  590.1706012979389   time:  1.4926934242248535
e:  10   train_loss:  573.6562253656516   time:  1.3626673221588135
e:  10   train_loss:  573.6562253656516   val_loss:  711.6874885242321   time:  1.464625597000122
e:  11   train_loss:  563.5148616599097   time:  1.3428840637207031
e:  12   train_loss:  558.5302833547335   time:  1.363102674484253
e:  13   train_loss:  550.809921927471   time:  1.3496739864349365
e:  14   train_loss:  552.5363860480545   time:  1.3611798286437988
e:  15   train_loss:  547.265990757457   time:  1.3604519367218018
e:  15   train_loss:  547.265990757457   val_loss:  643.3414168355037   time:  1.6060383319854736
e:  16   train_loss:  543.5617031682016   time:  1.3661754131317139
e:  17   train_loss:  541.0277188546895   time:  1.3623099327087402
e:  18   train_loss:  547.9239215322316   time:  1.3607354164123535
e:  19   train_loss:  545.6764619477392   time:  1.3547122478485107
e:  20   train_loss:  542.9941369417843   time:  1.3441927433013916
e:  20   train_loss:  542.9941369417843   val_loss:  659.5042531208343   time:  1.4457221031188965
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  21   train_loss:  531.1981481898869   time:  1.5124592781066895
e:  22   train_loss:  529.9066087154629   time:  1.3594353199005127
e:  23   train_loss:  534.9125849618001   time:  1.3433928489685059
e:  24   train_loss:  535.3949235890636   time:  1.3630566596984863
e:  25   train_loss:  526.5858667562806   time:  1.356462001800537
e:  25   train_loss:  526.5858667562806   val_loss:  653.2851376154226   time:  1.4571034908294678
e:  26   train_loss:  520.3307186036008   time:  1.410492181777954
e:  27   train_loss:  523.0032313139886   time:  1.346728801727295
e:  28   train_loss:  516.1602672038006   time:  1.5271217823028564
e:  29   train_loss:  520.63661738788   time:  1.3415305614471436
e:  30   train_loss:  517.2474326958321   time:  1.3599309921264648
e:  30   train_loss:  517.2474326958321   val_loss:  643.5710578885947   time:  1.4610874652862549
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  917.2301021928602   time:  1.3342995643615723
e:  0   train_loss:  917.2301021928602   val_loss:  484.80967566311944   time:  1.4407305717468262
e:  1   train_loss:  846.814629241317   time:  1.3948986530303955
e:  2   train_loss:  760.0629328171827   time:  1.4715957641601562
e:  3   train_loss:  788.9174883878902   time:  1.482192039489746
e:  4   train_loss:  762.0994119327722   time:  1.6468150615692139
e:  5   train_loss:  745.940488595874   time:  1.463571310043335
e:  5   train_loss:  745.940488595874   val_loss:  469.85655723446376   time:  1.567795753479004
e:  6   train_loss:  692.286044061612   time:  1.4886250495910645
e:  7   train_loss:  664.1761768395543   time:  1.5824816226959229
e:  8   train_loss:  673.571036924629   time:  1.427905559539795
e:  9   train_loss:  640.2325010704635   time:  1.408484697341919
e:  10   train_loss:  612.3626116245048   time:  1.5655503273010254
e:  10   train_loss:  612.3626116245048   val_loss:  514.4106017445853   time:  1.6690099239349365
e:  11   train_loss:  625.3582730034348   time:  1.4107651710510254
e:  12   train_loss:  581.4190102624287   time:  1.3978931903839111
e:  13   train_loss:  605.4745413660254   time:  1.3811781406402588
e:  14   train_loss:  581.755183557209   time:  1.4337713718414307
e:  15   train_loss:  631.5464359823428   time:  1.3950352668762207
e:  15   train_loss:  631.5464359823428   val_loss:  574.5934069153378   time:  1.4990458488464355
e:  16   train_loss:  568.0935033523174   time:  1.3458833694458008
e:  17   train_loss:  575.85676168702   time:  1.6096372604370117
e:  18   train_loss:  565.0835821757254   time:  1.4924025535583496
e:  19   train_loss:  553.9355485952268   time:  1.3642570972442627
e:  20   train_loss:  583.4562314630292   time:  1.3786664009094238
e:  20   train_loss:  583.4562314630292   val_loss:  594.184669743598   time:  1.4829764366149902
e:  21   train_loss:  564.9357548998481   time:  1.3600866794586182
e:  22   train_loss:  573.2879328707105   time:  1.352478265762329
e:  23   train_loss:  564.2908045987291   time:  1.3644475936889648
e:  24   train_loss:  593.2167451565952   time:  1.359041452407837
e:  25   train_loss:  555.9344202934702   time:  1.5495271682739258
e:  25   train_loss:  555.9344202934702   val_loss:  635.956827841632   time:  1.6534361839294434
e:  26   train_loss:  593.6332585188344   time:  1.297849416732788
e:  27   train_loss:  578.4526609058566   time:  1.1068837642669678
e:  28   train_loss:  555.5708848682674   time:  1.3635752201080322
e:  29   train_loss:  552.6353534710638   time:  1.3754761219024658
e:  30   train_loss:  576.1782832847616   time:  1.360534429550171
e:  30   train_loss:  576.1782832847616   val_loss:  655.9608276389994   time:  1.4640648365020752
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  31   train_loss:  559.8738767914787   time:  1.540600061416626
e:  32   train_loss:  550.0203425434755   time:  1.3619275093078613
e:  33   train_loss:  552.6890804706961   time:  1.3979437351226807
e:  34   train_loss:  538.9948886559159   time:  1.3645038604736328
e:  35   train_loss:  563.1440167147905   time:  1.3665025234222412
e:  35   train_loss:  563.1440167147905   val_loss:  586.717083426519   time:  1.470243215560913
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  891.4281504223874   time:  1.2615528106689453
e:  0   train_loss:  891.4281504223874   val_loss:  764.0654596603223   time:  1.369309902191162
e:  1   train_loss:  835.9988729128189   time:  1.2520272731781006
e:  2   train_loss:  820.792665249078   time:  1.2900018692016602
e:  3   train_loss:  805.4050993959889   time:  1.2579760551452637
e:  4   train_loss:  775.3944155052889   time:  1.3183181285858154
e:  5   train_loss:  739.4498780771265   time:  1.3069508075714111
e:  5   train_loss:  739.4498780771265   val_loss:  705.0740540355472   time:  1.4170098304748535
e:  6   train_loss:  695.8243475895874   time:  1.5329856872558594
e:  7   train_loss:  651.388497126772   time:  1.3340611457824707
e:  8   train_loss:  615.8266496925941   time:  1.3084943294525146
e:  9   train_loss:  585.3454119763142   time:  1.329923152923584
e:  10   train_loss:  563.8122019320683   time:  1.3128211498260498
e:  10   train_loss:  563.8122019320683   val_loss:  774.5616314211422   time:  1.4214320182800293
e:  11   train_loss:  548.5571532883926   time:  1.2665667533874512
e:  12   train_loss:  539.5445955525358   time:  1.338291883468628
e:  13   train_loss:  533.4965137827937   time:  1.3054559230804443
e:  14   train_loss:  528.4576311042015   time:  1.3189654350280762
e:  15   train_loss:  526.2499784864236   time:  1.5256412029266357
e:  15   train_loss:  526.2499784864236   val_loss:  811.4737893688748   time:  1.6275634765625
e:  16   train_loss:  525.71926051571   time:  1.2910146713256836
e:  17   train_loss:  522.7431951986932   time:  1.281590223312378
e:  18   train_loss:  521.4269410016693   time:  1.3695132732391357
e:  19   train_loss:  519.418995569308   time:  1.3309156894683838
e:  20   train_loss:  518.5329024711834   time:  1.2911503314971924
e:  20   train_loss:  518.5329024711834   val_loss:  839.0009496717831   time:  1.3997015953063965
e:  21   train_loss:  516.7116037383199   time:  1.2885239124298096
e:  22   train_loss:  515.5153240749141   time:  1.282660722732544
e:  23   train_loss:  514.9095821792084   time:  1.284010887145996
e:  24   train_loss:  514.9372559885363   time:  1.5166049003601074
e:  25   train_loss:  513.6157158716177   time:  1.3098268508911133
e:  25   train_loss:  513.6157158716177   val_loss:  842.0112579778712   time:  1.4192817211151123
e:  26   train_loss:  511.27762253027043   time:  1.2645618915557861
e:  27   train_loss:  511.43405203168743   time:  1.2652385234832764
e:  28   train_loss:  508.9349742836125   time:  1.248230218887329
e:  29   train_loss:  507.1127178279769   time:  1.2477319240570068
e:  30   train_loss:  507.63843267975767   time:  1.2475781440734863
e:  30   train_loss:  507.63843267975767   val_loss:  829.211170257131   time:  1.3553755283355713
e:  31   train_loss:  508.91067074002115   time:  1.249129056930542
e:  32   train_loss:  505.95843606773013   time:  1.231964111328125
e:  33   train_loss:  503.5662064981094   time:  1.2479186058044434
e:  34   train_loss:  503.64085215979884   time:  1.3463754653930664
e:  35   train_loss:  500.8107874100884   time:  1.401423454284668
e:  35   train_loss:  500.8107874100884   val_loss:  826.317611673955   time:  1.5101945400238037
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1063.950145420274   time:  1.3708901405334473
e:  0   train_loss:  1063.950145420274   val_loss:  610.931603301   time:  1.4737446308135986
e:  1   train_loss:  932.4957445843079   time:  1.3678650856018066
e:  2   train_loss:  866.9062527011777   time:  1.3622453212738037
e:  3   train_loss:  770.4951095051225   time:  1.3641467094421387
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  4   train_loss:  765.8375824312035   time:  1.5117614269256592
e:  5   train_loss:  739.2105657231672   time:  1.3596031665802002
e:  5   train_loss:  739.2105657231672   val_loss:  551.4930282560521   time:  1.4621124267578125
e:  6   train_loss:  734.8728259272891   time:  1.364339828491211
e:  7   train_loss:  728.1926833650563   time:  1.360347032546997
e:  8   train_loss:  717.9915794943287   time:  1.3633027076721191
e:  9   train_loss:  704.8617099954625   time:  1.3460230827331543
e:  10   train_loss:  684.6284640394127   time:  1.3368127346038818
e:  10   train_loss:  684.6284640394127   val_loss:  554.1318677520942   time:  1.5936262607574463
e:  11   train_loss:  661.0879702838324   time:  1.3586740493774414
e:  12   train_loss:  653.6184092766553   time:  1.3609049320220947
e:  13   train_loss:  651.1780777479564   time:  1.3482377529144287
e:  14   train_loss:  646.6062122591605   time:  1.3652358055114746
e:  15   train_loss:  618.368392038321   time:  1.3654985427856445
e:  15   train_loss:  618.368392038321   val_loss:  560.9224678898275   time:  1.4678764343261719
e:  16   train_loss:  597.4634730733344   time:  1.3584492206573486
e:  17   train_loss:  628.6677642156515   time:  1.3633971214294434
e:  18   train_loss:  584.0557754551553   time:  1.3621494770050049
e:  19   train_loss:  607.4900546693527   time:  1.5202455520629883
e:  20   train_loss:  586.4716409027938   time:  1.3454904556274414
e:  20   train_loss:  586.4716409027938   val_loss:  565.084991993839   time:  1.4482920169830322
e:  21   train_loss:  583.958309438422   time:  1.3642408847808838
e:  22   train_loss:  589.2716323787256   time:  1.3629090785980225
e:  23   train_loss:  591.4412508259297   time:  1.364990472793579
e:  24   train_loss:  574.758205566716   time:  1.3659543991088867
e:  25   train_loss:  575.4556017154488   time:  1.5397944450378418
e:  25   train_loss:  575.4556017154488   val_loss:  568.8369179016223   time:  1.642132043838501
e:  26   train_loss:  562.8729829454537   time:  1.3402342796325684
e:  27   train_loss:  577.220274512317   time:  1.3568875789642334
e:  28   train_loss:  563.6558461013217   time:  1.359797716140747
e:  29   train_loss:  562.7179561411629   time:  1.3444905281066895
e:  30   train_loss:  573.0962764811632   time:  1.3587031364440918
e:  30   train_loss:  573.0962764811632   val_loss:  572.5117146361279   time:  1.604806661605835
e:  31   train_loss:  556.1602175709402   time:  1.3574120998382568
e:  32   train_loss:  564.4743838721838   time:  1.35209059715271
e:  33   train_loss:  557.0991330415743   time:  1.3629734516143799
e:  34   train_loss:  553.5836785651067   time:  1.355510950088501
e:  35   train_loss:  560.1147981513274   time:  1.342668056488037
e:  35   train_loss:  560.1147981513274   val_loss:  575.2595065843558   time:  1.4457905292510986
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (2, 0, 5), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (2, 0, 5) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 5) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 5) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (2, 0, 5)
kwargs: {'config': {'batch_norm': False, 'ff_0': 1281, 'ff_num_layers': 3, 'gnn_0': 305, 'gnn_dropout': 0.1830051894187627, 'gnn_num_layers': 2, 'hid_0': 134, 'hid_dropout_rate': 0.4047384058252916, 'in_dropout_rate': 0.041029374763747295, 'lr': 0.007711710172126553, 'num_hid_layers': 1, 'optimizer': 'Adam', 'ff_1': 376, 'ff_2': 29, 'gnn_1': 96}, 'budget': 243.0, 'working_directory': '.'}
result: {'loss': 730.0411523558276, 'n_epochs': 36.0, 'info': {'validation loss': 730.0411523558276}}
exception: None

DEBUG:hpbandster:job_callback for (2, 0, 5) started
DEBUG:hpbandster:job_callback for (2, 0, 5) got condition
DEBUG:hpbandster:Only 12 run(s) for budget 243.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (2, 0, 5) finished
DEBUG:hpbandster:ITERATION: Advancing config (2, 0, 3) to next budget 729.000000
DEBUG:hpbandster:ITERATION: Advancing config (2, 0, 4) to next budget 729.000000
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: trying submitting job (2, 0, 3) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 3) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 3)
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 3) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 3) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (2, 0, 3)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 158, 'ff_num_layers': 2, 'gnn_0': 1037, 'gnn_dropout': 0.4159381407912401, 'gnn_num_layers': 3, 'hid_0': 362, 'hid_dropout_rate': 0.0015934472827938695, 'in_dropout_rate': 0.24414691946777917, 'lr': 0.0007279250329450922, 'num_hid_layers': 2, 'optimizer': 'SGD', 'ff_1': 421, 'gnn_1': 161, 'gnn_2': 311, 'hid_1': 276, 'sgd_momentum': 0.033203490940577535}, 'budget': 729.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  705.0965713225272   time:  1.345900058746338
e:  0   train_loss:  705.0965713225272   val_loss:  1667.0002698242222   time:  1.4576709270477295
e:  1   train_loss:  698.3380628024313   time:  1.4935946464538574
e:  2   train_loss:  685.3097043540256   time:  1.3328075408935547
e:  3   train_loss:  647.7789902170763   time:  1.3431873321533203
e:  4   train_loss:  602.9167408814628   time:  1.3477072715759277
e:  5   train_loss:  596.922578045053   time:  1.3496174812316895
e:  5   train_loss:  596.922578045053   val_loss:  1397.9063576443875   time:  1.4609308242797852
e:  6   train_loss:  595.7520255754637   time:  1.3349785804748535
e:  7   train_loss:  594.0674703392526   time:  1.349097728729248
e:  8   train_loss:  592.8519489538386   time:  1.3470969200134277
e:  9   train_loss:  592.8572720697032   time:  1.3476600646972656
e:  10   train_loss:  590.8526075990831   time:  1.3496408462524414
e:  10   train_loss:  590.8526075990831   val_loss:  1391.8108536036643   time:  1.4624881744384766
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  11   train_loss:  588.8166085830724   time:  1.4404933452606201
e:  12   train_loss:  587.8572335850017   time:  1.496929407119751
e:  13   train_loss:  585.7002541710665   time:  1.333622694015503
e:  14   train_loss:  583.325595161517   time:  1.3510003089904785
e:  15   train_loss:  581.4312585648217   time:  1.3523526191711426
e:  15   train_loss:  581.4312585648217   val_loss:  1390.6603248008646   time:  1.4651992321014404
e:  16   train_loss:  578.9334001419625   time:  1.3513689041137695
e:  17   train_loss:  576.4306344334981   time:  1.385432481765747
e:  18   train_loss:  574.3612760215801   time:  1.4001083374023438
e:  19   train_loss:  570.8215233257035   time:  1.3918936252593994
e:  20   train_loss:  567.4662293605879   time:  1.407726764678955
e:  20   train_loss:  567.4662293605879   val_loss:  1385.4133281316313   time:  1.5196318626403809
e:  21   train_loss:  563.7732996275378   time:  1.38832688331604
e:  22   train_loss:  559.9188890171706   time:  1.4015958309173584
e:  23   train_loss:  556.3942438261812   time:  1.4953949451446533
e:  24   train_loss:  552.0104898981131   time:  1.3333630561828613
e:  25   train_loss:  547.3544090851966   time:  1.3452861309051514
e:  25   train_loss:  547.3544090851966   val_loss:  1388.7787330379606   time:  1.4568941593170166
e:  26   train_loss:  544.5829071108027   time:  1.3486616611480713
e:  27   train_loss:  539.9910822791493   time:  1.3497965335845947
e:  28   train_loss:  536.0345319153744   time:  1.3460209369659424
e:  29   train_loss:  532.1966316634805   time:  1.3490664958953857
e:  30   train_loss:  529.9339262722096   time:  1.349689245223999
e:  30   train_loss:  529.9339262722096   val_loss:  1387.4109333657498   time:  1.4621124267578125
e:  31   train_loss:  526.6505550734656   time:  1.3509728908538818
e:  32   train_loss:  522.460390724994   time:  1.3535559177398682
e:  33   train_loss:  523.8213309671266   time:  1.3533685207366943
e:  34   train_loss:  516.9123675887324   time:  1.4971263408660889
e:  35   train_loss:  522.5418456674471   time:  1.3479056358337402
e:  35   train_loss:  522.5418456674471   val_loss:  1354.1569097219733   time:  1.460803747177124
e:  36   train_loss:  517.845929512936   time:  1.3506245613098145
e:  37   train_loss:  514.1470733805545   time:  1.3498992919921875
e:  38   train_loss:  514.7802733187744   time:  1.3210868835449219
e:  39   train_loss:  511.88222230693555   time:  1.3264081478118896
e:  40   train_loss:  509.28483630960096   time:  1.3515148162841797
e:  40   train_loss:  509.28483630960096   val_loss:  1360.6120206234968   time:  1.4637997150421143
e:  41   train_loss:  506.3395956791986   time:  1.3449273109436035
e:  42   train_loss:  501.9610340684063   time:  1.4786179065704346
e:  43   train_loss:  506.49729477616444   time:  1.3499174118041992
e:  44   train_loss:  503.5164763016135   time:  1.3501701354980469
e:  45   train_loss:  501.6366400076839   time:  1.3218035697937012
e:  45   train_loss:  501.6366400076839   val_loss:  1372.1597596658742   time:  1.432628870010376
e:  46   train_loss:  497.38136394089645   time:  1.3414435386657715
e:  47   train_loss:  506.7754810931442   time:  1.3469562530517578
e:  48   train_loss:  490.0835267970135   time:  1.3499512672424316
e:  49   train_loss:  504.4805878171939   time:  1.3502061367034912
e:  50   train_loss:  492.6243850444085   time:  1.3467464447021484
e:  50   train_loss:  492.6243850444085   val_loss:  1379.0595264654698   time:  1.4584503173828125
e:  51   train_loss:  488.7646139736122   time:  1.3538637161254883
e:  52   train_loss:  485.4292382181249   time:  1.3536927700042725
e:  53   train_loss:  486.4696398067348   time:  1.490309238433838
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  54   train_loss:  491.96741846965114   time:  1.4130299091339111
e:  55   train_loss:  486.1780094562191   time:  1.3716611862182617
e:  55   train_loss:  486.1780094562191   val_loss:  1383.6515974466433   time:  1.4850342273712158
e:  56   train_loss:  486.87045459329875   time:  1.3615961074829102
e:  57   train_loss:  482.75835422651295   time:  1.3543124198913574
e:  58   train_loss:  483.38449600866534   time:  1.3487415313720703
e:  59   train_loss:  478.7975058187956   time:  1.353219985961914
e:  60   train_loss:  475.84759246904366   time:  1.3405613899230957
e:  60   train_loss:  475.84759246904366   val_loss:  1501.674555638938   time:  1.4530212879180908
e:  61   train_loss:  486.2486136400563   time:  1.3281569480895996
e:  62   train_loss:  470.3343331978124   time:  1.4964704513549805
e:  63   train_loss:  483.28803376934655   time:  1.3387088775634766
e:  64   train_loss:  465.3605580720008   time:  1.3493947982788086
e:  65   train_loss:  474.8769176541604   time:  1.3547780513763428
e:  65   train_loss:  474.8769176541604   val_loss:  1466.4797308528616   time:  1.467759370803833
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1083.3004408636389   time:  1.4753172397613525
e:  0   train_loss:  1083.3004408636389   val_loss:  619.9848821026054   time:  1.5815777778625488
e:  1   train_loss:  1040.53547233022   time:  1.4747750759124756
e:  2   train_loss:  993.9653856362947   time:  1.4742262363433838
e:  3   train_loss:  909.710855404369   time:  1.6044888496398926
e:  4   train_loss:  891.8874641656289   time:  1.4739561080932617
e:  5   train_loss:  902.3506996145667   time:  1.4725005626678467
e:  5   train_loss:  902.3506996145667   val_loss:  550.7125295994981   time:  1.5780234336853027
e:  6   train_loss:  900.487491562959   time:  1.4701259136199951
e:  7   train_loss:  876.3214353331999   time:  1.471580982208252
e:  8   train_loss:  891.5945350993019   time:  1.456087350845337
e:  9   train_loss:  879.2982019290383   time:  1.4683315753936768
e:  10   train_loss:  878.2472871266741   time:  1.6333181858062744
e:  10   train_loss:  878.2472871266741   val_loss:  547.5444353645762   time:  1.739422082901001
e:  11   train_loss:  863.4282848838503   time:  1.4709558486938477
e:  12   train_loss:  845.0354680255977   time:  1.4678707122802734
e:  13   train_loss:  831.7748699439463   time:  1.466181755065918
e:  14   train_loss:  826.7556072109569   time:  1.4321086406707764
e:  15   train_loss:  794.0772249991915   time:  1.4549708366394043
e:  15   train_loss:  794.0772249991915   val_loss:  544.9071688072781   time:  1.713977336883545
e:  16   train_loss:  798.2194868424226   time:  1.4684503078460693
e:  17   train_loss:  771.1130876391314   time:  1.4559378623962402
e:  18   train_loss:  767.9491160548131   time:  1.470130443572998
e:  19   train_loss:  724.7958472523325   time:  1.4719600677490234
e:  20   train_loss:  741.0931076192552   time:  1.4574229717254639
e:  20   train_loss:  741.0931076192552   val_loss:  558.0617778683438   time:  1.563058614730835
e:  21   train_loss:  707.2594819747769   time:  1.6302640438079834
e:  22   train_loss:  704.049254335597   time:  1.4610397815704346
e:  23   train_loss:  683.9241286773499   time:  1.474686861038208
e:  24   train_loss:  669.2151458175463   time:  1.4696581363677979
e:  25   train_loss:  653.9857464786306   time:  1.473266839981079
e:  25   train_loss:  653.9857464786306   val_loss:  560.8028993056208   time:  1.579193115234375
e:  26   train_loss:  668.458543854971   time:  1.469452142715454
e:  27   train_loss:  653.5490398093278   time:  1.4705710411071777
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  28   train_loss:  705.4365697584893   time:  1.6355559825897217
e:  29   train_loss:  654.1786938224616   time:  1.4708092212677002
e:  30   train_loss:  668.3858530959886   time:  1.4727880954742432
e:  30   train_loss:  668.3858530959886   val_loss:  597.5947464718065   time:  1.5794122219085693
e:  31   train_loss:  638.4618912176028   time:  1.4736740589141846
e:  32   train_loss:  637.12589693565   time:  1.470182180404663
e:  33   train_loss:  634.2672956061471   time:  1.4588282108306885
e:  34   train_loss:  616.622657734912   time:  1.4630963802337646
e:  35   train_loss:  629.0341824421014   time:  1.6267495155334473
e:  35   train_loss:  629.0341824421014   val_loss:  562.4708061133762   time:  1.7320687770843506
e:  36   train_loss:  628.7383409322115   time:  1.4727861881256104
e:  37   train_loss:  613.3528679289949   time:  1.4597034454345703
e:  38   train_loss:  608.0340371348104   time:  1.4786376953125
e:  39   train_loss:  723.4909026552473   time:  1.4607465267181396
e:  40   train_loss:  624.6826801902141   time:  1.4674975872039795
e:  40   train_loss:  624.6826801902141   val_loss:  575.5482881673498   time:  1.5730767250061035
e:  41   train_loss:  619.5869594549742   time:  1.6326546669006348
e:  42   train_loss:  614.3014556596548   time:  1.4712090492248535
e:  43   train_loss:  597.7672063410535   time:  1.4702775478363037
e:  44   train_loss:  606.4880366715726   time:  1.5582547187805176
e:  45   train_loss:  605.7404252358472   time:  1.5643022060394287
e:  45   train_loss:  605.7404252358472   val_loss:  570.8260145320369   time:  1.7410593032836914
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1087.5133772098504   time:  1.4962797164916992
e:  0   train_loss:  1087.5133772098504   val_loss:  532.99471639818   time:  1.6044650077819824
e:  1   train_loss:  1042.7274657789285   time:  1.6002390384674072
e:  2   train_loss:  1025.6435976867767   time:  1.6228959560394287
e:  3   train_loss:  909.1838447011264   time:  1.4619712829589844
e:  4   train_loss:  886.7701604491799   time:  1.4567124843597412
e:  5   train_loss:  892.7307968646917   time:  1.4380221366882324
e:  5   train_loss:  892.7307968646917   val_loss:  502.4922183631862   time:  1.5457556247711182
e:  6   train_loss:  955.3881921290954   time:  1.5665323734283447
e:  7   train_loss:  872.0067524116895   time:  1.4370448589324951
e:  8   train_loss:  897.1688140560681   time:  1.5260910987854004
e:  9   train_loss:  878.2542520781644   time:  1.5249955654144287
e:  10   train_loss:  905.6346499330904   time:  1.6164865493774414
e:  10   train_loss:  905.6346499330904   val_loss:  499.34719580140563   time:  1.7238125801086426
e:  11   train_loss:  859.3066840529702   time:  1.4531688690185547
e:  12   train_loss:  850.673100190246   time:  1.445251703262329
e:  13   train_loss:  871.6439708072205   time:  1.5086467266082764
e:  14   train_loss:  896.6269157759865   time:  1.5621545314788818
e:  15   train_loss:  828.7492009117509   time:  1.6076436042785645
e:  15   train_loss:  828.7492009117509   val_loss:  462.6715475840555   time:  1.7160592079162598
e:  16   train_loss:  811.7773543917879   time:  1.7702033519744873
e:  17   train_loss:  779.3047157671529   time:  1.5465455055236816
e:  18   train_loss:  769.0318229692408   time:  1.5598104000091553
e:  19   train_loss:  757.2751195202816   time:  1.5566887855529785
e:  20   train_loss:  776.5203361894642   time:  1.5455760955810547
e:  20   train_loss:  776.5203361894642   val_loss:  633.8681285870738   time:  1.653568983078003
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  21   train_loss:  738.0680113117328   time:  1.5717546939849854
e:  22   train_loss:  721.4628565627636   time:  1.555215835571289
e:  23   train_loss:  732.4781242372932   time:  1.5555477142333984
e:  24   train_loss:  865.3688856732047   time:  1.558933973312378
e:  25   train_loss:  715.7841100426607   time:  1.801534652709961
e:  25   train_loss:  715.7841100426607   val_loss:  512.8448758752095   time:  1.9091098308563232
e:  26   train_loss:  667.0562012027697   time:  1.5474998950958252
e:  27   train_loss:  686.1569676413758   time:  1.5373108386993408
e:  28   train_loss:  667.5991759185994   time:  1.5604007244110107
e:  29   train_loss:  677.0569246817574   time:  1.5350837707519531
e:  30   train_loss:  681.2976937240666   time:  1.5598440170288086
e:  30   train_loss:  681.2976937240666   val_loss:  484.1315312604562   time:  1.6687963008880615
e:  31   train_loss:  655.3071753362171   time:  1.5995032787322998
e:  32   train_loss:  654.5524643066085   time:  1.7296805381774902
e:  33   train_loss:  669.9590624414129   time:  1.4954206943511963
e:  34   train_loss:  683.1602133023306   time:  1.4862844944000244
e:  35   train_loss:  673.6475466016501   time:  1.4883930683135986
e:  35   train_loss:  673.6475466016501   val_loss:  472.7845651049883   time:  1.5977611541748047
e:  36   train_loss:  664.66101878708   time:  1.4898369312286377
e:  37   train_loss:  666.7292228205574   time:  1.4884915351867676
e:  38   train_loss:  673.3624028712077   time:  1.4880790710449219
e:  39   train_loss:  634.8568657622924   time:  1.4910216331481934
e:  40   train_loss:  648.8128446365067   time:  1.6868224143981934
e:  40   train_loss:  648.8128446365067   val_loss:  465.69703467646   time:  1.797591209411621
e:  41   train_loss:  633.6730575624347   time:  1.5099952220916748
e:  42   train_loss:  656.3245607559863   time:  1.5143609046936035
e:  43   train_loss:  628.5715389001721   time:  1.5134036540985107
e:  44   train_loss:  629.9210246151996   time:  1.5056133270263672
e:  45   train_loss:  641.8023084490729   time:  1.4966492652893066
e:  45   train_loss:  641.8023084490729   val_loss:  506.2574468739656   time:  1.6035687923431396
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  998.5835612373074   time:  1.355301856994629
e:  0   train_loss:  998.5835612373074   val_loss:  910.2230051094803   time:  1.4671895503997803
e:  1   train_loss:  985.5826807570426   time:  1.4156951904296875
e:  2   train_loss:  961.8963587381572   time:  1.4172711372375488
e:  3   train_loss:  877.5666431470927   time:  1.620908260345459
e:  4   train_loss:  839.8064619219787   time:  1.393906831741333
e:  5   train_loss:  838.7315620417614   time:  1.397789716720581
e:  5   train_loss:  838.7315620417614   val_loss:  739.9642182075103   time:  1.5102097988128662
e:  6   train_loss:  835.4054557699299   time:  1.4006412029266357
e:  7   train_loss:  834.1264159570525   time:  1.3946242332458496
e:  8   train_loss:  830.377393467373   time:  1.4287493228912354
e:  9   train_loss:  824.7628419548304   time:  1.4521596431732178
e:  10   train_loss:  826.5093430986226   time:  1.414339303970337
e:  10   train_loss:  826.5093430986226   val_loss:  734.7749640027293   time:  1.5272018909454346
e:  11   train_loss:  820.8909833421203   time:  1.3715670108795166
e:  12   train_loss:  815.3917942050041   time:  1.4081544876098633
e:  13   train_loss:  814.0884521336318   time:  1.4137067794799805
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  14   train_loss:  806.7397759068443   time:  1.4131407737731934
e:  15   train_loss:  802.7501042038841   time:  1.631300449371338
e:  15   train_loss:  802.7501042038841   val_loss:  722.2691178239314   time:  1.7363951206207275
e:  16   train_loss:  792.244301343771   time:  1.4066472053527832
e:  17   train_loss:  783.8739553607534   time:  1.4134998321533203
e:  18   train_loss:  772.1484417691377   time:  1.3682029247283936
e:  19   train_loss:  760.434615230287   time:  1.4065392017364502
e:  20   train_loss:  745.2716350635545   time:  1.3945529460906982
e:  20   train_loss:  745.2716350635545   val_loss:  705.8015171116689   time:  1.5068953037261963
e:  21   train_loss:  743.1959257963094   time:  1.368668794631958
e:  22   train_loss:  738.6237948442779   time:  1.381521224975586
e:  23   train_loss:  721.5946065065972   time:  1.376138687133789
e:  24   train_loss:  709.21911500694   time:  1.3815553188323975
e:  25   train_loss:  689.1070988794273   time:  1.376124382019043
e:  25   train_loss:  689.1070988794273   val_loss:  701.7919493714589   time:  1.4891185760498047
e:  26   train_loss:  684.1120281125643   time:  1.5571563243865967
e:  27   train_loss:  667.3645001302147   time:  1.3637323379516602
e:  28   train_loss:  673.6873348391614   time:  1.3807401657104492
e:  29   train_loss:  661.5662331721242   time:  1.3825654983520508
e:  30   train_loss:  649.3719605126628   time:  1.3797779083251953
e:  30   train_loss:  649.3719605126628   val_loss:  726.9190187402097   time:  1.4922080039978027
e:  31   train_loss:  643.5371339614104   time:  1.3807101249694824
e:  32   train_loss:  643.3972756135279   time:  1.3727219104766846
e:  33   train_loss:  636.4248292085227   time:  1.3792846202850342
e:  34   train_loss:  639.2937742218119   time:  1.379314661026001
e:  35   train_loss:  636.5766775890111   time:  1.3811757564544678
e:  35   train_loss:  636.5766775890111   val_loss:  699.0221402315545   time:  1.4962091445922852
e:  36   train_loss:  631.447931173183   time:  1.380951166152954
e:  37   train_loss:  622.8619914311212   time:  1.381643533706665
e:  38   train_loss:  612.4159513744061   time:  1.564990758895874
e:  39   train_loss:  622.2334985885468   time:  1.3547146320343018
e:  40   train_loss:  619.8838484954873   time:  1.3777844905853271
e:  40   train_loss:  619.8838484954873   val_loss:  717.1484052310815   time:  1.491156816482544
e:  41   train_loss:  620.3875734221022   time:  1.364471197128296
e:  42   train_loss:  619.1477545481541   time:  1.3560457229614258
e:  43   train_loss:  615.7173294775747   time:  1.3772108554840088
e:  44   train_loss:  601.7074345964993   time:  1.379091739654541
e:  45   train_loss:  616.1331281678349   time:  1.380023717880249
e:  45   train_loss:  616.1331281678349   val_loss:  692.3346227848601   time:  1.4936847686767578
e:  46   train_loss:  595.4375951099403   time:  1.378641128540039
e:  47   train_loss:  600.4724775643051   time:  1.3777973651885986
e:  48   train_loss:  595.0419068477964   time:  1.5108540058135986
e:  49   train_loss:  616.9226411986028   time:  1.3787317276000977
e:  50   train_loss:  602.5128295470444   time:  1.374727487564087
e:  50   train_loss:  602.5128295470444   val_loss:  680.3675066250443   time:  1.4871654510498047
e:  51   train_loss:  585.8213889228379   time:  1.5574090480804443
e:  52   train_loss:  603.7193130454708   time:  1.378605604171753
e:  53   train_loss:  598.5399641012009   time:  1.3783817291259766
e:  54   train_loss:  591.6331650659387   time:  1.4284112453460693
e:  55   train_loss:  587.2721267707852   time:  1.5323877334594727
e:  55   train_loss:  587.2721267707852   val_loss:  678.5948823824854   time:  1.6452043056488037
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  56   train_loss:  603.618493026014   time:  1.3839268684387207
e:  57   train_loss:  583.4107915191394   time:  1.3742618560791016
e:  58   train_loss:  599.0390754157929   time:  1.380500078201294
e:  59   train_loss:  595.7891071012604   time:  1.3819806575775146
e:  60   train_loss:  585.6005580653439   time:  1.3829421997070312
e:  60   train_loss:  585.6005580653439   val_loss:  701.0845101749803   time:  1.4942898750305176
e:  61   train_loss:  596.6923572036999   time:  1.3731663227081299
e:  62   train_loss:  604.4044982631801   time:  1.3586935997009277
e:  63   train_loss:  568.8635098871947   time:  1.5418717861175537
e:  64   train_loss:  591.6549959098267   time:  1.3570384979248047
e:  65   train_loss:  577.0885058044747   time:  1.3763022422790527
e:  65   train_loss:  577.0885058044747   val_loss:  746.5382694319848   time:  1.4895539283752441
e:  66   train_loss:  574.1642783341093   time:  1.379678726196289
e:  67   train_loss:  601.4763145120028   time:  1.364861249923706
e:  68   train_loss:  582.4194281196434   time:  1.3734948635101318
e:  69   train_loss:  569.2113104431295   time:  1.376305103302002
e:  70   train_loss:  571.4008517774886   time:  1.382995843887329
e:  70   train_loss:  571.4008517774886   val_loss:  669.318057582703   time:  1.4964869022369385
e:  71   train_loss:  583.0103657243969   time:  1.378828763961792
e:  72   train_loss:  568.9797425179042   time:  1.3791353702545166
e:  73   train_loss:  556.5700669021122   time:  1.5137457847595215
e:  74   train_loss:  570.716111584313   time:  1.4609074592590332
e:  75   train_loss:  557.4012582676257   time:  1.374433994293213
e:  75   train_loss:  557.4012582676257   val_loss:  666.7320335711742   time:  1.487466812133789
e:  76   train_loss:  564.6821425595019   time:  1.5582020282745361
e:  77   train_loss:  562.7655649313982   time:  1.3769018650054932
e:  78   train_loss:  559.3633209595095   time:  1.377258062362671
e:  79   train_loss:  566.3433380804777   time:  1.3795032501220703
e:  80   train_loss:  565.3642852008899   time:  1.378481149673462
e:  80   train_loss:  565.3642852008899   val_loss:  698.1560017544693   time:  1.490997076034546
e:  81   train_loss:  561.2644852183911   time:  1.380242109298706
e:  82   train_loss:  547.4467786887656   time:  1.3734495639801025
e:  83   train_loss:  573.6187960634142   time:  1.3650224208831787
e:  84   train_loss:  539.4447529765516   time:  1.35373854637146
e:  85   train_loss:  552.0966043090723   time:  1.378882646560669
e:  85   train_loss:  552.0966043090723   val_loss:  683.2230678496428   time:  1.4917962551116943
e:  86   train_loss:  537.048664975201   time:  1.3773243427276611
e:  87   train_loss:  563.0630797810444   time:  1.3907999992370605
e:  88   train_loss:  553.5326438822844   time:  1.56357741355896
e:  89   train_loss:  563.6703065227495   time:  1.3573791980743408
e:  90   train_loss:  559.1922179743326   time:  1.3766820430755615
e:  90   train_loss:  559.1922179743326   val_loss:  681.761353242259   time:  1.4899423122406006
e:  91   train_loss:  544.4719660479182   time:  1.3790233135223389
e:  92   train_loss:  542.6556717318026   time:  1.3759558200836182
e:  93   train_loss:  542.1147293435238   time:  1.3756961822509766
e:  94   train_loss:  544.5909883342536   time:  1.3815746307373047
e:  95   train_loss:  546.5752592584513   time:  1.379199504852295
e:  95   train_loss:  546.5752592584513   val_loss:  690.9201763668311   time:  1.492717981338501
e:  96   train_loss:  553.3414235967958   time:  1.3797557353973389
e:  97   train_loss:  533.5638029117952   time:  1.3788628578186035
e:  98   train_loss:  528.9491550802073   time:  1.3776111602783203
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  99   train_loss:  522.1232148287265   time:  1.51682710647583
e:  100   train_loss:  540.3607355889649   time:  1.559882402420044
e:  100   train_loss:  540.3607355889649   val_loss:  812.00203831737   time:  1.6724317073822021
e:  101   train_loss:  551.4466603899123   time:  1.3810608386993408
e:  102   train_loss:  542.6702591871341   time:  1.3803577423095703
e:  103   train_loss:  539.5555787362471   time:  1.3797259330749512
e:  104   train_loss:  536.3767943353312   time:  1.3585550785064697
e:  105   train_loss:  525.0497279555275   time:  1.3495137691497803
e:  105   train_loss:  525.0497279555275   val_loss:  724.8299792301042   time:  1.4618761539459229
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1072.8474354644038   time:  1.5016257762908936
e:  0   train_loss:  1072.8474354644038   val_loss:  680.1839898683784   time:  1.6091179847717285
e:  1   train_loss:  1052.5716198943255   time:  1.4966890811920166
e:  2   train_loss:  959.1420404303959   time:  1.5029363632202148
e:  3   train_loss:  910.2489616665363   time:  1.7118136882781982
e:  4   train_loss:  913.038386713116   time:  1.4860830307006836
e:  5   train_loss:  904.3173171790971   time:  1.4999818801879883
e:  5   train_loss:  904.3173171790971   val_loss:  555.9828555872355   time:  1.6068179607391357
e:  6   train_loss:  891.673671119383   time:  1.5020315647125244
e:  7   train_loss:  893.8226566017576   time:  1.497530460357666
e:  8   train_loss:  877.1462855729206   time:  1.4973201751708984
e:  9   train_loss:  884.8105833697228   time:  1.4988758563995361
e:  10   train_loss:  867.4253584140147   time:  1.6962859630584717
e:  10   train_loss:  867.4253584140147   val_loss:  553.7807140011666   time:  1.802250862121582
e:  11   train_loss:  868.9971980259606   time:  1.4974265098571777
e:  12   train_loss:  852.9616066353678   time:  1.5009245872497559
e:  13   train_loss:  824.1228546223597   time:  1.502540111541748
e:  14   train_loss:  816.7794731057306   time:  1.4998188018798828
e:  15   train_loss:  801.7748332458264   time:  1.4989378452301025
e:  15   train_loss:  801.7748332458264   val_loss:  573.7081558365709   time:  1.605337142944336
e:  16   train_loss:  798.560793485189   time:  1.497758150100708
e:  17   train_loss:  771.9885433498137   time:  1.7114143371582031
e:  18   train_loss:  742.0727936090271   time:  1.480329990386963
e:  19   train_loss:  742.9288046668236   time:  1.4950706958770752
e:  20   train_loss:  724.9208874118304   time:  1.4828400611877441
e:  20   train_loss:  724.9208874118304   val_loss:  571.7399360111586   time:  1.5901381969451904
e:  21   train_loss:  717.2043714823541   time:  1.490370273590088
e:  22   train_loss:  706.4129629666351   time:  1.5001025199890137
e:  23   train_loss:  707.6184705352157   time:  1.7449254989624023
e:  24   train_loss:  687.7279706543657   time:  1.4950120449066162
e:  25   train_loss:  687.5757065552721   time:  1.5010929107666016
e:  25   train_loss:  687.5757065552721   val_loss:  554.4076265173037   time:  1.6073129177093506
e:  26   train_loss:  670.0355803182387   time:  1.5014328956604004
e:  27   train_loss:  677.8101091058502   time:  1.4985005855560303
e:  28   train_loss:  652.9685661721373   time:  1.5015182495117188
e:  29   train_loss:  650.2560502974976   time:  1.6812939643859863
e:  30   train_loss:  675.3980582653189   time:  1.5002939701080322
e:  30   train_loss:  675.3980582653189   val_loss:  551.3503937038328   time:  1.607299566268921
e:  31   train_loss:  669.9622737371511   time:  1.5008392333984375
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  32   train_loss:  654.6688207062682   time:  1.5000383853912354
e:  33   train_loss:  637.275014950345   time:  1.5161914825439453
e:  34   train_loss:  640.4960565809773   time:  1.478529691696167
e:  35   train_loss:  638.9805564270184   time:  1.487311601638794
e:  35   train_loss:  638.9805564270184   val_loss:  539.0450661686132   time:  1.7812111377716064
e:  36   train_loss:  655.6481684937861   time:  1.498748540878296
e:  37   train_loss:  634.0390237433832   time:  1.483996868133545
e:  38   train_loss:  635.5041724770152   time:  1.476142406463623
e:  39   train_loss:  628.8229531025677   time:  1.4987308979034424
e:  40   train_loss:  640.3145979615406   time:  1.5013771057128906
e:  40   train_loss:  640.3145979615406   val_loss:  540.9515446646446   time:  1.6078264713287354
e:  41   train_loss:  639.0860910299253   time:  1.49690580368042
e:  42   train_loss:  613.6869949364504   time:  1.501523494720459
e:  43   train_loss:  626.1330838443124   time:  1.499511480331421
e:  44   train_loss:  629.2008408520727   time:  1.6803240776062012
e:  45   train_loss:  619.7852102872585   time:  1.482823371887207
e:  45   train_loss:  619.7852102872585   val_loss:  534.7880082549843   time:  1.5896732807159424
e:  46   train_loss:  600.280227222603   time:  1.5036265850067139
e:  47   train_loss:  608.6278230369853   time:  1.5010502338409424
e:  48   train_loss:  626.6733920127867   time:  1.5027952194213867
e:  49   train_loss:  608.392930734382   time:  1.5053777694702148
e:  50   train_loss:  611.3905683176743   time:  1.7113254070281982
e:  50   train_loss:  611.3905683176743   val_loss:  538.559357165581   time:  1.8187341690063477
e:  51   train_loss:  591.2356246571667   time:  1.4889042377471924
e:  52   train_loss:  624.0420895280892   time:  1.4883801937103271
e:  53   train_loss:  590.7070239362749   time:  1.5721349716186523
e:  54   train_loss:  618.6508894061974   time:  1.4801044464111328
e:  55   train_loss:  604.8217479901883   time:  1.497722864151001
e:  55   train_loss:  604.8217479901883   val_loss:  556.5853824637106   time:  1.7745959758758545
e:  56   train_loss:  611.147103838526   time:  1.4937026500701904
e:  57   train_loss:  588.2966130597167   time:  1.4737131595611572
e:  58   train_loss:  617.952126110661   time:  1.4997990131378174
e:  59   train_loss:  604.8620973304905   time:  1.4961647987365723
e:  60   train_loss:  595.971973322215   time:  1.486889123916626
e:  60   train_loss:  595.971973322215   val_loss:  543.600458844813   time:  1.5934176445007324
e:  61   train_loss:  608.2323239159857   time:  1.4932820796966553
e:  62   train_loss:  580.3967714529302   time:  1.734300136566162
e:  63   train_loss:  634.7451490689774   time:  1.738255262374878
e:  64   train_loss:  584.4468128474037   time:  1.5343947410583496
e:  65   train_loss:  597.623062568382   time:  1.4995884895324707
e:  65   train_loss:  597.623062568382   val_loss:  537.1123250783232   time:  1.6067869663238525
e:  66   train_loss:  565.7900055879678   time:  1.4969441890716553
e:  67   train_loss:  586.1331887661992   time:  1.5023314952850342
e:  68   train_loss:  598.8863041459434   time:  1.6936545372009277
e:  69   train_loss:  566.7786870744131   time:  1.5003852844238281
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  70   train_loss:  564.3013548354338   time:  1.5000593662261963
e:  70   train_loss:  564.3013548354338   val_loss:  552.7310306650517   time:  1.6070265769958496
e:  71   train_loss:  614.8476874731525   time:  1.5306997299194336
e:  72   train_loss:  589.7713140316009   time:  1.5413947105407715
e:  73   train_loss:  576.2266170879071   time:  1.5236904621124268
e:  74   train_loss:  564.7494339794147   time:  1.5400276184082031
e:  75   train_loss:  581.6508931790909   time:  1.743328332901001
e:  75   train_loss:  581.6508931790909   val_loss:  542.4684664462625   time:  1.8490591049194336
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (2, 0, 3), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (2, 0, 3) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 3) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 3) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (2, 0, 3)
kwargs: {'config': {'batch_norm': False, 'ff_0': 158, 'ff_num_layers': 2, 'gnn_0': 1037, 'gnn_dropout': 0.4159381407912401, 'gnn_num_layers': 3, 'hid_0': 362, 'hid_dropout_rate': 0.0015934472827938695, 'in_dropout_rate': 0.24414691946777917, 'lr': 0.0007279250329450922, 'num_hid_layers': 2, 'optimizer': 'SGD', 'ff_1': 421, 'gnn_1': 161, 'gnn_2': 311, 'hid_1': 276, 'sgd_momentum': 0.033203490940577535}, 'budget': 729.0, 'working_directory': '.'}
result: {'loss': 712.6511335878931, 'n_epochs': 67.0, 'info': {'validation loss': 712.6511335878931}}
exception: None

DEBUG:hpbandster:job_callback for (2, 0, 3) started
DEBUG:hpbandster:job_callback for (2, 0, 3) got condition
DEBUG:hpbandster:Only 3 run(s) for budget 729.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (2, 0, 3) finished
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: trying submitting job (2, 0, 4) to dispatcher
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 4) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 4)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 4) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 4) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: start processing job (2, 0, 4)
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: args: ()
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: kwargs: {'config': {'batch_norm': False, 'ff_0': 1367, 'ff_num_layers': 1, 'gnn_0': 921, 'gnn_dropout': 0.41296454900911433, 'gnn_num_layers': 2, 'hid_0': 1906, 'hid_dropout_rate': 0.2868031356579865, 'in_dropout_rate': 0.4283977738400382, 'lr': 0.0003425347762745268, 'num_hid_layers': 1, 'optimizer': 'SGD', 'gnn_1': 341, 'sgd_momentum': 0.43265642667228815}, 'budget': 729.0, 'working_directory': '.'}
FOLD:  0
Model initialization done
Model training starts
e:  0   train_loss:  699.2333177196784   time:  1.7659952640533447
e:  0   train_loss:  699.2333177196784   val_loss:  1641.3608906495506   time:  1.8860840797424316
e:  1   train_loss:  671.9883089641205   time:  1.7338180541992188
e:  2   train_loss:  628.8438328951987   time:  1.721181869506836
e:  3   train_loss:  601.3131004788686   time:  1.7686476707458496
e:  4   train_loss:  596.9780483972038   time:  1.760469675064087
e:  5   train_loss:  595.9787120889281   time:  1.763061761856079
e:  5   train_loss:  595.9787120889281   val_loss:  1398.0470978371789   time:  1.883514165878296
e:  6   train_loss:  594.8264472317038   time:  1.7813925743103027
e:  7   train_loss:  593.9344145889733   time:  1.790177583694458
e:  8   train_loss:  593.4903140043419   time:  1.9843790531158447
e:  9   train_loss:  592.0187068357494   time:  1.786921739578247
e:  10   train_loss:  592.1471895016159   time:  1.7716054916381836
e:  10   train_loss:  592.1471895016159   val_loss:  1396.066888616361   time:  1.89339017868042
e:  11   train_loss:  590.5539306558017   time:  1.8211088180541992
e:  12   train_loss:  589.3759481586209   time:  1.8466174602508545
e:  13   train_loss:  588.6464901518134   time:  1.7842686176300049
e:  14   train_loss:  587.4743718837072   time:  1.8129005432128906
e:  15   train_loss:  587.0932289786407   time:  1.7755255699157715
e:  15   train_loss:  587.0932289786407   val_loss:  1393.8005428198956   time:  1.8974220752716064
e:  16   train_loss:  586.4610721448495   time:  1.682239055633545
e:  17   train_loss:  585.2811562562164   time:  1.9415192604064941
e:  18   train_loss:  584.2514091699477   time:  1.7739479541778564
e:  19   train_loss:  583.1448815418751   time:  1.768383502960205
e:  20   train_loss:  582.8055578522167   time:  1.7752611637115479
e:  20   train_loss:  582.8055578522167   val_loss:  1389.3030101632658   time:  1.896554708480835
e:  21   train_loss:  581.5206386287668   time:  1.7331125736236572
e:  22   train_loss:  579.927016520802   time:  1.772209644317627
e:  23   train_loss:  578.8609230132722   time:  1.7728478908538818
e:  24   train_loss:  577.386158039927   time:  1.7598631381988525
e:  25   train_loss:  576.9100505367834   time:  1.7526915073394775
e:  25   train_loss:  576.9100505367834   val_loss:  1387.0828147276206   time:  1.8738787174224854
e:  26   train_loss:  574.857327353665   time:  1.827073335647583
e:  27   train_loss:  574.0697880958135   time:  1.8018946647644043
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  28   train_loss:  572.3777375638915   time:  1.9389915466308594
e:  29   train_loss:  571.416760106487   time:  1.765528917312622
e:  30   train_loss:  569.2887476628282   time:  1.7780075073242188
e:  30   train_loss:  569.2887476628282   val_loss:  1386.172328099209   time:  1.8985092639923096
e:  31   train_loss:  567.6743321257495   time:  1.7290523052215576
e:  32   train_loss:  567.4207837250368   time:  1.724299430847168
e:  33   train_loss:  565.5747194648039   time:  1.6960399150848389
e:  34   train_loss:  564.0503590051894   time:  1.782442331314087
e:  35   train_loss:  562.540818660199   time:  1.784731388092041
e:  35   train_loss:  562.540818660199   val_loss:  1378.960997063804   time:  1.9965202808380127
e:  36   train_loss:  560.7381157707497   time:  1.7793002128601074
e:  37   train_loss:  559.3065875510548   time:  1.9817707538604736
e:  38   train_loss:  558.6975737487642   time:  1.7314341068267822
e:  39   train_loss:  557.2630890665653   time:  1.7770357131958008
e:  40   train_loss:  555.1291001874278   time:  1.7637121677398682
e:  40   train_loss:  555.1291001874278   val_loss:  1377.3320164598872   time:  1.8866267204284668
e:  41   train_loss:  554.0511006203664   time:  1.8081374168395996
e:  42   train_loss:  552.0653188966768   time:  1.778768539428711
e:  43   train_loss:  551.5430209066242   time:  1.8360211849212646
e:  44   train_loss:  549.7788397521625   time:  1.8056786060333252
e:  45   train_loss:  548.1350896793812   time:  1.81803560256958
e:  45   train_loss:  548.1350896793812   val_loss:  1378.5512673105623   time:  1.9394235610961914
e:  46   train_loss:  547.5155636698706   time:  1.7783317565917969
e:  47   train_loss:  545.5010542084783   time:  1.7790863513946533
e:  48   train_loss:  544.9112895244186   time:  1.976254940032959
e:  49   train_loss:  543.3639541241118   time:  1.6870405673980713
e:  50   train_loss:  541.79036260846   time:  1.8051745891571045
e:  50   train_loss:  541.79036260846   val_loss:  1373.7432930603923   time:  1.9255025386810303
e:  51   train_loss:  540.8408998914322   time:  1.800647497177124
e:  52   train_loss:  539.355944026914   time:  1.8086466789245605
e:  53   train_loss:  538.2248876566516   time:  1.7944676876068115
e:  54   train_loss:  537.21534568102   time:  1.80662202835083
e:  55   train_loss:  534.8249970095894   time:  1.7860512733459473
e:  55   train_loss:  534.8249970095894   val_loss:  1364.664555654306   time:  1.9557209014892578
e:  56   train_loss:  534.1688841637656   time:  1.7866301536560059
e:  57   train_loss:  533.3304724492488   time:  1.7949578762054443
e:  58   train_loss:  531.1592489562087   time:  1.7848291397094727
e:  59   train_loss:  531.8022799456141   time:  1.776606798171997
e:  60   train_loss:  529.4041486384981   time:  1.9977760314941406
e:  60   train_loss:  529.4041486384981   val_loss:  1368.0625784471886   time:  2.1119842529296875
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  61   train_loss:  528.2161670722027   time:  1.8563299179077148
e:  62   train_loss:  527.3986477238913   time:  1.7893540859222412
e:  63   train_loss:  526.3466699866335   time:  1.8429946899414062
e:  64   train_loss:  525.1209010233091   time:  1.8038923740386963
e:  65   train_loss:  524.006705392961   time:  1.7659258842468262
e:  65   train_loss:  524.006705392961   val_loss:  1362.7997592108995   time:  1.8849105834960938
e:  66   train_loss:  522.3899088329745   time:  1.817089319229126
e:  67   train_loss:  521.9920410896295   time:  1.785304069519043
e:  68   train_loss:  520.9831558608028   time:  1.7810750007629395
e:  69   train_loss:  519.0238263794148   time:  1.7722671031951904
e:  70   train_loss:  518.5022460619722   time:  1.9698810577392578
e:  70   train_loss:  518.5022460619722   val_loss:  1364.2083101652213   time:  2.083911895751953
e:  71   train_loss:  516.7440361968721   time:  1.7592806816101074
e:  72   train_loss:  515.9693049818804   time:  1.8147122859954834
e:  73   train_loss:  514.9834315007894   time:  1.765779733657837
e:  74   train_loss:  514.2690129534382   time:  1.8467528820037842
e:  75   train_loss:  513.0810916799419   time:  1.8012607097625732
e:  75   train_loss:  513.0810916799419   val_loss:  1370.125699762148   time:  1.9219965934753418
e:  76   train_loss:  511.2068612923068   time:  1.7840006351470947
e:  77   train_loss:  509.94306310183816   time:  1.7736568450927734
e:  78   train_loss:  508.6778074134162   time:  1.7821259498596191
e:  79   train_loss:  508.5489772641617   time:  1.966414213180542
e:  80   train_loss:  507.3856466025768   time:  1.764692783355713
e:  80   train_loss:  507.3856466025768   val_loss:  1360.0634532053618   time:  1.8856828212738037
e:  81   train_loss:  506.10822485465417   time:  1.7584254741668701
e:  82   train_loss:  505.09234474886364   time:  1.7011911869049072
e:  83   train_loss:  503.63516455666553   time:  1.769235610961914
e:  84   train_loss:  503.1112954738951   time:  1.7800121307373047
e:  85   train_loss:  501.68899036686145   time:  1.7872202396392822
e:  85   train_loss:  501.68899036686145   val_loss:  1365.9504784581518   time:  1.908759593963623
e:  86   train_loss:  499.7332906521291   time:  1.7815213203430176
e:  87   train_loss:  500.3061379786942   time:  1.7797648906707764
e:  88   train_loss:  499.258340214869   time:  1.778853416442871
e:  89   train_loss:  497.4396721615332   time:  1.770611047744751
e:  90   train_loss:  496.9801588425629   time:  1.7890207767486572
e:  90   train_loss:  496.9801588425629   val_loss:  1374.605929868115   time:  2.0897772312164307
e:  91   train_loss:  496.1587659412072   time:  1.7640399932861328
e:  92   train_loss:  495.0304314629934   time:  1.7916786670684814
e:  93   train_loss:  494.18233421645385   time:  1.7681794166564941
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  94   train_loss:  492.8619565383114   time:  1.7853667736053467
e:  95   train_loss:  492.19766033758265   time:  1.7817177772521973
e:  95   train_loss:  492.19766033758265   val_loss:  1365.5160026007793   time:  1.9027960300445557
e:  96   train_loss:  491.32278636492634   time:  1.7806146144866943
e:  97   train_loss:  490.1956288141816   time:  1.7909467220306396
e:  98   train_loss:  488.76625706493206   time:  1.7158753871917725
e:  99   train_loss:  487.761322999727   time:  1.720698356628418
e:  100   train_loss:  487.7019190582422   time:  1.718031644821167
e:  100   train_loss:  487.7019190582422   val_loss:  1365.399451753571   time:  1.8369240760803223
e:  101   train_loss:  486.7604604917225   time:  1.9646148681640625
e:  102   train_loss:  485.81007712077127   time:  1.780796766281128
e:  103   train_loss:  484.5187424184848   time:  1.6961853504180908
e:  104   train_loss:  485.42847266173294   time:  1.7675285339355469
e:  105   train_loss:  483.50390450810477   time:  1.8037397861480713
e:  105   train_loss:  483.50390450810477   val_loss:  1385.814888784567   time:  1.975642442703247
e:  106   train_loss:  481.9552550464678   time:  1.8005926609039307
e:  107   train_loss:  481.4012339410231   time:  1.7706663608551025
e:  108   train_loss:  481.68333627007166   time:  1.7690017223358154
e:  109   train_loss:  480.2071224411676   time:  1.7787482738494873
e:  110   train_loss:  479.38149625727317   time:  1.7830405235290527
e:  110   train_loss:  479.38149625727317   val_loss:  1390.4188190116267   time:  2.065868377685547
FOLD:  1
Model initialization done
Model training starts
e:  0   train_loss:  1079.851840883755   time:  1.9331533908843994
e:  0   train_loss:  1079.851840883755   val_loss:  599.5582247072513   time:  2.044898748397827
e:  1   train_loss:  995.3870992972655   time:  1.9228394031524658
e:  2   train_loss:  918.1501932408062   time:  1.9422850608825684
e:  3   train_loss:  904.8358174800107   time:  1.8954479694366455
e:  4   train_loss:  895.7287602285652   time:  1.9455878734588623
e:  5   train_loss:  886.3244536550249   time:  2.0386478900909424
e:  5   train_loss:  886.3244536550249   val_loss:  555.0865038309295   time:  2.40342116355896
e:  6   train_loss:  902.8949258840562   time:  1.967132568359375
e:  7   train_loss:  894.7683087063625   time:  2.050285577774048
e:  8   train_loss:  888.508167311597   time:  1.9820878505706787
e:  9   train_loss:  890.5867228751241   time:  1.9374380111694336
e:  10   train_loss:  883.7584677993731   time:  1.9200599193572998
e:  10   train_loss:  883.7584677993731   val_loss:  551.512529803909   time:  2.032400369644165
e:  11   train_loss:  888.3445643891827   time:  1.9301707744598389
e:  12   train_loss:  900.181793459902   time:  1.9302294254302979
e:  13   train_loss:  884.1230138210984   time:  2.1200613975524902
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  14   train_loss:  889.3678263022002   time:  1.9294989109039307
e:  15   train_loss:  883.5097273649716   time:  1.9314467906951904
e:  15   train_loss:  883.5097273649716   val_loss:  551.2040050053587   time:  2.0437369346618652
e:  16   train_loss:  871.9309664330924   time:  1.916064739227295
e:  17   train_loss:  871.7573007048418   time:  1.8577401638031006
e:  18   train_loss:  859.4513384448289   time:  1.8775660991668701
e:  19   train_loss:  861.3896374130418   time:  2.0217278003692627
e:  20   train_loss:  852.2758945350521   time:  1.8543040752410889
e:  20   train_loss:  852.2758945350521   val_loss:  545.4394055589413   time:  1.9667649269104004
e:  21   train_loss:  831.8928562113458   time:  1.9228403568267822
e:  22   train_loss:  844.2668026446477   time:  1.9127609729766846
e:  23   train_loss:  842.7313706108494   time:  1.9276134967803955
e:  24   train_loss:  835.00073662683   time:  1.8458433151245117
e:  25   train_loss:  822.7631977771903   time:  2.0648505687713623
e:  25   train_loss:  822.7631977771903   val_loss:  539.4779019057896   time:  2.176711082458496
e:  26   train_loss:  799.2904549632979   time:  1.9222993850708008
e:  27   train_loss:  799.9961255079621   time:  1.9301915168762207
e:  28   train_loss:  802.3900497180864   time:  1.8389430046081543
e:  29   train_loss:  778.2988784579927   time:  1.9071474075317383
e:  30   train_loss:  762.339075661977   time:  1.9202263355255127
e:  30   train_loss:  762.339075661977   val_loss:  548.1455407855979   time:  2.0321097373962402
e:  31   train_loss:  749.6891630694076   time:  1.9259066581726074
e:  32   train_loss:  737.2718028141032   time:  2.1440863609313965
e:  33   train_loss:  710.4757122148787   time:  1.9088151454925537
e:  34   train_loss:  709.7659701363597   time:  1.8426008224487305
e:  35   train_loss:  708.1357975261292   time:  1.9100825786590576
e:  35   train_loss:  708.1357975261292   val_loss:  770.5267236845606   time:  2.0218095779418945
e:  36   train_loss:  685.1149257867077   time:  1.8917951583862305
e:  37   train_loss:  691.0753026605505   time:  1.855855941772461
e:  38   train_loss:  674.9560733999824   time:  2.151993989944458
e:  39   train_loss:  673.7637251382753   time:  1.8357722759246826
e:  40   train_loss:  662.3868670691803   time:  1.8777523040771484
e:  40   train_loss:  662.3868670691803   val_loss:  834.56450935637   time:  1.9911534786224365
e:  41   train_loss:  673.0610571106263   time:  1.9195899963378906
e:  42   train_loss:  668.8695605148534   time:  1.8999643325805664
e:  43   train_loss:  659.9168598479098   time:  1.8355717658996582
e:  44   train_loss:  657.7762839105413   time:  2.1070797443389893
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  45   train_loss:  663.6297489004978   time:  1.918689489364624
e:  45   train_loss:  663.6297489004978   val_loss:  890.0058317902398   time:  2.028496026992798
e:  46   train_loss:  652.9381850329646   time:  1.8637793064117432
e:  47   train_loss:  655.2249017510429   time:  1.8258368968963623
e:  48   train_loss:  658.751015605447   time:  1.8302326202392578
e:  49   train_loss:  646.7136518015893   time:  1.8369941711425781
e:  50   train_loss:  651.2313826707685   time:  1.871084213256836
e:  50   train_loss:  651.2313826707685   val_loss:  909.3025636135774   time:  1.9830446243286133
e:  51   train_loss:  645.2476423645448   time:  2.1143624782562256
e:  52   train_loss:  660.8824215466933   time:  1.9250094890594482
e:  53   train_loss:  643.880358785053   time:  1.8366832733154297
e:  54   train_loss:  650.291459686217   time:  1.8865256309509277
e:  55   train_loss:  643.6274703368603   time:  1.9117431640625
e:  55   train_loss:  643.6274703368603   val_loss:  945.0028189715038   time:  2.022965669631958
FOLD:  2
Model initialization done
Model training starts
e:  0   train_loss:  1061.812959956545   time:  1.825157880783081
e:  0   train_loss:  1061.812959956545   val_loss:  517.046459543566   time:  1.9392120838165283
e:  1   train_loss:  989.620410782614   time:  1.9928662776947021
e:  2   train_loss:  946.5563270972895   time:  1.8089334964752197
e:  3   train_loss:  950.2565033546695   time:  1.8956761360168457
e:  4   train_loss:  939.3961775409914   time:  1.887113332748413
e:  5   train_loss:  882.168257105833   time:  1.894972324371338
e:  5   train_loss:  882.168257105833   val_loss:  498.645509005018   time:  2.0098884105682373
e:  6   train_loss:  908.1975517963432   time:  1.850951910018921
e:  7   train_loss:  893.577474100121   time:  1.8804082870483398
e:  8   train_loss:  881.4525711000166   time:  1.8889222145080566
e:  9   train_loss:  875.6181805660894   time:  1.8147211074829102
e:  10   train_loss:  884.5754579259817   time:  2.066640615463257
e:  10   train_loss:  884.5754579259817   val_loss:  496.67820818037467   time:  2.182565212249756
e:  11   train_loss:  869.9411742858051   time:  1.905303955078125
e:  12   train_loss:  882.1177283289161   time:  1.8888771533966064
e:  13   train_loss:  889.2003052437326   time:  1.8951542377471924
e:  14   train_loss:  856.989794703874   time:  1.8939907550811768
e:  15   train_loss:  862.1728482234463   time:  1.8924198150634766
e:  15   train_loss:  862.1728482234463   val_loss:  491.67284959333847   time:  2.006040334701538
e:  16   train_loss:  871.8468286419198   time:  1.805889368057251
e:  17   train_loss:  871.5465628307539   time:  2.07771635055542
e:  18   train_loss:  843.8544412489247   time:  1.888059377670288
e:  19   train_loss:  863.2489784110758   time:  1.8996543884277344
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  20   train_loss:  853.2177172629746   time:  1.8398237228393555
e:  20   train_loss:  853.2177172629746   val_loss:  495.9276247370753   time:  1.9552197456359863
e:  21   train_loss:  852.9020946417137   time:  1.896789789199829
e:  22   train_loss:  855.3554195250117   time:  1.8887951374053955
e:  23   train_loss:  831.7396730413354   time:  1.8990161418914795
e:  24   train_loss:  836.2785712764398   time:  1.842402458190918
e:  25   train_loss:  843.4933200495926   time:  2.0425827503204346
e:  25   train_loss:  843.4933200495926   val_loss:  487.1480163420929   time:  2.1565887928009033
e:  26   train_loss:  835.5920729566768   time:  1.8210086822509766
e:  27   train_loss:  845.7987277268153   time:  1.8892171382904053
e:  28   train_loss:  795.6747341380284   time:  1.8145530223846436
e:  29   train_loss:  796.0014498302914   time:  1.804917335510254
e:  30   train_loss:  782.868867765055   time:  1.8054554462432861
e:  30   train_loss:  782.868867765055   val_loss:  488.3921723243374   time:  1.9187994003295898
e:  31   train_loss:  775.904789410131   time:  1.8103930950164795
e:  32   train_loss:  790.7676758928716   time:  1.9844646453857422
e:  33   train_loss:  762.7824908710838   time:  1.9041614532470703
e:  34   train_loss:  792.1348710227891   time:  1.8969831466674805
e:  35   train_loss:  722.7014490053783   time:  1.9081909656524658
e:  35   train_loss:  722.7014490053783   val_loss:  528.1624911216215   time:  2.0254571437835693
e:  36   train_loss:  722.9206965483058   time:  1.9039723873138428
e:  37   train_loss:  744.1999550860659   time:  1.9013416767120361
e:  38   train_loss:  704.5052386565078   time:  1.8896145820617676
e:  39   train_loss:  711.569957401317   time:  1.8732399940490723
e:  40   train_loss:  698.2682491449663   time:  2.0044753551483154
e:  40   train_loss:  698.2682491449663   val_loss:  474.2581901143287   time:  2.1182994842529297
e:  41   train_loss:  701.6533372349081   time:  1.8872368335723877
e:  42   train_loss:  696.3401510046774   time:  1.8940250873565674
e:  43   train_loss:  690.7844009275902   time:  2.4185543060302734
e:  44   train_loss:  690.5644417011295   time:  1.8936176300048828
e:  45   train_loss:  699.8293389316615   time:  1.8845911026000977
e:  45   train_loss:  699.8293389316615   val_loss:  736.9193355324264   time:  1.9976825714111328
e:  46   train_loss:  724.3394762732145   time:  2.0165717601776123
e:  47   train_loss:  692.119418031117   time:  1.884059190750122
e:  48   train_loss:  687.2683419173013   time:  1.8106870651245117
e:  49   train_loss:  684.2555717359726   time:  1.8069756031036377
e:  50   train_loss:  691.8593833605295   time:  1.8036224842071533
e:  50   train_loss:  691.8593833605295   val_loss:  497.6567487174557   time:  1.9178986549377441
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  51   train_loss:  667.3035472779586   time:  1.8828046321868896
e:  52   train_loss:  667.4470374257891   time:  1.8868262767791748
e:  53   train_loss:  673.4637682017998   time:  1.8677072525024414
e:  54   train_loss:  666.7302809623836   time:  1.9890468120574951
e:  55   train_loss:  664.8668734008402   time:  1.8035216331481934
e:  55   train_loss:  664.8668734008402   val_loss:  476.2494955833363   time:  1.917637825012207
e:  56   train_loss:  655.1037539969271   time:  1.8413004875183105
e:  57   train_loss:  654.0346630056627   time:  1.8035507202148438
e:  58   train_loss:  664.4771960824105   time:  1.8039124011993408
e:  59   train_loss:  657.3011417271787   time:  1.8501465320587158
e:  60   train_loss:  694.3619733134178   time:  1.8018465042114258
e:  60   train_loss:  694.3619733134178   val_loss:  638.544963078642   time:  1.9154317378997803
e:  61   train_loss:  681.4030637638688   time:  1.8017022609710693
e:  62   train_loss:  650.0183376549982   time:  1.9930493831634521
e:  63   train_loss:  666.7592093103699   time:  1.8212180137634277
e:  64   train_loss:  674.3338598557552   time:  1.8831377029418945
e:  65   train_loss:  647.8697110497419   time:  1.8612079620361328
e:  65   train_loss:  647.8697110497419   val_loss:  515.9156342259707   time:  1.973973274230957
e:  66   train_loss:  667.2748414406893   time:  1.8048429489135742
e:  67   train_loss:  668.6885701717197   time:  1.8561091423034668
e:  68   train_loss:  654.178262360771   time:  1.8653333187103271
e:  69   train_loss:  670.5379037785931   time:  2.014719009399414
e:  70   train_loss:  684.5769408836493   time:  1.806603193283081
e:  70   train_loss:  684.5769408836493   val_loss:  603.0454492307538   time:  1.9204909801483154
FOLD:  3
Model initialization done
Model training starts
e:  0   train_loss:  989.183001949705   time:  1.6743860244750977
e:  0   train_loss:  989.183001949705   val_loss:  887.0188594779469   time:  1.7931270599365234
e:  1   train_loss:  943.5331399881596   time:  1.6886279582977295
e:  2   train_loss:  871.8504926914976   time:  1.69102144241333
e:  3   train_loss:  839.6466983162384   time:  1.7382159233093262
e:  4   train_loss:  836.6653034919327   time:  1.766002893447876
e:  5   train_loss:  835.8336023087454   time:  1.7644047737121582
e:  5   train_loss:  835.8336023087454   val_loss:  740.3049792942406   time:  1.8862581253051758
e:  6   train_loss:  838.1757888358719   time:  1.766777753829956
e:  7   train_loss:  834.1162072449918   time:  1.7666800022125244
e:  8   train_loss:  831.5873998604525   time:  1.925128698348999
e:  9   train_loss:  828.7821501916239   time:  1.7687044143676758
e:  10   train_loss:  831.67223357646   time:  1.7040455341339111
e:  10   train_loss:  831.67223357646   val_loss:  736.9898580300982   time:  1.8261005878448486
e:  11   train_loss:  827.2193174577136   time:  1.7844197750091553
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
e:  12   train_loss:  826.7544807933269   time:  1.7755553722381592
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  13   train_loss:  824.8066082805701   time:  1.7766673564910889
e:  14   train_loss:  820.0872259479318   time:  1.763218641281128
e:  15   train_loss:  822.4774236400989   time:  1.7729017734527588
e:  15   train_loss:  822.4774236400989   val_loss:  733.035344778318   time:  1.895500898361206
e:  16   train_loss:  818.4193108398704   time:  1.720947504043579
e:  17   train_loss:  816.077930293248   time:  1.699791431427002
e:  18   train_loss:  812.7083522843877   time:  1.7255198955535889
e:  19   train_loss:  809.5202134637213   time:  1.9369239807128906
e:  20   train_loss:  811.2328078368506   time:  1.7108094692230225
e:  20   train_loss:  811.2328078368506   val_loss:  728.0523996304537   time:  1.8312559127807617
e:  21   train_loss:  805.9143814544465   time:  1.7250268459320068
e:  22   train_loss:  803.1897766142656   time:  1.7643084526062012
e:  23   train_loss:  799.4479639944483   time:  1.7388453483581543
e:  24   train_loss:  796.0695107312748   time:  1.7468717098236084
e:  25   train_loss:  794.644965442323   time:  1.774125576019287
e:  25   train_loss:  794.644965442323   val_loss:  721.9456897966519   time:  1.8957164287567139
e:  26   train_loss:  789.386011703198   time:  1.778207778930664
e:  27   train_loss:  788.7204363590699   time:  1.7779841423034668
e:  28   train_loss:  780.0065591501402   time:  1.767019271850586
e:  29   train_loss:  776.7663654561409   time:  1.7711708545684814
e:  30   train_loss:  773.8953971445859   time:  1.7655205726623535
e:  30   train_loss:  773.8953971445859   val_loss:  715.513693662998   time:  1.887479305267334
e:  31   train_loss:  766.7689133807417   time:  1.7208616733551025
e:  32   train_loss:  761.8686849680215   time:  1.7751686573028564
e:  33   train_loss:  755.8020491318817   time:  1.921269178390503
e:  34   train_loss:  748.4491016817059   time:  1.6886351108551025
e:  35   train_loss:  739.7931516509659   time:  1.715930700302124
e:  35   train_loss:  739.7931516509659   val_loss:  708.1683413992649   time:  1.8377597332000732
e:  36   train_loss:  733.2552960693897   time:  1.773773193359375
e:  37   train_loss:  725.1793199971271   time:  1.7627413272857666
e:  38   train_loss:  716.1448561958453   time:  1.7809422016143799
e:  39   train_loss:  710.0490907833448   time:  1.7489960193634033
e:  40   train_loss:  701.9559613187498   time:  1.7588887214660645
e:  40   train_loss:  701.9559613187498   val_loss:  706.4964159990834   time:  1.8816754817962646
e:  41   train_loss:  695.3945004270569   time:  1.7680208683013916
e:  42   train_loss:  690.2879720111238   time:  1.7745616436004639
e:  43   train_loss:  680.4322343013969   time:  1.7379541397094727
e:  44   train_loss:  679.2682577793846   time:  1.8607454299926758
e:  45   train_loss:  672.1902800538743   time:  1.6744420528411865
e:  45   train_loss:  672.1902800538743   val_loss:  712.9600151562119   time:  1.7942121028900146
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  46   train_loss:  664.5352067605394   time:  1.6911404132843018
e:  47   train_loss:  661.5064654656999   time:  1.7252881526947021
e:  48   train_loss:  657.4768610121207   time:  1.76493239402771
e:  49   train_loss:  647.8699671132654   time:  1.7773733139038086
e:  50   train_loss:  651.7178933711466   time:  1.7623584270477295
e:  50   train_loss:  651.7178933711466   val_loss:  708.0228027252664   time:  1.881274700164795
e:  51   train_loss:  648.3776462227164   time:  1.6904478073120117
e:  52   train_loss:  641.729852957243   time:  1.757110357284546
e:  53   train_loss:  638.9900778197481   time:  1.7614197731018066
e:  54   train_loss:  637.0569100869855   time:  1.7580866813659668
e:  55   train_loss:  636.2846786028134   time:  1.7639997005462646
e:  55   train_loss:  636.2846786028134   val_loss:  702.2376587575033   time:  1.885676622390747
e:  56   train_loss:  637.8047968248666   time:  1.7640645503997803
e:  57   train_loss:  633.2706175020263   time:  1.765223741531372
e:  58   train_loss:  631.5691324329234   time:  1.921473503112793
e:  59   train_loss:  639.5099107948403   time:  1.7822647094726562
e:  60   train_loss:  641.2020777332308   time:  1.696505069732666
e:  60   train_loss:  641.2020777332308   val_loss:  694.2339086886601   time:  1.817204236984253
e:  61   train_loss:  627.4984306106627   time:  1.7526209354400635
e:  62   train_loss:  628.6347609303319   time:  1.7672874927520752
e:  63   train_loss:  626.5226767595799   time:  1.766291618347168
e:  64   train_loss:  631.1693518696308   time:  1.7510402202606201
e:  65   train_loss:  628.4663787294196   time:  1.7511591911315918
e:  65   train_loss:  628.4663787294196   val_loss:  695.500356298604   time:  1.8734850883483887
e:  66   train_loss:  624.732163445218   time:  1.7823984622955322
e:  67   train_loss:  621.8409540929282   time:  1.7429156303405762
e:  68   train_loss:  629.7969449142317   time:  1.709974765777588
e:  69   train_loss:  623.7474630872543   time:  1.9201481342315674
e:  70   train_loss:  617.9679092302938   time:  1.758965015411377
e:  70   train_loss:  617.9679092302938   val_loss:  690.6934155407574   time:  1.8817031383514404
e:  71   train_loss:  618.7977173917159   time:  1.7898175716400146
e:  72   train_loss:  618.3784213327549   time:  1.7794630527496338
e:  73   train_loss:  623.5533306864687   time:  1.7759873867034912
e:  74   train_loss:  620.1142928706992   time:  1.7731897830963135
e:  75   train_loss:  622.7275619426919   time:  1.7752985954284668
e:  75   train_loss:  622.7275619426919   val_loss:  684.2022623903687   time:  1.8968234062194824
e:  76   train_loss:  620.4593835513708   time:  1.7875115871429443
e:  77   train_loss:  615.205821411495   time:  1.7743544578552246
e:  78   train_loss:  619.204094667688   time:  1.7678186893463135
e:  79   train_loss:  616.0667994286982   time:  1.7780516147613525
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  80   train_loss:  613.6664299852225   time:  1.7623920440673828
e:  80   train_loss:  613.6664299852225   val_loss:  689.2699216622323   time:  1.8841984272003174
e:  81   train_loss:  614.1892843506083   time:  1.7559590339660645
e:  82   train_loss:  619.2609560489689   time:  1.7775874137878418
e:  83   train_loss:  615.0363671555056   time:  1.9209251403808594
e:  84   train_loss:  611.2701749119572   time:  1.713104009628296
e:  85   train_loss:  610.1819536779991   time:  1.697523832321167
e:  85   train_loss:  610.1819536779991   val_loss:  689.0756022050698   time:  1.819364070892334
e:  86   train_loss:  607.7623990761152   time:  1.774268627166748
e:  87   train_loss:  608.9222424431986   time:  1.7675390243530273
e:  88   train_loss:  606.7096216114037   time:  1.7739334106445312
e:  89   train_loss:  605.7815204409554   time:  1.7636408805847168
e:  90   train_loss:  607.6327085176526   time:  1.7781765460968018
e:  90   train_loss:  607.6327085176526   val_loss:  679.2989778532275   time:  1.9010143280029297
e:  91   train_loss:  611.6109217889714   time:  1.7238500118255615
e:  92   train_loss:  611.289650237526   time:  1.7780089378356934
e:  93   train_loss:  601.2756064393277   time:  1.7276885509490967
e:  94   train_loss:  604.623828378606   time:  1.8940377235412598
e:  95   train_loss:  601.6914823940235   time:  1.7416315078735352
e:  95   train_loss:  601.6914823940235   val_loss:  692.0350323986503   time:  1.8633229732513428
e:  96   train_loss:  619.1797354966108   time:  1.7742974758148193
e:  97   train_loss:  605.1369270292264   time:  1.7783150672912598
e:  98   train_loss:  600.8187603823338   time:  1.7727417945861816
e:  99   train_loss:  594.2973486691282   time:  1.7671892642974854
e:  100   train_loss:  602.5190890264108   time:  1.7733559608459473
e:  100   train_loss:  602.5190890264108   val_loss:  706.3543300632399   time:  1.8939018249511719
e:  101   train_loss:  613.9092121444952   time:  1.6874041557312012
e:  102   train_loss:  594.9018681936564   time:  1.7476344108581543
e:  103   train_loss:  599.2103386457338   time:  1.7602789402008057
e:  104   train_loss:  592.698256262487   time:  1.7525732517242432
e:  105   train_loss:  596.6961394312061   time:  1.7642390727996826
e:  105   train_loss:  596.6961394312061   val_loss:  671.9133161606201   time:  1.8859295845031738
e:  106   train_loss:  594.7763928625216   time:  1.7627689838409424
e:  107   train_loss:  617.7260850110947   time:  1.7651786804199219
e:  108   train_loss:  600.1047588344227   time:  1.9209327697753906
e:  109   train_loss:  594.0626208359346   time:  1.7819819450378418
e:  110   train_loss:  590.6406066108509   time:  1.6965863704681396
e:  110   train_loss:  590.6406066108509   val_loss:  669.9284279903974   time:  1.8175787925720215
e:  111   train_loss:  593.2940109404428   time:  1.7553327083587646
e:  112   train_loss:  592.9024014354886   time:  1.7666864395141602
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  113   train_loss:  590.8227310958179   time:  1.7674980163574219
e:  114   train_loss:  594.6049473631444   time:  1.77121901512146
e:  115   train_loss:  595.3169923672957   time:  1.777346134185791
e:  115   train_loss:  595.3169923672957   val_loss:  673.9423517136024   time:  1.8998193740844727
e:  116   train_loss:  591.1501648584062   time:  1.7666294574737549
e:  117   train_loss:  593.3650670543274   time:  1.7537577152252197
e:  118   train_loss:  599.3346018377492   time:  1.696420669555664
e:  119   train_loss:  597.9344602975995   time:  1.9016048908233643
e:  120   train_loss:  591.9801770086896   time:  1.7326407432556152
e:  120   train_loss:  591.9801770086896   val_loss:  688.3913226255877   time:  1.8557195663452148
e:  121   train_loss:  596.0932359228241   time:  1.7873659133911133
e:  122   train_loss:  586.4644552765112   time:  1.7753715515136719
e:  123   train_loss:  592.0933325109476   time:  1.7715730667114258
e:  124   train_loss:  587.7183585048945   time:  1.7742829322814941
e:  125   train_loss:  588.217104411825   time:  1.8422658443450928
e:  125   train_loss:  588.217104411825   val_loss:  664.79253316652   time:  1.9636433124542236
e:  126   train_loss:  586.8736585213381   time:  1.7742254734039307
e:  127   train_loss:  586.9602485163855   time:  1.7731311321258545
e:  128   train_loss:  580.7119352768592   time:  1.769542932510376
e:  129   train_loss:  599.7831310341329   time:  1.775853157043457
e:  130   train_loss:  601.284755852163   time:  1.7675886154174805
e:  130   train_loss:  601.284755852163   val_loss:  664.1024271283097   time:  1.8897984027862549
e:  131   train_loss:  584.5588138704082   time:  1.7518551349639893
e:  132   train_loss:  586.6433085152972   time:  1.7688753604888916
e:  133   train_loss:  581.8090666591658   time:  1.9285204410552979
e:  134   train_loss:  588.0421447374353   time:  1.7362780570983887
e:  135   train_loss:  589.8824031878298   time:  1.7107338905334473
e:  135   train_loss:  589.8824031878298   val_loss:  662.0418511445035   time:  1.8328163623809814
e:  136   train_loss:  580.8904920181002   time:  1.7572221755981445
e:  137   train_loss:  579.8672413760655   time:  1.7740511894226074
e:  138   train_loss:  577.1917996564084   time:  1.7426340579986572
e:  139   train_loss:  578.1056906629791   time:  1.7160110473632812
e:  140   train_loss:  579.8002442848727   time:  1.8285505771636963
e:  140   train_loss:  579.8002442848727   val_loss:  662.061871378101   time:  1.9507026672363281
e:  141   train_loss:  588.1102064763276   time:  1.7772471904754639
e:  142   train_loss:  590.6029635356165   time:  1.7810769081115723
e:  143   train_loss:  575.1707858089893   time:  1.7961866855621338
e:  144   train_loss:  583.6007372073325   time:  1.9579648971557617
e:  145   train_loss:  586.1687427176846   time:  1.749903678894043
e:  145   train_loss:  586.1687427176846   val_loss:  661.1397379951603   time:  1.8726046085357666
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  146   train_loss:  575.0148077459526   time:  1.7715096473693848
e:  147   train_loss:  572.4364282450847   time:  1.7669692039489746
e:  148   train_loss:  579.0109304538041   time:  1.778294324874878
e:  149   train_loss:  572.3605169750037   time:  1.7754087448120117
e:  150   train_loss:  576.5000707254046   time:  1.7826805114746094
e:  150   train_loss:  576.5000707254046   val_loss:  662.7872572075761   time:  1.9042479991912842
e:  151   train_loss:  596.6331453434019   time:  1.6999177932739258
e:  152   train_loss:  573.2866424961755   time:  1.7205758094787598
e:  153   train_loss:  568.1945021543897   time:  1.7564177513122559
e:  154   train_loss:  583.6842797170325   time:  1.7362587451934814
e:  155   train_loss:  572.7774074133331   time:  1.7597756385803223
e:  155   train_loss:  572.7774074133331   val_loss:  669.1740752472509   time:  1.8818368911743164
e:  156   train_loss:  589.5872367648781   time:  1.7795207500457764
e:  157   train_loss:  573.5255157818403   time:  1.7766075134277344
e:  158   train_loss:  571.790936402965   time:  1.9513623714447021
e:  159   train_loss:  564.6829774599958   time:  1.8058135509490967
e:  160   train_loss:  570.6366908331954   time:  1.7874119281768799
e:  160   train_loss:  570.6366908331954   val_loss:  668.8581686439823   time:  1.9104251861572266
e:  161   train_loss:  574.7854157462027   time:  1.7244694232940674
e:  162   train_loss:  572.6964629419664   time:  1.7822747230529785
e:  163   train_loss:  571.5723171791192   time:  1.7726943492889404
e:  164   train_loss:  570.0824808650821   time:  1.7123034000396729
e:  165   train_loss:  561.1518793930704   time:  1.793450117111206
e:  165   train_loss:  561.1518793930704   val_loss:  665.1908744098365   time:  1.916210412979126
e:  166   train_loss:  584.715183318235   time:  1.7806453704833984
e:  167   train_loss:  570.3539186148078   time:  1.747204303741455
e:  168   train_loss:  575.7660456071047   time:  1.755134105682373
e:  169   train_loss:  572.7711385982997   time:  1.938680648803711
e:  170   train_loss:  563.2512467320317   time:  1.6936769485473633
e:  170   train_loss:  563.2512467320317   val_loss:  658.6044764658878   time:  1.8140170574188232
e:  171   train_loss:  574.4891927510695   time:  1.7974379062652588
e:  172   train_loss:  566.5530501115239   time:  1.7927918434143066
e:  173   train_loss:  575.2109527477934   time:  1.7790727615356445
e:  174   train_loss:  564.4579660541417   time:  1.7860357761383057
e:  175   train_loss:  588.5544939366675   time:  1.797790765762329
e:  175   train_loss:  588.5544939366675   val_loss:  683.3306446235468   time:  1.9211158752441406
e:  176   train_loss:  568.9053298421732   time:  1.7933225631713867
e:  177   train_loss:  561.020572267093   time:  1.788426399230957
e:  178   train_loss:  566.3961802690594   time:  1.7893078327178955
e:  179   train_loss:  561.3622846945377   time:  1.7819674015045166
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  180   train_loss:  559.1285680641785   time:  1.760913372039795
e:  180   train_loss:  559.1285680641785   val_loss:  679.6593963997298   time:  1.882972240447998
e:  181   train_loss:  560.5183660797712   time:  1.7773044109344482
e:  182   train_loss:  572.4860646339512   time:  1.76041579246521
e:  183   train_loss:  558.7888385423537   time:  1.9139785766601562
e:  184   train_loss:  570.7383072672682   time:  1.740607500076294
e:  185   train_loss:  560.2906583534584   time:  1.747898817062378
e:  185   train_loss:  560.2906583534584   val_loss:  655.5892362138759   time:  1.8693103790283203
e:  186   train_loss:  562.1136362410106   time:  1.7411587238311768
e:  187   train_loss:  580.0995070657298   time:  1.7679996490478516
e:  188   train_loss:  562.738657347447   time:  1.7847285270690918
e:  189   train_loss:  558.6937346560903   time:  1.7802088260650635
e:  190   train_loss:  571.7131897272454   time:  1.7780890464782715
e:  190   train_loss:  571.7131897272454   val_loss:  663.6972035496748   time:  1.9000766277313232
e:  191   train_loss:  559.663184383699   time:  1.7690858840942383
e:  192   train_loss:  567.767501236564   time:  1.7791345119476318
e:  193   train_loss:  565.1868136576626   time:  1.7518694400787354
e:  194   train_loss:  557.6799724562854   time:  1.9454569816589355
e:  195   train_loss:  562.7640295503526   time:  1.7625439167022705
e:  195   train_loss:  562.7640295503526   val_loss:  666.222571200162   time:  1.8854970932006836
e:  196   train_loss:  556.7570785985431   time:  1.7963361740112305
e:  197   train_loss:  558.3459840734547   time:  1.7980058193206787
e:  198   train_loss:  556.5397818765767   time:  1.7642829418182373
e:  199   train_loss:  579.8274654608826   time:  1.768021821975708
e:  200   train_loss:  558.8019866221399   time:  1.7789897918701172
e:  200   train_loss:  558.8019866221399   val_loss:  653.9859988998707   time:  1.8979918956756592
e:  201   train_loss:  564.2281281093419   time:  1.7040555477142334
e:  202   train_loss:  553.9086345047667   time:  1.755401611328125
e:  203   train_loss:  563.0556801410402   time:  1.7426295280456543
e:  204   train_loss:  564.2031198472589   time:  1.744527816772461
e:  205   train_loss:  553.41086317431   time:  1.7824726104736328
e:  205   train_loss:  553.41086317431   val_loss:  659.5095148230653   time:  1.9043526649475098
e:  206   train_loss:  549.5591954516393   time:  1.7842366695404053
e:  207   train_loss:  554.2099444862351   time:  1.8046495914459229
e:  208   train_loss:  576.8953559148407   time:  1.9501368999481201
e:  209   train_loss:  552.5362798383708   time:  1.7848942279815674
e:  210   train_loss:  551.0846379044835   time:  1.7204678058624268
e:  210   train_loss:  551.0846379044835   val_loss:  653.6452791402344   time:  1.932941198348999
e:  211   train_loss:  550.7937897127727   time:  1.7690379619598389
e:  212   train_loss:  554.381642495974   time:  1.791473150253296
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  213   train_loss:  574.3641114771501   time:  1.8223986625671387
e:  214   train_loss:  549.2937232863505   time:  1.7909200191497803
e:  215   train_loss:  550.3604317958731   time:  1.8125081062316895
e:  215   train_loss:  550.3604317958731   val_loss:  731.3589933368182   time:  1.9374876022338867
e:  216   train_loss:  572.9945952225345   time:  1.7871026992797852
e:  217   train_loss:  546.5763723709337   time:  1.8341953754425049
e:  218   train_loss:  562.6784918602623   time:  1.7692694664001465
e:  219   train_loss:  555.5458398655111   time:  1.9744868278503418
e:  220   train_loss:  562.6296616059983   time:  1.780761957168579
e:  220   train_loss:  562.6296616059983   val_loss:  659.583877694343   time:  1.9039711952209473
e:  221   train_loss:  550.1951713387411   time:  1.8035392761230469
e:  222   train_loss:  569.2831742633895   time:  1.800597906112671
e:  223   train_loss:  550.1920673142376   time:  1.772505521774292
e:  224   train_loss:  556.8367293354869   time:  1.7722911834716797
e:  225   train_loss:  543.479708278931   time:  1.7720377445220947
e:  225   train_loss:  543.479708278931   val_loss:  658.9965770607278   time:  1.8934967517852783
e:  226   train_loss:  557.3853014736425   time:  1.767404556274414
e:  227   train_loss:  545.2779138388078   time:  1.7709808349609375
e:  228   train_loss:  554.2404626719898   time:  1.7679152488708496
e:  229   train_loss:  548.8435026606804   time:  1.7712597846984863
e:  230   train_loss:  545.7689670944529   time:  1.7650694847106934
e:  230   train_loss:  545.7689670944529   val_loss:  659.2793611702184   time:  1.8870837688446045
e:  231   train_loss:  541.7176361281533   time:  1.7636675834655762
e:  232   train_loss:  552.2994083203962   time:  1.7768044471740723
e:  233   train_loss:  550.0537475788702   time:  1.908449411392212
e:  234   train_loss:  544.120479415315   time:  1.6894681453704834
e:  235   train_loss:  544.5543242905757   time:  1.680265188217163
e:  235   train_loss:  544.5543242905757   val_loss:  661.7404014642445   time:  1.7999391555786133
e:  236   train_loss:  551.054891414377   time:  1.7269062995910645
e:  237   train_loss:  551.0817276299248   time:  1.7278258800506592
e:  238   train_loss:  545.2237490962716   time:  1.7324137687683105
e:  239   train_loss:  542.7868858927562   time:  1.7631134986877441
e:  240   train_loss:  543.4867186762295   time:  1.7723720073699951
e:  240   train_loss:  543.4867186762295   val_loss:  659.6086954716735   time:  1.8949599266052246
FOLD:  4
Model initialization done
Model training starts
e:  0   train_loss:  1060.0567555110415   time:  1.8719313144683838
e:  0   train_loss:  1060.0567555110415   val_loss:  658.3114475569525   time:  1.9855868816375732
e:  1   train_loss:  1018.2181787147905   time:  2.1362130641937256
e:  2   train_loss:  920.0725772678608   time:  1.9267618656158447
e:  3   train_loss:  906.0950665680615   time:  1.9293606281280518
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  4   train_loss:  894.502222198149   time:  1.914215326309204
e:  5   train_loss:  887.7828970118229   time:  1.9174449443817139
e:  5   train_loss:  887.7828970118229   val_loss:  556.6891592167048   time:  2.030749559402466
e:  6   train_loss:  888.6358602308584   time:  1.904987096786499
e:  7   train_loss:  888.5008868669471   time:  1.8749535083770752
e:  8   train_loss:  898.7815599901355   time:  2.1186695098876953
e:  9   train_loss:  886.1902759245143   time:  1.8458330631256104
e:  10   train_loss:  892.7892323452911   time:  1.8308765888214111
e:  10   train_loss:  892.7892323452911   val_loss:  555.5172950872077   time:  1.9429385662078857
e:  11   train_loss:  879.1226848087797   time:  1.83052659034729
e:  12   train_loss:  897.3097366148163   time:  1.8293819427490234
e:  13   train_loss:  871.7760395622927   time:  1.8983862400054932
e:  14   train_loss:  874.8135261795782   time:  1.9057447910308838
e:  15   train_loss:  875.4480389324003   time:  2.1236023902893066
e:  15   train_loss:  875.4480389324003   val_loss:  554.7042009798125   time:  2.236588954925537
e:  16   train_loss:  864.9784398870826   time:  1.928513765335083
e:  17   train_loss:  873.0394679190437   time:  1.9225516319274902
e:  18   train_loss:  850.9173442995485   time:  1.8985605239868164
e:  19   train_loss:  854.5577898279466   time:  1.920515775680542
e:  20   train_loss:  839.334103984598   time:  1.9176557064056396
e:  20   train_loss:  839.334103984598   val_loss:  554.0530974159791   time:  2.0315017700195312
e:  21   train_loss:  845.0650039439478   time:  1.9276039600372314
e:  22   train_loss:  830.3705189526935   time:  2.1353390216827393
e:  23   train_loss:  828.9158006547817   time:  1.9357776641845703
e:  24   train_loss:  822.9590608690123   time:  1.83842134475708
e:  25   train_loss:  814.1435028473203   time:  1.8250861167907715
e:  25   train_loss:  814.1435028473203   val_loss:  557.2271343593757   time:  1.9377598762512207
e:  26   train_loss:  806.3090159193631   time:  1.834364891052246
e:  27   train_loss:  808.486557786372   time:  1.8524584770202637
e:  28   train_loss:  782.298439948261   time:  2.0629727840423584
e:  29   train_loss:  779.1083103351439   time:  1.8936045169830322
e:  30   train_loss:  768.0222272090915   time:  1.9195632934570312
e:  30   train_loss:  768.0222272090915   val_loss:  566.8183219055297   time:  2.04845929145813
e:  31   train_loss:  737.971157483556   time:  1.8859519958496094
e:  32   train_loss:  728.1172880360433   time:  1.8265557289123535
e:  33   train_loss:  744.1513095549185   time:  1.9048690795898438
e:  34   train_loss:  706.9458086699592   time:  2.0938024520874023
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
e:  35   train_loss:  701.828355890276   time:  1.927494764328003
e:  35   train_loss:  701.828355890276   val_loss:  577.1328438992938   time:  2.041400909423828
e:  36   train_loss:  701.5165338286592   time:  1.9174156188964844
e:  37   train_loss:  689.7934160076791   time:  1.912726640701294
e:  38   train_loss:  685.2282163759919   time:  1.8947367668151855
e:  39   train_loss:  674.7636023783922   time:  1.84397292137146
e:  40   train_loss:  679.4142271335505   time:  1.8390512466430664
e:  40   train_loss:  679.4142271335505   val_loss:  577.192379923973   time:  2.1324918270111084
e:  41   train_loss:  680.6361740678271   time:  1.8335678577423096
e:  42   train_loss:  678.8217370607322   time:  1.8317539691925049
e:  43   train_loss:  668.8318154025941   time:  1.9095158576965332
e:  44   train_loss:  673.0144628167741   time:  1.8305184841156006
e:  45   train_loss:  654.9379421457617   time:  1.8320951461791992
e:  45   train_loss:  654.9379421457617   val_loss:  570.5413808186162   time:  1.9443202018737793
e:  46   train_loss:  664.8115404851446   time:  1.90262770652771
e:  47   train_loss:  668.0424703760455   time:  1.9143404960632324
e:  48   train_loss:  654.3499656588002   time:  1.9162414073944092
e:  49   train_loss:  654.3017750249447   time:  2.1059377193450928
e:  50   train_loss:  655.3666923761432   time:  1.909017562866211
e:  50   train_loss:  655.3666923761432   val_loss:  575.651131436996   time:  2.0224921703338623
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: done with job (2, 0, 4), trying to register it.
INFO:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: registered result for job (2, 0, 4) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 4) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 4) on hpbandster.run_example_1.worker.tc-dgx004.251801123456247932736 finished
DEBUG:hpbandster:job_id: (2, 0, 4)
kwargs: {'config': {'batch_norm': False, 'ff_0': 1367, 'ff_num_layers': 1, 'gnn_0': 921, 'gnn_dropout': 0.41296454900911433, 'gnn_num_layers': 2, 'hid_0': 1906, 'hid_dropout_rate': 0.2868031356579865, 'in_dropout_rate': 0.4283977738400382, 'lr': 0.0003425347762745268, 'num_hid_layers': 1, 'optimizer': 'SGD', 'gnn_1': 341, 'sgd_momentum': 0.43265642667228815}, 'budget': 729.0, 'working_directory': '.'}
result: {'loss': 716.2995843563388, 'n_epochs': 105.0, 'info': {'validation loss': 716.2995843563388}}
exception: None

DEBUG:hpbandster:job_callback for (2, 0, 4) started
DEBUG:hpbandster:job_callback for (2, 0, 4) got condition
DEBUG:hpbandster:Only 4 run(s) for budget 729.000000 available, need more than 21 -> can't build model!
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:job_callback for (2, 0, 4) finished
DEBUG:hpbandster:HBMASTER: shutdown initiated, shutdown_workers = True
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster.run_example_1.worker.tc-dgx004.2518011:WORKER: shutting down now!
INFO:hpbandster:DISPATCHER: Dispatcher shutting down
DEBUG:hpbandster:DISPATCHER: discover_workers shutting down
DEBUG:hpbandster:DISPATCHER: 'discover_worker' thread exited
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: job_runner shutting down
DEBUG:hpbandster:DISPATCHER: 'job_runner' thread exited
INFO:hpbandster:DISPATCHER: shut down complete
Best found configuration: {'batch_norm': True, 'ff_0': 106, 'ff_num_layers': 2, 'gnn_0': 317, 'gnn_dropout': 0.3368733383678324, 'gnn_num_layers': 1, 'hid_0': 74, 'hid_dropout_rate': 0.29648329598290585, 'in_dropout_rate': 0.04789760399280041, 'lr': 0.0007931206855937558, 'num_hid_layers': 3, 'optimizer': 'Adam', 'ff_1': 221, 'hid_1': 555, 'hid_2': 1092}
A total of 42 unique configurations where sampled.
A total of 61 runs where executed.
Total budget corresponds to 11.0 full function evaluations.
Model initialization done
Model training starts
e:  0   train_loss:  892.1534025804095   time:  2.662836790084839
e:  1   train_loss:  693.8686134979912   time:  2.112590789794922
e:  2   train_loss:  654.6088369567256   time:  2.6026225090026855
e:  3   train_loss:  622.0990439309772   time:  2.4372739791870117
e:  4   train_loss:  604.9722342297374   time:  2.4691662788391113
e:  5   train_loss:  595.6655930856169   time:  2.3186745643615723
e:  6   train_loss:  584.4192504970416   time:  2.105375051498413
e:  7   train_loss:  571.4360847818805   time:  2.1189098358154297
e:  8   train_loss:  567.1782352614015   time:  2.1349973678588867
e:  9   train_loss:  567.878612969589   time:  2.2337543964385986
e:  10   train_loss:  562.7095159964057   time:  2.5868968963623047
e:  11   train_loss:  559.1472527127571   time:  2.6836063861846924
e:  12   train_loss:  562.8139422274539   time:  2.124971389770508
e:  13   train_loss:  554.5503340297339   time:  2.0102689266204834
e:  14   train_loss:  551.1779218889376   time:  2.1278440952301025
e:  15   train_loss:  540.2428346638146   time:  2.142561912536621
e:  16   train_loss:  541.8334620184703   time:  1.9741671085357666
e:  17   train_loss:  531.1578574537992   time:  2.1632189750671387
e:  18   train_loss:  524.265259925215   time:  2.29001784324646
e:  19   train_loss:  524.5756516245915   time:  2.0699944496154785
e:  20   train_loss:  518.450551486257   time:  2.1567506790161133
e:  21   train_loss:  514.9542006166018   time:  2.1122000217437744
e:  22   train_loss:  515.6143526721706   time:  2.1440963745117188
e:  23   train_loss:  503.6042370242611   time:  2.1541330814361572
e:  24   train_loss:  502.376496560198   time:  2.019460439682007
e:  25   train_loss:  488.55495936329004   time:  2.14853572845459
e:  26   train_loss:  495.9676639604278   time:  2.144585371017456
e:  27   train_loss:  485.82063530384414   time:  2.211822509765625
e:  28   train_loss:  473.5033232886417   time:  2.0700955390930176
e:  29   train_loss:  459.1089795568007   time:  2.123347520828247
e:  30   train_loss:  449.5833966259106   time:  2.1246068477630615
e:  31   train_loss:  443.43472373931314   time:  2.0064408779144287
e:  32   train_loss:  432.88827983875336   time:  2.1557648181915283
e:  33   train_loss:  426.9676890804172   time:  2.12831449508667
e:  34   train_loss:  425.59560505719105   time:  2.1244442462921143
e:  35   train_loss:  416.11711512547754   time:  2.0079734325408936
e:  36   train_loss:  405.0145604098725   time:  2.135659694671631
e:  37   train_loss:  414.8098849820848   time:  2.186586618423462
e:  38   train_loss:  398.78375508014045   time:  2.353194236755371
e:  39   train_loss:  385.00343702337074   time:  2.122311592102051
e:  40   train_loss:  374.3158440007443   time:  2.128098726272583
e:  41   train_loss:  372.22367022887477   time:  2.12605357170105
e:  42   train_loss:  371.66359042367975   time:  2.126119375228882
e:  43   train_loss:  362.74549032360807   time:  2.0136826038360596
e:  44   train_loss:  362.7769117560649   time:  2.118053436279297
e:  45   train_loss:  349.00094712750877   time:  2.1351399421691895
e:  46   train_loss:  350.657101429472   time:  2.015711784362793
e:  47   train_loss:  348.47880096273144   time:  2.1394615173339844
e:  48   train_loss:  333.2021629462786   time:  2.144690990447998
e:  49   train_loss:  351.29131072389   time:  2.0296833515167236
e:  50   train_loss:  341.0900532123485   time:  2.1312248706817627
e:  51   train_loss:  330.25305756881266   time:  2.1387100219726562
e:  52   train_loss:  327.26184489480784   time:  2.1316168308258057
e:  53   train_loss:  322.2649159731082   time:  2.0000879764556885
e:  54   train_loss:  319.43100110655695   time:  2.1559629440307617
e:  55   train_loss:  312.2563917645516   time:  2.137669086456299
e:  56   train_loss:  318.1003990178657   time:  2.1180412769317627
e:  57   train_loss:  314.11482006253675   time:  2.167856454849243
Model initialization done
Predicted score saved to /home/tasnina/Projects/SynVerse/outputs//k_6/leave_drug/Encoder_MLP/drug_1hot_mol_graph_MACCS_cell_1hot_must_test_predicted_scores.tsv
test loss:  1231.3934000688948
