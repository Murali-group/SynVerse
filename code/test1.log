/home/grads/tasnina/Projects/SynVerse/code/main.py:3: DeprecationWarning: 
Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),
(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)
but was not found to be installed on your system.
If this would cause problems for you,
please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466
        
  import pandas as pd
SYNVERSE STARTING
Before feature based fitering: 

#of triplets : 556905,
#drugs 3969, 
#cell lines 263
filtering for d1hot
filtering for MACCS
filtering for MFP
filtering for ECFP_4
filtering for mol_graph
filtering for c1hot
After feature based filtering: 

#of triplets : 556905,
#drugs 3969, 
#cell lines 263
After abundance based filtering: 
frac triplets retrieved:  0.1898384823264291

#of triplets : 105722,
#drugs 2582, 
#cell lines 9

#of triplets : 105722,
#drugs 2582, 
#cell lines 9
TEST #triplets: 21128 
 #drugs: 1213 
 #cell lines: 9
fold 0 # TRAIN triplets:  67711
fold 0 # VAL triplets:  16883
fold 1 # TRAIN triplets:  67595
fold 1 # VAL triplets:  16999
fold 2 # TRAIN triplets:  67732
fold 2 # VAL triplets:  16862
fold 3 # TRAIN triplets:  67741
fold 3 # VAL triplets:  16853
fold 4 # TRAIN triplets:  67597
fold 4 # VAL triplets:  16997
ran till model part
SPLIT:  leave_comb
/home/grads/tasnina/miniconda3/envs/synverse/lib/python3.9/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
Model initialization done
FOLD:  0
Model training starts
e:  0   train_loss:  1075.5015406176162
                                   e:  0   val_loss:  1404.0783198641377
e:  1   train_loss:  1045.6342222797875
                                   e:  1   val_loss:  1349.2922420416112
e:  2   train_loss:  962.7732801640568
                                   e:  2   val_loss:  1206.3787709788523
e:  3   train_loss:  878.3380194396037
                                   e:  3   val_loss:  1145.29363743588
e:  4   train_loss:  863.5233310276551
                                   e:  4   val_loss:  1142.3696628812627
e:  5   train_loss:  864.4624974347846
                                   e:  5   val_loss:  1139.5886378578002
e:  6   train_loss:  860.664878781266
                                   e:  6   val_loss:  1138.766802277423
e:  7   train_loss:  860.05034421038
                                   e:  7   val_loss:  1135.5478759764924
e:  8   train_loss:  855.8994794148939
                                   e:  8   val_loss:  1134.2100349056273
e:  9   train_loss:  855.5026915901475
                                   e:  9   val_loss:  1131.5632867462991
e:  10   train_loss:  855.8734584193616
                                   e:  10   val_loss:  1130.1731793804934
e:  11   train_loss:  851.2103254158095
                                   e:  11   val_loss:  1128.6203966909209
e:  12   train_loss:  854.6978208912464
                                   e:  12   val_loss:  1125.5715729035987
e:  13   train_loss:  854.1655904059157
                                   e:  13   val_loss:  1123.5259244123456
e:  14   train_loss:  854.3054861983514
                                   e:  14   val_loss:  1121.842159224804
e:  15   train_loss:  855.1699289103161
                                   e:  15   val_loss:  1119.8040643646807
e:  16   train_loss:  845.9187196927895
                                   e:  16   val_loss:  1116.9427149135438
e:  17   train_loss:  847.247894506104
                                   e:  17   val_loss:  1114.895523984626
e:  18   train_loss:  842.6172290207893
                                   e:  18   val_loss:  1111.6562281431038
e:  19   train_loss:  841.9865466782535
                                   e:  19   val_loss:  1109.3659858890937
e:  20   train_loss:  839.802141792204
                                   e:  20   val_loss:  1106.3725699176441
e:  21   train_loss:  839.4139026644933
                                   e:  21   val_loss:  1101.9483947477252
e:  22   train_loss:  834.2073562649721
                                   e:  22   val_loss:  1099.1771658479988
e:  23   train_loss:  834.0869254765382
                                   e:  23   val_loss:  1095.7045843249405
e:  24   train_loss:  830.4151097021029
                                   e:  24   val_loss:  1091.9167391570256
e:  25   train_loss:  832.4709688067242
                                   e:  25   val_loss:  1088.7102978496023
e:  26   train_loss:  825.2893010586649
                                   e:  26   val_loss:  1084.5313628312094
e:  27   train_loss:  823.2261746974431
                                   e:  27   val_loss:  1080.798905638651
e:  28   train_loss:  816.0020697489322
                                   e:  28   val_loss:  1076.9204665784684
e:  29   train_loss:  818.148040138225
                                   e:  29   val_loss:  1072.867548051019
e:  30   train_loss:  817.3731498258184
                                   e:  30   val_loss:  1065.14721777875
e:  31   train_loss:  808.3217543738368
                                   e:  31   val_loss:  1062.0718474841833
e:  32   train_loss:  806.8304072946177
                                   e:  32   val_loss:  1057.074971193776
e:  33   train_loss:  804.2613521033354
                                   e:  33   val_loss:  1052.0379796606576
e:  34   train_loss:  800.5473387071519
                                   e:  34   val_loss:  1044.7200537875913
e:  35   train_loss:  800.2044987789227
                                   e:  35   val_loss:  1038.3331354422403
e:  36   train_loss:  796.0934544049194
                                   e:  36   val_loss:  1031.7145538805657
e:  37   train_loss:  793.5126498565631
                                   e:  37   val_loss:  1026.905353553218
e:  38   train_loss:  789.9764246411722
                                   e:  38   val_loss:  1020.1359994771337
e:  39   train_loss:  785.3174577190329
                                   e:  39   val_loss:  1012.4254424971147
e:  40   train_loss:  783.309291906074
                                   e:  40   val_loss:  1005.6165777627979
e:  41   train_loss:  780.6810529977321
                                   e:  41   val_loss:  998.4601404006647
e:  42   train_loss:  774.3276895872174
                                   e:  42   val_loss:  990.865703784412
e:  43   train_loss:  775.4639107293226
                                   e:  43   val_loss:  983.6752107848042
e:  44   train_loss:  767.5742941240726
                                   e:  44   val_loss:  976.2816598769532
e:  45   train_loss:  764.9031274543713
                                   e:  45   val_loss:  971.2319636989157
e:  46   train_loss:  758.2788971257758
                                   e:  46   val_loss:  962.5987185798209
e:  47   train_loss:  756.0802016701668
                                   e:  47   val_loss:  954.7661351361548
e:  48   train_loss:  751.7727410935253
                                   e:  48   val_loss:  947.7407883924736
e:  49   train_loss:  751.0682271416496
                                   e:  49   val_loss:  938.3929685691268
e:  50   train_loss:  748.4409581561019
                                   e:  50   val_loss:  930.1839553577745
e:  51   train_loss:  739.629489590425
                                   e:  51   val_loss:  924.8842364526936
e:  52   train_loss:  737.5706011687005
                                   e:  52   val_loss:  915.2619153285519
e:  53   train_loss:  731.5867135870785
                                   e:  53   val_loss:  911.7451697553713
e:  54   train_loss:  727.5015864929458
                                   e:  54   val_loss:  903.9736014641807
e:  55   train_loss:  725.4211305181074
                                   e:  55   val_loss:  895.8559066385676
e:  56   train_loss:  727.8348854424887
                                   e:  56   val_loss:  885.5289445742719
e:  57   train_loss:  717.5066951076741
                                   e:  57   val_loss:  879.4558870414436
e:  58   train_loss:  718.0256203486903
                                   e:  58   val_loss:  872.4232806361904
e:  59   train_loss:  711.1787934065894
                                   e:  59   val_loss:  870.8296751184998
e:  60   train_loss:  709.0611068692992
                                   e:  60   val_loss:  859.4983305663911
e:  61   train_loss:  702.557428130565
                                   e:  61   val_loss:  854.5504271222304
e:  62   train_loss:  699.4611697004245
                                   e:  62   val_loss:  845.6711768162535
e:  63   train_loss:  698.8490772102529
                                   e:  63   val_loss:  840.6164512803222
e:  64   train_loss:  693.8262206663806
                                   e:  64   val_loss:  835.8816419993382
e:  65   train_loss:  688.86889439556
                                   e:  65   val_loss:  829.514903026951
e:  66   train_loss:  688.9145306254981
                                   e:  66   val_loss:  822.0592345789139
e:  67   train_loss:  686.1802478958225
                                   e:  67   val_loss:  818.2519441255097
e:  68   train_loss:  683.9118426771498
                                   e:  68   val_loss:  814.6223666095268
e:  69   train_loss:  678.236453984647
                                   e:  69   val_loss:  810.1238567493622
e:  70   train_loss:  676.9489512604544
                                   e:  70   val_loss:  805.076989559972
e:  71   train_loss:  675.4145552329812
                                   e:  71   val_loss:  798.1914165686592
e:  72   train_loss:  670.4004941855077
                                   e:  72   val_loss:  800.9344666942909
e:  73   train_loss:  668.0935738224833
                                   e:  73   val_loss:  789.1883533962043
e:  74   train_loss:  662.1908651717855
                                   e:  74   val_loss:  786.4468694468223
e:  75   train_loss:  663.38715303439
                                   e:  75   val_loss:  784.4815090072659
e:  76   train_loss:  662.4190137347834
                                   e:  76   val_loss:  776.5374974307464
e:  77   train_loss:  658.0165168907519
                                   e:  77   val_loss:  778.7933457948385
e:  78   train_loss:  658.5478374035886
                                   e:  78   val_loss:  771.2684597326727
e:  79   train_loss:  651.4359903782787
                                   e:  79   val_loss:  765.501103533756
e:  80   train_loss:  654.1925030465347
                                   e:  80   val_loss:  763.1161718028036
e:  81   train_loss:  652.2060337795082
                                   e:  81   val_loss:  758.065861335637
e:  82   train_loss:  646.4071268792111
                                   e:  82   val_loss:  763.5364704889555
e:  83   train_loss:  645.343505034915
                                   e:  83   val_loss:  758.2101932002452
e:  84   train_loss:  645.8731711535794
                                   e:  84   val_loss:  750.3800254656486
e:  85   train_loss:  641.5378454920312
                                   e:  85   val_loss:  748.9158579568633
e:  86   train_loss:  639.8428284121396
                                   e:  86   val_loss:  746.0300715254019
e:  87   train_loss:  636.5181895010825
                                   e:  87   val_loss:  751.0540159137396
e:  88   train_loss:  635.6759522448584
                                   e:  88   val_loss:  741.0548627414922
e:  89   train_loss:  635.0876344081918
                                   e:  89   val_loss:  735.6503047603647
e:  90   train_loss:  635.7856190744525
                                   e:  90   val_loss:  735.478967656878
e:  91   train_loss:  631.4220571281543
                                   e:  91   val_loss:  735.4076908975804
e:  92   train_loss:  630.9804669065015
                                   e:  92   val_loss:  733.8266637463415
e:  93   train_loss:  630.1119983089819
                                   e:  93   val_loss:  728.8890499974971
e:  94   train_loss:  628.596925789635
                                   e:  94   val_loss:  729.8017880735975
e:  95   train_loss:  625.1528453042507
                                   e:  95   val_loss:  733.0264430938191
e:  96   train_loss:  623.0043218711878
                                   e:  96   val_loss:  727.3010449704163
e:  97   train_loss:  624.1013958502446
                                   e:  97   val_loss:  727.5645744066562
e:  98   train_loss:  621.9976668576455
                                   e:  98   val_loss:  718.5836284891045
e:  99   train_loss:  619.9365876760986
                                   e:  99   val_loss:  721.5745382899895
e:  100   train_loss:  617.6559387426904
                                   e:  100   val_loss:  715.9705268230616
e:  101   train_loss:  619.129750920201
                                   e:  101   val_loss:  713.8670999389473
e:  102   train_loss:  611.4650952026012
                                   e:  102   val_loss:  716.1329210773923
e:  103   train_loss:  612.8712499840431
                                   e:  103   val_loss:  716.1164959093228
e:  104   train_loss:  612.2390390009983
                                   e:  104   val_loss:  721.2882894101573
e:  105   train_loss:  608.7819041238187
                                   e:  105   val_loss:  712.0734040025998
e:  106   train_loss:  606.6817296188069
                                   e:  106   val_loss:  718.2507684663706
e:  107   train_loss:  608.4871302913324
                                   e:  107   val_loss:  706.7295933144118
e:  108   train_loss:  607.1869542944881
                                   e:  108   val_loss:  705.2539936833676
e:  109   train_loss:  604.7994763824435
                                   e:  109   val_loss:  714.6275580817886
e:  110   train_loss:  606.9585929174423
                                   e:  110   val_loss:  699.3567124669087
e:  111   train_loss:  601.3488473907377
                                   e:  111   val_loss:  706.0436079942946
e:  112   train_loss:  602.0014307793261
                                   e:  112   val_loss:  714.6483985475206
e:  113   train_loss:  600.545903793758
                                   e:  113   val_loss:  696.5082392449301
e:  114   train_loss:  601.0157802808471
                                   e:  114   val_loss:  694.3967524370439
e:  115   train_loss:  596.6985225489385
                                   e:  115   val_loss:  693.547231924128
e:  116   train_loss:  599.1096041128695
                                   e:  116   val_loss:  690.7335054826419
e:  117   train_loss:  595.1897146903511
                                   e:  117   val_loss:  689.5150048666317
e:  118   train_loss:  592.9008743010636
                                   e:  118   val_loss:  706.375598051183
e:  119   train_loss:  595.5158961937555
                                   e:  119   val_loss:  689.9281938852994
e:  120   train_loss:  593.2366271898131
                                   e:  120   val_loss:  699.437164720239
e:  121   train_loss:  591.1608959351468
                                   e:  121   val_loss:  682.7572025353325
e:  122   train_loss:  589.323222580467
                                   e:  122   val_loss:  682.8797634403387
e:  123   train_loss:  586.8694301673659
                                   e:  123   val_loss:  682.0762879025758
e:  124   train_loss:  587.8567575927498
                                   e:  124   val_loss:  679.761229833455
e:  125   train_loss:  589.0824685594556
                                   e:  125   val_loss:  692.5361720859929
e:  126   train_loss:  585.2423855688039
                                   e:  126   val_loss:  683.3609343654495
e:  127   train_loss:  586.3911896032299
                                   e:  127   val_loss:  681.060939138319
e:  128   train_loss:  584.738239943692
                                   e:  128   val_loss:  693.9246509624351
e:  129   train_loss:  583.2199010813399
                                   e:  129   val_loss:  681.5952357289236
e:  130   train_loss:  581.0677833432303
                                   e:  130   val_loss:  671.8371830795197
e:  131   train_loss:  579.485534192135
                                   e:  131   val_loss:  719.0182812022197
e:  132   train_loss:  582.4363646029891
                                   e:  132   val_loss:  672.2153134387763
e:  133   train_loss:  574.6614722890203
                                   e:  133   val_loss:  674.6287596151354
e:  134   train_loss:  576.4085261156101
                                   e:  134   val_loss:  672.68741221863
e:  135   train_loss:  576.2507668341748
                                   e:  135   val_loss:  668.1502407176552
e:  136   train_loss:  574.642083848719
                                   e:  136   val_loss:  690.7571623308759
e:  137   train_loss:  571.4874663904294
                                   e:  137   val_loss:  665.457092048909
e:  138   train_loss:  571.3035616279551
                                   e:  138   val_loss:  666.8558039362069
e:  139   train_loss:  565.3626914649467
                                   e:  139   val_loss:  667.963562236385
e:  140   train_loss:  565.8192180709711
                                   e:  140   val_loss:  661.3047800790379
e:  141   train_loss:  565.854770965801
                                   e:  141   val_loss:  658.3437352562225
e:  142   train_loss:  565.6776617808843
                                   e:  142   val_loss:  658.4385411576075
e:  143   train_loss:  567.4112418654623
                                   e:  143   val_loss:  656.4158619638367
e:  144   train_loss:  568.2286860768601
                                   e:  144   val_loss:  665.3377425372319
e:  145   train_loss:  565.9222211193542
                                   e:  145   val_loss:  656.4069240541015
e:  146   train_loss:  559.7526855669238
                                   e:  146   val_loss:  651.4062966015965
e:  147   train_loss:  561.9912664378876
                                   e:  147   val_loss:  661.6607024889051
e:  148   train_loss:  558.0898051901794
                                   e:  148   val_loss:  683.9812005063341
e:  149   train_loss:  560.8908948189463
                                   e:  149   val_loss:  655.3324105785645
e:  150   train_loss:  557.67055985399
                                   e:  150   val_loss:  649.087585846762
e:  151   train_loss:  550.9842941882829
                                   e:  151   val_loss:  651.7676968667907
e:  152   train_loss:  553.2877147958371
                                   e:  152   val_loss:  656.9372466783384
e:  153   train_loss:  554.5484660435732
                                   e:  153   val_loss:  674.4531985921725
e:  154   train_loss:  549.5132265390046
                                   e:  154   val_loss:  641.777632043748
e:  155   train_loss:  561.5277387599497
                                   e:  155   val_loss:  650.2624518479721
e:  156   train_loss:  545.8084467616673
                                   e:  156   val_loss:  694.6812252409485
e:  157   train_loss:  550.2585512029667
                                   e:  157   val_loss:  673.0507938162859
e:  158   train_loss:  547.6725496462732
                                   e:  158   val_loss:  662.2038467653676
e:  159   train_loss:  556.6432569226129
                                   e:  159   val_loss:  643.3567500918534
e:  160   train_loss:  538.6948859199688
                                   e:  160   val_loss:  632.1896625393936
e:  161   train_loss:  541.5194711411442
                                   e:  161   val_loss:  673.37133065733
e:  162   train_loss:  546.3049007728886
                                   e:  162   val_loss:  640.4645284844867
e:  163   train_loss:  536.1120117517731
                                   e:  163   val_loss:  628.5236009693215
e:  164   train_loss:  544.2410956402142
                                   e:  164   val_loss:  629.0739878855117
e:  165   train_loss:  539.4606484063897
                                   e:  165   val_loss:  744.5930722394348
e:  166   train_loss:  549.2418180290214
                                   e:  166   val_loss:  628.0194344287908
e:  167   train_loss:  536.2758958363588
                                   e:  167   val_loss:  638.3681095137989
e:  168   train_loss:  539.1445912522275
                                   e:  168   val_loss:  625.2093863468618
e:  169   train_loss:  539.8571082718971
                                   e:  169   val_loss:  620.9684461682566
e:  170   train_loss:  533.9632955180359
                                   e:  170   val_loss:  680.170922424043
e:  171   train_loss:  534.8316188704392
                                   e:  171   val_loss:  628.7079175455447
e:  172   train_loss:  528.7327772389142
                                   e:  172   val_loss:  618.4708045890266
e:  173   train_loss:  532.5828844578176
                                   e:  173   val_loss:  632.1199948145819
e:  174   train_loss:  530.6289833564406
                                   e:  174   val_loss:  616.8631813835198
e:  175   train_loss:  532.2836142794465
                                   e:  175   val_loss:  614.0685267346919
e:  176   train_loss:  533.2263400736241
                                   e:  176   val_loss:  664.5830372534613
e:  177   train_loss:  526.7992778543655
                                   e:  177   val_loss:  647.1701494372022
e:  178   train_loss:  532.5645628117888
                                   e:  178   val_loss:  610.6841488261696
e:  179   train_loss:  517.6630443300223
                                   e:  179   val_loss:  607.7184051396384
e:  180   train_loss:  525.104703073418
                                   e:  180   val_loss:  652.967950586397
e:  181   train_loss:  527.4137250400672
                                   e:  181   val_loss:  631.3817859368073
e:  182   train_loss:  523.0480204723451
                                   e:  182   val_loss:  603.9885785288876
e:  183   train_loss:  523.2154684545707
                                   e:  183   val_loss:  614.6997286720649
e:  184   train_loss:  517.6727765685205
                                   e:  184   val_loss:  614.7160307789902
e:  185   train_loss:  513.6237738988115
                                   e:  185   val_loss:  596.7794358825688
e:  186   train_loss:  518.3011418568249
                                   e:  186   val_loss:  632.2392227489836
e:  187   train_loss:  515.3305486981111
                                   e:  187   val_loss:  729.1533438522096
e:  188   train_loss:  516.7964382148799
                                   e:  188   val_loss:  710.5468578254937
e:  189   train_loss:  515.2394494313621
                                   e:  189   val_loss:  668.8173855741167
e:  190   train_loss:  508.6763784308252
                                   e:  190   val_loss:  589.1674820825762
e:  191   train_loss:  497.81736527539346
                                   e:  191   val_loss:  584.2649801986838
e:  192   train_loss:  506.5977019997249
                                   e:  192   val_loss:  651.7139586811047
e:  193   train_loss:  510.38811849713215
                                   e:  193   val_loss:  596.8498446684648
e:  194   train_loss:  503.52500949540445
                                   e:  194   val_loss:  578.0611511212222
e:  195   train_loss:  520.219112187137
                                   e:  195   val_loss:  595.8243123337137
e:  196   train_loss:  506.0757192853967
                                   e:  196   val_loss:  606.3001791579144
e:  197   train_loss:  502.24117410019073
                                   e:  197   val_loss:  578.3453831189069
e:  198   train_loss:  498.33401574473163
                                   e:  198   val_loss:  574.812146665992
e:  199   train_loss:  506.5187896104115
                                   e:  199   val_loss:  574.18365004637
e:  200   train_loss:  502.25619058268626
                                   e:  200   val_loss:  577.1211417880502
e:  201   train_loss:  491.1407658337219
                                   e:  201   val_loss:  614.3856199228356
e:  202   train_loss:  498.2596213457367
                                   e:  202   val_loss:  570.8721606572288
e:  203   train_loss:  487.4977761116052
                                   e:  203   val_loss:  586.9585770330149
e:  204   train_loss:  496.5106960049999
                                   e:  204   val_loss:  570.255904103694
e:  205   train_loss:  499.6112916956669
                                   e:  205   val_loss:  563.6403286474275
e:  206   train_loss:  491.4111626520589
                                   e:  206   val_loss:  623.3134469715064
e:  207   train_loss:  493.3478014467271
                                   e:  207   val_loss:  561.3345844997887
e:  208   train_loss:  481.3287664818196
                                   e:  208   val_loss:  579.1410180813616
e:  209   train_loss:  495.78017045602536
                                   e:  209   val_loss:  577.8295102961969
e:  210   train_loss:  476.2673549197432
                                   e:  210   val_loss:  547.5074106838122
e:  211   train_loss:  482.6005354536172
                                   e:  211   val_loss:  640.4567389108768
e:  212   train_loss:  483.3660538061574
                                   e:  212   val_loss:  567.3245174899937
e:  213   train_loss:  476.59837849331643
                                   e:  213   val_loss:  679.1238748528078
e:  214   train_loss:  493.1716053595986
                                   e:  214   val_loss:  549.632261830353
e:  215   train_loss:  481.9151979374172
                                   e:  215   val_loss:  543.811738104295
e:  216   train_loss:  472.7557312466916
                                   e:  216   val_loss:  549.2173321054896
e:  217   train_loss:  479.007425236638
                                   e:  217   val_loss:  555.0723680112978
e:  218   train_loss:  472.9533250622671
                                   e:  218   val_loss:  536.6863718084456
e:  219   train_loss:  468.0247270153584
                                   e:  219   val_loss:  551.6777417606634
e:  220   train_loss:  470.7215014450584
                                   e:  220   val_loss:  640.9251816114767
e:  221   train_loss:  478.64200706733425
                                   e:  221   val_loss:  535.9737157528845
e:  222   train_loss:  453.3139408810864
                                   e:  222   val_loss:  539.4474613754082
e:  223   train_loss:  472.0173915294063
                                   e:  223   val_loss:  533.0911647648887
e:  224   train_loss:  462.44946869621384
                                   e:  224   val_loss:  576.7414582133714
e:  225   train_loss:  473.5191207164269
                                   e:  225   val_loss:  569.3839185391548
e:  226   train_loss:  464.2168433123521
                                   e:  226   val_loss:  534.8512128923545
e:  227   train_loss:  450.6250898765659
                                   e:  227   val_loss:  514.8602443146877
e:  228   train_loss:  467.50957523681785
                                   e:  228   val_loss:  523.3263334163139
e:  229   train_loss:  456.94749743290765
                                   e:  229   val_loss:  574.7314851497383
e:  230   train_loss:  464.339500717794
                                   e:  230   val_loss:  514.6671445696094
e:  231   train_loss:  446.0235151713458
                                   e:  231   val_loss:  615.1587330342132
e:  232   train_loss:  470.1608587502541
                                   e:  232   val_loss:  509.0889011896919
e:  233   train_loss:  437.6027573823583
                                   e:  233   val_loss:  520.7912143277581
e:  234   train_loss:  457.79292831859476
                                   e:  234   val_loss:  502.19361890752043
e:  235   train_loss:  428.7586351325309
                                   e:  235   val_loss:  543.4818011672389
e:  236   train_loss:  457.91580364239127
                                   e:  236   val_loss:  509.7083004063982
e:  237   train_loss:  459.6679363793868
                                   e:  237   val_loss:  679.2340295109545
e:  238   train_loss:  437.1808135803032
                                   e:  238   val_loss:  605.8799030583039
e:  239   train_loss:  452.68246589317107
                                   e:  239   val_loss:  516.5918466610941
e:  240   train_loss:  436.7211274546491
                                   e:  240   val_loss:  491.13134516416005
e:  241   train_loss:  446.7101338689645
                                   e:  241   val_loss:  505.3584886929931
e:  242   train_loss:  443.4662011152418
                                   e:  242   val_loss:  511.51129596518257
e:  243   train_loss:  439.1508906206373
                                   e:  243   val_loss:  774.727354884345
e:  244   train_loss:  435.7749971914617
                                   e:  244   val_loss:  481.76098986605086
e:  245   train_loss:  442.7083792003624
                                   e:  245   val_loss:  483.84940265728494
e:  246   train_loss:  437.69071363142336
                                   e:  246   val_loss:  482.1172701557721
e:  247   train_loss:  426.3106232813884
                                   e:  247   val_loss:  582.3095312999064
e:  248   train_loss:  425.9304884333611
                                   e:  248   val_loss:  503.8946796740236
e:  249   train_loss:  427.19121028879573
                                   e:  249   val_loss:  575.4007922315427
e:  250   train_loss:  434.43797682440936
                                   e:  250   val_loss:  492.33285607416855
e:  251   train_loss:  439.6988020957053
                                   e:  251   val_loss:  490.6931868185246
e:  252   train_loss:  429.99336899573336
                                   e:  252   val_loss:  485.846844451885
e:  253   train_loss:  430.9500634620674
                                   e:  253   val_loss:  466.8795274315104
e:  254   train_loss:  414.627294753906
                                   e:  254   val_loss:  506.19084023663754
e:  255   train_loss:  437.06098233057446
                                   e:  255   val_loss:  470.75062781506824
e:  256   train_loss:  414.150287836323
                                   e:  256   val_loss:  548.55740946733
e:  257   train_loss:  413.907472154047
                                   e:  257   val_loss:  655.1457555103145
e:  258   train_loss:  410.1591556267872
                                   e:  258   val_loss:  459.95577178766945
e:  259   train_loss:  412.70820208933804
                                   e:  259   val_loss:  485.5455112372339
e:  260   train_loss:  402.94353925199135
                                   e:  260   val_loss:  509.3449851549738
e:  261   train_loss:  417.93088064175964
                                   e:  261   val_loss:  477.52531539940156
e:  262   train_loss:  416.6502083247845
                                   e:  262   val_loss:  468.47404613019137
e:  263   train_loss:  412.2652474585007
                                   e:  263   val_loss:  449.16588736516303
e:  264   train_loss:  413.66350787470753
                                   e:  264   val_loss:  458.18711093632885
e:  265   train_loss:  407.2650397090172
                                   e:  265   val_loss:  482.8647571871041
e:  266   train_loss:  405.2547004681774
                                   e:  266   val_loss:  531.7106451573238
e:  267   train_loss:  410.3952586902914
                                   e:  267   val_loss:  464.12064118421296
e:  268   train_loss:  405.8785074718009
                                   e:  268   val_loss:  493.835046124815
e:  269   train_loss:  405.28000946361817
                                   e:  269   val_loss:  449.0863434811443
e:  270   train_loss:  417.9672366502541
                                   e:  270   val_loss:  443.12538362613213
e:  271   train_loss:  401.67083868835743
                                   e:  271   val_loss:  432.13601444162776
e:  272   train_loss:  394.8086037904078
                                   e:  272   val_loss:  471.5024483888945
e:  273   train_loss:  392.32414070728964
                                   e:  273   val_loss:  637.6057856257731
e:  274   train_loss:  406.79318950450806
                                   e:  274   val_loss:  472.32862838723634
e:  275   train_loss:  395.9024381179033
                                   e:  275   val_loss:  426.0170037067398
e:  276   train_loss:  385.1955462668332
                                   e:  276   val_loss:  433.0965020705829
e:  277   train_loss:  401.7055256919555
                                   e:  277   val_loss:  467.643231940616
e:  278   train_loss:  401.9114593373438
                                   e:  278   val_loss:  437.76672122007693
e:  279   train_loss:  393.4325165994265
                                   e:  279   val_loss:  454.79843632666905
e:  280   train_loss:  397.8201476403234
                                   e:  280   val_loss:  426.63903324772826
e:  281   train_loss:  385.03437336232327
                                   e:  281   val_loss:  432.1411611044953
e:  282   train_loss:  378.7258282184944
                                   e:  282   val_loss:  504.9282834969031
e:  283   train_loss:  388.78852633440863
                                   e:  283   val_loss:  419.5240554111862
e:  284   train_loss:  387.93114830982483
                                   e:  284   val_loss:  420.2163496495515
e:  285   train_loss:  386.9821584556084
                                   e:  285   val_loss:  440.03457933848256
e:  286   train_loss:  373.0027966837246
                                   e:  286   val_loss:  419.42268527539653
e:  287   train_loss:  382.0954911077573
                                   e:  287   val_loss:  459.8475378937393
e:  288   train_loss:  385.3166258031822
                                   e:  288   val_loss:  419.78469058469966
e:  289   train_loss:  373.2400895514538
                                   e:  289   val_loss:  479.2620314215389
e:  290   train_loss:  375.1633535935717
                                   e:  290   val_loss:  451.54962325465493
e:  291   train_loss:  372.69559265545894
                                   e:  291   val_loss:  451.37145731682375
e:  292   train_loss:  383.78961730719544
                                   e:  292   val_loss:  432.4256772590355
e:  293   train_loss:  373.12770398082847
                                   e:  293   val_loss:  406.95910796163696
e:  294   train_loss:  378.87570867521714
                                   e:  294   val_loss:  413.93081156214555
e:  295   train_loss:  378.45735411998083
                                   e:  295   val_loss:  396.7181076543573
e:  296   train_loss:  360.3572002008018
                                   e:  296   val_loss:  409.1299180197476
e:  297   train_loss:  380.30348577458517
                                   e:  297   val_loss:  429.1497774779274
e:  298   train_loss:  375.48056336430875
                                   e:  298   val_loss:  404.57045900409594
e:  299   train_loss:  354.8265573873389
                                   e:  299   val_loss:  392.9496395873183
e:  300   train_loss:  363.58913927334936
                                   e:  300   val_loss:  383.8981909707071
e:  301   train_loss:  373.6257572322406
                                   e:  301   val_loss:  397.9270896544548
e:  302   train_loss:  370.265104227401
                                   e:  302   val_loss:  411.3918483685364
e:  303   train_loss:  357.25777433922985
                                   e:  303   val_loss:  503.04044608183705
e:  304   train_loss:  366.494724388649
                                   e:  304   val_loss:  391.7202313105221
e:  305   train_loss:  367.98353050266246
                                   e:  305   val_loss:  455.78902926935336
e:  306   train_loss:  362.35640631736254
                                   e:  306   val_loss:  384.1531397210474
e:  307   train_loss:  356.26312041349775
                                   e:  307   val_loss:  486.1638738363612
e:  308   train_loss:  362.4686285296134
                                   e:  308   val_loss:  384.2738798090706
e:  309   train_loss:  358.98188506603907
                                   e:  309   val_loss:  390.2268896183728
e:  310   train_loss:  363.54932256950076
                                   e:  310   val_loss:  487.45080957396993
e:  311   train_loss:  370.301345364012
                                   e:  311   val_loss:  442.75750572366826
e:  312   train_loss:  360.62466779782176
                                   e:  312   val_loss:  435.1089453861294
e:  313   train_loss:  367.4601765014527
                                   e:  313   val_loss:  379.8768471583865
e:  314   train_loss:  350.9116045655253
                                   e:  314   val_loss:  400.094141192414
e:  315   train_loss:  346.6023608943474
                                   e:  315   val_loss:  392.2030156059493
e:  316   train_loss:  348.22440926075404
                                   e:  316   val_loss:  440.02588781525844
e:  317   train_loss:  354.0865658033041
                                   e:  317   val_loss:  385.17221526310965
e:  318   train_loss:  349.22087785482756
                                   e:  318   val_loss:  481.9303169208729
e:  319   train_loss:  364.6461709711233
                                   e:  319   val_loss:  389.9859482214048
e:  320   train_loss:  342.0489872319331
                                   e:  320   val_loss:  368.25618112005066
e:  321   train_loss:  364.82664174443494
                                   e:  321   val_loss:  415.1069213228622
e:  322   train_loss:  352.26870254370726
                                   e:  322   val_loss:  366.4505463686373
e:  323   train_loss:  342.23809189758714
                                   e:  323   val_loss:  417.71967840794815
e:  324   train_loss:  335.5119988589872
                                   e:  324   val_loss:  399.4110454784366
e:  325   train_loss:  346.34667979926024
                                   e:  325   val_loss:  436.7489996693037
e:  326   train_loss:  355.330709860536
                                   e:  326   val_loss:  378.48968915166677
e:  327   train_loss:  344.59526068260146
                                   e:  327   val_loss:  483.4963249966246
e:  328   train_loss:  334.98820779506343
                                   e:  328   val_loss:  415.8615192744055
e:  329   train_loss:  351.7603963339452
                                   e:  329   val_loss:  424.4338941296872
e:  330   train_loss:  334.62793166086914
                                   e:  330   val_loss:  467.77766433330015
e:  331   train_loss:  344.6941094145137
                                   e:  331   val_loss:  355.48540850421
e:  332   train_loss:  331.718149334873
                                   e:  332   val_loss:  375.2231483446444
e:  333   train_loss:  347.56475155878877
                                   e:  333   val_loss:  371.8754389623682
e:  334   train_loss:  337.99147541751734
                                   e:  334   val_loss:  439.038030134606
e:  335   train_loss:  339.42017955834905
                                   e:  335   val_loss:  352.97409853321426
e:  336   train_loss:  328.32899543000065
                                   e:  336   val_loss:  354.37227579058197
e:  337   train_loss:  340.7345133124313
                                   e:  337   val_loss:  348.03425300637355
e:  338   train_loss:  335.92608519172506
                                   e:  338   val_loss:  471.4950524075706
e:  339   train_loss:  335.32896914945434
                                   e:  339   val_loss:  426.65019388857854
e:  340   train_loss:  334.81779388758923
                                   e:  340   val_loss:  359.3137881610136
e:  341   train_loss:  328.78902694849455
                                   e:  341   val_loss:  354.9390769375346
e:  342   train_loss:  328.0416207008788
                                   e:  342   val_loss:  384.8439516327643
e:  343   train_loss:  329.82303391834785
                                   e:  343   val_loss:  354.10886975616324
e:  344   train_loss:  323.5467944168763
                                   e:  344   val_loss:  363.10369836509005
e:  345   train_loss:  339.128073531486
                                   e:  345   val_loss:  344.7333586408517
e:  346   train_loss:  333.1081605301799
                                   e:  346   val_loss:  457.8493185437619
e:  347   train_loss:  338.1264367093096
                                   e:  347   val_loss:  369.8573374589218
e:  348   train_loss:  333.7300247050274
                                   e:  348   val_loss:  344.0028000303016
e:  349   train_loss:  323.3567950983474
                                   e:  349   val_loss:  492.1013193343171
e:  350   train_loss:  332.53044598934076
                                   e:  350   val_loss:  347.93186951181644
e:  351   train_loss:  330.5736586710757
                                   e:  351   val_loss:  484.1519109010993
e:  352   train_loss:  329.96096671544296
                                   e:  352   val_loss:  414.93105226191085
e:  353   train_loss:  318.86464101247884
                                   e:  353   val_loss:  341.89753944234013
e:  354   train_loss:  321.87126398733125
                                   e:  354   val_loss:  379.86368969917123
e:  355   train_loss:  323.1612792864952
                                   e:  355   val_loss:  354.9910130269712
e:  356   train_loss:  320.2357163877717
                                   e:  356   val_loss:  348.00059618736236
e:  357   train_loss:  330.5112027512974
                                   e:  357   val_loss:  340.70169412375543
e:  358   train_loss:  319.1597621695285
                                   e:  358   val_loss:  356.9557700088279
e:  359   train_loss:  318.5291289978907
                                   e:  359   val_loss:  445.3177408517064
e:  360   train_loss:  334.53314884584444
                                   e:  360   val_loss:  353.79315920352667
e:  361   train_loss:  318.28898112727325
                                   e:  361   val_loss:  390.15810320412686
e:  362   train_loss:  320.53016351242553
                                   e:  362   val_loss:  335.23806122292956
e:  363   train_loss:  308.7609187762623
                                   e:  363   val_loss:  405.1030720442129
e:  364   train_loss:  323.68649197788426
                                   e:  364   val_loss:  347.73381167385236
e:  365   train_loss:  317.5824814505646
                                   e:  365   val_loss:  334.01909892417495
e:  366   train_loss:  323.3509688768492
                                   e:  366   val_loss:  382.3729133114198
e:  367   train_loss:  315.3398696011389
                                   e:  367   val_loss:  331.834210079993
e:  368   train_loss:  317.67887404254225
                                   e:  368   val_loss:  375.41551351947044
e:  369   train_loss:  317.19450561806485
                                   e:  369   val_loss:  339.80423424285925
e:  370   train_loss:  320.9709441922523
                                   e:  370   val_loss:  371.4619328565591
e:  371   train_loss:  316.38916067016044
                                   e:  371   val_loss:  346.34170988723037
e:  372   train_loss:  313.613754335965
                                   e:  372   val_loss:  331.4727403561631
e:  373   train_loss:  305.322835450454
                                   e:  373   val_loss:  347.9215491003704
e:  374   train_loss:  313.32939013101304
                                   e:  374   val_loss:  329.39214538795875
e:  375   train_loss:  308.5343365967604
                                   e:  375   val_loss:  363.094083070956
e:  376   train_loss:  316.71981503834695
                                   e:  376   val_loss:  356.3161141599889
e:  377   train_loss:  317.0602657471679
                                   e:  377   val_loss:  527.5723770753473
e:  378   train_loss:  320.92919423810906
                                   e:  378   val_loss:  372.3010175971252
e:  379   train_loss:  307.41340807148566
                                   e:  379   val_loss:  325.4527815821651
e:  380   train_loss:  307.5177543909361
                                   e:  380   val_loss:  402.29499110438724
e:  381   train_loss:  302.08352961652315
                                   e:  381   val_loss:  353.01999950451165
e:  382   train_loss:  311.5674071715222
                                   e:  382   val_loss:  395.04558028103145
e:  383   train_loss:  300.94201122456195
                                   e:  383   val_loss:  328.0509744155007
e:  384   train_loss:  311.1452521222814
                                   e:  384   val_loss:  371.70225346830756
e:  385   train_loss:  299.9534726274301
                                   e:  385   val_loss:  344.4097330168654
e:  386   train_loss:  300.6040425645334
                                   e:  386   val_loss:  364.4400876294394
e:  387   train_loss:  296.25458562109367
                                   e:  387   val_loss:  343.2646237228452
e:  388   train_loss:  299.0091160861854
                                   e:  388   val_loss:  391.8410167310296
e:  389   train_loss:  310.90090930291444
                                   e:  389   val_loss:  343.3107635726541
e:  390   train_loss:  303.1709700634912
                                   e:  390   val_loss:  342.757790989913
e:  391   train_loss:  313.5512167510847
                                   e:  391   val_loss:  360.5299112838837
e:  392   train_loss:  302.7897114655461
                                   e:  392   val_loss:  415.8948529311557
e:  393   train_loss:  311.0345453939275
                                   e:  393   val_loss:  351.8986814198368
e:  394   train_loss:  292.82549438066076
                                   e:  394   val_loss:  394.0554725705
e:  395   train_loss:  304.2419445265735
                                   e:  395   val_loss:  333.1936187004095
e:  396   train_loss:  302.37958128542004
                                   e:  396   val_loss:  408.4837646669874
e:  397   train_loss:  297.99631724456736
                                   e:  397   val_loss:  377.35220510339707
e:  398   train_loss:  308.20075433678323
                                   e:  398   val_loss:  329.2018985907813
e:  399   train_loss:  298.43064184075274
                                   e:  399   val_loss:  319.7707485768841
e:  400   train_loss:  299.3602421240741
                                   e:  400   val_loss:  348.33415762337233
e:  401   train_loss:  290.8065066811431
                                   e:  401   val_loss:  367.999001107573
e:  402   train_loss:  307.2131310208661
                                   e:  402   val_loss:  339.4572563364723
e:  403   train_loss:  298.0914229882514
                                   e:  403   val_loss:  353.13650121038756
e:  404   train_loss:  302.58024277088066
                                   e:  404   val_loss:  349.97423498548324
e:  405   train_loss:  298.5574572708319
                                   e:  405   val_loss:  385.4151446995203
e:  406   train_loss:  296.9897838056217
                                   e:  406   val_loss:  343.4948024652549
e:  407   train_loss:  303.16701529087146
                                   e:  407   val_loss:  334.7232537436313
e:  408   train_loss:  292.4533225356794
                                   e:  408   val_loss:  326.33350684808613
e:  409   train_loss:  294.53144640185417
                                   e:  409   val_loss:  344.3681499990603
e:  410   train_loss:  297.4310571178764
                                   e:  410   val_loss:  335.87904896281407
e:  411   train_loss:  292.0635285336223
                                   e:  411   val_loss:  358.9456473627306
e:  412   train_loss:  287.79104969359753
                                   e:  412   val_loss:  332.1768884678501
e:  413   train_loss:  285.8273830796721
                                   e:  413   val_loss:  314.4917840500943
e:  414   train_loss:  296.59709226623835
                                   e:  414   val_loss:  318.7134503805371
e:  415   train_loss:  297.1047697601762
                                   e:  415   val_loss:  343.3654358895405
e:  416   train_loss:  301.33732966097523
                                   e:  416   val_loss:  317.46856936842494
e:  417   train_loss:  284.4911968988033
                                   e:  417   val_loss:  447.9474373949498
e:  418   train_loss:  287.63709638042457
                                   e:  418   val_loss:  344.73997705482134
e:  419   train_loss:  291.5521213450317
                                   e:  419   val_loss:  375.5621614314945
e:  420   train_loss:  295.8943141634416
                                   e:  420   val_loss:  357.4138368144166
e:  421   train_loss:  298.7468765247042
                                   e:  421   val_loss:  390.87880476790747
e:  422   train_loss:  293.99945500365135
                                   e:  422   val_loss:  321.96704974265697
e:  423   train_loss:  284.25028265087985
                                   e:  423   val_loss:  365.56890230047327
e:  424   train_loss:  292.6473865877174
                                   e:  424   val_loss:  315.10897766380515
e:  425   train_loss:  292.69792009127076
                                   e:  425   val_loss:  330.161097952616
e:  426   train_loss:  293.3916010554941
                                   e:  426   val_loss:  311.5977146682838
e:  427   train_loss:  294.78099901120174
                                   e:  427   val_loss:  337.3843623028873
e:  428   train_loss:  279.6550572354836
                                   e:  428   val_loss:  395.15331990460544
e:  429   train_loss:  289.6257797663839
                                   e:  429   val_loss:  317.1365540864972
e:  430   train_loss:  295.1674923941347
                                   e:  430   val_loss:  402.10817005952276
e:  431   train_loss:  292.47009168211736
                                   e:  431   val_loss:  365.71754303931556
e:  432   train_loss:  284.63221910090084
                                   e:  432   val_loss:  312.5180268309727
e:  433   train_loss:  283.84938093507253
                                   e:  433   val_loss:  394.41368825632765
e:  434   train_loss:  291.4627629055067
                                   e:  434   val_loss:  312.6866474426397
e:  435   train_loss:  281.5902290890488
                                   e:  435   val_loss:  349.0090614473937
e:  436   train_loss:  284.637208963876
                                   e:  436   val_loss:  339.49146070408403
e:  437   train_loss:  287.13483419065517
                                   e:  437   val_loss:  362.5352413553421
e:  438   train_loss:  284.4723175253017
                                   e:  438   val_loss:  331.02227576149016
e:  439   train_loss:  288.3229235947035
                                   e:  439   val_loss:  324.3778379033889
e:  440   train_loss:  287.912582736743
                                   e:  440   val_loss:  331.6966720337433
e:  441   train_loss:  283.59932166255544
                                   e:  441   val_loss:  334.2681160784876
e:  442   train_loss:  291.98095256589977
                                   e:  442   val_loss:  322.75083955075615
e:  443   train_loss:  278.99054150316033
                                   e:  443   val_loss:  369.7248087475832
e:  444   train_loss:  277.9963935447797
                                   e:  444   val_loss:  331.7967060064187
e:  445   train_loss:  282.27438045916057
                                   e:  445   val_loss:  314.72926721475176
e:  446   train_loss:  276.8165579088003
                                   e:  446   val_loss:  315.3806799153698
e:  447   train_loss:  286.82359283029984
                                   e:  447   val_loss:  332.7119836793963
e:  448   train_loss:  277.5631225240207
                                   e:  448   val_loss:  314.7709003865486
e:  449   train_loss:  282.75814021938567
                                   e:  449   val_loss:  344.22785975992537
e:  450   train_loss:  285.1418022401317
                                   e:  450   val_loss:  351.0553246245512
e:  451   train_loss:  275.11329567359235
                                   e:  451   val_loss:  348.56326726852046
e:  452   train_loss:  281.6855940440748
                                   e:  452   val_loss:  346.8675365695757
Model initialization done
FOLD:  1
Model training starts
e:  0   train_loss:  1070.4555386945424
                                   e:  0   val_loss:  1284.2999992092562
e:  1   train_loss:  1039.174401335673
                                   e:  1   val_loss:  1216.8307225236197
e:  2   train_loss:  943.3948139321483
                                   e:  2   val_loss:  1071.1840869796083
e:  3   train_loss:  870.9916368720515
                                   e:  3   val_loss:  1035.5632741491834
e:  4   train_loss:  866.4186152056277
                                   e:  4   val_loss:  1032.6945386281843
e:  5   train_loss:  861.9234518443826
                                   e:  5   val_loss:  1030.8518216179498
e:  6   train_loss:  863.1008136868888
                                   e:  6   val_loss:  1029.511310873419
e:  7   train_loss:  860.2127355901582
                                   e:  7   val_loss:  1027.0073385733183
e:  8   train_loss:  863.7784347544148
                                   e:  8   val_loss:  1026.2148456541825
e:  9   train_loss:  857.5766006653529
                                   e:  9   val_loss:  1024.1267617389863
e:  10   train_loss:  861.9688744365035
                                   e:  10   val_loss:  1021.3677442916799
e:  11   train_loss:  859.1338275088893
                                   e:  11   val_loss:  1020.6145551991474
e:  12   train_loss:  855.294574124736
                                   e:  12   val_loss:  1018.2200611786953
e:  13   train_loss:  852.4633929058698
                                   e:  13   val_loss:  1016.3264539818801
e:  14   train_loss:  851.6885653934924
                                   e:  14   val_loss:  1014.397682282269
e:  15   train_loss:  849.5039324088817
                                   e:  15   val_loss:  1013.4478384416564
e:  16   train_loss:  847.4373028425648
                                   e:  16   val_loss:  1011.2072494630493
e:  17   train_loss:  850.0721189434258
                                   e:  17   val_loss:  1007.9845173004638
e:  18   train_loss:  849.4810232311183
                                   e:  18   val_loss:  1004.3104004986141
e:  19   train_loss:  847.2727630014439
                                   e:  19   val_loss:  1001.6793395924797
e:  20   train_loss:  837.4956714285469
                                   e:  20   val_loss:  999.7870431487861
e:  21   train_loss:  836.964752329843
                                   e:  21   val_loss:  997.2102027224162
e:  22   train_loss:  838.1357334929653
                                   e:  22   val_loss:  994.1857897880379
e:  23   train_loss:  829.9828740394926
                                   e:  23   val_loss:  991.7444890006257
e:  24   train_loss:  827.9687695056076
                                   e:  24   val_loss:  987.7448645332972
e:  25   train_loss:  827.0569112397361
                                   e:  25   val_loss:  985.2519887785368
e:  26   train_loss:  825.4460192030502
                                   e:  26   val_loss:  980.8432830401298
e:  27   train_loss:  823.7676261141269
                                   e:  27   val_loss:  977.444891611028
e:  28   train_loss:  821.0197035785794
                                   e:  28   val_loss:  973.7641023002072
e:  29   train_loss:  817.9492952097256
                                   e:  29   val_loss:  970.6930126209584
e:  30   train_loss:  818.5969503615853
                                   e:  30   val_loss:  964.793198890214
e:  31   train_loss:  807.2554678115755
                                   e:  31   val_loss:  962.8984071616054
e:  32   train_loss:  807.6351240806291
                                   e:  32   val_loss:  957.7895756343805
e:  33   train_loss:  805.3728692347
                                   e:  33   val_loss:  952.6739917648613
e:  34   train_loss:  802.0863304265326
                                   e:  34   val_loss:  947.8450685459222
e:  35   train_loss:  795.2465363624341
                                   e:  35   val_loss:  943.3414740140186
e:  36   train_loss:  794.1739155984282
                                   e:  36   val_loss:  938.2236688743182
e:  37   train_loss:  789.1551730621761
                                   e:  37   val_loss:  933.895955589581
e:  38   train_loss:  788.9791077209994
                                   e:  38   val_loss:  927.9108988319953
e:  39   train_loss:  778.3064387587548
                                   e:  39   val_loss:  924.7493991314044
e:  40   train_loss:  779.1281674051296
                                   e:  40   val_loss:  917.4538102564969
e:  41   train_loss:  773.7581389892379
                                   e:  41   val_loss:  912.5323983529564
e:  42   train_loss:  773.2334694102508
                                   e:  42   val_loss:  903.5235212031164
e:  43   train_loss:  769.7486048684984
                                   e:  43   val_loss:  898.0552418563668
e:  44   train_loss:  764.0547145663444
                                   e:  44   val_loss:  892.8276790019867
e:  45   train_loss:  757.6381277821345
                                   e:  45   val_loss:  890.0800323373293
e:  46   train_loss:  756.697805014428
                                   e:  46   val_loss:  880.2134848909221
e:  47   train_loss:  752.1529536121542
                                   e:  47   val_loss:  875.7219678786984
e:  48   train_loss:  752.647008146866
                                   e:  48   val_loss:  867.6186913817088
e:  49   train_loss:  747.1341567813164
                                   e:  49   val_loss:  862.7497356659438
e:  50   train_loss:  738.2342755938226
                                   e:  50   val_loss:  859.5211128263691
e:  51   train_loss:  737.5666495162772
                                   e:  51   val_loss:  852.3154520758657
e:  52   train_loss:  734.1739555180624
                                   e:  52   val_loss:  844.5523180519818
e:  53   train_loss:  725.7040696835032
                                   e:  53   val_loss:  841.5687126317544
e:  54   train_loss:  722.7029833286125
                                   e:  54   val_loss:  837.824171928722
e:  55   train_loss:  721.8969670672728
                                   e:  55   val_loss:  829.9097707231219
e:  56   train_loss:  716.9939552031037
                                   e:  56   val_loss:  823.6109789456001
e:  57   train_loss:  714.1138855793967
                                   e:  57   val_loss:  817.525178757644
e:  58   train_loss:  706.8721485640264
                                   e:  58   val_loss:  813.2435770624734
e:  59   train_loss:  706.2001286639355
                                   e:  59   val_loss:  808.2254469526217
e:  60   train_loss:  700.9447133477696
                                   e:  60   val_loss:  804.0780524877003
e:  61   train_loss:  703.7924802869675
                                   e:  61   val_loss:  796.6225849658059
e:  62   train_loss:  695.9051196200753
                                   e:  62   val_loss:  793.1201781926153
e:  63   train_loss:  694.18529702663
                                   e:  63   val_loss:  786.8116072759245
e:  64   train_loss:  687.8365885311972
                                   e:  64   val_loss:  782.4047147916287
e:  65   train_loss:  683.8167977632254
                                   e:  65   val_loss:  779.7859129680849
e:  66   train_loss:  681.8446699298856
                                   e:  66   val_loss:  773.0867703791753
e:  67   train_loss:  680.6931930787036
                                   e:  67   val_loss:  769.5746864403229
e:  68   train_loss:  678.9480258991524
                                   e:  68   val_loss:  764.6438574230253
e:  69   train_loss:  672.7347220954526
                                   e:  69   val_loss:  761.0699628165237
e:  70   train_loss:  671.2459000275885
                                   e:  70   val_loss:  757.3621828248436
e:  71   train_loss:  668.5703475076162
                                   e:  71   val_loss:  752.8130750524222
e:  72   train_loss:  662.5798127336014
                                   e:  72   val_loss:  753.7684335997718
e:  73   train_loss:  659.6641547361472
                                   e:  73   val_loss:  753.1832324969806
e:  74   train_loss:  659.6043255850124
                                   e:  74   val_loss:  745.8540317177043
e:  75   train_loss:  653.7589853053072
                                   e:  75   val_loss:  743.1352497036016
e:  76   train_loss:  655.1672428025531
                                   e:  76   val_loss:  735.3699986149386
e:  77   train_loss:  650.1292911696746
                                   e:  77   val_loss:  739.1899463972732
e:  78   train_loss:  651.1190398704811
                                   e:  78   val_loss:  729.486659919669
e:  79   train_loss:  646.8318140903467
                                   e:  79   val_loss:  726.3149631231329
e:  80   train_loss:  643.6557801197505
                                   e:  80   val_loss:  726.6165459716533
e:  81   train_loss:  643.5315929943602
                                   e:  81   val_loss:  725.1272461640983
e:  82   train_loss:  639.6051218593482
                                   e:  82   val_loss:  720.465564689862
e:  83   train_loss:  638.5643873365088
                                   e:  83   val_loss:  715.5915381783873
e:  84   train_loss:  635.7848303335841
                                   e:  84   val_loss:  713.2733224275547
e:  85   train_loss:  633.8029214241174
                                   e:  85   val_loss:  710.8765562589105
e:  86   train_loss:  631.9342075818014
                                   e:  86   val_loss:  714.532378176086
e:  87   train_loss:  631.2677320339386
                                   e:  87   val_loss:  705.8790206229828
e:  88   train_loss:  631.4369424842617
                                   e:  88   val_loss:  703.211492498254
e:  89   train_loss:  629.1952457915626
                                   e:  89   val_loss:  700.6938184616962
e:  90   train_loss:  624.8831853897027
                                   e:  90   val_loss:  698.7140240835818
e:  91   train_loss:  622.5143824620959
                                   e:  91   val_loss:  700.6924960145925
e:  92   train_loss:  625.1218474097902
                                   e:  92   val_loss:  696.5859212443718
e:  93   train_loss:  621.1737284712755
                                   e:  93   val_loss:  694.6981375115718
e:  94   train_loss:  620.8603503665614
                                   e:  94   val_loss:  691.9394845972031
e:  95   train_loss:  618.3197035951831
                                   e:  95   val_loss:  687.6129148342304
e:  96   train_loss:  613.7285017705462
                                   e:  96   val_loss:  686.7684304586635
e:  97   train_loss:  617.1316478701017
                                   e:  97   val_loss:  684.0708709880449
e:  98   train_loss:  619.0092942892438
                                   e:  98   val_loss:  682.4976827012388
e:  99   train_loss:  612.4008423997955
                                   e:  99   val_loss:  679.9774179447577
e:  100   train_loss:  611.4153844944085
                                   e:  100   val_loss:  678.1919691024757
e:  101   train_loss:  605.8258601264549
                                   e:  101   val_loss:  680.5978617425613
e:  102   train_loss:  607.3206715387029
                                   e:  102   val_loss:  680.1875334250323
e:  103   train_loss:  606.8259031910044
                                   e:  103   val_loss:  674.4146195550954
e:  104   train_loss:  604.8618606771968
                                   e:  104   val_loss:  676.8965877772097
e:  105   train_loss:  608.6264638202795
                                   e:  105   val_loss:  669.9183808726732
e:  106   train_loss:  602.8269503756234
                                   e:  106   val_loss:  668.3662748149245
e:  107   train_loss:  600.3843623456257
                                   e:  107   val_loss:  666.2391189325657
e:  108   train_loss:  599.9150567135314
                                   e:  108   val_loss:  663.6741556990075
e:  109   train_loss:  595.5629594096232
                                   e:  109   val_loss:  682.9068634344785
e:  110   train_loss:  597.6592840333988
                                   e:  110   val_loss:  667.1115345075656
e:  111   train_loss:  596.4157245856645
                                   e:  111   val_loss:  659.4831329991455
e:  112   train_loss:  594.8438391962164
                                   e:  112   val_loss:  658.2536198253572
e:  113   train_loss:  591.0596439923664
                                   e:  113   val_loss:  658.3840311230708
e:  114   train_loss:  590.2694793551552
                                   e:  114   val_loss:  660.2121833936308
e:  115   train_loss:  590.5894509358737
                                   e:  115   val_loss:  654.6457492421765
e:  116   train_loss:  589.1405741778945
                                   e:  116   val_loss:  659.2236220035126
e:  117   train_loss:  590.9215653015715
                                   e:  117   val_loss:  651.213132438727
e:  118   train_loss:  588.304727142428
                                   e:  118   val_loss:  649.5916447075938
e:  119   train_loss:  586.7274449475851
                                   e:  119   val_loss:  646.1282145881262
e:  120   train_loss:  586.9188917733605
                                   e:  120   val_loss:  646.45704756965
e:  121   train_loss:  585.0113085864168
                                   e:  121   val_loss:  646.4934885104045
e:  122   train_loss:  582.2431051671952
                                   e:  122   val_loss:  643.7960556350063
e:  123   train_loss:  582.0738709982043
                                   e:  123   val_loss:  653.0387644915
e:  124   train_loss:  582.9230032435681
                                   e:  124   val_loss:  639.2612118214018
e:  125   train_loss:  578.6545164426366
                                   e:  125   val_loss:  638.1943398695632
e:  126   train_loss:  577.6078420877208
                                   e:  126   val_loss:  637.2492447787238
e:  127   train_loss:  575.9450923608683
                                   e:  127   val_loss:  635.7015790867147
e:  128   train_loss:  574.3702115011532
                                   e:  128   val_loss:  639.9260359405472
e:  129   train_loss:  576.1828933791758
                                   e:  129   val_loss:  640.5200072496937
e:  130   train_loss:  574.5563581492491
                                   e:  130   val_loss:  648.9650019330073
e:  131   train_loss:  580.3550005158456
                                   e:  131   val_loss:  640.2696468294702
e:  132   train_loss:  572.0736653664868
                                   e:  132   val_loss:  628.5952006529648
e:  133   train_loss:  570.7797044953868
                                   e:  133   val_loss:  627.0767287613941
e:  134   train_loss:  567.8976179056065
                                   e:  134   val_loss:  634.4323527803269
e:  135   train_loss:  566.4415213092286
                                   e:  135   val_loss:  633.2984812868833
e:  136   train_loss:  567.5244834690047
                                   e:  136   val_loss:  626.8553124398113
e:  137   train_loss:  561.8996998737277
                                   e:  137   val_loss:  621.4899780335658
e:  138   train_loss:  565.5189035512067
                                   e:  138   val_loss:  630.2938413328153
e:  139   train_loss:  564.6366026576462
                                   e:  139   val_loss:  634.0964247121867
e:  140   train_loss:  563.4159041707121
                                   e:  140   val_loss:  615.9263921236378
e:  141   train_loss:  560.0350482006354
                                   e:  141   val_loss:  626.8907764248092
e:  142   train_loss:  560.2703784526025
                                   e:  142   val_loss:  618.6726075983563
e:  143   train_loss:  562.7161744294219
                                   e:  143   val_loss:  615.9329444852204
e:  144   train_loss:  557.0580108126416
                                   e:  144   val_loss:  615.3857470574176
e:  145   train_loss:  555.189729545192
                                   e:  145   val_loss:  619.9848884695314
e:  146   train_loss:  556.3462947988712
                                   e:  146   val_loss:  609.4582795863116
e:  147   train_loss:  551.1680675567812
                                   e:  147   val_loss:  606.5116655630616
e:  148   train_loss:  549.6595831296704
                                   e:  148   val_loss:  620.7803685233864
e:  149   train_loss:  553.405221808184
                                   e:  149   val_loss:  619.2356810697563
e:  150   train_loss:  554.5361438243904
                                   e:  150   val_loss:  599.9167027770202
e:  151   train_loss:  553.9691209003986
                                   e:  151   val_loss:  667.2649066875495
e:  152   train_loss:  549.338385038761
                                   e:  152   val_loss:  604.5539030587404
e:  153   train_loss:  547.2538461591142
                                   e:  153   val_loss:  595.4639447094553
e:  154   train_loss:  546.2003032982062
                                   e:  154   val_loss:  599.2982237111522
e:  155   train_loss:  542.3722079200717
                                   e:  155   val_loss:  597.8254798661035
e:  156   train_loss:  543.5669204994789
                                   e:  156   val_loss:  601.7062451066944
e:  157   train_loss:  546.7497338634678
                                   e:  157   val_loss:  607.4056775288236
e:  158   train_loss:  546.3694063594164
                                   e:  158   val_loss:  606.5752827591637
e:  159   train_loss:  547.078285027432
                                   e:  159   val_loss:  628.9089460157196
e:  160   train_loss:  534.6290601967289
                                   e:  160   val_loss:  593.8145349594856
e:  161   train_loss:  543.0928508777537
                                   e:  161   val_loss:  602.2497394288696
e:  162   train_loss:  535.8628657462571
                                   e:  162   val_loss:  582.0935533767757
e:  163   train_loss:  533.3473273102543
                                   e:  163   val_loss:  612.1406517194233
e:  164   train_loss:  527.8977062603191
                                   e:  164   val_loss:  689.243421588019
e:  165   train_loss:  541.759587958845
                                   e:  165   val_loss:  579.4597550413398
e:  166   train_loss:  533.1202845944678
                                   e:  166   val_loss:  579.8933169991277
e:  167   train_loss:  533.5162561798753
                                   e:  167   val_loss:  599.6884266154656
e:  168   train_loss:  528.4749831976676
                                   e:  168   val_loss:  611.6765110876597
e:  169   train_loss:  537.532627776521
                                   e:  169   val_loss:  588.4780034361959
e:  170   train_loss:  527.1521893114759
                                   e:  170   val_loss:  608.7682426519463
e:  171   train_loss:  529.453007575992
                                   e:  171   val_loss:  568.2001103522804
e:  172   train_loss:  526.0879988827912
                                   e:  172   val_loss:  603.8635504777355
e:  173   train_loss:  531.6557575978824
                                   e:  173   val_loss:  568.947503024571
e:  174   train_loss:  524.4833646436565
                                   e:  174   val_loss:  593.774043506384
e:  175   train_loss:  523.5814627759446
                                   e:  175   val_loss:  569.7367814100777
e:  176   train_loss:  516.6377922210937
                                   e:  176   val_loss:  567.3638452332174
e:  177   train_loss:  520.9348932741165
                                   e:  177   val_loss:  559.423945379762
e:  178   train_loss:  513.7108638646432
                                   e:  178   val_loss:  557.0049654592067
e:  179   train_loss:  512.4123635777331
                                   e:  179   val_loss:  611.4718492037339
e:  180   train_loss:  519.3457855732803
                                   e:  180   val_loss:  557.6531826614175
e:  181   train_loss:  519.5771971282985
                                   e:  181   val_loss:  553.0950456050538
e:  182   train_loss:  516.5084231797828
                                   e:  182   val_loss:  556.4884014909251
e:  183   train_loss:  505.7011587710227
                                   e:  183   val_loss:  546.4265268287745
e:  184   train_loss:  518.2318100226797
                                   e:  184   val_loss:  547.7058163521034
e:  185   train_loss:  509.8190015493752
                                   e:  185   val_loss:  549.0189320566467
e:  186   train_loss:  507.88147520040184
                                   e:  186   val_loss:  559.6661968831139
e:  187   train_loss:  505.9874120568586
                                   e:  187   val_loss:  562.9354578099028
e:  188   train_loss:  498.92770411597996
                                   e:  188   val_loss:  548.0533562577732
e:  189   train_loss:  512.5054271403123
                                   e:  189   val_loss:  542.075134107888
e:  190   train_loss:  504.3576736734411
                                   e:  190   val_loss:  542.5052914258426
e:  191   train_loss:  500.44916006797416
                                   e:  191   val_loss:  568.029105917523
e:  192   train_loss:  495.809568674911
                                   e:  192   val_loss:  533.6555603644684
e:  193   train_loss:  499.3231868591756
                                   e:  193   val_loss:  544.998141315974
e:  194   train_loss:  499.6986399688713
                                   e:  194   val_loss:  531.2028755121531
e:  195   train_loss:  494.2710993179074
                                   e:  195   val_loss:  554.8088305973239
e:  196   train_loss:  492.2778716374481
                                   e:  196   val_loss:  538.1468754209711
e:  197   train_loss:  499.79543163850525
                                   e:  197   val_loss:  563.6937936116932
e:  198   train_loss:  486.205925978849
                                   e:  198   val_loss:  565.4679700512072
e:  199   train_loss:  499.58447989050256
                                   e:  199   val_loss:  522.1230295431099
e:  200   train_loss:  486.5037009368836
                                   e:  200   val_loss:  530.6168361678401
e:  201   train_loss:  484.9731930868671
                                   e:  201   val_loss:  516.2977137649102
e:  202   train_loss:  488.877723269385
                                   e:  202   val_loss:  520.6949000483653
e:  203   train_loss:  493.5387349916336
                                   e:  203   val_loss:  515.1248255206568
e:  204   train_loss:  488.8502434413178
                                   e:  204   val_loss:  517.2802669116588
e:  205   train_loss:  482.83248218603694
                                   e:  205   val_loss:  538.8801515989328
e:  206   train_loss:  487.6166661004422
                                   e:  206   val_loss:  508.67385027700846
e:  207   train_loss:  475.22801689841367
                                   e:  207   val_loss:  507.06410695844045
e:  208   train_loss:  476.5749907254202
                                   e:  208   val_loss:  536.9175700657005
e:  209   train_loss:  486.99196742646905
                                   e:  209   val_loss:  507.4299717600491
e:  210   train_loss:  473.43254658327675
                                   e:  210   val_loss:  498.8765551878904
e:  211   train_loss:  468.1185203603763
                                   e:  211   val_loss:  588.0434188750521
e:  212   train_loss:  479.9469815197634
                                   e:  212   val_loss:  498.5864866548951
e:  213   train_loss:  477.1859247528681
                                   e:  213   val_loss:  494.7847143193646
e:  214   train_loss:  468.4062090717046
                                   e:  214   val_loss:  501.46226572050546
e:  215   train_loss:  485.56893062737566
                                   e:  215   val_loss:  505.325529165824
e:  216   train_loss:  457.9056109206068
                                   e:  216   val_loss:  519.4514190571075
e:  217   train_loss:  483.3958431059172
                                   e:  217   val_loss:  514.7871051789546
e:  218   train_loss:  472.33995047965465
                                   e:  218   val_loss:  558.200898829394
e:  219   train_loss:  462.3571972525796
                                   e:  219   val_loss:  487.16836321374905
e:  220   train_loss:  468.8429407250962
                                   e:  220   val_loss:  535.6610364843034
e:  221   train_loss:  464.7786402432083
                                   e:  221   val_loss:  506.7446448750803
e:  222   train_loss:  462.2600195112995
                                   e:  222   val_loss:  481.5990411927005
e:  223   train_loss:  460.06544651394034
                                   e:  223   val_loss:  480.08923575339696
e:  224   train_loss:  457.3451658386225
                                   e:  224   val_loss:  617.9454171600717
e:  225   train_loss:  447.7230818527192
                                   e:  225   val_loss:  522.723040389614
e:  226   train_loss:  450.9955150873816
                                   e:  226   val_loss:  474.3479116601984
e:  227   train_loss:  457.82483121841335
                                   e:  227   val_loss:  468.0507478503679
e:  228   train_loss:  452.1955084555139
                                   e:  228   val_loss:  473.67661096338725
e:  229   train_loss:  447.1409196937751
                                   e:  229   val_loss:  472.0886637020045
e:  230   train_loss:  457.2524777986932
                                   e:  230   val_loss:  479.45883401835374
e:  231   train_loss:  447.9511089430871
                                   e:  231   val_loss:  476.9421253579844
e:  232   train_loss:  448.0305332142132
                                   e:  232   val_loss:  468.0773861850128
e:  233   train_loss:  453.4832440353943
                                   e:  233   val_loss:  529.955631749422
e:  234   train_loss:  447.81393420886246
                                   e:  234   val_loss:  457.0001438126199
e:  235   train_loss:  439.08515597061205
                                   e:  235   val_loss:  554.0212913582699
e:  236   train_loss:  441.01940059102964
                                   e:  236   val_loss:  531.5896676590619
e:  237   train_loss:  448.7131360374374
                                   e:  237   val_loss:  496.014567180775
e:  238   train_loss:  440.9360768102607
                                   e:  238   val_loss:  459.2069318944169
e:  239   train_loss:  437.2063573575678
                                   e:  239   val_loss:  466.2034795565407
e:  240   train_loss:  424.9109929218946
                                   e:  240   val_loss:  445.88303664176493
e:  241   train_loss:  438.8985677082849
                                   e:  241   val_loss:  445.96925574964473
e:  242   train_loss:  423.7261919672119
                                   e:  242   val_loss:  491.93745179769
e:  243   train_loss:  431.79728066723123
                                   e:  243   val_loss:  440.19306610882916
e:  244   train_loss:  428.66175320722226
                                   e:  244   val_loss:  444.7274836486745
e:  245   train_loss:  420.05966651253084
                                   e:  245   val_loss:  444.09752660342076
e:  246   train_loss:  401.15704446218825
                                   e:  246   val_loss:  469.14871121204334
e:  247   train_loss:  445.30730127856134
                                   e:  247   val_loss:  471.564824449263
e:  248   train_loss:  440.1981779302903
                                   e:  248   val_loss:  460.23081093726114
e:  249   train_loss:  416.5449832365654
                                   e:  249   val_loss:  440.08648432275623
e:  250   train_loss:  420.0051548904636
                                   e:  250   val_loss:  489.0537452139764
e:  251   train_loss:  427.2767609831476
                                   e:  251   val_loss:  428.96413127964354
e:  252   train_loss:  413.25040015856985
                                   e:  252   val_loss:  457.516658907252
e:  253   train_loss:  430.5527398203003
                                   e:  253   val_loss:  431.7353694986329
e:  254   train_loss:  406.5212835090206
                                   e:  254   val_loss:  422.4287686780523
e:  255   train_loss:  410.34465629487175
                                   e:  255   val_loss:  433.80913623242157
e:  256   train_loss:  415.4928552889048
                                   e:  256   val_loss:  459.2230500447258
e:  257   train_loss:  410.7515959541994
                                   e:  257   val_loss:  429.1257685296747
e:  258   train_loss:  414.05109139878385
                                   e:  258   val_loss:  454.6489187268877
e:  259   train_loss:  402.6541763037845
                                   e:  259   val_loss:  425.44371266626
e:  260   train_loss:  419.11394051396
                                   e:  260   val_loss:  463.8338674066896
e:  261   train_loss:  409.0469448645385
                                   e:  261   val_loss:  432.0312077423422
e:  262   train_loss:  397.6601617173218
                                   e:  262   val_loss:  481.33294732493925
e:  263   train_loss:  411.39064194903415
                                   e:  263   val_loss:  417.19731223749443
e:  264   train_loss:  406.78053871477044
                                   e:  264   val_loss:  458.37772531750215
e:  265   train_loss:  402.67376260982354
                                   e:  265   val_loss:  402.48510921948736
e:  266   train_loss:  395.7370695384358
                                   e:  266   val_loss:  537.9111395018863
e:  267   train_loss:  397.7030716314568
                                   e:  267   val_loss:  411.6316814684922
e:  268   train_loss:  406.71438845014245
                                   e:  268   val_loss:  404.62885369418854
e:  269   train_loss:  399.1423607168733
                                   e:  269   val_loss:  405.6243451208662
e:  270   train_loss:  400.159097304045
                                   e:  270   val_loss:  452.96539174897396
e:  271   train_loss:  392.67404805488997
                                   e:  271   val_loss:  391.67663659575726
e:  272   train_loss:  393.6868651271234
                                   e:  272   val_loss:  471.2806472895726
e:  273   train_loss:  404.49581299918896
                                   e:  273   val_loss:  438.2505694091693
e:  274   train_loss:  396.72014582770635
                                   e:  274   val_loss:  397.2357926344042
e:  275   train_loss:  390.760785077414
                                   e:  275   val_loss:  403.137649443697
e:  276   train_loss:  401.7762546766969
                                   e:  276   val_loss:  428.39302970211395
e:  277   train_loss:  384.60385423463316
                                   e:  277   val_loss:  389.6237294943452
e:  278   train_loss:  384.08937276184884
                                   e:  278   val_loss:  419.14728754785574
e:  279   train_loss:  382.41233631617365
                                   e:  279   val_loss:  394.5204288427373
e:  280   train_loss:  393.606411853725
                                   e:  280   val_loss:  530.1107050560611
e:  281   train_loss:  394.5448320361764
                                   e:  281   val_loss:  435.28261838844764
e:  282   train_loss:  383.01741798332745
                                   e:  282   val_loss:  379.75803407376077
e:  283   train_loss:  390.57374988061673
                                   e:  283   val_loss:  380.59399547647473
e:  284   train_loss:  377.46425482235946
                                   e:  284   val_loss:  401.75936286772264
e:  285   train_loss:  381.3729404376445
                                   e:  285   val_loss:  511.11359465269607
e:  286   train_loss:  384.06006198654313
                                   e:  286   val_loss:  394.18681898979764
e:  287   train_loss:  375.23410244130696
                                   e:  287   val_loss:  421.8754104254473
e:  288   train_loss:  382.59813997840683
                                   e:  288   val_loss:  385.87435518432324
e:  289   train_loss:  374.6263195723117
                                   e:  289   val_loss:  479.0669079727888
e:  290   train_loss:  376.592665557938
                                   e:  290   val_loss:  395.1329271867517
e:  291   train_loss:  374.5007483820108
                                   e:  291   val_loss:  404.258783635927
e:  292   train_loss:  371.5288469680175
                                   e:  292   val_loss:  376.9894034110276
e:  293   train_loss:  369.79067858272447
                                   e:  293   val_loss:  403.2060384521107
e:  294   train_loss:  374.9457767855308
                                   e:  294   val_loss:  418.0324049723034
e:  295   train_loss:  367.11225133568087
                                   e:  295   val_loss:  362.9982696878698
e:  296   train_loss:  358.7298141220867
                                   e:  296   val_loss:  389.6790704713567
e:  297   train_loss:  373.8081893357631
                                   e:  297   val_loss:  403.050044542151
e:  298   train_loss:  355.64237267483514
                                   e:  298   val_loss:  373.05300859343066
e:  299   train_loss:  362.4476672366478
                                   e:  299   val_loss:  409.1992587546728
e:  300   train_loss:  365.787584578701
                                   e:  300   val_loss:  361.0009258924649
e:  301   train_loss:  361.7584539512118
                                   e:  301   val_loss:  378.6044391596764
e:  302   train_loss:  363.87944932252077
                                   e:  302   val_loss:  379.6316514957709
e:  303   train_loss:  365.5227905426975
                                   e:  303   val_loss:  454.3564875949593
e:  304   train_loss:  343.86135543556315
                                   e:  304   val_loss:  353.21781490127546
e:  305   train_loss:  368.50963824261225
                                   e:  305   val_loss:  367.3479084414595
e:  306   train_loss:  358.1695051928971
                                   e:  306   val_loss:  376.78696132154346
e:  307   train_loss:  348.53165605924545
                                   e:  307   val_loss:  361.8715847873548
e:  308   train_loss:  362.5206395635716
                                   e:  308   val_loss:  374.7452343344112
e:  309   train_loss:  364.1922167908604
                                   e:  309   val_loss:  411.74748066785423
e:  310   train_loss:  358.23741686033225
                                   e:  310   val_loss:  399.09793258854296
e:  311   train_loss:  363.9190081358994
                                   e:  311   val_loss:  358.9781660936558
e:  312   train_loss:  359.3784285442931
                                   e:  312   val_loss:  372.2644168397998
e:  313   train_loss:  349.65450981498964
                                   e:  313   val_loss:  384.7175952615042
e:  314   train_loss:  349.9513526956245
                                   e:  314   val_loss:  350.46425382155223
e:  315   train_loss:  343.7721178184486
                                   e:  315   val_loss:  352.6743738176341
e:  316   train_loss:  356.39097475744853
                                   e:  316   val_loss:  400.0720634318784
e:  317   train_loss:  342.67425836684424
                                   e:  317   val_loss:  344.70211129204307
e:  318   train_loss:  341.6618403335558
                                   e:  318   val_loss:  410.6704904883404
e:  319   train_loss:  343.9283883051816
                                   e:  319   val_loss:  571.7801929380345
e:  320   train_loss:  349.0800182112072
                                   e:  320   val_loss:  357.4600636790287
e:  321   train_loss:  342.673109649297
                                   e:  321   val_loss:  402.38514414839835
e:  322   train_loss:  350.56327809249376
                                   e:  322   val_loss:  341.41283281877674
e:  323   train_loss:  349.96555753957824
                                   e:  323   val_loss:  360.74468555341747
e:  324   train_loss:  346.141965806189
                                   e:  324   val_loss:  352.95843440708677
e:  325   train_loss:  336.763672440302
                                   e:  325   val_loss:  377.5767117877009
e:  326   train_loss:  343.6602577959241
                                   e:  326   val_loss:  336.7787413504516
e:  327   train_loss:  345.7860099157008
                                   e:  327   val_loss:  360.79738896875745
e:  328   train_loss:  338.70572801955274
                                   e:  328   val_loss:  417.75647129473373
e:  329   train_loss:  342.137243168043
                                   e:  329   val_loss:  359.7864965200944
e:  330   train_loss:  330.03659540190904
                                   e:  330   val_loss:  399.7705756798858
e:  331   train_loss:  346.629796344912
                                   e:  331   val_loss:  358.8774368115667
e:  332   train_loss:  333.86906469727757
                                   e:  332   val_loss:  343.62798745596825
e:  333   train_loss:  331.4085682968743
                                   e:  333   val_loss:  365.51108969221843
e:  334   train_loss:  338.88617617339054
                                   e:  334   val_loss:  391.7704649590605
e:  335   train_loss:  341.1183929846535
                                   e:  335   val_loss:  363.8128174262317
e:  336   train_loss:  338.57070545000806
                                   e:  336   val_loss:  341.90285778000344
e:  337   train_loss:  336.6834269317491
                                   e:  337   val_loss:  335.63874203165705
e:  338   train_loss:  333.2906153627822
                                   e:  338   val_loss:  335.67879456414687
e:  339   train_loss:  329.50889322441117
                                   e:  339   val_loss:  339.2072779847645
e:  340   train_loss:  330.09374650654064
                                   e:  340   val_loss:  434.68493923374115
e:  341   train_loss:  333.6599816631524
                                   e:  341   val_loss:  371.74103292356966
e:  342   train_loss:  316.5128598204627
                                   e:  342   val_loss:  332.0222731397713
e:  343   train_loss:  331.21062339023416
                                   e:  343   val_loss:  391.72500159863347
e:  344   train_loss:  328.75580863145154
                                   e:  344   val_loss:  341.36883016677746
e:  345   train_loss:  328.4637906104278
                                   e:  345   val_loss:  446.9375582326993
e:  346   train_loss:  331.7137448762346
                                   e:  346   val_loss:  361.4592206940301
e:  347   train_loss:  333.4534201238134
                                   e:  347   val_loss:  326.1333286767973
e:  348   train_loss:  320.29392365851794
                                   e:  348   val_loss:  400.2589395207586
e:  349   train_loss:  336.7337411932841
                                   e:  349   val_loss:  354.5859750894902
e:  350   train_loss:  322.65101570827426
                                   e:  350   val_loss:  331.0457888918046
e:  351   train_loss:  325.53854215035017
                                   e:  351   val_loss:  324.7463921415314
e:  352   train_loss:  313.8088805508613
                                   e:  352   val_loss:  334.1740746328937
e:  353   train_loss:  327.631291260667
                                   e:  353   val_loss:  325.68747365179456
e:  354   train_loss:  317.2580357857191
                                   e:  354   val_loss:  348.0156369112528
e:  355   train_loss:  317.8269330359809
                                   e:  355   val_loss:  353.42711892439263
e:  356   train_loss:  321.5353787966102
                                   e:  356   val_loss:  336.753757474224
e:  357   train_loss:  331.4074435905065
                                   e:  357   val_loss:  358.54843316707706
e:  358   train_loss:  313.23570412387323
                                   e:  358   val_loss:  345.13885200911136
e:  359   train_loss:  318.57413075935875
                                   e:  359   val_loss:  319.2240715641779
e:  360   train_loss:  330.01336512524665
                                   e:  360   val_loss:  363.802520778921
e:  361   train_loss:  317.2453472497059
                                   e:  361   val_loss:  326.8858221459051
e:  362   train_loss:  330.14933360769777
                                   e:  362   val_loss:  408.25883372943576
e:  363   train_loss:  322.02055642497834
                                   e:  363   val_loss:  338.3791070210832
e:  364   train_loss:  319.95272106128505
                                   e:  364   val_loss:  322.42054078840494
e:  365   train_loss:  315.6631144166102
                                   e:  365   val_loss:  329.8808181657163
e:  366   train_loss:  317.703523953881
                                   e:  366   val_loss:  314.87745366948604
e:  367   train_loss:  306.29485084422606
                                   e:  367   val_loss:  343.7530756541921
e:  368   train_loss:  314.6759679001593
                                   e:  368   val_loss:  317.7811417713835
e:  369   train_loss:  318.2957229041954
                                   e:  369   val_loss:  317.5581356140882
e:  370   train_loss:  317.3108801572721
                                   e:  370   val_loss:  446.2855600190895
e:  371   train_loss:  320.9827307620668
                                   e:  371   val_loss:  330.63688654841076
e:  372   train_loss:  313.7407606729382
                                   e:  372   val_loss:  313.46037285601386
e:  373   train_loss:  306.18864171227654
                                   e:  373   val_loss:  312.1637325859168
e:  374   train_loss:  309.3092656015283
                                   e:  374   val_loss:  354.73269974446026
e:  375   train_loss:  320.3541541581667
                                   e:  375   val_loss:  319.1084409721612
e:  376   train_loss:  308.5303567515647
                                   e:  376   val_loss:  352.59633844487576
e:  377   train_loss:  322.27684074689205
                                   e:  377   val_loss:  377.30230448650474
e:  378   train_loss:  303.7903667273754
                                   e:  378   val_loss:  333.537689545458
e:  379   train_loss:  303.57738469800125
                                   e:  379   val_loss:  325.08813081760684
e:  380   train_loss:  297.01123034763435
                                   e:  380   val_loss:  411.6365613501437
e:  381   train_loss:  317.8402547266317
                                   e:  381   val_loss:  328.83280047993634
e:  382   train_loss:  313.7921494858195
                                   e:  382   val_loss:  370.5524038523419
e:  383   train_loss:  312.93788659683605
                                   e:  383   val_loss:  327.3221792719172
e:  384   train_loss:  310.8282939279284
                                   e:  384   val_loss:  311.0260562636999
e:  385   train_loss:  314.62826944332596
                                   e:  385   val_loss:  331.3200552942
e:  386   train_loss:  312.1884039512906
                                   e:  386   val_loss:  345.5335876469931
e:  387   train_loss:  297.919600737268
                                   e:  387   val_loss:  319.2756852196434
e:  388   train_loss:  301.9637012821056
                                   e:  388   val_loss:  355.0799817829761
e:  389   train_loss:  302.28730241878975
                                   e:  389   val_loss:  328.66897624426105
e:  390   train_loss:  301.1951385595398
                                   e:  390   val_loss:  310.9995581080941
e:  391   train_loss:  312.8729638075055
                                   e:  391   val_loss:  356.06316277136443
e:  392   train_loss:  298.7275345263547
                                   e:  392   val_loss:  311.4079563317314
e:  393   train_loss:  304.8366026052806
                                   e:  393   val_loss:  372.2854439636711
e:  394   train_loss:  308.508810118093
                                   e:  394   val_loss:  337.48407168542883
e:  395   train_loss:  302.39171972561843
                                   e:  395   val_loss:  380.47981725950956
e:  396   train_loss:  305.42453533214814
                                   e:  396   val_loss:  312.85451912509177
e:  397   train_loss:  304.6118230292755
                                   e:  397   val_loss:  408.63936067183926
e:  398   train_loss:  300.6123021374253
                                   e:  398   val_loss:  336.34989734293674
e:  399   train_loss:  306.1297773295494
                                   e:  399   val_loss:  344.7138314294225
e:  400   train_loss:  297.4671894731051
                                   e:  400   val_loss:  313.1164698577923
e:  401   train_loss:  301.6147735213491
                                   e:  401   val_loss:  325.389268419132
e:  402   train_loss:  298.28749001626414
                                   e:  402   val_loss:  345.3932491194714
e:  403   train_loss:  300.63376615506513
                                   e:  403   val_loss:  436.90382463008956
e:  404   train_loss:  308.35494176870765
                                   e:  404   val_loss:  331.5072246634571
e:  405   train_loss:  295.26147116224104
                                   e:  405   val_loss:  334.8711809550032
e:  406   train_loss:  298.5852323624328
                                   e:  406   val_loss:  315.76474634324734
e:  407   train_loss:  296.02808145804545
                                   e:  407   val_loss:  376.24281950680904
e:  408   train_loss:  302.7448723327374
                                   e:  408   val_loss:  323.21632313962766
e:  409   train_loss:  298.50407316249505
                                   e:  409   val_loss:  341.64933338573485
e:  410   train_loss:  291.6627870725016
                                   e:  410   val_loss:  356.0010345355884
e:  411   train_loss:  296.92230063886876
                                   e:  411   val_loss:  306.1167564865595
e:  412   train_loss:  288.04123947864
                                   e:  412   val_loss:  320.3111979420928
e:  413   train_loss:  290.1708963373131
                                   e:  413   val_loss:  312.5147469844763
e:  414   train_loss:  291.6019926199524
                                   e:  414   val_loss:  331.91495743290886
e:  415   train_loss:  292.46113002414705
                                   e:  415   val_loss:  299.75243203534984
e:  416   train_loss:  288.2537674369799
                                   e:  416   val_loss:  331.937973608168
e:  417   train_loss:  296.2444638683271
                                   e:  417   val_loss:  334.21145559820746
e:  418   train_loss:  294.54660019010373
                                   e:  418   val_loss:  407.5993643916755
e:  419   train_loss:  286.72951118315643
                                   e:  419   val_loss:  316.21631593202216
e:  420   train_loss:  297.032657944453
                                   e:  420   val_loss:  393.76686207823695
e:  421   train_loss:  303.3044809522073
                                   e:  421   val_loss:  314.8732255268186
e:  422   train_loss:  287.71952136399557
                                   e:  422   val_loss:  327.92999234518794
e:  423   train_loss:  287.90990631141335
                                   e:  423   val_loss:  314.9438110698667
e:  424   train_loss:  292.8232440026321
                                   e:  424   val_loss:  310.1467447238269
e:  425   train_loss:  286.955750077335
                                   e:  425   val_loss:  308.00314068693496
e:  426   train_loss:  279.4586411534572
                                   e:  426   val_loss:  302.0040641641407
e:  427   train_loss:  295.8235275611677
                                   e:  427   val_loss:  307.97323867258507
e:  428   train_loss:  288.7370250624949
                                   e:  428   val_loss:  328.88518415675725
e:  429   train_loss:  276.66722328984963
                                   e:  429   val_loss:  348.1390740893096
e:  430   train_loss:  297.4070805141468
                                   e:  430   val_loss:  307.95712676312905
e:  431   train_loss:  289.00720563160866
                                   e:  431   val_loss:  328.0454163339874
e:  432   train_loss:  300.4779026694487
                                   e:  432   val_loss:  315.6966599622353
e:  433   train_loss:  279.95753696579504
                                   e:  433   val_loss:  386.67333877166357
e:  434   train_loss:  284.68091123499744
                                   e:  434   val_loss:  304.74067819669267
e:  435   train_loss:  292.05273168850664
                                   e:  435   val_loss:  343.9196838663007
e:  436   train_loss:  280.8090658764679
                                   e:  436   val_loss:  294.5362346671319
e:  437   train_loss:  298.0536446110335
                                   e:  437   val_loss:  296.58377133204505
e:  438   train_loss:  279.95193757878036
                                   e:  438   val_loss:  322.72830066384057
e:  439   train_loss:  280.95921022152396
                                   e:  439   val_loss:  300.09598507856526
e:  440   train_loss:  284.69704381693197
                                   e:  440   val_loss:  302.56665846206437
e:  441   train_loss:  288.5537730878789
                                   e:  441   val_loss:  302.7804063900974
e:  442   train_loss:  281.60582325341124
                                   e:  442   val_loss:  443.4741329901302
e:  443   train_loss:  291.1729696808085
                                   e:  443   val_loss:  312.5452143569535
e:  444   train_loss:  290.42096967021314
                                   e:  444   val_loss:  356.8327421000136
e:  445   train_loss:  284.0898318628583
                                   e:  445   val_loss:  301.1963751537965
e:  446   train_loss:  280.2103639155216
                                   e:  446   val_loss:  294.58274934721084
e:  447   train_loss:  279.4763572103039
                                   e:  447   val_loss:  333.93239915006063
e:  448   train_loss:  282.6044934332336
                                   e:  448   val_loss:  355.724591243441
e:  449   train_loss:  290.9703986917008
                                   e:  449   val_loss:  336.31962005589537
e:  450   train_loss:  291.5364523758941
                                   e:  450   val_loss:  312.52897913698143
e:  451   train_loss:  290.14792863650814
                                   e:  451   val_loss:  322.79083321872804
e:  452   train_loss:  285.7558280061138
                                   e:  452   val_loss:  371.0079326841392
e:  453   train_loss:  283.90854754612167
                                   e:  453   val_loss:  364.6544138706955
e:  454   train_loss:  289.5315225126899
                                   e:  454   val_loss:  295.8503311496374
e:  455   train_loss:  275.7603766542356
                                   e:  455   val_loss:  328.31482912358194
e:  456   train_loss:  281.49308950253
                                   e:  456   val_loss:  295.94704313449876
e:  457   train_loss:  273.43957591283004
                                   e:  457   val_loss:  310.9621457832913
e:  458   train_loss:  285.97845784608387
                                   e:  458   val_loss:  319.75721255255246
e:  459   train_loss:  272.1109161443817
                                   e:  459   val_loss:  335.6178868200701
e:  460   train_loss:  281.32910271719516
                                   e:  460   val_loss:  313.2102447169956
e:  461   train_loss:  287.181481811224
                                   e:  461   val_loss:  299.89698112504607
e:  462   train_loss:  285.98762806388595
                                   e:  462   val_loss:  329.51953142074234
Model initialization done
FOLD:  2
Model training starts
e:  0   train_loss:  1079.019652540602
                                   e:  0   val_loss:  1395.8562437722996
e:  1   train_loss:  1058.298908951665
                                   e:  1   val_loss:  1357.2516870791658
e:  2   train_loss:  1000.8763189058077
                                   e:  2   val_loss:  1239.422053543563
e:  3   train_loss:  890.1970026327448
                                   e:  3   val_loss:  1144.3161582546984
e:  4   train_loss:  867.8947289970828
                                   e:  4   val_loss:  1136.0495461413097
e:  5   train_loss:  865.9666350345864
                                   e:  5   val_loss:  1133.592050390812
e:  6   train_loss:  860.7795585141863
                                   e:  6   val_loss:  1132.2801982150227
e:  7   train_loss:  858.9266643706356
                                   e:  7   val_loss:  1130.5471123387329
e:  8   train_loss:  860.4757515108353
                                   e:  8   val_loss:  1128.314289328168
e:  9   train_loss:  858.1857596143179
                                   e:  9   val_loss:  1126.2468843943807
e:  10   train_loss:  858.9092377659559
                                   e:  10   val_loss:  1125.8444072041025
e:  11   train_loss:  854.8364597008899
                                   e:  11   val_loss:  1123.394994122131
e:  12   train_loss:  854.8986673770246
                                   e:  12   val_loss:  1120.546745145714
e:  13   train_loss:  851.6145472573185
                                   e:  13   val_loss:  1118.7167586335984
e:  14   train_loss:  851.9316353244604
                                   e:  14   val_loss:  1116.9090921315394
e:  15   train_loss:  846.8140898692245
                                   e:  15   val_loss:  1114.3849896877666
e:  16   train_loss:  852.9135536623371
                                   e:  16   val_loss:  1110.5238596597496
e:  17   train_loss:  847.0895433545077
                                   e:  17   val_loss:  1108.2559555687071
e:  18   train_loss:  843.9819992249935
                                   e:  18   val_loss:  1105.5926077971362
e:  19   train_loss:  841.8483614441976
                                   e:  19   val_loss:  1102.9593759065406
e:  20   train_loss:  838.1482119651547
                                   e:  20   val_loss:  1101.136180820433
e:  21   train_loss:  842.6287029331711
                                   e:  21   val_loss:  1096.7576956188027
e:  22   train_loss:  837.5854601351793
                                   e:  22   val_loss:  1093.9528125724491
e:  23   train_loss:  833.6349064743885
                                   e:  23   val_loss:  1089.572374761354
e:  24   train_loss:  831.0547934632688
                                   e:  24   val_loss:  1085.9500945178293
e:  25   train_loss:  832.2620138669872
                                   e:  25   val_loss:  1082.758082755538
e:  26   train_loss:  830.5414471633121
                                   e:  26   val_loss:  1077.753051130235
e:  27   train_loss:  823.5581223994874
                                   e:  27   val_loss:  1074.3881249810029
e:  28   train_loss:  822.9795183953375
                                   e:  28   val_loss:  1069.7729429458984
e:  29   train_loss:  819.9634686518372
                                   e:  29   val_loss:  1064.8012968942562
e:  30   train_loss:  814.7318725564672
                                   e:  30   val_loss:  1059.1496683019047
e:  31   train_loss:  813.0187028392683
                                   e:  31   val_loss:  1055.0579074631737
e:  32   train_loss:  811.6964669861536
                                   e:  32   val_loss:  1049.7207004733805
e:  33   train_loss:  807.1981403169672
                                   e:  33   val_loss:  1043.840084911923
e:  34   train_loss:  804.9417932564744
                                   e:  34   val_loss:  1039.5156774702602
e:  35   train_loss:  799.4860514174912
                                   e:  35   val_loss:  1034.283529630119
e:  36   train_loss:  799.9706496867101
                                   e:  36   val_loss:  1027.1153907693592
e:  37   train_loss:  804.2892030088906
                                   e:  37   val_loss:  1019.3298160323975
e:  38   train_loss:  796.6487216138563
                                   e:  38   val_loss:  1013.4175919071604
e:  39   train_loss:  788.7194369777707
                                   e:  39   val_loss:  1007.4205646946559
e:  40   train_loss:  785.4013564143428
                                   e:  40   val_loss:  999.9511051034326
e:  41   train_loss:  784.2731190839537
                                   e:  41   val_loss:  993.0340835161074
e:  42   train_loss:  774.3757612209985
                                   e:  42   val_loss:  988.9597964145116
e:  43   train_loss:  777.0618147024652
                                   e:  43   val_loss:  979.690427450432
e:  44   train_loss:  776.7545019113403
                                   e:  44   val_loss:  971.5514924013833
e:  45   train_loss:  764.0239593195847
                                   e:  45   val_loss:  966.1845183584908
e:  46   train_loss:  762.9985257132527
                                   e:  46   val_loss:  957.9204164445295
e:  47   train_loss:  760.4472692616367
                                   e:  47   val_loss:  950.5057565324325
e:  48   train_loss:  750.3215013496476
                                   e:  48   val_loss:  946.6368710199138
e:  49   train_loss:  752.5158661276961
                                   e:  49   val_loss:  937.5207082691398
e:  50   train_loss:  751.8060485469991
                                   e:  50   val_loss:  928.769216865065
e:  51   train_loss:  741.6801263102739
                                   e:  51   val_loss:  922.9586139851074
e:  52   train_loss:  743.7124787994959
                                   e:  52   val_loss:  913.7598175281058
e:  53   train_loss:  735.9589894964922
                                   e:  53   val_loss:  907.0527015781445
e:  54   train_loss:  731.0987332727925
                                   e:  54   val_loss:  899.524056186001
e:  55   train_loss:  733.5991346923868
                                   e:  55   val_loss:  891.9485124871644
e:  56   train_loss:  724.7039941732215
                                   e:  56   val_loss:  886.3811578675222
e:  57   train_loss:  724.7136085684834
                                   e:  57   val_loss:  879.7216805537868
e:  58   train_loss:  716.9435877754125
                                   e:  58   val_loss:  874.2487249789108
e:  59   train_loss:  714.7394685472366
                                   e:  59   val_loss:  864.0881656481027
e:  60   train_loss:  712.8335448676168
                                   e:  60   val_loss:  859.4848316232298
e:  61   train_loss:  707.9081808403208
                                   e:  61   val_loss:  852.8125434222086
e:  62   train_loss:  705.5318687381944
                                   e:  62   val_loss:  847.165325931151
e:  63   train_loss:  700.5814456372391
                                   e:  63   val_loss:  839.1836672305928
e:  64   train_loss:  700.9310096316809
                                   e:  64   val_loss:  832.4230203644631
e:  65   train_loss:  693.3246772774814
                                   e:  65   val_loss:  831.2301566187805
e:  66   train_loss:  690.6572170081016
                                   e:  66   val_loss:  826.3058629655825
e:  67   train_loss:  690.8803642822294
                                   e:  67   val_loss:  816.1801577374441
e:  68   train_loss:  688.9820416375342
                                   e:  68   val_loss:  810.0219074690087
e:  69   train_loss:  684.3750054490732
                                   e:  69   val_loss:  804.9547555045476
e:  70   train_loss:  679.6984605148641
                                   e:  70   val_loss:  801.3408394552669
e:  71   train_loss:  679.0811056337017
                                   e:  71   val_loss:  798.6973820383625
e:  72   train_loss:  672.4954850943801
                                   e:  72   val_loss:  793.1175617229226
e:  73   train_loss:  671.5233820824714
                                   e:  73   val_loss:  791.2269885088083
e:  74   train_loss:  667.0028817753158
                                   e:  74   val_loss:  782.6836688413839
e:  75   train_loss:  669.9959423462205
                                   e:  75   val_loss:  778.3315865003391
e:  76   train_loss:  667.7802397690109
                                   e:  76   val_loss:  773.6659565046386
e:  77   train_loss:  662.4483237721826
                                   e:  77   val_loss:  773.8183830955488
e:  78   train_loss:  657.1572507935331
                                   e:  78   val_loss:  771.2803661569787
e:  79   train_loss:  654.3907522651914
                                   e:  79   val_loss:  776.5553522217884
e:  80   train_loss:  656.5255388984168
                                   e:  80   val_loss:  763.5675828156396
e:  81   train_loss:  657.4300358167447
                                   e:  81   val_loss:  756.1413223992179
e:  82   train_loss:  650.5164517769988
                                   e:  82   val_loss:  755.4801978051725
e:  83   train_loss:  649.8343315138098
                                   e:  83   val_loss:  750.2868642733335
e:  84   train_loss:  645.5642384628626
                                   e:  84   val_loss:  753.531097696997
e:  85   train_loss:  644.7904355833027
                                   e:  85   val_loss:  745.0153299103363
e:  86   train_loss:  644.0168615094659
                                   e:  86   val_loss:  748.7650208045198
e:  87   train_loss:  643.1661085754719
                                   e:  87   val_loss:  739.6956132154576
e:  88   train_loss:  640.5699953036253
                                   e:  88   val_loss:  738.260522490541
e:  89   train_loss:  637.1727436515359
                                   e:  89   val_loss:  734.1461254833588
e:  90   train_loss:  634.44899119482
                                   e:  90   val_loss:  740.043392999489
e:  91   train_loss:  633.9947610556825
                                   e:  91   val_loss:  729.275229382468
e:  92   train_loss:  631.7809338336383
                                   e:  92   val_loss:  727.8433613360367
e:  93   train_loss:  629.5270365356297
                                   e:  93   val_loss:  725.0999773708317
e:  94   train_loss:  633.2322006945351
                                   e:  94   val_loss:  725.1138108373665
e:  95   train_loss:  627.516328949669
                                   e:  95   val_loss:  730.4461605155172
e:  96   train_loss:  627.4279596407904
                                   e:  96   val_loss:  723.4389460885188
e:  97   train_loss:  626.1602222111433
                                   e:  97   val_loss:  715.4832042523756
e:  98   train_loss:  624.8846398100944
                                   e:  98   val_loss:  718.6378850196342
e:  99   train_loss:  621.731233861637
                                   e:  99   val_loss:  712.2321511976002
e:  100   train_loss:  622.5406266462421
                                   e:  100   val_loss:  716.8293076497332
e:  101   train_loss:  617.498317573936
                                   e:  101   val_loss:  717.4548353978684
e:  102   train_loss:  617.3717332348991
                                   e:  102   val_loss:  711.3594722161972
e:  103   train_loss:  614.830829265481
                                   e:  103   val_loss:  705.1395664177651
e:  104   train_loss:  614.9765845242893
                                   e:  104   val_loss:  707.8310831842809
e:  105   train_loss:  615.9528693807925
                                   e:  105   val_loss:  702.9810602593183
e:  106   train_loss:  610.7485720927459
                                   e:  106   val_loss:  703.7285858023955
e:  107   train_loss:  610.6479451707717
                                   e:  107   val_loss:  700.2273236378526
e:  108   train_loss:  607.6636171977043
                                   e:  108   val_loss:  696.1431408226465
e:  109   train_loss:  607.7404264828248
                                   e:  109   val_loss:  697.044337980967
e:  110   train_loss:  608.2697807306678
                                   e:  110   val_loss:  694.9037183563205
e:  111   train_loss:  606.1861774706778
                                   e:  111   val_loss:  690.8367514730411
e:  112   train_loss:  604.022401516438
                                   e:  112   val_loss:  690.5061880489454
e:  113   train_loss:  602.6908229172549
                                   e:  113   val_loss:  689.5100750203603
e:  114   train_loss:  602.1163970991406
                                   e:  114   val_loss:  694.784782237246
e:  115   train_loss:  598.5331501979819
                                   e:  115   val_loss:  688.4833040905298
e:  116   train_loss:  598.0006067756628
                                   e:  116   val_loss:  685.6958058021477
e:  117   train_loss:  597.2295619967438
                                   e:  117   val_loss:  682.6966106309432
e:  118   train_loss:  594.849143242044
                                   e:  118   val_loss:  685.2150112765593
e:  119   train_loss:  593.6367618776047
                                   e:  119   val_loss:  682.3556833668893
e:  120   train_loss:  592.1602145052268
                                   e:  120   val_loss:  678.1136995421328
e:  121   train_loss:  592.4182471962264
                                   e:  121   val_loss:  676.6846625453775
e:  122   train_loss:  593.2242483214342
                                   e:  122   val_loss:  678.4018880898475
e:  123   train_loss:  588.9435873961138
                                   e:  123   val_loss:  676.2699830250925
e:  124   train_loss:  590.0131627178141
                                   e:  124   val_loss:  676.109220975955
e:  125   train_loss:  588.5889186194171
                                   e:  125   val_loss:  674.9048055437861
e:  126   train_loss:  586.7574764597771
                                   e:  126   val_loss:  674.0571483638572
e:  127   train_loss:  587.2891247700744
                                   e:  127   val_loss:  677.4991514176605
e:  128   train_loss:  588.3164280177368
                                   e:  128   val_loss:  674.4093148590797
e:  129   train_loss:  581.0769205685438
                                   e:  129   val_loss:  675.6821339810674
e:  130   train_loss:  581.0256884247985
                                   e:  130   val_loss:  665.4673412657703
e:  131   train_loss:  579.4310248866342
                                   e:  131   val_loss:  662.9406175556347
e:  132   train_loss:  581.394560466806
                                   e:  132   val_loss:  661.6819314884417
e:  133   train_loss:  580.691560463693
                                   e:  133   val_loss:  661.9563459322137
e:  134   train_loss:  573.3002845575913
                                   e:  134   val_loss:  662.8043303976923
e:  135   train_loss:  578.2571565891831
                                   e:  135   val_loss:  664.6303003329501
e:  136   train_loss:  575.3397167226591
                                   e:  136   val_loss:  660.0712793608958
e:  137   train_loss:  578.132574234088
                                   e:  137   val_loss:  666.4456098471783
e:  138   train_loss:  573.5831718795714
                                   e:  138   val_loss:  656.4700539812964
e:  139   train_loss:  569.979424311007
                                   e:  139   val_loss:  654.3337054100326
e:  140   train_loss:  571.8012063993663
                                   e:  140   val_loss:  659.3099809624888
e:  141   train_loss:  567.7768031369337
                                   e:  141   val_loss:  654.7852259722886
e:  142   train_loss:  565.1511471225961
                                   e:  142   val_loss:  649.0555900824131
e:  143   train_loss:  568.601804374357
                                   e:  143   val_loss:  659.4763339935065
e:  144   train_loss:  564.598444330783
                                   e:  144   val_loss:  656.5810004303369
e:  145   train_loss:  567.7177575082542
                                   e:  145   val_loss:  644.2583253053741
e:  146   train_loss:  562.8710035804152
                                   e:  146   val_loss:  642.0474090035474
e:  147   train_loss:  563.2887611660444
                                   e:  147   val_loss:  642.3189772806081
e:  148   train_loss:  560.0786646580433
                                   e:  148   val_loss:  642.3891673539614
e:  149   train_loss:  560.5839787715162
                                   e:  149   val_loss:  637.9715572700752
e:  150   train_loss:  555.7237664766075
                                   e:  150   val_loss:  638.3783905099966
e:  151   train_loss:  559.3982168993712
                                   e:  151   val_loss:  646.8876396851347
e:  152   train_loss:  563.7722459229215
                                   e:  152   val_loss:  634.0469084849221
e:  153   train_loss:  548.4917076003331
                                   e:  153   val_loss:  640.9369017765757
e:  154   train_loss:  554.4791115676102
                                   e:  154   val_loss:  651.9672745958738
e:  155   train_loss:  559.2943106638942
                                   e:  155   val_loss:  632.4624141441857
e:  156   train_loss:  552.5791425585991
                                   e:  156   val_loss:  653.0733308607241
e:  157   train_loss:  545.4144103685621
                                   e:  157   val_loss:  630.4683056584596
e:  158   train_loss:  554.136285687898
                                   e:  158   val_loss:  627.470674308456
e:  159   train_loss:  542.0723270141609
                                   e:  159   val_loss:  623.0940878513168
e:  160   train_loss:  549.6909182869305
                                   e:  160   val_loss:  627.5727172046251
e:  161   train_loss:  544.4120875319767
                                   e:  161   val_loss:  619.8516669062317
e:  162   train_loss:  547.5170789397628
                                   e:  162   val_loss:  628.9854111278557
e:  163   train_loss:  545.4477579941736
                                   e:  163   val_loss:  618.9442668691885
e:  164   train_loss:  542.0197572190103
                                   e:  164   val_loss:  619.6349606854805
e:  165   train_loss:  539.9088313726136
                                   e:  165   val_loss:  613.5379840220694
e:  166   train_loss:  548.3210035565816
                                   e:  166   val_loss:  625.7455074764628
e:  167   train_loss:  541.0312468063104
                                   e:  167   val_loss:  619.768578525777
e:  168   train_loss:  541.8156735833082
                                   e:  168   val_loss:  642.2877104209308
e:  169   train_loss:  533.0978132546807
                                   e:  169   val_loss:  670.8578528476161
e:  170   train_loss:  532.4922264956588
                                   e:  170   val_loss:  619.8331805669606
e:  171   train_loss:  540.641017892775
                                   e:  171   val_loss:  621.6473010443523
e:  172   train_loss:  537.8155527075545
                                   e:  172   val_loss:  681.5531084008984
e:  173   train_loss:  538.590141792416
                                   e:  173   val_loss:  607.6740514816659
e:  174   train_loss:  525.4965510535098
                                   e:  174   val_loss:  599.8711828008894
e:  175   train_loss:  531.3197935443867
                                   e:  175   val_loss:  601.3846086930786
e:  176   train_loss:  536.2403303013963
                                   e:  176   val_loss:  601.8408713968157
e:  177   train_loss:  529.1064543397586
                                   e:  177   val_loss:  625.0432937929688
e:  178   train_loss:  517.0714445767763
                                   e:  178   val_loss:  593.7770596870314
e:  179   train_loss:  526.5501618961142
                                   e:  179   val_loss:  673.6965886782555
e:  180   train_loss:  521.9426351536234
                                   e:  180   val_loss:  603.5751486881782
e:  181   train_loss:  516.9941108788481
                                   e:  181   val_loss:  589.2976899264889
e:  182   train_loss:  522.6320332394672
                                   e:  182   val_loss:  650.4351306349205
e:  183   train_loss:  523.6538171565528
                                   e:  183   val_loss:  609.6543093468997
e:  184   train_loss:  524.4735686811064
                                   e:  184   val_loss:  591.0953756852434
e:  185   train_loss:  501.9792626143352
                                   e:  185   val_loss:  582.2150261559566
e:  186   train_loss:  519.9722319689461
                                   e:  186   val_loss:  590.6875020397918
e:  187   train_loss:  511.3571739276408
                                   e:  187   val_loss:  577.3899808563995
e:  188   train_loss:  520.3755653088779
                                   e:  188   val_loss:  579.4718718152584
e:  189   train_loss:  512.7432565556788
                                   e:  189   val_loss:  576.4594185818708
e:  190   train_loss:  512.0716285585193
                                   e:  190   val_loss:  585.3511719624777
e:  191   train_loss:  513.0180992685384
                                   e:  191   val_loss:  579.2516671583938
e:  192   train_loss:  503.0861791257662
                                   e:  192   val_loss:  568.0419645775695
e:  193   train_loss:  503.3128484034164
                                   e:  193   val_loss:  634.5571563941764
e:  194   train_loss:  508.4460276582785
                                   e:  194   val_loss:  580.3439998217317
e:  195   train_loss:  508.6713947975983
                                   e:  195   val_loss:  564.9571882518192
e:  196   train_loss:  503.55298308866
                                   e:  196   val_loss:  577.8690668810916
e:  197   train_loss:  497.0783919399381
                                   e:  197   val_loss:  567.0421695547708
e:  198   train_loss:  497.0785162719703
                                   e:  198   val_loss:  560.244116244402
e:  199   train_loss:  501.3874989079946
                                   e:  199   val_loss:  584.1754646093514
e:  200   train_loss:  497.73899785931076
                                   e:  200   val_loss:  563.564420336259
e:  201   train_loss:  502.3122224730135
                                   e:  201   val_loss:  582.0474409935107
e:  202   train_loss:  497.5943650871456
                                   e:  202   val_loss:  569.6675831538282
e:  203   train_loss:  485.50977612000776
                                   e:  203   val_loss:  565.4714631640511
e:  204   train_loss:  506.11626103024855
                                   e:  204   val_loss:  549.5041885106959
e:  205   train_loss:  478.4096160100531
                                   e:  205   val_loss:  578.2548675107379
e:  206   train_loss:  504.1514734068324
                                   e:  206   val_loss:  550.5012668081365
e:  207   train_loss:  488.9782100967505
                                   e:  207   val_loss:  550.1670005095262
e:  208   train_loss:  489.01683446757886
                                   e:  208   val_loss:  546.1240370666931
e:  209   train_loss:  482.2312673146424
                                   e:  209   val_loss:  546.4166238985428
e:  210   train_loss:  485.72130499514475
                                   e:  210   val_loss:  551.1310708072604
e:  211   train_loss:  483.75176608621877
                                   e:  211   val_loss:  535.7692854297944
e:  212   train_loss:  484.9330157739863
                                   e:  212   val_loss:  549.4691290502344
e:  213   train_loss:  483.02213510728376
                                   e:  213   val_loss:  549.9778956260242
e:  214   train_loss:  463.4454168867108
                                   e:  214   val_loss:  612.4332744536559
e:  215   train_loss:  492.24398665880784
                                   e:  215   val_loss:  542.1864203184557
e:  216   train_loss:  483.72453427325246
                                   e:  216   val_loss:  535.926540142648
e:  217   train_loss:  472.56000576285385
                                   e:  217   val_loss:  524.6728429949953
e:  218   train_loss:  473.91812370081476
                                   e:  218   val_loss:  535.9158017877404
e:  219   train_loss:  467.47616181503594
                                   e:  219   val_loss:  533.017838935062
e:  220   train_loss:  461.19676792728063
                                   e:  220   val_loss:  567.7463770527966
e:  221   train_loss:  474.704370156546
                                   e:  221   val_loss:  558.991701394694
e:  222   train_loss:  457.02997426046284
                                   e:  222   val_loss:  553.7232938571884
e:  223   train_loss:  469.86332476070396
                                   e:  223   val_loss:  589.2637484304635
e:  224   train_loss:  451.9761536962037
                                   e:  224   val_loss:  734.8718160351578
e:  225   train_loss:  467.5231721100036
                                   e:  225   val_loss:  553.6745611651876
e:  226   train_loss:  467.15356301966057
                                   e:  226   val_loss:  501.451002000479
e:  227   train_loss:  449.85756240249856
                                   e:  227   val_loss:  627.8657317740553
e:  228   train_loss:  466.7961087108911
                                   e:  228   val_loss:  527.0250712023143
e:  229   train_loss:  461.9072289511781
                                   e:  229   val_loss:  507.85356489770095
e:  230   train_loss:  463.2668097800477
                                   e:  230   val_loss:  506.95758358919204
e:  231   train_loss:  448.8635287440986
                                   e:  231   val_loss:  526.8942262576145
e:  232   train_loss:  459.96334574396127
                                   e:  232   val_loss:  497.9966703386341
e:  233   train_loss:  449.53298080229183
                                   e:  233   val_loss:  572.9133862357023
e:  234   train_loss:  460.6987505724578
                                   e:  234   val_loss:  499.66017313105823
e:  235   train_loss:  453.01075226098885
                                   e:  235   val_loss:  497.42204390534533
e:  236   train_loss:  447.0018657170158
                                   e:  236   val_loss:  509.0167188276079
e:  237   train_loss:  438.21490233247494
                                   e:  237   val_loss:  501.51206131082074
e:  238   train_loss:  436.9500126672272
                                   e:  238   val_loss:  518.9006472798426
e:  239   train_loss:  444.9180244300577
                                   e:  239   val_loss:  502.3392533589581
e:  240   train_loss:  434.817249960869
                                   e:  240   val_loss:  535.3603118619087
e:  241   train_loss:  444.1865029395068
                                   e:  241   val_loss:  518.8786871342434
e:  242   train_loss:  442.09362885712676
                                   e:  242   val_loss:  473.81844468587815
e:  243   train_loss:  439.28878257212125
                                   e:  243   val_loss:  518.1247666433478
e:  244   train_loss:  436.2054067084751
                                   e:  244   val_loss:  476.2234161299718
e:  245   train_loss:  426.6068027067275
                                   e:  245   val_loss:  511.7107977834845
e:  246   train_loss:  439.2780583477306
                                   e:  246   val_loss:  513.4491599332557
e:  247   train_loss:  431.59923620208815
                                   e:  247   val_loss:  502.2492195561519
e:  248   train_loss:  441.9806631011068
                                   e:  248   val_loss:  468.73808295216986
e:  249   train_loss:  428.12646214201646
                                   e:  249   val_loss:  476.68048071548964
e:  250   train_loss:  428.3246175482097
                                   e:  250   val_loss:  506.2503349704992
e:  251   train_loss:  427.7218821159505
                                   e:  251   val_loss:  496.4266649986595
e:  252   train_loss:  428.9488547904413
                                   e:  252   val_loss:  516.3712311497791
e:  253   train_loss:  424.9044470060139
                                   e:  253   val_loss:  478.70552855618615
e:  254   train_loss:  417.38327230038993
                                   e:  254   val_loss:  449.62679081119904
e:  255   train_loss:  409.1382103337994
                                   e:  255   val_loss:  448.7509000956332
e:  256   train_loss:  414.78957182228186
                                   e:  256   val_loss:  491.29586153183607
e:  257   train_loss:  423.1717969347119
                                   e:  257   val_loss:  541.6606428507159
e:  258   train_loss:  417.38739670067855
                                   e:  258   val_loss:  559.9397580504053
e:  259   train_loss:  440.54448875153207
                                   e:  259   val_loss:  526.3967439731525
e:  260   train_loss:  417.47565273217634
                                   e:  260   val_loss:  458.60917088902426
e:  261   train_loss:  422.83999877448105
                                   e:  261   val_loss:  484.0373443125707
e:  262   train_loss:  415.9982729641238
                                   e:  262   val_loss:  435.8912046922922
e:  263   train_loss:  409.67504565861833
                                   e:  263   val_loss:  513.2023272026141
e:  264   train_loss:  406.1734037493147
                                   e:  264   val_loss:  473.3845973467727
e:  265   train_loss:  407.3905137014586
                                   e:  265   val_loss:  492.39387444688373
e:  266   train_loss:  409.78993481965597
                                   e:  266   val_loss:  484.28688124014207
e:  267   train_loss:  407.10409266580075
                                   e:  267   val_loss:  432.2997994044011
e:  268   train_loss:  403.39273604164873
                                   e:  268   val_loss:  467.0699280675303
e:  269   train_loss:  403.87887876222294
                                   e:  269   val_loss:  432.688662459432
e:  270   train_loss:  403.3496122501006
                                   e:  270   val_loss:  449.9450697781514
e:  271   train_loss:  393.2551954419369
                                   e:  271   val_loss:  421.6850260888426
e:  272   train_loss:  395.469965442948
                                   e:  272   val_loss:  419.581003476541
e:  273   train_loss:  401.9178784925771
                                   e:  273   val_loss:  428.40788951772373
e:  274   train_loss:  394.86994284461684
                                   e:  274   val_loss:  426.9360500036217
e:  275   train_loss:  400.7794358482842
                                   e:  275   val_loss:  419.157113475697
e:  276   train_loss:  385.39410550550224
                                   e:  276   val_loss:  431.5493746040237
e:  277   train_loss:  393.5326707368463
                                   e:  277   val_loss:  412.2358375716359
e:  278   train_loss:  381.07954146739417
                                   e:  278   val_loss:  420.6687833391546
e:  279   train_loss:  397.97370007019384
                                   e:  279   val_loss:  477.248673089647
e:  280   train_loss:  388.84931503401333
                                   e:  280   val_loss:  502.7149042429639
e:  281   train_loss:  392.1222024088961
                                   e:  281   val_loss:  437.6510209698492
e:  282   train_loss:  390.3495495745735
                                   e:  282   val_loss:  501.5448098400889
e:  283   train_loss:  380.1695636637248
                                   e:  283   val_loss:  493.55482155314877
e:  284   train_loss:  398.9036302962686
                                   e:  284   val_loss:  413.1648295534974
e:  285   train_loss:  377.22699797644304
                                   e:  285   val_loss:  404.1910804614323
e:  286   train_loss:  378.45559543733526
                                   e:  286   val_loss:  500.968490352593
e:  287   train_loss:  389.25862526554795
                                   e:  287   val_loss:  418.5677117752337
e:  288   train_loss:  369.3585555224199
                                   e:  288   val_loss:  396.06922903131954
e:  289   train_loss:  383.82497075810187
                                   e:  289   val_loss:  401.68720308774107
e:  290   train_loss:  382.4548449368377
                                   e:  290   val_loss:  434.76835281507476
e:  291   train_loss:  379.0384124239812
                                   e:  291   val_loss:  417.152119892661
e:  292   train_loss:  371.2784297765112
                                   e:  292   val_loss:  441.2680914860809
e:  293   train_loss:  381.73318994177293
                                   e:  293   val_loss:  389.453922087721
e:  294   train_loss:  373.70062072622795
                                   e:  294   val_loss:  441.29864024899433
e:  295   train_loss:  373.74773236262604
                                   e:  295   val_loss:  537.0064869242779
e:  296   train_loss:  369.35745993861156
                                   e:  296   val_loss:  407.8508578449786
e:  297   train_loss:  371.04376228586887
                                   e:  297   val_loss:  388.64276276932134
e:  298   train_loss:  359.29566428250536
                                   e:  298   val_loss:  388.1486972871815
e:  299   train_loss:  364.75932708517354
                                   e:  299   val_loss:  441.37441924329215
e:  300   train_loss:  366.7938383739635
                                   e:  300   val_loss:  398.98096844646824
e:  301   train_loss:  371.89125880719223
                                   e:  301   val_loss:  413.19252649400477
e:  302   train_loss:  367.0860621290067
                                   e:  302   val_loss:  462.42352049416803
e:  303   train_loss:  372.5054714497464
                                   e:  303   val_loss:  406.5705998827093
e:  304   train_loss:  361.57380627535787
                                   e:  304   val_loss:  377.2151056091751
e:  305   train_loss:  363.73991897511047
                                   e:  305   val_loss:  399.9223285595992
e:  306   train_loss:  362.69289986897576
                                   e:  306   val_loss:  444.327695506086
e:  307   train_loss:  367.74232009764927
                                   e:  307   val_loss:  436.4214368681831
e:  308   train_loss:  363.39664972254945
                                   e:  308   val_loss:  672.6151642169477
e:  309   train_loss:  374.0155196910275
                                   e:  309   val_loss:  408.73207628918084
e:  310   train_loss:  355.09277374562254
                                   e:  310   val_loss:  406.44145932057563
e:  311   train_loss:  352.67103731606437
                                   e:  311   val_loss:  408.3620663461785
e:  312   train_loss:  355.3045429188948
                                   e:  312   val_loss:  368.21405450747454
e:  313   train_loss:  347.2534184746227
                                   e:  313   val_loss:  379.74546008356276
e:  314   train_loss:  352.35606569262256
                                   e:  314   val_loss:  425.2392695774345
e:  315   train_loss:  365.14805959523574
                                   e:  315   val_loss:  418.2719287394246
e:  316   train_loss:  353.88481874447126
                                   e:  316   val_loss:  400.30468711688707
e:  317   train_loss:  344.8363250896897
                                   e:  317   val_loss:  368.8266770717736
e:  318   train_loss:  332.77607365341083
                                   e:  318   val_loss:  402.6162656993523
e:  319   train_loss:  361.0222697807798
                                   e:  319   val_loss:  405.8143740989008
e:  320   train_loss:  356.3644714934186
                                   e:  320   val_loss:  412.3974910904335
e:  321   train_loss:  348.10180630489265
                                   e:  321   val_loss:  385.1412529126445
e:  322   train_loss:  358.0646746366792
                                   e:  322   val_loss:  357.6751579718847
e:  323   train_loss:  345.53223759580305
                                   e:  323   val_loss:  387.16889017397676
e:  324   train_loss:  352.71530468691054
                                   e:  324   val_loss:  408.34800923643024
e:  325   train_loss:  354.0573827892598
                                   e:  325   val_loss:  410.5647646061574
e:  326   train_loss:  343.32798228158293
                                   e:  326   val_loss:  387.0719017998041
e:  327   train_loss:  346.9162749522301
                                   e:  327   val_loss:  414.2818886094536
e:  328   train_loss:  345.37038124876494
                                   e:  328   val_loss:  395.55301727961876
e:  329   train_loss:  347.8129256784983
                                   e:  329   val_loss:  354.3612917778031
e:  330   train_loss:  340.2391649988812
                                   e:  330   val_loss:  454.14956452798924
e:  331   train_loss:  343.8651501086881
                                   e:  331   val_loss:  422.813827988473
e:  332   train_loss:  345.88184286883325
                                   e:  332   val_loss:  406.100191753477
e:  333   train_loss:  346.22117471968147
                                   e:  333   val_loss:  397.7498641512251
e:  334   train_loss:  336.3872141161213
                                   e:  334   val_loss:  425.4437934635219
e:  335   train_loss:  342.766696538328
                                   e:  335   val_loss:  377.1740727391566
e:  336   train_loss:  331.00335139994365
                                   e:  336   val_loss:  384.6416753595451
e:  337   train_loss:  345.26020439431926
                                   e:  337   val_loss:  367.0732084594107
e:  338   train_loss:  338.3317642345693
                                   e:  338   val_loss:  377.25810032307743
e:  339   train_loss:  321.1602286894255
                                   e:  339   val_loss:  345.7263512671369
e:  340   train_loss:  324.1946243603381
                                   e:  340   val_loss:  394.27041114690866
e:  341   train_loss:  346.96631340114374
                                   e:  341   val_loss:  381.2708571266779
e:  342   train_loss:  333.2144839380021
                                   e:  342   val_loss:  364.7917047677314
e:  343   train_loss:  336.2698379703329
                                   e:  343   val_loss:  401.4788410171212
e:  344   train_loss:  330.83185386223414
                                   e:  344   val_loss:  346.1449778391442
e:  345   train_loss:  332.3636364021485
                                   e:  345   val_loss:  357.0882899811002
e:  346   train_loss:  327.56364655524413
                                   e:  346   val_loss:  340.6330936835846
e:  347   train_loss:  333.6851986258472
                                   e:  347   val_loss:  433.8464285809845
e:  348   train_loss:  328.8568836421265
                                   e:  348   val_loss:  355.5208812985553
e:  349   train_loss:  333.75062166921947
                                   e:  349   val_loss:  351.0758114157344
e:  350   train_loss:  320.64651036653396
                                   e:  350   val_loss:  408.0427982417401
e:  351   train_loss:  332.9564498074277
                                   e:  351   val_loss:  371.2167017062272
e:  352   train_loss:  334.61346061603376
                                   e:  352   val_loss:  388.1738633100236
e:  353   train_loss:  328.85575233605124
                                   e:  353   val_loss:  417.1214426928397
e:  354   train_loss:  324.71435013069873
                                   e:  354   val_loss:  390.2705831260491
e:  355   train_loss:  320.49513295912794
                                   e:  355   val_loss:  348.3830941334146
e:  356   train_loss:  311.56566524438665
                                   e:  356   val_loss:  342.3503201283148
e:  357   train_loss:  324.0169118897062
                                   e:  357   val_loss:  335.93223449031245
e:  358   train_loss:  317.46227151153147
                                   e:  358   val_loss:  369.4501222603584
e:  359   train_loss:  325.81612046202764
                                   e:  359   val_loss:  366.7496607155655
e:  360   train_loss:  331.0685715149501
                                   e:  360   val_loss:  418.2497071166901
e:  361   train_loss:  320.46741825099326
                                   e:  361   val_loss:  336.14807043624035
e:  362   train_loss:  318.348618491964
                                   e:  362   val_loss:  405.3516868463648
e:  363   train_loss:  329.4936969733656
                                   e:  363   val_loss:  348.1536727631244
e:  364   train_loss:  309.3375311468534
                                   e:  364   val_loss:  363.657041969553
e:  365   train_loss:  330.0447156848876
                                   e:  365   val_loss:  354.3612085681069
e:  366   train_loss:  319.5667124203126
                                   e:  366   val_loss:  365.7521327287424
e:  367   train_loss:  317.9188383133237
                                   e:  367   val_loss:  379.5906531099118
e:  368   train_loss:  325.8181979322089
                                   e:  368   val_loss:  398.34455052475994
e:  369   train_loss:  325.7867125873329
                                   e:  369   val_loss:  350.26396701524806
e:  370   train_loss:  311.73051653007826
                                   e:  370   val_loss:  331.8143227104514
e:  371   train_loss:  311.2321758942832
                                   e:  371   val_loss:  329.91498329731076
e:  372   train_loss:  323.25729207995704
                                   e:  372   val_loss:  346.55726793441346
e:  373   train_loss:  314.4645960012402
                                   e:  373   val_loss:  328.81772468527686
e:  374   train_loss:  318.5359706602548
                                   e:  374   val_loss:  363.6759144761877
e:  375   train_loss:  307.5549586114297
                                   e:  375   val_loss:  411.7987928245269
e:  376   train_loss:  310.27781940064625
                                   e:  376   val_loss:  374.28724454618197
e:  377   train_loss:  320.08887929286345
                                   e:  377   val_loss:  356.36617220415
e:  378   train_loss:  306.2370908786957
                                   e:  378   val_loss:  387.8828540130563
e:  379   train_loss:  307.18768675872604
                                   e:  379   val_loss:  370.60524733885427
e:  380   train_loss:  313.82308199872034
                                   e:  380   val_loss:  326.32345341448956
e:  381   train_loss:  300.94991851980893
                                   e:  381   val_loss:  332.3663982288157
e:  382   train_loss:  305.1482833886324
                                   e:  382   val_loss:  343.5427421808603
e:  383   train_loss:  309.1902062859436
                                   e:  383   val_loss:  346.04297878922677
e:  384   train_loss:  314.4567944650068
                                   e:  384   val_loss:  375.63972921922857
e:  385   train_loss:  307.8539874657362
                                   e:  385   val_loss:  326.6649407894971
e:  386   train_loss:  305.74454504811945
                                   e:  386   val_loss:  338.4657220989881
e:  387   train_loss:  313.10224833198765
                                   e:  387   val_loss:  321.78442669392456
e:  388   train_loss:  305.23652208962625
                                   e:  388   val_loss:  355.18597701793425
e:  389   train_loss:  309.00056613816497
                                   e:  389   val_loss:  339.95106618970885
e:  390   train_loss:  301.0171111884672
                                   e:  390   val_loss:  443.0117137638542
e:  391   train_loss:  309.185242581519
                                   e:  391   val_loss:  322.23000608251505
e:  392   train_loss:  304.1920752632981
                                   e:  392   val_loss:  372.8201091949129
e:  393   train_loss:  303.1501533304824
                                   e:  393   val_loss:  342.97570691050004
e:  394   train_loss:  306.60669518534644
                                   e:  394   val_loss:  337.93814369767915
e:  395   train_loss:  306.18834730943274
                                   e:  395   val_loss:  327.3414143747335
e:  396   train_loss:  298.36533119703023
                                   e:  396   val_loss:  353.13310011369765
e:  397   train_loss:  301.42419417789836
                                   e:  397   val_loss:  325.33233676695505
e:  398   train_loss:  298.0922774798087
                                   e:  398   val_loss:  344.60663014559697
e:  399   train_loss:  308.62955057419595
                                   e:  399   val_loss:  346.7624685393756
e:  400   train_loss:  301.7211952224393
                                   e:  400   val_loss:  318.9913048223329
e:  401   train_loss:  297.78237058402226
                                   e:  401   val_loss:  325.2625910601681
e:  402   train_loss:  291.7245187108582
                                   e:  402   val_loss:  350.8977134128172
e:  403   train_loss:  299.3134685699185
                                   e:  403   val_loss:  342.0835966824676
e:  404   train_loss:  303.43119611089384
                                   e:  404   val_loss:  332.7088214249702
e:  405   train_loss:  310.6882156568995
                                   e:  405   val_loss:  327.5404598366893
e:  406   train_loss:  307.688070371702
                                   e:  406   val_loss:  363.1876739127857
e:  407   train_loss:  300.14807236815693
                                   e:  407   val_loss:  321.0028046310257
e:  408   train_loss:  303.12508411428166
                                   e:  408   val_loss:  329.14936233034103
e:  409   train_loss:  294.13393094264023
                                   e:  409   val_loss:  364.14137097019744
e:  410   train_loss:  305.5935670630906
                                   e:  410   val_loss:  373.81474386833986
e:  411   train_loss:  286.73337072457133
                                   e:  411   val_loss:  338.9791103451292
e:  412   train_loss:  288.63999053473975
                                   e:  412   val_loss:  321.98191282296233
e:  413   train_loss:  294.7482499496879
                                   e:  413   val_loss:  331.6844711593872
e:  414   train_loss:  297.82370856797496
                                   e:  414   val_loss:  328.3492511160467
e:  415   train_loss:  301.44046990903206
                                   e:  415   val_loss:  317.9151318966162
e:  416   train_loss:  290.8422513757569
                                   e:  416   val_loss:  320.51563361037097
e:  417   train_loss:  294.5008142448139
                                   e:  417   val_loss:  372.7452085041008
e:  418   train_loss:  294.78240586709893
                                   e:  418   val_loss:  340.47128849557737
e:  419   train_loss:  305.1251038085095
                                   e:  419   val_loss:  314.3708588708558
e:  420   train_loss:  287.3725643642855
                                   e:  420   val_loss:  342.8578014049048
e:  421   train_loss:  287.3700743239848
                                   e:  421   val_loss:  321.0790345924659
e:  422   train_loss:  294.66886882072515
                                   e:  422   val_loss:  325.45766680619965
e:  423   train_loss:  292.18538474411116
                                   e:  423   val_loss:  318.7569381178029
e:  424   train_loss:  289.93719878744406
                                   e:  424   val_loss:  320.49326217084183
e:  425   train_loss:  294.83278507470453
                                   e:  425   val_loss:  347.53910432820885
e:  426   train_loss:  303.5302190319651
                                   e:  426   val_loss:  326.2176068718787
e:  427   train_loss:  285.87007921099894
                                   e:  427   val_loss:  354.7240975671448
e:  428   train_loss:  299.6744845326325
                                   e:  428   val_loss:  315.78280404190826
e:  429   train_loss:  289.2022073706482
                                   e:  429   val_loss:  416.5019240933436
e:  430   train_loss:  297.76799365966076
                                   e:  430   val_loss:  343.1701788973904
e:  431   train_loss:  287.30390655885884
                                   e:  431   val_loss:  327.89110280846444
e:  432   train_loss:  285.73654423656393
                                   e:  432   val_loss:  339.90788440522994
e:  433   train_loss:  283.63500825123845
                                   e:  433   val_loss:  323.4054913990588
e:  434   train_loss:  285.6159699575425
                                   e:  434   val_loss:  372.5794988814508
e:  435   train_loss:  289.69842735320185
                                   e:  435   val_loss:  388.486479961339
e:  436   train_loss:  298.38578920294094
                                   e:  436   val_loss:  338.86271685404
e:  437   train_loss:  290.6619913859573
                                   e:  437   val_loss:  323.2562078544619
e:  438   train_loss:  290.8739259193394
                                   e:  438   val_loss:  315.68607929367823
e:  439   train_loss:  284.72502016709495
                                   e:  439   val_loss:  322.21211009824043
e:  440   train_loss:  290.2737639200229
                                   e:  440   val_loss:  321.5862016522145
e:  441   train_loss:  284.0013319630045
                                   e:  441   val_loss:  335.65716059203055
e:  442   train_loss:  283.2515009067372
                                   e:  442   val_loss:  349.4793125790522
e:  443   train_loss:  294.92462029005645
                                   e:  443   val_loss:  344.7473497872508
e:  444   train_loss:  286.5840625309164
                                   e:  444   val_loss:  312.2474415751707
e:  445   train_loss:  277.6168104218922
                                   e:  445   val_loss:  316.38362072867756
e:  446   train_loss:  281.53870784106965
                                   e:  446   val_loss:  343.7483818741585
e:  447   train_loss:  295.10502999326684
                                   e:  447   val_loss:  327.4074019632627
e:  448   train_loss:  276.3768207788275
                                   e:  448   val_loss:  335.3109278768519
e:  449   train_loss:  286.50644306745426
                                   e:  449   val_loss:  357.9155168664566
e:  450   train_loss:  289.6744787982232
                                   e:  450   val_loss:  359.96965772450653
e:  451   train_loss:  282.68585634097127
                                   e:  451   val_loss:  356.3685708627789
e:  452   train_loss:  287.57200713725547
                                   e:  452   val_loss:  326.47505873595503
e:  453   train_loss:  284.1322301914702
                                   e:  453   val_loss:  356.64377910997234
e:  454   train_loss:  281.23041709784155
                                   e:  454   val_loss:  328.1875919346142
e:  455   train_loss:  294.3589153762257
                                   e:  455   val_loss:  327.9491810148786
e:  456   train_loss:  282.3163929087653
                                   e:  456   val_loss:  318.25390260716347
e:  457   train_loss:  288.0835005634538
                                   e:  457   val_loss:  311.0724588698359
e:  458   train_loss:  280.8433708617663
                                   e:  458   val_loss:  317.44314547345846
e:  459   train_loss:  273.8706282106297
                                   e:  459   val_loss:  344.080012904664
e:  460   train_loss:  282.72541313182063
                                   e:  460   val_loss:  353.4424039564609
e:  461   train_loss:  277.897853485623
                                   e:  461   val_loss:  310.81032241340483
e:  462   train_loss:  278.4744292757279
                                   e:  462   val_loss:  366.44980082606526
e:  463   train_loss:  288.93878907530114
                                   e:  463   val_loss:  390.56190151093546
e:  464   train_loss:  269.19163028554107
                                   e:  464   val_loss:  328.89592361013894
e:  465   train_loss:  282.2267974644301
                                   e:  465   val_loss:  317.0161114180001
e:  466   train_loss:  274.2992224018594
                                   e:  466   val_loss:  310.47179329347443
e:  467   train_loss:  287.5231395421791
                                   e:  467   val_loss:  339.19867343257545
e:  468   train_loss:  277.1367432622847
                                   e:  468   val_loss:  313.25955571367365
e:  469   train_loss:  279.78672716550466
                                   e:  469   val_loss:  326.6791813336712
e:  470   train_loss:  274.9817855075574
                                   e:  470   val_loss:  333.7733092487193
e:  471   train_loss:  287.5243397790523
                                   e:  471   val_loss:  315.28279063224375
e:  472   train_loss:  274.11778211081264
                                   e:  472   val_loss:  313.74063964014005
e:  473   train_loss:  273.4573080885436
                                   e:  473   val_loss:  320.2482692438787
e:  474   train_loss:  273.5751473503216
                                   e:  474   val_loss:  340.7444301091882
e:  475   train_loss:  277.50953902892286
                                   e:  475   val_loss:  337.03940913845446
e:  476   train_loss:  278.25021400852677
                                   e:  476   val_loss:  306.46578355419786
e:  477   train_loss:  274.7485518113236
                                   e:  477   val_loss:  331.0241752103549
e:  478   train_loss:  277.68871047397005
                                   e:  478   val_loss:  312.37892352817585
e:  479   train_loss:  269.8342373375251
                                   e:  479   val_loss:  304.96276415144416
e:  480   train_loss:  270.76393135970056
                                   e:  480   val_loss:  317.84700435266024
e:  481   train_loss:  276.17194753332615
                                   e:  481   val_loss:  354.93355809683703
e:  482   train_loss:  279.2792727143086
                                   e:  482   val_loss:  324.6048865684273
e:  483   train_loss:  272.93640227890427
                                   e:  483   val_loss:  312.8403270268558
e:  484   train_loss:  266.90053053468046
                                   e:  484   val_loss:  305.64031259910746
e:  485   train_loss:  284.2736433513663
                                   e:  485   val_loss:  326.46141194418703
e:  486   train_loss:  274.58771618243645
                                   e:  486   val_loss:  309.72770168983277
e:  487   train_loss:  273.3605326349852
                                   e:  487   val_loss:  315.93394835199365
e:  488   train_loss:  263.11332753858
                                   e:  488   val_loss:  355.3872498006927
e:  489   train_loss:  275.0326980360709
                                   e:  489   val_loss:  319.95280053420123
e:  490   train_loss:  270.69467995976163
                                   e:  490   val_loss:  333.68139342600676
e:  491   train_loss:  280.59801340629883
                                   e:  491   val_loss:  320.906026401654
e:  492   train_loss:  278.704376633764
                                   e:  492   val_loss:  313.0015858200466
e:  493   train_loss:  274.045160268214
                                   e:  493   val_loss:  300.8042562712908
e:  494   train_loss:  267.05516000139625
                                   e:  494   val_loss:  310.42243730656276
e:  495   train_loss:  276.0764197974508
                                   e:  495   val_loss:  310.7606929547313
e:  496   train_loss:  269.39211463850944
                                   e:  496   val_loss:  329.098964412582
e:  497   train_loss:  264.9491143987621
                                   e:  497   val_loss:  300.9286148344445
e:  498   train_loss:  253.0601884641311
                                   e:  498   val_loss:  337.16286187934253
e:  499   train_loss:  278.41206182942756
                                   e:  499   val_loss:  311.7597689561399
e:  500   train_loss:  270.51634824485797
                                   e:  500   val_loss:  330.0398155160343
e:  501   train_loss:  272.8070034619178
                                   e:  501   val_loss:  330.824334291987
e:  502   train_loss:  269.2341828359124
                                   e:  502   val_loss:  312.7777165357521
e:  503   train_loss:  269.77802914566325
                                   e:  503   val_loss:  303.4013443005171
e:  504   train_loss:  272.9739030255072
                                   e:  504   val_loss:  300.5908629031013
e:  505   train_loss:  262.63249892095837
                                   e:  505   val_loss:  329.8223747334715
e:  506   train_loss:  268.6529712701831
                                   e:  506   val_loss:  307.8078841811638
e:  507   train_loss:  265.49353621795086
                                   e:  507   val_loss:  317.0977364017464
e:  508   train_loss:  279.68460841398735
                                   e:  508   val_loss:  367.2986840992714
e:  509   train_loss:  258.6347370946349
                                   e:  509   val_loss:  303.06711840955006
e:  510   train_loss:  267.4158477141991
                                   e:  510   val_loss:  314.6958396507832
e:  511   train_loss:  274.90843045345935
                                   e:  511   val_loss:  304.247469231174
e:  512   train_loss:  267.00267744390624
                                   e:  512   val_loss:  331.7928327154454
e:  513   train_loss:  272.8010102025033
                                   e:  513   val_loss:  313.1179382877598
e:  514   train_loss:  262.07569279727113
                                   e:  514   val_loss:  336.594068170882
e:  515   train_loss:  254.11598713790772
                                   e:  515   val_loss:  339.5646415025905
e:  516   train_loss:  271.1154786185843
                                   e:  516   val_loss:  317.4251815212517
e:  517   train_loss:  266.3675211561806
                                   e:  517   val_loss:  316.12444122888576
e:  518   train_loss:  269.73450471316346
                                   e:  518   val_loss:  337.2457122613009
e:  519   train_loss:  270.13087296861244
                                   e:  519   val_loss:  296.4574527830845
e:  520   train_loss:  261.23943318500875
                                   e:  520   val_loss:  314.5563498454274
e:  521   train_loss:  259.62067950734786
                                   e:  521   val_loss:  309.33408165971485
e:  522   train_loss:  262.14680241905387
                                   e:  522   val_loss:  323.2318491740199
e:  523   train_loss:  266.8155622383758
                                   e:  523   val_loss:  312.33130335855293
e:  524   train_loss:  263.19721958464885
                                   e:  524   val_loss:  310.00218410436986
e:  525   train_loss:  268.0980723011588
                                   e:  525   val_loss:  309.6341254002629
e:  526   train_loss:  265.11209230343405
                                   e:  526   val_loss:  337.0493965061003
e:  527   train_loss:  264.40717574371934
                                   e:  527   val_loss:  333.10336760662585
e:  528   train_loss:  264.21188779561027
                                   e:  528   val_loss:  328.56794816262504
e:  529   train_loss:  266.7380952605236
                                   e:  529   val_loss:  319.4368810243281
e:  530   train_loss:  264.3853214104451
                                   e:  530   val_loss:  301.39327727769813
e:  531   train_loss:  249.44259672218803
                                   e:  531   val_loss:  309.73625531394407
e:  532   train_loss:  259.3610786042719
                                   e:  532   val_loss:  316.83982791064284
e:  533   train_loss:  270.08118942656483
                                   e:  533   val_loss:  352.77801145636886
e:  534   train_loss:  265.169336272745
                                   e:  534   val_loss:  336.51383289446824
e:  535   train_loss:  261.8015182661309
                                   e:  535   val_loss:  314.09557348002556
e:  536   train_loss:  265.73329762924044
                                   e:  536   val_loss:  329.1920389432043
e:  537   train_loss:  266.78100635439546
                                   e:  537   val_loss:  297.61849328743966
e:  538   train_loss:  255.92303598475743
                                   e:  538   val_loss:  321.46724234733733
e:  539   train_loss:  263.4922859026051
                                   e:  539   val_loss:  300.3495962098137
e:  540   train_loss:  260.2870579545245
                                   e:  540   val_loss:  329.3606107348629
e:  541   train_loss:  266.0285503755923
                                   e:  541   val_loss:  368.3538847397411
e:  542   train_loss:  262.51974236198504
                                   e:  542   val_loss:  377.8469388943412
e:  543   train_loss:  262.2435884413021
                                   e:  543   val_loss:  312.0075702376915
e:  544   train_loss:  255.9500509343751
                                   e:  544   val_loss:  363.11590144631197
e:  545   train_loss:  263.054408069724
                                   e:  545   val_loss:  410.73395101391225
Model initialization done
FOLD:  3
Model training starts
e:  0   train_loss:  1094.6303820469077
                                   e:  0   val_loss:  1203.4768169180911
e:  1   train_loss:  1071.595151321504
                                   e:  1   val_loss:  1154.6221795499387
e:  2   train_loss:  981.6331206300611
                                   e:  2   val_loss:  1025.841639384914
e:  3   train_loss:  885.8363948469416
                                   e:  3   val_loss:  976.868003522296
e:  4   train_loss:  879.6014883321087
                                   e:  4   val_loss:  974.0364769938693
e:  5   train_loss:  873.2712171528796
                                   e:  5   val_loss:  972.4248363405155
e:  6   train_loss:  871.8369710957985
                                   e:  6   val_loss:  971.4003716441345
e:  7   train_loss:  872.2550342646819
                                   e:  7   val_loss:  969.8809671240124
e:  8   train_loss:  868.7664357766593
                                   e:  8   val_loss:  968.0096941598249
e:  9   train_loss:  868.5643853317008
                                   e:  9   val_loss:  967.0405369760314
e:  10   train_loss:  871.8479212633478
                                   e:  10   val_loss:  964.972625563387
e:  11   train_loss:  865.5717273982458
                                   e:  11   val_loss:  963.6458733340847
e:  12   train_loss:  863.9316998598746
                                   e:  12   val_loss:  961.6167489949355
e:  13   train_loss:  857.8866364888376
                                   e:  13   val_loss:  960.194041312523
e:  14   train_loss:  862.3189568193485
                                   e:  14   val_loss:  958.5213873236373
e:  15   train_loss:  853.5086837923295
                                   e:  15   val_loss:  956.4621047774165
e:  16   train_loss:  854.905284323338
                                   e:  16   val_loss:  954.4348607935563
e:  17   train_loss:  858.6866446676831
                                   e:  17   val_loss:  952.2826611533244
e:  18   train_loss:  859.0651552288841
                                   e:  18   val_loss:  950.0785794748117
e:  19   train_loss:  864.0806353927156
                                   e:  19   val_loss:  947.1121886834413
e:  20   train_loss:  854.7950588637474
                                   e:  20   val_loss:  944.9512865424352
e:  21   train_loss:  847.1831769305865
                                   e:  21   val_loss:  942.9672912836288
e:  22   train_loss:  842.4531242789917
                                   e:  22   val_loss:  939.6093100578394
e:  23   train_loss:  843.4089333799919
                                   e:  23   val_loss:  937.00002897529
e:  24   train_loss:  840.1537206630727
                                   e:  24   val_loss:  933.8474811825336
e:  25   train_loss:  839.8798482861697
                                   e:  25   val_loss:  931.1281717946928
e:  26   train_loss:  833.5943833908608
                                   e:  26   val_loss:  928.207923470246
e:  27   train_loss:  829.0230289690396
                                   e:  27   val_loss:  924.9559609647961
e:  28   train_loss:  824.8408923080985
                                   e:  28   val_loss:  921.6575858015933
e:  29   train_loss:  828.3602734569348
                                   e:  29   val_loss:  917.6238486360311
e:  30   train_loss:  823.7538819369767
                                   e:  30   val_loss:  914.0169116011557
e:  31   train_loss:  818.5379850476983
                                   e:  31   val_loss:  910.9537193376425
e:  32   train_loss:  818.049635625355
                                   e:  32   val_loss:  906.3570514367842
e:  33   train_loss:  812.0297176327452
                                   e:  33   val_loss:  902.102607794532
e:  34   train_loss:  808.5205026483784
                                   e:  34   val_loss:  897.9641648356995
e:  35   train_loss:  800.5249288842191
                                   e:  35   val_loss:  893.7069726330126
e:  36   train_loss:  798.8071923467626
                                   e:  36   val_loss:  889.3187162536449
e:  37   train_loss:  793.5885419094208
                                   e:  37   val_loss:  884.4734611544121
e:  38   train_loss:  793.958197885182
                                   e:  38   val_loss:  879.7380043368266
e:  39   train_loss:  789.1623923675126
                                   e:  39   val_loss:  874.6152355754454
e:  40   train_loss:  782.3963831959961
                                   e:  40   val_loss:  869.6104154509742
e:  41   train_loss:  775.342715163095
                                   e:  41   val_loss:  864.892952704741
e:  42   train_loss:  773.7347182586873
                                   e:  42   val_loss:  859.8709528329302
e:  43   train_loss:  771.2523232328169
                                   e:  43   val_loss:  854.3064876406448
e:  44   train_loss:  764.9431283142565
                                   e:  44   val_loss:  850.0256945179474
e:  45   train_loss:  765.5877563663968
                                   e:  45   val_loss:  844.136593845614
e:  46   train_loss:  759.0271070539818
                                   e:  46   val_loss:  838.2640475658129
e:  47   train_loss:  755.158456080879
                                   e:  47   val_loss:  833.1680752366025
e:  48   train_loss:  754.9971986994905
                                   e:  48   val_loss:  827.8945220011319
e:  49   train_loss:  745.585265966727
                                   e:  49   val_loss:  822.1100858540251
e:  50   train_loss:  743.5214401802376
                                   e:  50   val_loss:  816.7662533332544
e:  51   train_loss:  742.9795337584081
                                   e:  51   val_loss:  811.3620516143379
e:  52   train_loss:  735.2730424062341
                                   e:  52   val_loss:  806.2273510927498
e:  53   train_loss:  732.3230192587898
                                   e:  53   val_loss:  801.9715776271008
e:  54   train_loss:  730.1274129942473
                                   e:  54   val_loss:  795.7918626655613
e:  55   train_loss:  722.0968667483788
                                   e:  55   val_loss:  790.2110378655152
e:  56   train_loss:  717.7677805994235
                                   e:  56   val_loss:  784.8596130466815
e:  57   train_loss:  718.1253134639369
                                   e:  57   val_loss:  780.6207762459353
e:  58   train_loss:  709.8722785768236
                                   e:  58   val_loss:  774.9826417192222
e:  59   train_loss:  709.3630162707451
                                   e:  59   val_loss:  771.0652323632677
e:  60   train_loss:  702.3748862665313
                                   e:  60   val_loss:  766.4226748342837
e:  61   train_loss:  699.8414269963503
                                   e:  61   val_loss:  761.2293542690992
e:  62   train_loss:  697.8483648679894
                                   e:  62   val_loss:  756.2740934514879
e:  63   train_loss:  693.5458846626586
                                   e:  63   val_loss:  752.410141645624
e:  64   train_loss:  694.6394061929738
                                   e:  64   val_loss:  748.2792888868331
e:  65   train_loss:  688.6978279368786
                                   e:  65   val_loss:  743.1219113396057
e:  66   train_loss:  683.3576266603577
                                   e:  66   val_loss:  738.8700428771443
e:  67   train_loss:  680.9004882882949
                                   e:  67   val_loss:  734.9663008297405
e:  68   train_loss:  678.4582355519123
                                   e:  68   val_loss:  731.558542641784
e:  69   train_loss:  673.5077684644458
                                   e:  69   val_loss:  727.5200069225846
e:  70   train_loss:  672.4532789366391
                                   e:  70   val_loss:  723.7361419206759
e:  71   train_loss:  670.7698639412821
                                   e:  71   val_loss:  720.4812040744312
e:  72   train_loss:  666.0765953666785
                                   e:  72   val_loss:  717.0758597064361
e:  73   train_loss:  664.4158592911195
                                   e:  73   val_loss:  714.5946162593159
e:  74   train_loss:  661.2262513374203
                                   e:  74   val_loss:  710.9266695221773
e:  75   train_loss:  659.0585356473459
                                   e:  75   val_loss:  709.3107967580315
e:  76   train_loss:  660.3631342902677
                                   e:  76   val_loss:  707.2902370264202
e:  77   train_loss:  653.7779404799933
                                   e:  77   val_loss:  701.8374375949718
e:  78   train_loss:  654.5588711988497
                                   e:  78   val_loss:  700.9184778067663
e:  79   train_loss:  650.9750141872263
                                   e:  79   val_loss:  696.054187004064
e:  80   train_loss:  649.5577496197523
                                   e:  80   val_loss:  693.352038641284
e:  81   train_loss:  645.2870164753194
                                   e:  81   val_loss:  695.0601353582297
e:  82   train_loss:  645.8443575929014
                                   e:  82   val_loss:  690.3505465741227
e:  83   train_loss:  642.8352697412196
                                   e:  83   val_loss:  686.7822615312398
e:  84   train_loss:  641.9393351395378
                                   e:  84   val_loss:  685.0216696566506
e:  85   train_loss:  638.1122107510097
                                   e:  85   val_loss:  682.4979032938561
e:  86   train_loss:  634.6167880052462
                                   e:  86   val_loss:  687.336350837835
e:  87   train_loss:  636.781984431969
                                   e:  87   val_loss:  678.5179465379389
e:  88   train_loss:  634.6856888809986
                                   e:  88   val_loss:  676.5462899299107
e:  89   train_loss:  631.544784476276
                                   e:  89   val_loss:  674.6196827157848
e:  90   train_loss:  634.2896115202037
                                   e:  90   val_loss:  673.1008693998526
e:  91   train_loss:  628.8517704105273
                                   e:  91   val_loss:  670.7485133172404
e:  92   train_loss:  627.8617799835616
                                   e:  92   val_loss:  672.715239304049
e:  93   train_loss:  628.3848508253869
                                   e:  93   val_loss:  668.1559338712046
e:  94   train_loss:  624.5996160986149
                                   e:  94   val_loss:  668.4599519972542
e:  95   train_loss:  624.2539312165084
                                   e:  95   val_loss:  669.0239110600883
e:  96   train_loss:  620.764137963184
                                   e:  96   val_loss:  662.5427447348009
e:  97   train_loss:  616.765669900216
                                   e:  97   val_loss:  660.5739058873329
e:  98   train_loss:  617.1121500903851
                                   e:  98   val_loss:  661.9722329371438
e:  99   train_loss:  616.241320474788
                                   e:  99   val_loss:  659.9436598340193
e:  100   train_loss:  614.6980301020302
                                   e:  100   val_loss:  656.5697845415162
e:  101   train_loss:  613.6560368619917
                                   e:  101   val_loss:  654.868953530821
e:  102   train_loss:  613.6086432081943
                                   e:  102   val_loss:  653.918914167338
e:  103   train_loss:  609.0021421890588
                                   e:  103   val_loss:  651.3549920770498
e:  104   train_loss:  609.5796511940515
                                   e:  104   val_loss:  651.0663590251323
e:  105   train_loss:  606.293431767765
                                   e:  105   val_loss:  661.5818929322437
e:  106   train_loss:  608.9545387820906
                                   e:  106   val_loss:  648.1420287048622
e:  107   train_loss:  603.9149178799312
                                   e:  107   val_loss:  646.6826313331405
e:  108   train_loss:  605.0726210568552
                                   e:  108   val_loss:  645.3381688002535
e:  109   train_loss:  603.1287671387687
                                   e:  109   val_loss:  649.923642483267
e:  110   train_loss:  605.0079509194398
                                   e:  110   val_loss:  648.8533204563148
e:  111   train_loss:  598.3783795745875
                                   e:  111   val_loss:  644.9683563132081
e:  112   train_loss:  599.5425203857502
                                   e:  112   val_loss:  642.3185210103737
e:  113   train_loss:  600.1320899711694
                                   e:  113   val_loss:  640.8600612601781
e:  114   train_loss:  592.6609187943214
                                   e:  114   val_loss:  647.7594616318551
e:  115   train_loss:  596.6766909867135
                                   e:  115   val_loss:  642.0103386639206
e:  116   train_loss:  595.5137739244144
                                   e:  116   val_loss:  635.4668117484505
e:  117   train_loss:  588.4241793878552
                                   e:  117   val_loss:  653.1608190536008
e:  118   train_loss:  595.7509500869406
                                   e:  118   val_loss:  631.9416708931695
e:  119   train_loss:  590.5351311645893
                                   e:  119   val_loss:  648.646971046991
e:  120   train_loss:  587.789990336689
                                   e:  120   val_loss:  630.3489558977969
e:  121   train_loss:  584.3228446905124
                                   e:  121   val_loss:  630.2232758390695
e:  122   train_loss:  586.8467659073352
                                   e:  122   val_loss:  629.4692263075355
e:  123   train_loss:  586.0246184172961
                                   e:  123   val_loss:  629.4855706520905
e:  124   train_loss:  584.3688964888779
                                   e:  124   val_loss:  624.7126185896839
e:  125   train_loss:  583.921421253971
                                   e:  125   val_loss:  634.9981283051444
e:  126   train_loss:  581.3178468485953
                                   e:  126   val_loss:  621.5594599542617
e:  127   train_loss:  582.6291452188595
                                   e:  127   val_loss:  622.8360313696151
e:  128   train_loss:  584.8238132598647
                                   e:  128   val_loss:  626.3316154108934
e:  129   train_loss:  576.1478137190644
                                   e:  129   val_loss:  622.3771303390456
e:  130   train_loss:  576.7894004206707
                                   e:  130   val_loss:  618.9364813941887
e:  131   train_loss:  575.4012923430759
                                   e:  131   val_loss:  616.921982683649
e:  132   train_loss:  576.3951229508675
                                   e:  132   val_loss:  631.2508930116048
e:  133   train_loss:  570.6791712114045
                                   e:  133   val_loss:  616.9381164869108
e:  134   train_loss:  572.1858864843643
                                   e:  134   val_loss:  612.0301909828452
e:  135   train_loss:  568.8876023641005
                                   e:  135   val_loss:  616.0404270217407
e:  136   train_loss:  570.1041456529792
                                   e:  136   val_loss:  609.2912212048401
e:  137   train_loss:  567.5543912414723
                                   e:  137   val_loss:  613.065236925048
e:  138   train_loss:  566.9812336043151
                                   e:  138   val_loss:  606.5152587390018
e:  139   train_loss:  568.2255105806844
                                   e:  139   val_loss:  647.8806451544363
e:  140   train_loss:  566.1325867372069
                                   e:  140   val_loss:  615.3107975332882
e:  141   train_loss:  574.3101185357796
                                   e:  141   val_loss:  603.1210909987573
e:  142   train_loss:  565.5697670606288
                                   e:  142   val_loss:  622.1431008852685
e:  143   train_loss:  562.447268456211
                                   e:  143   val_loss:  600.264844887434
e:  144   train_loss:  560.9495402133923
                                   e:  144   val_loss:  598.6079947305101
e:  145   train_loss:  560.3325058407827
                                   e:  145   val_loss:  596.9745327556085
e:  146   train_loss:  564.9718725022677
                                   e:  146   val_loss:  642.9826203258183
e:  147   train_loss:  569.0088123024219
                                   e:  147   val_loss:  597.1656606580891
e:  148   train_loss:  556.8233514406709
                                   e:  148   val_loss:  593.7503081825023
e:  149   train_loss:  549.0794493410718
                                   e:  149   val_loss:  591.6629483275237
e:  150   train_loss:  552.6989877173361
                                   e:  150   val_loss:  602.2750171919959
e:  151   train_loss:  558.2170164617394
                                   e:  151   val_loss:  605.724090836864
e:  152   train_loss:  550.4813713071457
                                   e:  152   val_loss:  590.8854802437561
e:  153   train_loss:  549.6853302296904
                                   e:  153   val_loss:  607.2674941913336
e:  154   train_loss:  547.5568884919643
                                   e:  154   val_loss:  599.656331762093
e:  155   train_loss:  553.8942588062516
                                   e:  155   val_loss:  584.3225285308779
e:  156   train_loss:  548.9926920380263
                                   e:  156   val_loss:  583.5612049959061
e:  157   train_loss:  549.8031396282793
                                   e:  157   val_loss:  597.2413322932586
e:  158   train_loss:  542.3229439025922
                                   e:  158   val_loss:  581.7267544178111
e:  159   train_loss:  553.3280069382314
                                   e:  159   val_loss:  580.4890091288831
e:  160   train_loss:  542.2356719601356
                                   e:  160   val_loss:  582.6628600762583
e:  161   train_loss:  539.6569662244099
                                   e:  161   val_loss:  583.0431796416982
e:  162   train_loss:  540.6112098538388
                                   e:  162   val_loss:  574.2199440930024
e:  163   train_loss:  538.4781089853268
                                   e:  163   val_loss:  578.6003242900816
e:  164   train_loss:  540.0189251505557
                                   e:  164   val_loss:  582.3548971625517
e:  165   train_loss:  542.4766850344295
                                   e:  165   val_loss:  577.8179753262002
e:  166   train_loss:  532.3494354023765
                                   e:  166   val_loss:  569.1029733790901
e:  167   train_loss:  536.3471476814663
                                   e:  167   val_loss:  569.8015388900761
e:  168   train_loss:  541.0615559447142
                                   e:  168   val_loss:  698.983375887887
e:  169   train_loss:  543.3222020494251
                                   e:  169   val_loss:  568.7502043066186
e:  170   train_loss:  525.3308204988854
                                   e:  170   val_loss:  613.8601625938819
e:  171   train_loss:  534.0946035544121
                                   e:  171   val_loss:  567.4919412449899
e:  172   train_loss:  529.4643276548471
                                   e:  172   val_loss:  604.2457804724529
e:  173   train_loss:  530.876987244125
                                   e:  173   val_loss:  566.8359743893354
e:  174   train_loss:  524.9243398330397
                                   e:  174   val_loss:  559.0422222963982
e:  175   train_loss:  518.8430292209388
                                   e:  175   val_loss:  563.9934209183499
e:  176   train_loss:  530.4511086052701
                                   e:  176   val_loss:  554.213287399713
e:  177   train_loss:  526.2948099729806
                                   e:  177   val_loss:  552.8385218852493
e:  178   train_loss:  516.473761787133
                                   e:  178   val_loss:  554.5642696217185
e:  179   train_loss:  526.5091314657916
                                   e:  179   val_loss:  582.0216220678866
e:  180   train_loss:  520.2938739127907
                                   e:  180   val_loss:  548.2270430632421
e:  181   train_loss:  521.4412654057161
                                   e:  181   val_loss:  553.087615324117
e:  182   train_loss:  513.5474090802642
                                   e:  182   val_loss:  548.1986396971458
e:  183   train_loss:  522.8840266127783
                                   e:  183   val_loss:  545.7060317976297
e:  184   train_loss:  510.6682046706532
                                   e:  184   val_loss:  547.3157478087194
e:  185   train_loss:  507.25950393997516
                                   e:  185   val_loss:  588.5046191745066
e:  186   train_loss:  524.0557003321575
                                   e:  186   val_loss:  563.4753466934661
e:  187   train_loss:  516.8481709815485
                                   e:  187   val_loss:  591.6547884851252
e:  188   train_loss:  511.5322475011753
                                   e:  188   val_loss:  578.1838096303984
e:  189   train_loss:  504.4022979665773
                                   e:  189   val_loss:  543.5340247614572
e:  190   train_loss:  515.5183633732656
                                   e:  190   val_loss:  533.6199886368835
e:  191   train_loss:  509.453743149008
                                   e:  191   val_loss:  538.6717450232798
e:  192   train_loss:  510.59485427625367
                                   e:  192   val_loss:  531.434330011387
e:  193   train_loss:  499.170423338468
                                   e:  193   val_loss:  530.278090163503
e:  194   train_loss:  509.0212491842163
                                   e:  194   val_loss:  543.9483295977736
e:  195   train_loss:  498.3056709104801
                                   e:  195   val_loss:  527.3643133713639
e:  196   train_loss:  494.36480709319693
                                   e:  196   val_loss:  529.4652349775287
e:  197   train_loss:  496.3898200737548
                                   e:  197   val_loss:  520.5405444772879
e:  198   train_loss:  499.0419350686197
                                   e:  198   val_loss:  525.1120938915335
e:  199   train_loss:  489.5028174382826
                                   e:  199   val_loss:  518.8025054130534
e:  200   train_loss:  482.26819049449705
                                   e:  200   val_loss:  517.7346550881355
e:  201   train_loss:  491.8326434227188
                                   e:  201   val_loss:  515.014500179819
e:  202   train_loss:  483.9878466822526
                                   e:  202   val_loss:  519.6750253909934
e:  203   train_loss:  490.4925596524184
                                   e:  203   val_loss:  541.816102328821
e:  204   train_loss:  489.44156861087066
                                   e:  204   val_loss:  509.3621641162414
e:  205   train_loss:  476.213014471093
                                   e:  205   val_loss:  560.2531935866796
e:  206   train_loss:  480.7543874322496
                                   e:  206   val_loss:  550.2231691628588
e:  207   train_loss:  486.18853217180026
                                   e:  207   val_loss:  510.32065038507244
e:  208   train_loss:  478.0156103375778
                                   e:  208   val_loss:  546.693950430175
e:  209   train_loss:  491.8409034790202
                                   e:  209   val_loss:  522.4652629353553
e:  210   train_loss:  471.71810104097915
                                   e:  210   val_loss:  498.277000196842
e:  211   train_loss:  481.4027755106709
                                   e:  211   val_loss:  501.0012275210041
e:  212   train_loss:  468.4853257292575
                                   e:  212   val_loss:  509.11255465171143
e:  213   train_loss:  477.35745800252533
                                   e:  213   val_loss:  520.1981140518076
e:  214   train_loss:  472.347960407041
                                   e:  214   val_loss:  512.6972276486538
e:  215   train_loss:  471.6187705600307
                                   e:  215   val_loss:  496.6244697624976
e:  216   train_loss:  473.37018885836164
                                   e:  216   val_loss:  522.5838201077022
e:  217   train_loss:  471.1156150875151
                                   e:  217   val_loss:  535.9335833763902
e:  218   train_loss:  474.66929468451514
                                   e:  218   val_loss:  490.7024109126963
e:  219   train_loss:  466.31988204597985
                                   e:  219   val_loss:  485.8579268785347
e:  220   train_loss:  462.0710585367402
                                   e:  220   val_loss:  482.4598071980161
e:  221   train_loss:  459.9034833782259
                                   e:  221   val_loss:  511.8876484825987
e:  222   train_loss:  446.27526419931746
                                   e:  222   val_loss:  528.9944221976123
e:  223   train_loss:  480.0942992356962
                                   e:  223   val_loss:  477.41892248931
e:  224   train_loss:  466.83301035419464
                                   e:  224   val_loss:  474.6035819489378
e:  225   train_loss:  455.8874956698445
                                   e:  225   val_loss:  500.6278051200492
e:  226   train_loss:  458.2868674503028
                                   e:  226   val_loss:  494.4551946855493
e:  227   train_loss:  454.90281814696436
                                   e:  227   val_loss:  518.6343121646485
e:  228   train_loss:  451.79339806151853
                                   e:  228   val_loss:  503.4705003937519
e:  229   train_loss:  461.8300675985514
                                   e:  229   val_loss:  506.1994810901192
e:  230   train_loss:  444.61155140634986
                                   e:  230   val_loss:  466.37543144420687
e:  231   train_loss:  438.9844183091858
                                   e:  231   val_loss:  500.5131030519503
e:  232   train_loss:  451.26294629889844
                                   e:  232   val_loss:  520.2878170287906
e:  233   train_loss:  448.55309912406085
                                   e:  233   val_loss:  467.32312190062896
e:  234   train_loss:  453.11634649830364
                                   e:  234   val_loss:  461.27930696260154
e:  235   train_loss:  447.77691483161055
                                   e:  235   val_loss:  466.5786143313966
e:  236   train_loss:  431.5603697757993
                                   e:  236   val_loss:  491.3041922231384
e:  237   train_loss:  427.3863219001943
                                   e:  237   val_loss:  579.8707542373704
e:  238   train_loss:  452.13525340420733
                                   e:  238   val_loss:  467.80576219523226
e:  239   train_loss:  436.3652279722433
                                   e:  239   val_loss:  469.1595053407738
e:  240   train_loss:  431.85718835532043
                                   e:  240   val_loss:  446.4152007099883
e:  241   train_loss:  440.1126446279512
                                   e:  241   val_loss:  450.10860744272003
e:  242   train_loss:  440.3552794567818
                                   e:  242   val_loss:  453.26487105527457
e:  243   train_loss:  431.4243734384297
                                   e:  243   val_loss:  458.96076136548197
e:  244   train_loss:  439.26768009103375
                                   e:  244   val_loss:  467.1435496444166
e:  245   train_loss:  424.36057799502885
                                   e:  245   val_loss:  439.3378381386863
e:  246   train_loss:  430.6577499671753
                                   e:  246   val_loss:  479.98257449057985
e:  247   train_loss:  429.0237577893181
                                   e:  247   val_loss:  436.9146233979342
e:  248   train_loss:  436.15345418474
                                   e:  248   val_loss:  442.55725559142354
e:  249   train_loss:  418.1281502425969
                                   e:  249   val_loss:  448.63229166876073
e:  250   train_loss:  422.1885124185208
                                   e:  250   val_loss:  469.0192925504086
e:  251   train_loss:  425.88327257559627
                                   e:  251   val_loss:  453.7874327881148
e:  252   train_loss:  413.0815940544324
                                   e:  252   val_loss:  437.046683726912
e:  253   train_loss:  425.80014144887997
                                   e:  253   val_loss:  432.920893991973
e:  254   train_loss:  413.54974605074995
                                   e:  254   val_loss:  437.2975992976893
e:  255   train_loss:  415.8062140333865
                                   e:  255   val_loss:  439.4689362620558
e:  256   train_loss:  419.74790146528045
                                   e:  256   val_loss:  424.93723033477715
e:  257   train_loss:  418.02235777733137
                                   e:  257   val_loss:  519.4482960434153
e:  258   train_loss:  415.45280379461445
                                   e:  258   val_loss:  447.8213431213313
e:  259   train_loss:  404.9622197155582
                                   e:  259   val_loss:  455.82925695915236
e:  260   train_loss:  405.30601445806576
                                   e:  260   val_loss:  415.53732475588987
e:  261   train_loss:  412.2986995032252
                                   e:  261   val_loss:  435.81282258453587
e:  262   train_loss:  400.81356458121786
                                   e:  262   val_loss:  412.602963706036
e:  263   train_loss:  404.28982711721955
                                   e:  263   val_loss:  413.92064357198507
e:  264   train_loss:  406.1082365522203
                                   e:  264   val_loss:  462.355716419696
e:  265   train_loss:  398.0568354284211
                                   e:  265   val_loss:  432.376116540628
e:  266   train_loss:  414.57547303871297
                                   e:  266   val_loss:  413.7856834945431
e:  267   train_loss:  407.8044691482853
                                   e:  267   val_loss:  422.3763101589595
e:  268   train_loss:  395.56415795568745
                                   e:  268   val_loss:  433.88300099061155
e:  269   train_loss:  402.0359686286232
                                   e:  269   val_loss:  431.99029459136165
e:  270   train_loss:  400.5679805120762
                                   e:  270   val_loss:  443.8286597865541
e:  271   train_loss:  399.96292962505174
                                   e:  271   val_loss:  405.2271621144485
e:  272   train_loss:  372.280507547752
                                   e:  272   val_loss:  472.8395421844467
e:  273   train_loss:  413.181395700834
                                   e:  273   val_loss:  412.05633835055306
e:  274   train_loss:  383.3604410189477
                                   e:  274   val_loss:  408.50172645285267
e:  275   train_loss:  394.29582019497354
                                   e:  275   val_loss:  495.1733768965081
e:  276   train_loss:  397.51468915282686
                                   e:  276   val_loss:  401.8440555687807
e:  277   train_loss:  378.51787922222724
                                   e:  277   val_loss:  423.82502370893445
e:  278   train_loss:  389.3295688541429
                                   e:  278   val_loss:  414.893597083679
e:  279   train_loss:  387.0790636600107
                                   e:  279   val_loss:  441.43085515438435
e:  280   train_loss:  380.04714023117765
                                   e:  280   val_loss:  390.9983842116301
e:  281   train_loss:  384.06588957685034
                                   e:  281   val_loss:  421.287181187343
e:  282   train_loss:  379.56933461224605
                                   e:  282   val_loss:  395.340212968641
e:  283   train_loss:  388.00514422070046
                                   e:  283   val_loss:  428.2111825509417
e:  284   train_loss:  375.19598432532143
                                   e:  284   val_loss:  438.23473365895677
e:  285   train_loss:  389.45339340630534
                                   e:  285   val_loss:  399.8501619675045
e:  286   train_loss:  372.7404868978494
                                   e:  286   val_loss:  514.6167390078832
e:  287   train_loss:  389.87283914687464
                                   e:  287   val_loss:  385.1083067078176
e:  288   train_loss:  372.33973222063713
                                   e:  288   val_loss:  444.9416239744949
e:  289   train_loss:  382.20459673632433
                                   e:  289   val_loss:  443.02990979618653
e:  290   train_loss:  378.9192499892337
                                   e:  290   val_loss:  377.25976053988677
e:  291   train_loss:  356.09692377294874
                                   e:  291   val_loss:  438.77418498819577
e:  292   train_loss:  382.87270153667936
                                   e:  292   val_loss:  398.52055496506756
e:  293   train_loss:  360.3918190207377
                                   e:  293   val_loss:  462.88334726986324
e:  294   train_loss:  385.0981689909352
                                   e:  294   val_loss:  380.4699314657506
e:  295   train_loss:  366.6595727577292
                                   e:  295   val_loss:  370.4326114508973
e:  296   train_loss:  363.76792822581365
                                   e:  296   val_loss:  431.2012394945159
e:  297   train_loss:  376.93457712848596
                                   e:  297   val_loss:  400.0268886049798
e:  298   train_loss:  364.4144847457173
                                   e:  298   val_loss:  397.1688152718042
e:  299   train_loss:  373.3709833730261
                                   e:  299   val_loss:  413.99956111660333
e:  300   train_loss:  364.0768806375713
                                   e:  300   val_loss:  374.2451776206068
e:  301   train_loss:  350.5109542254185
                                   e:  301   val_loss:  381.4046099027709
e:  302   train_loss:  366.8556057129969
                                   e:  302   val_loss:  404.3773024883329
e:  303   train_loss:  349.92388707040703
                                   e:  303   val_loss:  429.67345240651105
e:  304   train_loss:  373.5212246119949
                                   e:  304   val_loss:  378.5998775337069
e:  305   train_loss:  371.8170712186942
                                   e:  305   val_loss:  371.1567334998778
e:  306   train_loss:  360.05563664140993
                                   e:  306   val_loss:  383.03409180807756
e:  307   train_loss:  356.18399923385226
                                   e:  307   val_loss:  380.4382239369943
e:  308   train_loss:  367.42521280865026
                                   e:  308   val_loss:  386.0205786200043
e:  309   train_loss:  357.91340941046985
                                   e:  309   val_loss:  420.54973354955825
e:  310   train_loss:  358.78115844749203
                                   e:  310   val_loss:  375.94898872822944
e:  311   train_loss:  355.7805945157046
                                   e:  311   val_loss:  379.97022553233484
e:  312   train_loss:  352.9487136191609
                                   e:  312   val_loss:  386.433731759695
e:  313   train_loss:  345.7060092442332
                                   e:  313   val_loss:  355.9593172398375
e:  314   train_loss:  356.81107398591257
                                   e:  314   val_loss:  352.5858422566967
e:  315   train_loss:  346.99279795531413
                                   e:  315   val_loss:  375.4721126896464
e:  316   train_loss:  363.9316985627129
                                   e:  316   val_loss:  364.3940061370284
e:  317   train_loss:  348.48592080378575
                                   e:  317   val_loss:  354.54883231161983
e:  318   train_loss:  348.0864645913186
                                   e:  318   val_loss:  392.4220885323101
e:  319   train_loss:  351.2723566297112
                                   e:  319   val_loss:  375.0542105692036
e:  320   train_loss:  351.74179954104335
                                   e:  320   val_loss:  493.21305252464737
e:  321   train_loss:  353.9488945125012
                                   e:  321   val_loss:  537.8596373038421
e:  322   train_loss:  354.6590187308634
                                   e:  322   val_loss:  357.1844162788458
e:  323   train_loss:  341.4117482900891
                                   e:  323   val_loss:  364.70786859031017
e:  324   train_loss:  345.54493767393757
                                   e:  324   val_loss:  376.91712510778143
e:  325   train_loss:  350.64321827181567
                                   e:  325   val_loss:  349.29929290052644
e:  326   train_loss:  335.21139106179476
                                   e:  326   val_loss:  344.20724952327885
e:  327   train_loss:  346.84286289516507
                                   e:  327   val_loss:  358.38740484914945
e:  328   train_loss:  338.3915083417994
                                   e:  328   val_loss:  354.7890525666029
e:  329   train_loss:  344.10305387406
                                   e:  329   val_loss:  390.19005235693146
e:  330   train_loss:  345.73683464340763
                                   e:  330   val_loss:  343.4239742781091
e:  331   train_loss:  337.90733597780775
                                   e:  331   val_loss:  373.04641232614307
e:  332   train_loss:  339.90649057906313
                                   e:  332   val_loss:  418.69741705387605
e:  333   train_loss:  348.78007335542446
                                   e:  333   val_loss:  383.96628606616423
e:  334   train_loss:  351.7071458502305
                                   e:  334   val_loss:  342.69352105169094
e:  335   train_loss:  339.15167297385904
                                   e:  335   val_loss:  359.99895113906166
e:  336   train_loss:  334.98076178898464
                                   e:  336   val_loss:  397.60459747690373
e:  337   train_loss:  333.691111177437
                                   e:  337   val_loss:  391.43249142997814
e:  338   train_loss:  337.4336088667184
                                   e:  338   val_loss:  375.61532084279213
e:  339   train_loss:  334.5704362371543
                                   e:  339   val_loss:  346.31241766442133
e:  340   train_loss:  340.35989854834844
                                   e:  340   val_loss:  363.63333027090823
e:  341   train_loss:  336.60832863120726
                                   e:  341   val_loss:  384.24363173712675
e:  342   train_loss:  332.5514264135168
                                   e:  342   val_loss:  365.62450768238796
e:  343   train_loss:  332.78150282398474
                                   e:  343   val_loss:  373.0454244278236
e:  344   train_loss:  338.77024506015033
                                   e:  344   val_loss:  358.474840201324
e:  345   train_loss:  316.5716970975826
                                   e:  345   val_loss:  335.67753343450795
e:  346   train_loss:  337.52579994688983
                                   e:  346   val_loss:  336.26815928920723
e:  347   train_loss:  321.0955679610877
                                   e:  347   val_loss:  384.97486306458745
e:  348   train_loss:  328.6261213257857
                                   e:  348   val_loss:  356.52641046795134
e:  349   train_loss:  329.9616874919917
                                   e:  349   val_loss:  329.70210106240086
e:  350   train_loss:  319.7747424710677
                                   e:  350   val_loss:  347.3676028260576
e:  351   train_loss:  328.54588031955996
                                   e:  351   val_loss:  391.8380243358911
e:  352   train_loss:  315.5519004639087
                                   e:  352   val_loss:  340.1386885822934
e:  353   train_loss:  336.9426327196765
                                   e:  353   val_loss:  348.592268297794
e:  354   train_loss:  331.79120021672776
                                   e:  354   val_loss:  336.4632113064182
e:  355   train_loss:  318.13157610379085
                                   e:  355   val_loss:  345.87714494460954
e:  356   train_loss:  323.22958661218536
                                   e:  356   val_loss:  345.7138618122027
e:  357   train_loss:  327.7061306543569
                                   e:  357   val_loss:  364.46982581356133
e:  358   train_loss:  316.1499591113647
                                   e:  358   val_loss:  325.5750782093888
e:  359   train_loss:  326.89685154983107
                                   e:  359   val_loss:  323.47528532118446
e:  360   train_loss:  309.9823111111218
                                   e:  360   val_loss:  342.25214729308806
e:  361   train_loss:  323.9782868275707
                                   e:  361   val_loss:  365.2754411371533
e:  362   train_loss:  317.56919791572636
                                   e:  362   val_loss:  351.7337133315159
e:  363   train_loss:  324.4678837885117
                                   e:  363   val_loss:  342.8316980021104
e:  364   train_loss:  309.60464417814137
                                   e:  364   val_loss:  354.3259439199969
e:  365   train_loss:  324.2354141831588
                                   e:  365   val_loss:  350.62229969082784
e:  366   train_loss:  323.6166254679133
                                   e:  366   val_loss:  363.0806976223058
e:  367   train_loss:  324.2981374331304
                                   e:  367   val_loss:  331.71012166623007
e:  368   train_loss:  312.5419441724136
                                   e:  368   val_loss:  334.5471988169582
e:  369   train_loss:  316.9024633944951
                                   e:  369   val_loss:  350.258902810992
e:  370   train_loss:  306.156289618239
                                   e:  370   val_loss:  319.9389961967055
e:  371   train_loss:  308.04586181225704
                                   e:  371   val_loss:  325.2794601143144
e:  372   train_loss:  319.3487430804791
                                   e:  372   val_loss:  402.46931555654635
e:  373   train_loss:  316.06067072786857
                                   e:  373   val_loss:  338.34462664370653
e:  374   train_loss:  320.0990307433624
                                   e:  374   val_loss:  336.3940568441073
e:  375   train_loss:  315.48878237791797
                                   e:  375   val_loss:  347.3911177166326
e:  376   train_loss:  311.1301825973571
                                   e:  376   val_loss:  348.0812090966924
e:  377   train_loss:  315.58189763731485
                                   e:  377   val_loss:  379.4255439832315
e:  378   train_loss:  318.08128206945605
                                   e:  378   val_loss:  324.8468108509601
e:  379   train_loss:  311.1025512986365
                                   e:  379   val_loss:  321.0147651875517
e:  380   train_loss:  305.3238405234383
                                   e:  380   val_loss:  355.76410713111244
e:  381   train_loss:  324.5042137247941
                                   e:  381   val_loss:  327.39960061321415
e:  382   train_loss:  290.3802535189135
                                   e:  382   val_loss:  318.996681375154
e:  383   train_loss:  313.9008915131256
                                   e:  383   val_loss:  351.38328122203376
e:  384   train_loss:  315.36846162051637
                                   e:  384   val_loss:  323.8257521469699
e:  385   train_loss:  311.51086546588294
                                   e:  385   val_loss:  416.7250367943931
e:  386   train_loss:  317.5295295070505
                                   e:  386   val_loss:  328.1451922951402
e:  387   train_loss:  305.15272144736855
                                   e:  387   val_loss:  323.70046961320867
e:  388   train_loss:  297.9378583775339
                                   e:  388   val_loss:  315.9317315176153
e:  389   train_loss:  293.02897980725675
                                   e:  389   val_loss:  311.31699754939626
e:  390   train_loss:  298.67477066478466
                                   e:  390   val_loss:  349.75204625899903
e:  391   train_loss:  311.7387948614808
                                   e:  391   val_loss:  326.1132341922721
e:  392   train_loss:  298.42945808414015
                                   e:  392   val_loss:  311.9377403998638
e:  393   train_loss:  307.57616707563903
                                   e:  393   val_loss:  326.475944508678
e:  394   train_loss:  295.9019962999117
                                   e:  394   val_loss:  325.26439649732185
e:  395   train_loss:  308.95330707673594
                                   e:  395   val_loss:  311.54514219169374
e:  396   train_loss:  305.86894194874566
                                   e:  396   val_loss:  329.78692516081816
e:  397   train_loss:  293.8991597952516
                                   e:  397   val_loss:  379.7377102810831
e:  398   train_loss:  305.45458819571485
                                   e:  398   val_loss:  317.2199052727526
e:  399   train_loss:  302.8341985463862
                                   e:  399   val_loss:  326.8719316702024
e:  400   train_loss:  312.5874656479073
                                   e:  400   val_loss:  317.4610804419396
e:  401   train_loss:  298.19389256928093
                                   e:  401   val_loss:  326.15006778128037
e:  402   train_loss:  307.67666398229875
                                   e:  402   val_loss:  361.84466318439485
e:  403   train_loss:  294.9027976218243
                                   e:  403   val_loss:  448.3026320909672
e:  404   train_loss:  308.25853126566335
                                   e:  404   val_loss:  315.99978224248747
e:  405   train_loss:  294.5840105690124
                                   e:  405   val_loss:  336.4675680200549
e:  406   train_loss:  304.6911380434608
                                   e:  406   val_loss:  308.0111872851618
e:  407   train_loss:  296.0836656567656
                                   e:  407   val_loss:  304.17905649644683
e:  408   train_loss:  286.36641372326096
                                   e:  408   val_loss:  316.4957982409027
e:  409   train_loss:  296.13383830640356
                                   e:  409   val_loss:  320.7762710381059
e:  410   train_loss:  286.1492867175615
                                   e:  410   val_loss:  309.73616094624293
e:  411   train_loss:  301.18564924663514
                                   e:  411   val_loss:  339.39311335487315
e:  412   train_loss:  297.0790114189012
                                   e:  412   val_loss:  343.1464654487072
e:  413   train_loss:  304.36507593377314
                                   e:  413   val_loss:  308.0412533486856
e:  414   train_loss:  295.5141011392099
                                   e:  414   val_loss:  303.02555678254873
e:  415   train_loss:  289.3366032668889
                                   e:  415   val_loss:  336.70111688199154
e:  416   train_loss:  291.83536168285696
                                   e:  416   val_loss:  391.01157396441306
e:  417   train_loss:  301.30068838000875
                                   e:  417   val_loss:  320.68972456782694
e:  418   train_loss:  298.83841081885964
                                   e:  418   val_loss:  383.8891130224983
e:  419   train_loss:  282.90055012389945
                                   e:  419   val_loss:  342.91592967585154
e:  420   train_loss:  301.9493132976105
                                   e:  420   val_loss:  345.2251895955232
e:  421   train_loss:  295.19541577990407
                                   e:  421   val_loss:  320.81948189289653
Traceback (most recent call last):
  File "/home/grads/tasnina/Projects/SynVerse/code/main.py", line 213, in <module>
    main(config_map, **kwargs)
  File "/home/grads/tasnina/Projects/SynVerse/code/main.py", line 208, in main
    run_SynVerse(inputs, params, **kwargs)
  File "/home/grads/tasnina/Projects/SynVerse/code/main.py", line 161, in run_SynVerse
    trained_model_state, train_loss = runner.train_model_given_config(hyperparam, best_n_epochs,
  File "/home/grads/tasnina/Projects/SynVerse/code/models/runner.py", line 200, in train_model_given_config
    best_model_state, val_loss[fold], train_loss[fold], req_epochs[fold] = self.train_model(model, optimizer,
  File "/home/grads/tasnina/Projects/SynVerse/code/models/runner.py", line 230, in train_model
    for inputs, targets in train_loader:
  File "/home/grads/tasnina/miniconda3/envs/synverse/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/home/grads/tasnina/miniconda3/envs/synverse/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/grads/tasnina/miniconda3/envs/synverse/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/grads/tasnina/miniconda3/envs/synverse/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/grads/tasnina/miniconda3/envs/synverse/lib/python3.9/site-packages/torch/utils/data/dataset.py", line 298, in __getitem__
    return self.dataset[self.indices[idx]]
  File "/home/grads/tasnina/miniconda3/envs/synverse/lib/python3.9/site-packages/torch/utils/data/dataset.py", line 196, in __getitem__
    return tuple(tensor[index] for tensor in self.tensors)
KeyboardInterrupt
